{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_HOME'] = '/usr/local/cuda-7.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten, Lambda, Convolution2D, AveragePooling2D, BatchNormalization\n",
    "from keras.engine import merge, Input, Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# reorder dimensions for tensorflow\n",
    "x_train = np.transpose(x_train.astype('float32'), (0, 2, 3, 1))\n",
    "mean = np.mean(x_train, axis=0, keepdims=True)\n",
    "std = np.std(x_train)\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = np.transpose(x_test.astype('float32'), (0, 2, 3, 1))\n",
    "x_test = (x_test - mean) / std\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stochastic depth residual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_p_survival(block=0, nb_total_blocks=110, p_survival_end=0.5, mode='linear_decay'):\n",
    "    \"\"\"\n",
    "    See eq. (4) in stochastic depth paper: http://arxiv.org/pdf/1603.09382v1.pdf\n",
    "    \"\"\"\n",
    "    if mode == 'uniform':\n",
    "        return p_survival_end\n",
    "    elif mode == 'linear_decay':\n",
    "        return 1 - ((block + 1) / nb_total_blocks) * (1 - p_survival_end)\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "            \n",
    "def zero_pad_channels(x, pad=0):\n",
    "    \"\"\"\n",
    "    Function for Lambda layer\n",
    "    \"\"\"\n",
    "    pattern = [[0, 0], [0, 0], [0, 0], [pad - pad // 2, pad // 2]]\n",
    "    return tf.pad(x, pattern)\n",
    "\n",
    "\n",
    "def stochastic_survival(y, p_survival=1.0):\n",
    "    # binomial random variable\n",
    "    survival = K.random_binomial((1,), p=p_survival)\n",
    "    # during testing phase:\n",
    "    # - scale y (see eq. (6))\n",
    "    # - p_survival effectively becomes 1 for all layers (no layer dropout)\n",
    "    return K.in_test_phase(tf.constant(p_survival, dtype='float32') * y, \n",
    "                           survival * y)\n",
    "\n",
    "\n",
    "def stochastic_depth_residual_block(x, nb_filters=16, block=0, nb_total_blocks=110, subsample_factor=1):\n",
    "    \"\"\"\n",
    "    Stochastic depth paper: http://arxiv.org/pdf/1603.09382v1.pdf\n",
    "    \n",
    "    Residual block consisting of:\n",
    "    - Conv - BN - ReLU - Conv - BN\n",
    "    - identity shortcut connection\n",
    "    - merge Conv path with shortcut path\n",
    "\n",
    "    Original paper (http://arxiv.org/pdf/1512.03385v1.pdf) then has ReLU,\n",
    "    but we leave this out: see https://github.com/gcr/torch-residual-networks\n",
    "\n",
    "    Additional variants explored in http://arxiv.org/pdf/1603.05027v1.pdf\n",
    "    \n",
    "    some code adapted from https://github.com/dblN/stochastic_depth_keras\n",
    "    \"\"\"\n",
    "    \n",
    "    prev_nb_channels = K.int_shape(x)[3]\n",
    "\n",
    "    if subsample_factor > 1:\n",
    "        subsample = (subsample_factor, subsample_factor)\n",
    "        # shortcut: subsample + zero-pad channel dim\n",
    "        shortcut = AveragePooling2D(pool_size=subsample, dim_ordering='tf')(x)\n",
    "        if nb_filters > prev_nb_channels:\n",
    "            shortcut = Lambda(zero_pad_channels,\n",
    "                              arguments={'pad': nb_filters - prev_nb_channels})(shortcut)\n",
    "    else:\n",
    "        subsample = (1, 1)\n",
    "        # shortcut: identity\n",
    "        shortcut = x\n",
    "\n",
    "    y = Convolution2D(nb_filters, 3, 3, subsample=subsample,\n",
    "                      init='he_normal', border_mode='same', dim_ordering='tf')(x)\n",
    "    y = BatchNormalization(axis=3)(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Convolution2D(nb_filters, 3, 3, subsample=(1, 1),\n",
    "                      init='he_normal', border_mode='same', dim_ordering='tf')(y)\n",
    "    y = BatchNormalization(axis=3)(y)\n",
    "    \n",
    "    p_survival = get_p_survival(block=block, nb_total_blocks=nb_total_blocks, p_survival_end=0.5, mode='linear_decay')\n",
    "    y = Lambda(stochastic_survival, arguments={'p_survival': p_survival})(y)\n",
    "    \n",
    "    out = merge([y, shortcut], mode='sum')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 s, sys: 82.7 ms, total: 2.72 s\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "img_channels = 3\n",
    "\n",
    "blocks_per_group = 3\n",
    "\n",
    "inputs = Input(shape=(img_rows, img_cols, img_channels))\n",
    "\n",
    "x = Convolution2D(16, 3, 3, \n",
    "                  init='he_normal', border_mode='same', dim_ordering='tf')(inputs)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "for i in range(0, blocks_per_group):\n",
    "    nb_filters = 16\n",
    "    x = stochastic_depth_residual_block(x, nb_filters=nb_filters, \n",
    "                                        block=i, nb_total_blocks=3 * blocks_per_group, \n",
    "                                        subsample_factor=1)\n",
    "\n",
    "for i in range(0, blocks_per_group):\n",
    "    nb_filters = 32\n",
    "    if i == 0:\n",
    "        subsample_factor = 2\n",
    "    else:\n",
    "        subsample_factor = 1\n",
    "    x = stochastic_depth_residual_block(x, nb_filters=nb_filters, \n",
    "                                        block=blocks_per_group + i, nb_total_blocks=3 * blocks_per_group, \n",
    "                                        subsample_factor=subsample_factor)\n",
    "\n",
    "for i in range(0, blocks_per_group):\n",
    "    nb_filters = 64\n",
    "    if i == 0:\n",
    "        subsample_factor = 2\n",
    "    else:\n",
    "        subsample_factor = 1\n",
    "    x = stochastic_depth_residual_block(x, nb_filters=nb_filters, \n",
    "                                        block=2 * blocks_per_group + i, nb_total_blocks=3 * blocks_per_group, \n",
    "                                        subsample_factor=subsample_factor)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(8, 8), strides=None, border_mode='valid', dim_ordering='tf')(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)               (None, 32, 32, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 32, 32, 16)  448         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormaliz(None, 32, 32, 16)  32          convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 32, 32, 16)  0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)    (None, 32, 32, 16)  2320        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNormaliz(None, 32, 32, 16)  32          convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 32, 32, 16)  0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)    (None, 32, 32, 16)  2320        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNormaliz(None, 32, 32, 16)  32          convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                  (None, 32, 32, 16)  0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                    (None, 32, 32, 16)  0           lambda_1[0][0]                   \n",
      "                                                                   activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)    (None, 32, 32, 16)  2320        merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNormaliz(None, 32, 32, 16)  32          convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 32, 32, 16)  0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)    (None, 32, 32, 16)  2320        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNormaliz(None, 32, 32, 16)  32          convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                  (None, 32, 32, 16)  0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                    (None, 32, 32, 16)  0           lambda_2[0][0]                   \n",
      "                                                                   merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)    (None, 32, 32, 16)  2320        merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNormaliz(None, 32, 32, 16)  32          convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)          (None, 32, 32, 16)  0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)    (None, 32, 32, 16)  2320        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNormaliz(None, 32, 32, 16)  32          convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                  (None, 32, 32, 16)  0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                    (None, 32, 32, 16)  0           lambda_3[0][0]                   \n",
      "                                                                   merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)    (None, 16, 16, 32)  4640        merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNormaliz(None, 16, 16, 32)  64          convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)          (None, 16, 16, 32)  0           batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D)   (None, 16, 16, 32)  9248        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_1 (AveragePooling2(None, 16, 16, 16)  0           merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNormali(None, 16, 16, 32)  64          convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                  (None, 16, 16, 32)  0           averagepooling2d_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                  (None, 16, 16, 32)  0           batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                    (None, 16, 16, 32)  0           lambda_5[0][0]                   \n",
      "                                                                   lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D)   (None, 16, 16, 32)  9248        merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNormali(None, 16, 16, 32)  64          convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)          (None, 16, 16, 32)  0           batchnormalization_11[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D)   (None, 16, 16, 32)  9248        activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNormali(None, 16, 16, 32)  64          convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                  (None, 16, 16, 32)  0           batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                    (None, 16, 16, 32)  0           lambda_6[0][0]                   \n",
      "                                                                   merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D)   (None, 16, 16, 32)  9248        merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_13 (BatchNormali(None, 16, 16, 32)  64          convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)          (None, 16, 16, 32)  0           batchnormalization_13[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D)   (None, 16, 16, 32)  9248        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNormali(None, 16, 16, 32)  64          convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)                  (None, 16, 16, 32)  0           batchnormalization_14[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                    (None, 16, 16, 32)  0           lambda_7[0][0]                   \n",
      "                                                                   merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D)   (None, 8, 8, 64)    18496       merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNormali(None, 8, 8, 64)    128         convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)          (None, 8, 8, 64)    0           batchnormalization_15[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D)   (None, 8, 8, 64)    36928       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_2 (AveragePooling2(None, 8, 8, 32)    0           merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNormali(None, 8, 8, 64)    128         convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                  (None, 8, 8, 64)    0           averagepooling2d_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                  (None, 8, 8, 64)    0           batchnormalization_16[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                    (None, 8, 8, 64)    0           lambda_9[0][0]                   \n",
      "                                                                   lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D)   (None, 8, 8, 64)    36928       merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNormali(None, 8, 8, 64)    128         convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)         (None, 8, 8, 64)    0           batchnormalization_17[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D)   (None, 8, 8, 64)    36928       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNormali(None, 8, 8, 64)    128         convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)                 (None, 8, 8, 64)    0           batchnormalization_18[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                    (None, 8, 8, 64)    0           lambda_10[0][0]                  \n",
      "                                                                   merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D)   (None, 8, 8, 64)    36928       merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNormali(None, 8, 8, 64)    128         convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)         (None, 8, 8, 64)    0           batchnormalization_19[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D)   (None, 8, 8, 64)    36928       activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNormali(None, 8, 8, 64)    128         convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)                 (None, 8, 8, 64)    0           batchnormalization_20[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                    (None, 8, 8, 64)    0           lambda_11[0][0]                  \n",
      "                                                                   merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_3 (AveragePooling2(None, 1, 1, 64)    0           merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 64)          0           averagepooling2d_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 10)          650         flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 270410\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 955 ms, sys: 48.4 ms, total: 1 s\n",
      "Wall time: 955 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_epoch = 200\n",
    "data_augmentation = True\n",
    "\n",
    "# Learning rate schedule\n",
    "def lr_sch(epoch):\n",
    "    if epoch < nb_epoch * 0.5:\n",
    "        return 0.1\n",
    "    elif epoch < nb_epoch * 0.75:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "# Learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_sch)\n",
    "\n",
    "# Model saving callback\n",
    "#checkpointer = ModelCheckpoint(filepath='stochastic_depth_cifar10.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        batch_size=batch_size, nb_epoch=nb_epoch, verbose=1,\n",
    "                        validation_data=(x_test, y_test), shuffle=True,\n",
    "                        callbacks=[lr_scheduler])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "\n",
    "    # realtime data augmentation\n",
    "    datagen_train = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.125,\n",
    "        height_shift_range=0.125,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False)\n",
    "    datagen_train.fit(x_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=True),\n",
    "                                  samples_per_epoch=x_train.shape[0], \n",
    "                                  nb_epoch=nb_epoch, verbose=1,\n",
    "                                  validation_data=(x_test, y_test),\n",
    "                                  callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
