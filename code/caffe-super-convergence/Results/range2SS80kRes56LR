I0818 13:44:36.670388 22726 caffe.cpp:217] Using GPUs 0, 1, 2, 3, 4, 5, 6, 7
I0818 13:44:36.672737 22726 caffe.cpp:222] GPU 0: GeForce GTX TITAN Black
I0818 13:44:36.673976 22726 caffe.cpp:222] GPU 1: GeForce GTX TITAN Black
I0818 13:44:36.675190 22726 caffe.cpp:222] GPU 2: GeForce GTX TITAN Black
I0818 13:44:36.676404 22726 caffe.cpp:222] GPU 3: GeForce GTX TITAN Black
I0818 13:44:36.677634 22726 caffe.cpp:222] GPU 4: GeForce GTX TITAN Black
I0818 13:44:36.678869 22726 caffe.cpp:222] GPU 5: GeForce GTX TITAN Black
I0818 13:44:36.680096 22726 caffe.cpp:222] GPU 6: GeForce GTX TITAN Black
I0818 13:44:36.681329 22726 caffe.cpp:222] GPU 7: GeForce GTX TITAN Black
I0818 13:44:37.100294 22726 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 100
base_lr: 0
display: 100
max_iter: 80000
lr_policy: "triangular"
momentum: 0.9
weight_decay: 0.0001
stepsize: 80000
snapshot: 100000
snapshot_prefix: "examples/sc/snapshots/range2SS80kRes56LR"
solver_mode: GPU
device_id: 0
net: "examples/sc/architectures/arch.prototxt"
train_state {
  level: 0
  stage: ""
}
max_lr: 2
I0818 13:44:37.103940 22726 solver.cpp:91] Creating training net from net file: examples/sc/architectures/arch.prototxt
I0818 13:44:37.115777 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:37.115855 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:37.116821 22726 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer dataLayer
I0818 13:44:37.118732 22726 net.cpp:58] Initializing net from parameters: 
name: "Cifar-Resnet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "dataLayer"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 125
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv"
  type: "Convolution"
  bottom: "data"
  top: "conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_conv"
  type: "BatchNorm"
  bottom: "conv"
  top: "bn_conv"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv"
  type: "Scale"
  bottom: "bn_conv"
  top: "bn_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_conv"
  type: "ReLU"
  bottom: "bn_conv"
  top: "bn_conv"
}
layer {
  name: "Conv16_1"
  type: "Convolution"
  bottom: "bn_conv"
  top: "Conv16_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_1"
  type: "BatchNorm"
  bottom: "Conv16_1"
  top: "bn_Conv16_1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_1"
  type: "Scale"
  bottom: "bn_Conv16_1"
  top: "bn_Conv16_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_1"
  type: "ReLU"
  bottom: "bn_Conv16_1"
  top: "bn_Conv16_1"
}
layer {
  name: "Conv16_1_b"
  type: "Convolution"
  bottom: "bn_Conv16_1"
  top: "Conv16_1_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_1_b"
  type: "BatchNorm"
  bottom: "Conv16_1_b"
  top: "bn_Conv16_1_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_1_b"
  type: "Scale"
  bottom: "bn_Conv16_1_b"
  top: "bn_Conv16_1_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_bn_conv"
  type: "Eltwise"
  bottom: "bn_conv"
  bottom: "bn_Conv16_1_b"
  top: "sum_bn_Conv16_1_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_1_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_1_b"
  top: "sum_bn_Conv16_1_b"
}
layer {
  name: "Conv16_2"
  type: "Convolution"
  bottom: "sum_bn_Conv16_1_b"
  top: "Conv16_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_2"
  type: "BatchNorm"
  bottom: "Conv16_2"
  top: "bn_Conv16_2"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_2"
  type: "Scale"
  bottom: "bn_Conv16_2"
  top: "bn_Conv16_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_2"
  type: "ReLU"
  bottom: "bn_Conv16_2"
  top: "bn_Conv16_2"
}
layer {
  name: "Conv16_2_b"
  type: "Convolution"
  bottom: "bn_Conv16_2"
  top: "Conv16_2_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_2_b"
  type: "BatchNorm"
  bottom: "Conv16_2_b"
  top: "bn_Conv16_2_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_2_b"
  type: "Scale"
  bottom: "bn_Conv16_2_b"
  top: "bn_Conv16_2_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_1_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_1_b"
  bottom: "bn_Conv16_2_b"
  top: "sum_bn_Conv16_2_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_2_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_2_b"
  top: "sum_bn_Conv16_2_b"
}
layer {
  name: "Conv16_3"
  type: "Convolution"
  bottom: "sum_bn_Conv16_2_b"
  top: "Conv16_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_3"
  type: "BatchNorm"
  bottom: "Conv16_3"
  top: "bn_Conv16_3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_3"
  type: "Scale"
  bottom: "bn_Conv16_3"
  top: "bn_Conv16_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_3"
  type: "ReLU"
  bottom: "bn_Conv16_3"
  top: "bn_Conv16_3"
}
layer {
  name: "Conv16_3_b"
  type: "Convolution"
  bottom: "bn_Conv16_3"
  top: "Conv16_3_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_3_b"
  type: "BatchNorm"
  bottom: "Conv16_3_b"
  top: "bn_Conv16_3_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_3_b"
  type: "Scale"
  bottom: "bn_Conv16_3_b"
  top: "bn_Conv16_3_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_2_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_2_b"
  bottom: "bn_Conv16_3_b"
  top: "sum_bn_Conv16_3_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_3_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_3_b"
  top: "sum_bn_Conv16_3_b"
}
layer {
  name: "Conv16_4"
  type: "Convolution"
  bottom: "sum_bn_Conv16_3_b"
  top: "Conv16_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_4"
  type: "BatchNorm"
  bottom: "Conv16_4"
  top: "bn_Conv16_4"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_4"
  type: "Scale"
  bottom: "bn_Conv16_4"
  top: "bn_Conv16_4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_4"
  type: "ReLU"
  bottom: "bn_Conv16_4"
  top: "bn_Conv16_4"
}
layer {
  name: "Conv16_4_b"
  type: "Convolution"
  bottom: "bn_Conv16_4"
  top: "Conv16_4_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_4_b"
  type: "BatchNorm"
  bottom: "Conv16_4_b"
  top: "bn_Conv16_4_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_4_b"
  type: "Scale"
  bottom: "bn_Conv16_4_b"
  top: "bn_Conv16_4_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_3_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_3_b"
  bottom: "bn_Conv16_4_b"
  top: "sum_bn_Conv16_4_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_4_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_4_b"
  top: "sum_bn_Conv16_4_b"
}
layer {
  name: "Conv16_5"
  type: "Convolution"
  bottom: "sum_bn_Conv16_4_b"
  top: "Conv16_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_5"
  type: "BatchNorm"
  bottom: "Conv16_5"
  top: "bn_Conv16_5"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_5"
  type: "Scale"
  bottom: "bn_Conv16_5"
  top: "bn_Conv16_5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_5"
  type: "ReLU"
  bottom: "bn_Conv16_5"
  top: "bn_Conv16_5"
}
layer {
  name: "Conv16_5_b"
  type: "Convolution"
  bottom: "bn_Conv16_5"
  top: "Conv16_5_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_5_b"
  type: "BatchNorm"
  bottom: "Conv16_5_b"
  top: "bn_Conv16_5_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_5_b"
  type: "Scale"
  bottom: "bn_Conv16_5_b"
  top: "bn_Conv16_5_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_4_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_4_b"
  bottom: "bn_Conv16_5_b"
  top: "sum_bn_Conv16_5_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_5_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_5_b"
  top: "sum_bn_Conv16_5_b"
}
layer {
  name: "Conv16_6"
  type: "Convolution"
  bottom: "sum_bn_Conv16_5_b"
  top: "Conv16_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_6"
  type: "BatchNorm"
  bottom: "Conv16_6"
  top: "bn_Conv16_6"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_6"
  type: "Scale"
  bottom: "bn_Conv16_6"
  top: "bn_Conv16_6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_6"
  type: "ReLU"
  bottom: "bn_Conv16_6"
  top: "bn_Conv16_6"
}
layer {
  name: "Conv16_6_b"
  type: "Convolution"
  bottom: "bn_Conv16_6"
  top: "Conv16_6_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_6_b"
  type: "BatchNorm"
  bottom: "Conv16_6_b"
  top: "bn_Conv16_6_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_6_b"
  type: "Scale"
  bottom: "bn_Conv16_6_b"
  top: "bn_Conv16_6_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_5_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_5_b"
  bottom: "bn_Conv16_6_b"
  top: "sum_bn_Conv16_6_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_6_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_6_b"
  top: "sum_bn_Conv16_6_b"
}
layer {
  name: "Conv16_7"
  type: "Convolution"
  bottom: "sum_bn_Conv16_6_b"
  top: "Conv16_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_7"
  type: "BatchNorm"
  bottom: "Conv16_7"
  top: "bn_Conv16_7"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_7"
  type: "Scale"
  bottom: "bn_Conv16_7"
  top: "bn_Conv16_7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_7"
  type: "ReLU"
  bottom: "bn_Conv16_7"
  top: "bn_Conv16_7"
}
layer {
  name: "Conv16_7_b"
  type: "Convolution"
  bottom: "bn_Conv16_7"
  top: "Conv16_7_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_7_b"
  type: "BatchNorm"
  bottom: "Conv16_7_b"
  top: "bn_Conv16_7_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_7_b"
  type: "Scale"
  bottom: "bn_Conv16_7_b"
  top: "bn_Conv16_7_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_6_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_6_b"
  bottom: "bn_Conv16_7_b"
  top: "sum_bn_Conv16_7_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_7_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_7_b"
  top: "sum_bn_Conv16_7_b"
}
layer {
  name: "Conv16_8"
  type: "Convolution"
  bottom: "sum_bn_Conv16_7_b"
  top: "Conv16_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_8"
  type: "BatchNorm"
  bottom: "Conv16_8"
  top: "bn_Conv16_8"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_8"
  type: "Scale"
  bottom: "bn_Conv16_8"
  top: "bn_Conv16_8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_8"
  type: "ReLU"
  bottom: "bn_Conv16_8"
  top: "bn_Conv16_8"
}
layer {
  name: "Conv16_8_b"
  type: "Convolution"
  bottom: "bn_Conv16_8"
  top: "Conv16_8_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_8_b"
  type: "BatchNorm"
  bottom: "Conv16_8_b"
  top: "bn_Conv16_8_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_8_b"
  type: "Scale"
  bottom: "bn_Conv16_8_b"
  top: "bn_Conv16_8_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_7_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_7_b"
  bottom: "bn_Conv16_8_b"
  top: "sum_bn_Conv16_8_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_8_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_8_b"
  top: "sum_bn_Conv16_8_b"
}
layer {
  name: "Conv16_9"
  type: "Convolution"
  bottom: "sum_bn_Conv16_8_b"
  top: "Conv16_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_9"
  type: "BatchNorm"
  bottom: "Conv16_9"
  top: "bn_Conv16_9"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_9"
  type: "Scale"
  bottom: "bn_Conv16_9"
  top: "bn_Conv16_9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_9"
  type: "ReLU"
  bottom: "bn_Conv16_9"
  top: "bn_Conv16_9"
}
layer {
  name: "Conv16_9_b"
  type: "Convolution"
  bottom: "bn_Conv16_9"
  top: "Conv16_9_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_9_b"
  type: "BatchNorm"
  bottom: "Conv16_9_b"
  top: "bn_Conv16_9_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_9_b"
  type: "Scale"
  bottom: "bn_Conv16_9_b"
  top: "bn_Conv16_9_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_8_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_8_b"
  bottom: "bn_Conv16_9_b"
  top: "sum_bn_Conv16_9_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_9_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_9_b"
  top: "sum_bn_Conv16_9_b"
}
layer {
  name: "resblk32"
  type: "Convolution"
  bottom: "sum_bn_Conv16_9_b"
  top: "resblk32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32"
  type: "BatchNorm"
  bottom: "resblk32"
  top: "bn_resblk32"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32"
  type: "Scale"
  bottom: "bn_resblk32"
  top: "bn_resblk32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32"
  type: "ReLU"
  bottom: "bn_resblk32"
  top: "bn_resblk32"
}
layer {
  name: "resblk32_b"
  type: "Convolution"
  bottom: "bn_resblk32"
  top: "resblk32_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_b"
  type: "BatchNorm"
  bottom: "resblk32_b"
  top: "bn_resblk32_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_b"
  type: "Scale"
  bottom: "bn_resblk32_b"
  top: "bn_resblk32_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "avePooling_resblk32"
  type: "Pooling"
  bottom: "sum_bn_Conv16_9_b"
  top: "avgPool_resblk32"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "sum_avgPool_resblk32"
  type: "Eltwise"
  bottom: "avgPool_resblk32"
  bottom: "bn_resblk32_b"
  top: "sum_bn_resblk32_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_b"
  top: "sum_bn_resblk32_b"
}
layer {
  name: "zeros_sum_bn_resblk32_b"
  type: "DummyData"
  top: "zeros_sum_bn_resblk32_b"
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 125
      dim: 16
      dim: 16
      dim: 16
    }
  }
}
layer {
  name: "CC_sum_bn_resblk32_b"
  type: "Concat"
  bottom: "sum_bn_resblk32_b"
  bottom: "zeros_sum_bn_resblk32_b"
  top: "CC_sum_bn_resblk32_b"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resblk32_1"
  type: "Convolution"
  bottom: "CC_sum_bn_resblk32_b"
  top: "resblk32_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_1"
  type: "BatchNorm"
  bottom: "resblk32_1"
  top: "bn_resblk32_1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_1"
  type: "Scale"
  bottom: "bn_resblk32_1"
  top: "bn_resblk32_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_1"
  type: "ReLU"
  bottom: "bn_resblk32_1"
  top: "bn_resblk32_1"
}
layer {
  name: "resblk32_1_b"
  type: "Convolution"
  bottom: "bn_resblk32_1"
  top: "resblk32_1_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_1_b"
  type: "BatchNorm"
  bottom: "resblk32_1_b"
  top: "bn_resblk32_1_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_1_b"
  type: "Scale"
  bottom: "bn_resblk32_1_b"
  top: "bn_resblk32_1_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_CC_sum_bn_resblk32_b"
  type: "Eltwise"
  bottom: "CC_sum_bn_resblk32_b"
  bottom: "bn_resblk32_1_b"
  top: "sum_bn_resblk32_1_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_1_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_1_b"
  top: "sum_bn_resblk32_1_b"
}
layer {
  name: "resblk32_2"
  type: "Convolution"
  bottom: "sum_bn_resblk32_1_b"
  top: "resblk32_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_2"
  type: "BatchNorm"
  bottom: "resblk32_2"
  top: "bn_resblk32_2"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_2"
  type: "Scale"
  bottom: "bn_resblk32_2"
  top: "bn_resblk32_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_2"
  type: "ReLU"
  bottom: "bn_resblk32_2"
  top: "bn_resblk32_2"
}
layer {
  name: "resblk32_2_b"
  type: "Convolution"
  bottom: "bn_resblk32_2"
  top: "resblk32_2_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_2_b"
  type: "BatchNorm"
  bottom: "resblk32_2_b"
  top: "bn_resblk32_2_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_2_b"
  type: "Scale"
  bottom: "bn_resblk32_2_b"
  top: "bn_resblk32_2_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_resblk32_1_b"
  type: "Eltwise"
  bottom: "sum_bn_resblk32_1_b"
  bottom: "bn_resblk32_2_b"
  top: "sum_bn_resblk32_2_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_2_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_2_b"
  top: "sum_bn_resblk32_2_b"
}
layer {
  name: "resblk32_3"
  type: "Convolution"
  bottom: "sum_bn_resblk32_2_b"
  top: "resblk32_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_3"
  type: "BatchNorm"
  bottom: "resblk32_3"
  top: "bn_resblk32_3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_3"
  type: "Scale"
  bottom: "bn_resblk32_3"
  top: "bn_resblk32_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_3"
  type: "ReLU"
  bottom: "bn_resblk32_3"
  top: "bn_resblk32_3"
}
layer {
  name: "resblk32_3_b"
  type: "Convolution"
  bottom: "bn_resblk32_3"
  top: "resblk32_3_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_3_b"
  type: "BatchNorm"
  bottom: "resblk32_3_b"
  top: "bn_resblk32_3_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_3_b"
  type: "Scale"
  bottom: "bn_resblk32_3_b"
  top: "bn_resblk32_3_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_resblk32_2_b"
  type: "Eltwise"
  bottom: "sum_bn_resblk32_2_b"
  bottom: "bn_resblk32_3_b"
  top: "sum_bn_resblk32_3_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_3_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_3_b"
  top: "sum_bn_resblk32_3_b"
}
layer {
  name: "resblk32_4"
  type: "Convolution"
  bottom: "sum_bn_resblk32_3_b"
  top: "resblk32_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_4"
  type: "BatchNorm"
  bottom: "resblk32_4"
  top: "bn_resblk32_4"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_4"
  type: "Scale"
  bottom: "bn_resblk32_4"
  top: "bn_resblk32_4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_4"
  type: "ReLU"
  bottom: "bn_resblk32_4"
  top: "bn_resblk32_4"
}
layer {
  name: "resblk32_4_b"
  type: "Convolution"
  bottom: "bn_resblk32_4"
  top: "resblk32_4_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_4_b"
  type: "BatchNorm"
  bottom: "resblk32_4_b"
  top: "bn_resblk32_4_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_4_b"
  type: "Scale"
  bottom: "bn_resblk32_4_b"
  top: "bn_resblk32_4_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_resblk32_3_b"
  type: "Eltwise"
  bottom: "sum_bn_resblk32_3_b"
  bottom: "bn_resblk32_4_b"
  top: "sum_bn_resblk32_4_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_4_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_4_b"
  top: "sum_bn_resblk32_4_b"
}
layer {
  name: "resblk32_5"
  type: "Convolution"
  bottom: "sum_bn_resblk32_4_b"
  top: "resblk32_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_5"
  type: "BatchNorm"
  bottom: "resblk32_5"
  top: "bn_resblk32_5"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_5"
  type: "Scale"
  bottom: "bn_resblk32_5"
  top: "bn_resblk32_5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_5"
  type: "ReLU"
  bottom: "bn_resblk32_5"
  top: "bn_resblk32_5"
}
layer {
  name: "resblk32_5_b"
  type: "Convolution"
  bottom: "bn_resblk32_5"
  top: "resblk32_5_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_5_b"
  type: "BatchNorm"
  bottom: "resblk32_5_b"
  top: "bn_resblk32_5_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_5_b"
  type: "Scale"
  bottom: "bn_resblk32_5_b"
  top: "bn_resblk32_5_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_resblk32_4_b"
  type: "Eltwise"
  bottom: "sum_bn_resblk32_4_b"
  bottom: "bn_resblk32_5_b"
  top: "sum_bn_resblk32_5_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_5_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_5_b"
  top: "sum_bn_resblk32_5_b"
}
layer {
  name: "resblk32_6"
  type: "Convolution"
  bottom: "sum_bn_resblk32_5_b"
  top: "resblk32_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_6"
  type: "BatchNorm"
  bottom: "resblk32_6"
  top: "bn_resblk32_6"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_6"
  type: "Scale"
  bottom: "bn_resblk32_6"
  top: "bn_resblk32_6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_6"
  type: "ReLU"
  bottom: "bn_resblk32_6"
  top: "bn_resblk32_6"
}
layer {
  name: "res
I0818 13:44:37.120782 22726 layer_factory.hpp:77] Creating layer dataLayer
I0818 13:44:37.121978 22726 net.cpp:100] Creating Layer dataLayer
I0818 13:44:37.122062 22726 net.cpp:408] dataLayer -> data
I0818 13:44:37.122258 22726 net.cpp:408] dataLayer -> label
I0818 13:44:37.122375 22726 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0818 13:44:37.132936 22731 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0818 13:44:37.154294 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:37.161983 22726 net.cpp:150] Setting up dataLayer
I0818 13:44:37.162046 22726 net.cpp:157] Top shape: 125 3 32 32 (384000)
I0818 13:44:37.162060 22726 net.cpp:157] Top shape: 125 (125)
I0818 13:44:37.162065 22726 net.cpp:165] Memory required for data: 1536500
I0818 13:44:37.162081 22726 layer_factory.hpp:77] Creating layer label_dataLayer_1_split
I0818 13:44:37.162094 22726 net.cpp:100] Creating Layer label_dataLayer_1_split
I0818 13:44:37.162102 22726 net.cpp:434] label_dataLayer_1_split <- label
I0818 13:44:37.162125 22726 net.cpp:408] label_dataLayer_1_split -> label_dataLayer_1_split_0
I0818 13:44:37.162140 22726 net.cpp:408] label_dataLayer_1_split -> label_dataLayer_1_split_1
I0818 13:44:37.162221 22726 net.cpp:150] Setting up label_dataLayer_1_split
I0818 13:44:37.162237 22726 net.cpp:157] Top shape: 125 (125)
I0818 13:44:37.162245 22726 net.cpp:157] Top shape: 125 (125)
I0818 13:44:37.162250 22726 net.cpp:165] Memory required for data: 1537500
I0818 13:44:37.162255 22726 layer_factory.hpp:77] Creating layer conv
I0818 13:44:37.162317 22726 net.cpp:100] Creating Layer conv
I0818 13:44:37.162329 22726 net.cpp:434] conv <- data
I0818 13:44:37.162339 22726 net.cpp:408] conv -> conv
I0818 13:44:37.164067 22726 net.cpp:150] Setting up conv
I0818 13:44:37.164088 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.164093 22726 net.cpp:165] Memory required for data: 9729500
I0818 13:44:37.164146 22726 layer_factory.hpp:77] Creating layer batchNorm_conv
I0818 13:44:37.164224 22726 net.cpp:100] Creating Layer batchNorm_conv
I0818 13:44:37.164235 22726 net.cpp:434] batchNorm_conv <- conv
I0818 13:44:37.164248 22726 net.cpp:408] batchNorm_conv -> bn_conv
I0818 13:44:37.164582 22732 blocking_queue.cpp:50] Waiting for data
I0818 13:44:37.164721 22726 net.cpp:150] Setting up batchNorm_conv
I0818 13:44:37.164741 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.164746 22726 net.cpp:165] Memory required for data: 17921500
I0818 13:44:37.164763 22726 layer_factory.hpp:77] Creating layer scale_conv
I0818 13:44:37.164815 22726 net.cpp:100] Creating Layer scale_conv
I0818 13:44:37.164825 22726 net.cpp:434] scale_conv <- bn_conv
I0818 13:44:37.164839 22726 net.cpp:395] scale_conv -> bn_conv (in-place)
I0818 13:44:37.165011 22726 layer_factory.hpp:77] Creating layer scale_conv
I0818 13:44:37.165266 22726 net.cpp:150] Setting up scale_conv
I0818 13:44:37.165284 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.165290 22726 net.cpp:165] Memory required for data: 26113500
I0818 13:44:37.165300 22726 layer_factory.hpp:77] Creating layer relu_bn_conv
I0818 13:44:37.165343 22726 net.cpp:100] Creating Layer relu_bn_conv
I0818 13:44:37.165351 22726 net.cpp:434] relu_bn_conv <- bn_conv
I0818 13:44:37.165359 22726 net.cpp:395] relu_bn_conv -> bn_conv (in-place)
I0818 13:44:37.165369 22726 net.cpp:150] Setting up relu_bn_conv
I0818 13:44:37.165376 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.165381 22726 net.cpp:165] Memory required for data: 34305500
I0818 13:44:37.165386 22726 layer_factory.hpp:77] Creating layer bn_conv_relu_bn_conv_0_split
I0818 13:44:37.165397 22726 net.cpp:100] Creating Layer bn_conv_relu_bn_conv_0_split
I0818 13:44:37.165402 22726 net.cpp:434] bn_conv_relu_bn_conv_0_split <- bn_conv
I0818 13:44:37.165410 22726 net.cpp:408] bn_conv_relu_bn_conv_0_split -> bn_conv_relu_bn_conv_0_split_0
I0818 13:44:37.165419 22726 net.cpp:408] bn_conv_relu_bn_conv_0_split -> bn_conv_relu_bn_conv_0_split_1
I0818 13:44:37.165478 22726 net.cpp:150] Setting up bn_conv_relu_bn_conv_0_split
I0818 13:44:37.165490 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.165498 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.165501 22726 net.cpp:165] Memory required for data: 50689500
I0818 13:44:37.165506 22726 layer_factory.hpp:77] Creating layer Conv16_1
I0818 13:44:37.165518 22726 net.cpp:100] Creating Layer Conv16_1
I0818 13:44:37.165524 22726 net.cpp:434] Conv16_1 <- bn_conv_relu_bn_conv_0_split_0
I0818 13:44:37.165536 22726 net.cpp:408] Conv16_1 -> Conv16_1
I0818 13:44:37.165866 22726 net.cpp:150] Setting up Conv16_1
I0818 13:44:37.165881 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.165886 22726 net.cpp:165] Memory required for data: 58881500
I0818 13:44:37.165899 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_1
I0818 13:44:37.165910 22726 net.cpp:100] Creating Layer batchNorm_Conv16_1
I0818 13:44:37.165915 22726 net.cpp:434] batchNorm_Conv16_1 <- Conv16_1
I0818 13:44:37.165926 22726 net.cpp:408] batchNorm_Conv16_1 -> bn_Conv16_1
I0818 13:44:37.166162 22726 net.cpp:150] Setting up batchNorm_Conv16_1
I0818 13:44:37.166174 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.166188 22726 net.cpp:165] Memory required for data: 67073500
I0818 13:44:37.166198 22726 layer_factory.hpp:77] Creating layer scale_Conv16_1
I0818 13:44:37.166210 22726 net.cpp:100] Creating Layer scale_Conv16_1
I0818 13:44:37.166216 22726 net.cpp:434] scale_Conv16_1 <- bn_Conv16_1
I0818 13:44:37.166224 22726 net.cpp:395] scale_Conv16_1 -> bn_Conv16_1 (in-place)
I0818 13:44:37.166281 22726 layer_factory.hpp:77] Creating layer scale_Conv16_1
I0818 13:44:37.166420 22726 net.cpp:150] Setting up scale_Conv16_1
I0818 13:44:37.166434 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.166438 22726 net.cpp:165] Memory required for data: 75265500
I0818 13:44:37.166446 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_1
I0818 13:44:37.166457 22726 net.cpp:100] Creating Layer relu_bn_Conv16_1
I0818 13:44:37.166463 22726 net.cpp:434] relu_bn_Conv16_1 <- bn_Conv16_1
I0818 13:44:37.166471 22726 net.cpp:395] relu_bn_Conv16_1 -> bn_Conv16_1 (in-place)
I0818 13:44:37.166479 22726 net.cpp:150] Setting up relu_bn_Conv16_1
I0818 13:44:37.166486 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.166491 22726 net.cpp:165] Memory required for data: 83457500
I0818 13:44:37.166496 22726 layer_factory.hpp:77] Creating layer Conv16_1_b
I0818 13:44:37.166512 22726 net.cpp:100] Creating Layer Conv16_1_b
I0818 13:44:37.166517 22726 net.cpp:434] Conv16_1_b <- bn_Conv16_1
I0818 13:44:37.166528 22726 net.cpp:408] Conv16_1_b -> Conv16_1_b
I0818 13:44:37.166843 22726 net.cpp:150] Setting up Conv16_1_b
I0818 13:44:37.166858 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.166863 22726 net.cpp:165] Memory required for data: 91649500
I0818 13:44:37.166872 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_1_b
I0818 13:44:37.166885 22726 net.cpp:100] Creating Layer batchNorm_Conv16_1_b
I0818 13:44:37.166891 22726 net.cpp:434] batchNorm_Conv16_1_b <- Conv16_1_b
I0818 13:44:37.166899 22726 net.cpp:408] batchNorm_Conv16_1_b -> bn_Conv16_1_b
I0818 13:44:37.167134 22726 net.cpp:150] Setting up batchNorm_Conv16_1_b
I0818 13:44:37.167146 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.167151 22726 net.cpp:165] Memory required for data: 99841500
I0818 13:44:37.167170 22726 layer_factory.hpp:77] Creating layer scale_Conv16_1_b
I0818 13:44:37.167178 22726 net.cpp:100] Creating Layer scale_Conv16_1_b
I0818 13:44:37.167184 22726 net.cpp:434] scale_Conv16_1_b <- bn_Conv16_1_b
I0818 13:44:37.167194 22726 net.cpp:395] scale_Conv16_1_b -> bn_Conv16_1_b (in-place)
I0818 13:44:37.167258 22726 layer_factory.hpp:77] Creating layer scale_Conv16_1_b
I0818 13:44:37.167397 22726 net.cpp:150] Setting up scale_Conv16_1_b
I0818 13:44:37.167409 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.167414 22726 net.cpp:165] Memory required for data: 108033500
I0818 13:44:37.167423 22726 layer_factory.hpp:77] Creating layer sum_bn_conv
I0818 13:44:37.167477 22726 net.cpp:100] Creating Layer sum_bn_conv
I0818 13:44:37.167487 22726 net.cpp:434] sum_bn_conv <- bn_conv_relu_bn_conv_0_split_1
I0818 13:44:37.167495 22726 net.cpp:434] sum_bn_conv <- bn_Conv16_1_b
I0818 13:44:37.167502 22726 net.cpp:408] sum_bn_conv -> sum_bn_Conv16_1_b
I0818 13:44:37.167575 22726 net.cpp:150] Setting up sum_bn_conv
I0818 13:44:37.167590 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.167595 22726 net.cpp:165] Memory required for data: 116225500
I0818 13:44:37.167601 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_1_b
I0818 13:44:37.167609 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_1_b
I0818 13:44:37.167614 22726 net.cpp:434] relu_sum_bn_Conv16_1_b <- sum_bn_Conv16_1_b
I0818 13:44:37.167625 22726 net.cpp:395] relu_sum_bn_Conv16_1_b -> sum_bn_Conv16_1_b (in-place)
I0818 13:44:37.167635 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_1_b
I0818 13:44:37.167642 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.167647 22726 net.cpp:165] Memory required for data: 124417500
I0818 13:44:37.167651 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split
I0818 13:44:37.167668 22726 net.cpp:100] Creating Layer sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split
I0818 13:44:37.167675 22726 net.cpp:434] sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split <- sum_bn_Conv16_1_b
I0818 13:44:37.167681 22726 net.cpp:408] sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split -> sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split_0
I0818 13:44:37.167690 22726 net.cpp:408] sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split -> sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split_1
I0818 13:44:37.167737 22726 net.cpp:150] Setting up sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split
I0818 13:44:37.167748 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.167755 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.167759 22726 net.cpp:165] Memory required for data: 140801500
I0818 13:44:37.167764 22726 layer_factory.hpp:77] Creating layer Conv16_2
I0818 13:44:37.167778 22726 net.cpp:100] Creating Layer Conv16_2
I0818 13:44:37.167784 22726 net.cpp:434] Conv16_2 <- sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split_0
I0818 13:44:37.167793 22726 net.cpp:408] Conv16_2 -> Conv16_2
I0818 13:44:37.168107 22726 net.cpp:150] Setting up Conv16_2
I0818 13:44:37.168120 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.168125 22726 net.cpp:165] Memory required for data: 148993500
I0818 13:44:37.168134 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_2
I0818 13:44:37.168148 22726 net.cpp:100] Creating Layer batchNorm_Conv16_2
I0818 13:44:37.168154 22726 net.cpp:434] batchNorm_Conv16_2 <- Conv16_2
I0818 13:44:37.168162 22726 net.cpp:408] batchNorm_Conv16_2 -> bn_Conv16_2
I0818 13:44:37.168403 22726 net.cpp:150] Setting up batchNorm_Conv16_2
I0818 13:44:37.168417 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.168421 22726 net.cpp:165] Memory required for data: 157185500
I0818 13:44:37.168432 22726 layer_factory.hpp:77] Creating layer scale_Conv16_2
I0818 13:44:37.168442 22726 net.cpp:100] Creating Layer scale_Conv16_2
I0818 13:44:37.168447 22726 net.cpp:434] scale_Conv16_2 <- bn_Conv16_2
I0818 13:44:37.168454 22726 net.cpp:395] scale_Conv16_2 -> bn_Conv16_2 (in-place)
I0818 13:44:37.168509 22726 layer_factory.hpp:77] Creating layer scale_Conv16_2
I0818 13:44:37.168649 22726 net.cpp:150] Setting up scale_Conv16_2
I0818 13:44:37.168663 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.168668 22726 net.cpp:165] Memory required for data: 165377500
I0818 13:44:37.168675 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_2
I0818 13:44:37.168684 22726 net.cpp:100] Creating Layer relu_bn_Conv16_2
I0818 13:44:37.168689 22726 net.cpp:434] relu_bn_Conv16_2 <- bn_Conv16_2
I0818 13:44:37.168699 22726 net.cpp:395] relu_bn_Conv16_2 -> bn_Conv16_2 (in-place)
I0818 13:44:37.168709 22726 net.cpp:150] Setting up relu_bn_Conv16_2
I0818 13:44:37.168715 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.168720 22726 net.cpp:165] Memory required for data: 173569500
I0818 13:44:37.168725 22726 layer_factory.hpp:77] Creating layer Conv16_2_b
I0818 13:44:37.168741 22726 net.cpp:100] Creating Layer Conv16_2_b
I0818 13:44:37.168747 22726 net.cpp:434] Conv16_2_b <- bn_Conv16_2
I0818 13:44:37.168756 22726 net.cpp:408] Conv16_2_b -> Conv16_2_b
I0818 13:44:37.169068 22726 net.cpp:150] Setting up Conv16_2_b
I0818 13:44:37.169082 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.169087 22726 net.cpp:165] Memory required for data: 181761500
I0818 13:44:37.169096 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_2_b
I0818 13:44:37.169104 22726 net.cpp:100] Creating Layer batchNorm_Conv16_2_b
I0818 13:44:37.169111 22726 net.cpp:434] batchNorm_Conv16_2_b <- Conv16_2_b
I0818 13:44:37.169121 22726 net.cpp:408] batchNorm_Conv16_2_b -> bn_Conv16_2_b
I0818 13:44:37.169358 22726 net.cpp:150] Setting up batchNorm_Conv16_2_b
I0818 13:44:37.169373 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.169378 22726 net.cpp:165] Memory required for data: 189953500
I0818 13:44:37.169400 22726 layer_factory.hpp:77] Creating layer scale_Conv16_2_b
I0818 13:44:37.169409 22726 net.cpp:100] Creating Layer scale_Conv16_2_b
I0818 13:44:37.169415 22726 net.cpp:434] scale_Conv16_2_b <- bn_Conv16_2_b
I0818 13:44:37.169425 22726 net.cpp:395] scale_Conv16_2_b -> bn_Conv16_2_b (in-place)
I0818 13:44:37.169479 22726 layer_factory.hpp:77] Creating layer scale_Conv16_2_b
I0818 13:44:37.169618 22726 net.cpp:150] Setting up scale_Conv16_2_b
I0818 13:44:37.169633 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.169638 22726 net.cpp:165] Memory required for data: 198145500
I0818 13:44:37.169647 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_1_b
I0818 13:44:37.169656 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_1_b
I0818 13:44:37.169661 22726 net.cpp:434] sum_sum_bn_Conv16_1_b <- sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split_1
I0818 13:44:37.169669 22726 net.cpp:434] sum_sum_bn_Conv16_1_b <- bn_Conv16_2_b
I0818 13:44:37.169677 22726 net.cpp:408] sum_sum_bn_Conv16_1_b -> sum_bn_Conv16_2_b
I0818 13:44:37.169710 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_1_b
I0818 13:44:37.169719 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.169724 22726 net.cpp:165] Memory required for data: 206337500
I0818 13:44:37.169729 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_2_b
I0818 13:44:37.169737 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_2_b
I0818 13:44:37.169742 22726 net.cpp:434] relu_sum_bn_Conv16_2_b <- sum_bn_Conv16_2_b
I0818 13:44:37.169749 22726 net.cpp:395] relu_sum_bn_Conv16_2_b -> sum_bn_Conv16_2_b (in-place)
I0818 13:44:37.169757 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_2_b
I0818 13:44:37.169764 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.169770 22726 net.cpp:165] Memory required for data: 214529500
I0818 13:44:37.169773 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split
I0818 13:44:37.169780 22726 net.cpp:100] Creating Layer sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split
I0818 13:44:37.169785 22726 net.cpp:434] sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split <- sum_bn_Conv16_2_b
I0818 13:44:37.169795 22726 net.cpp:408] sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split -> sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split_0
I0818 13:44:37.169806 22726 net.cpp:408] sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split -> sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split_1
I0818 13:44:37.169853 22726 net.cpp:150] Setting up sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split
I0818 13:44:37.169868 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.169875 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.169880 22726 net.cpp:165] Memory required for data: 230913500
I0818 13:44:37.169885 22726 layer_factory.hpp:77] Creating layer Conv16_3
I0818 13:44:37.169896 22726 net.cpp:100] Creating Layer Conv16_3
I0818 13:44:37.169903 22726 net.cpp:434] Conv16_3 <- sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split_0
I0818 13:44:37.169911 22726 net.cpp:408] Conv16_3 -> Conv16_3
I0818 13:44:37.170218 22726 net.cpp:150] Setting up Conv16_3
I0818 13:44:37.170231 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.170236 22726 net.cpp:165] Memory required for data: 239105500
I0818 13:44:37.170245 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_3
I0818 13:44:37.170253 22726 net.cpp:100] Creating Layer batchNorm_Conv16_3
I0818 13:44:37.170262 22726 net.cpp:434] batchNorm_Conv16_3 <- Conv16_3
I0818 13:44:37.170271 22726 net.cpp:408] batchNorm_Conv16_3 -> bn_Conv16_3
I0818 13:44:37.170509 22726 net.cpp:150] Setting up batchNorm_Conv16_3
I0818 13:44:37.170521 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.170526 22726 net.cpp:165] Memory required for data: 247297500
I0818 13:44:37.170537 22726 layer_factory.hpp:77] Creating layer scale_Conv16_3
I0818 13:44:37.170545 22726 net.cpp:100] Creating Layer scale_Conv16_3
I0818 13:44:37.170552 22726 net.cpp:434] scale_Conv16_3 <- bn_Conv16_3
I0818 13:44:37.170562 22726 net.cpp:395] scale_Conv16_3 -> bn_Conv16_3 (in-place)
I0818 13:44:37.170621 22726 layer_factory.hpp:77] Creating layer scale_Conv16_3
I0818 13:44:37.170759 22726 net.cpp:150] Setting up scale_Conv16_3
I0818 13:44:37.170774 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.170779 22726 net.cpp:165] Memory required for data: 255489500
I0818 13:44:37.170789 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_3
I0818 13:44:37.170796 22726 net.cpp:100] Creating Layer relu_bn_Conv16_3
I0818 13:44:37.170801 22726 net.cpp:434] relu_bn_Conv16_3 <- bn_Conv16_3
I0818 13:44:37.170815 22726 net.cpp:395] relu_bn_Conv16_3 -> bn_Conv16_3 (in-place)
I0818 13:44:37.170825 22726 net.cpp:150] Setting up relu_bn_Conv16_3
I0818 13:44:37.170832 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.170837 22726 net.cpp:165] Memory required for data: 263681500
I0818 13:44:37.170841 22726 layer_factory.hpp:77] Creating layer Conv16_3_b
I0818 13:44:37.170855 22726 net.cpp:100] Creating Layer Conv16_3_b
I0818 13:44:37.170861 22726 net.cpp:434] Conv16_3_b <- bn_Conv16_3
I0818 13:44:37.170872 22726 net.cpp:408] Conv16_3_b -> Conv16_3_b
I0818 13:44:37.171180 22726 net.cpp:150] Setting up Conv16_3_b
I0818 13:44:37.171193 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.171198 22726 net.cpp:165] Memory required for data: 271873500
I0818 13:44:37.171207 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_3_b
I0818 13:44:37.171223 22726 net.cpp:100] Creating Layer batchNorm_Conv16_3_b
I0818 13:44:37.171229 22726 net.cpp:434] batchNorm_Conv16_3_b <- Conv16_3_b
I0818 13:44:37.171238 22726 net.cpp:408] batchNorm_Conv16_3_b -> bn_Conv16_3_b
I0818 13:44:37.171471 22726 net.cpp:150] Setting up batchNorm_Conv16_3_b
I0818 13:44:37.171483 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.171489 22726 net.cpp:165] Memory required for data: 280065500
I0818 13:44:37.171499 22726 layer_factory.hpp:77] Creating layer scale_Conv16_3_b
I0818 13:44:37.171507 22726 net.cpp:100] Creating Layer scale_Conv16_3_b
I0818 13:44:37.171514 22726 net.cpp:434] scale_Conv16_3_b <- bn_Conv16_3_b
I0818 13:44:37.171524 22726 net.cpp:395] scale_Conv16_3_b -> bn_Conv16_3_b (in-place)
I0818 13:44:37.171576 22726 layer_factory.hpp:77] Creating layer scale_Conv16_3_b
I0818 13:44:37.171715 22726 net.cpp:150] Setting up scale_Conv16_3_b
I0818 13:44:37.171730 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.171735 22726 net.cpp:165] Memory required for data: 288257500
I0818 13:44:37.171742 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_2_b
I0818 13:44:37.171751 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_2_b
I0818 13:44:37.171757 22726 net.cpp:434] sum_sum_bn_Conv16_2_b <- sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split_1
I0818 13:44:37.171764 22726 net.cpp:434] sum_sum_bn_Conv16_2_b <- bn_Conv16_3_b
I0818 13:44:37.171772 22726 net.cpp:408] sum_sum_bn_Conv16_2_b -> sum_bn_Conv16_3_b
I0818 13:44:37.171805 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_2_b
I0818 13:44:37.171828 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.171833 22726 net.cpp:165] Memory required for data: 296449500
I0818 13:44:37.171838 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_3_b
I0818 13:44:37.171849 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_3_b
I0818 13:44:37.171855 22726 net.cpp:434] relu_sum_bn_Conv16_3_b <- sum_bn_Conv16_3_b
I0818 13:44:37.171862 22726 net.cpp:395] relu_sum_bn_Conv16_3_b -> sum_bn_Conv16_3_b (in-place)
I0818 13:44:37.171871 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_3_b
I0818 13:44:37.171878 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.171882 22726 net.cpp:165] Memory required for data: 304641500
I0818 13:44:37.171887 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split
I0818 13:44:37.171905 22726 net.cpp:100] Creating Layer sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split
I0818 13:44:37.171911 22726 net.cpp:434] sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split <- sum_bn_Conv16_3_b
I0818 13:44:37.171924 22726 net.cpp:408] sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split -> sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split_0
I0818 13:44:37.171933 22726 net.cpp:408] sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split -> sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split_1
I0818 13:44:37.171977 22726 net.cpp:150] Setting up sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split
I0818 13:44:37.171995 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.172003 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.172008 22726 net.cpp:165] Memory required for data: 321025500
I0818 13:44:37.172013 22726 layer_factory.hpp:77] Creating layer Conv16_4
I0818 13:44:37.172022 22726 net.cpp:100] Creating Layer Conv16_4
I0818 13:44:37.172029 22726 net.cpp:434] Conv16_4 <- sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split_0
I0818 13:44:37.172037 22726 net.cpp:408] Conv16_4 -> Conv16_4
I0818 13:44:37.172354 22726 net.cpp:150] Setting up Conv16_4
I0818 13:44:37.172369 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.172374 22726 net.cpp:165] Memory required for data: 329217500
I0818 13:44:37.172382 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_4
I0818 13:44:37.172394 22726 net.cpp:100] Creating Layer batchNorm_Conv16_4
I0818 13:44:37.172399 22726 net.cpp:434] batchNorm_Conv16_4 <- Conv16_4
I0818 13:44:37.172407 22726 net.cpp:408] batchNorm_Conv16_4 -> bn_Conv16_4
I0818 13:44:37.172643 22726 net.cpp:150] Setting up batchNorm_Conv16_4
I0818 13:44:37.172657 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.172662 22726 net.cpp:165] Memory required for data: 337409500
I0818 13:44:37.172672 22726 layer_factory.hpp:77] Creating layer scale_Conv16_4
I0818 13:44:37.172679 22726 net.cpp:100] Creating Layer scale_Conv16_4
I0818 13:44:37.172685 22726 net.cpp:434] scale_Conv16_4 <- bn_Conv16_4
I0818 13:44:37.172696 22726 net.cpp:395] scale_Conv16_4 -> bn_Conv16_4 (in-place)
I0818 13:44:37.172749 22726 layer_factory.hpp:77] Creating layer scale_Conv16_4
I0818 13:44:37.172897 22726 net.cpp:150] Setting up scale_Conv16_4
I0818 13:44:37.172912 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.172917 22726 net.cpp:165] Memory required for data: 345601500
I0818 13:44:37.172926 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_4
I0818 13:44:37.172935 22726 net.cpp:100] Creating Layer relu_bn_Conv16_4
I0818 13:44:37.172940 22726 net.cpp:434] relu_bn_Conv16_4 <- bn_Conv16_4
I0818 13:44:37.172947 22726 net.cpp:395] relu_bn_Conv16_4 -> bn_Conv16_4 (in-place)
I0818 13:44:37.172956 22726 net.cpp:150] Setting up relu_bn_Conv16_4
I0818 13:44:37.172963 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.172967 22726 net.cpp:165] Memory required for data: 353793500
I0818 13:44:37.172972 22726 layer_factory.hpp:77] Creating layer Conv16_4_b
I0818 13:44:37.172986 22726 net.cpp:100] Creating Layer Conv16_4_b
I0818 13:44:37.172991 22726 net.cpp:434] Conv16_4_b <- bn_Conv16_4
I0818 13:44:37.173003 22726 net.cpp:408] Conv16_4_b -> Conv16_4_b
I0818 13:44:37.173317 22726 net.cpp:150] Setting up Conv16_4_b
I0818 13:44:37.173331 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.173336 22726 net.cpp:165] Memory required for data: 361985500
I0818 13:44:37.173344 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_4_b
I0818 13:44:37.173355 22726 net.cpp:100] Creating Layer batchNorm_Conv16_4_b
I0818 13:44:37.173362 22726 net.cpp:434] batchNorm_Conv16_4_b <- Conv16_4_b
I0818 13:44:37.173372 22726 net.cpp:408] batchNorm_Conv16_4_b -> bn_Conv16_4_b
I0818 13:44:37.173610 22726 net.cpp:150] Setting up batchNorm_Conv16_4_b
I0818 13:44:37.173624 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.173629 22726 net.cpp:165] Memory required for data: 370177500
I0818 13:44:37.173640 22726 layer_factory.hpp:77] Creating layer scale_Conv16_4_b
I0818 13:44:37.173647 22726 net.cpp:100] Creating Layer scale_Conv16_4_b
I0818 13:44:37.173653 22726 net.cpp:434] scale_Conv16_4_b <- bn_Conv16_4_b
I0818 13:44:37.173671 22726 net.cpp:395] scale_Conv16_4_b -> bn_Conv16_4_b (in-place)
I0818 13:44:37.173724 22726 layer_factory.hpp:77] Creating layer scale_Conv16_4_b
I0818 13:44:37.173872 22726 net.cpp:150] Setting up scale_Conv16_4_b
I0818 13:44:37.173887 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.173892 22726 net.cpp:165] Memory required for data: 378369500
I0818 13:44:37.173900 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_3_b
I0818 13:44:37.173909 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_3_b
I0818 13:44:37.173914 22726 net.cpp:434] sum_sum_bn_Conv16_3_b <- sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split_1
I0818 13:44:37.173921 22726 net.cpp:434] sum_sum_bn_Conv16_3_b <- bn_Conv16_4_b
I0818 13:44:37.173933 22726 net.cpp:408] sum_sum_bn_Conv16_3_b -> sum_bn_Conv16_4_b
I0818 13:44:37.173964 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_3_b
I0818 13:44:37.173976 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.173981 22726 net.cpp:165] Memory required for data: 386561500
I0818 13:44:37.173986 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_4_b
I0818 13:44:37.173993 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_4_b
I0818 13:44:37.174000 22726 net.cpp:434] relu_sum_bn_Conv16_4_b <- sum_bn_Conv16_4_b
I0818 13:44:37.174006 22726 net.cpp:395] relu_sum_bn_Conv16_4_b -> sum_bn_Conv16_4_b (in-place)
I0818 13:44:37.174015 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_4_b
I0818 13:44:37.174021 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.174026 22726 net.cpp:165] Memory required for data: 394753500
I0818 13:44:37.174031 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split
I0818 13:44:37.174042 22726 net.cpp:100] Creating Layer sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split
I0818 13:44:37.174047 22726 net.cpp:434] sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split <- sum_bn_Conv16_4_b
I0818 13:44:37.174054 22726 net.cpp:408] sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split -> sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split_0
I0818 13:44:37.174064 22726 net.cpp:408] sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split -> sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split_1
I0818 13:44:37.174105 22726 net.cpp:150] Setting up sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split
I0818 13:44:37.174120 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.174126 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.174131 22726 net.cpp:165] Memory required for data: 411137500
I0818 13:44:37.174136 22726 layer_factory.hpp:77] Creating layer Conv16_5
I0818 13:44:37.174147 22726 net.cpp:100] Creating Layer Conv16_5
I0818 13:44:37.174152 22726 net.cpp:434] Conv16_5 <- sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split_0
I0818 13:44:37.174161 22726 net.cpp:408] Conv16_5 -> Conv16_5
I0818 13:44:37.174474 22726 net.cpp:150] Setting up Conv16_5
I0818 13:44:37.174487 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.174492 22726 net.cpp:165] Memory required for data: 419329500
I0818 13:44:37.174515 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_5
I0818 13:44:37.174525 22726 net.cpp:100] Creating Layer batchNorm_Conv16_5
I0818 13:44:37.174531 22726 net.cpp:434] batchNorm_Conv16_5 <- Conv16_5
I0818 13:44:37.174540 22726 net.cpp:408] batchNorm_Conv16_5 -> bn_Conv16_5
I0818 13:44:37.174787 22726 net.cpp:150] Setting up batchNorm_Conv16_5
I0818 13:44:37.174799 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.174804 22726 net.cpp:165] Memory required for data: 427521500
I0818 13:44:37.174821 22726 layer_factory.hpp:77] Creating layer scale_Conv16_5
I0818 13:44:37.174830 22726 net.cpp:100] Creating Layer scale_Conv16_5
I0818 13:44:37.174835 22726 net.cpp:434] scale_Conv16_5 <- bn_Conv16_5
I0818 13:44:37.174846 22726 net.cpp:395] scale_Conv16_5 -> bn_Conv16_5 (in-place)
I0818 13:44:37.174901 22726 layer_factory.hpp:77] Creating layer scale_Conv16_5
I0818 13:44:37.175040 22726 net.cpp:150] Setting up scale_Conv16_5
I0818 13:44:37.175055 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.175066 22726 net.cpp:165] Memory required for data: 435713500
I0818 13:44:37.175076 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_5
I0818 13:44:37.175083 22726 net.cpp:100] Creating Layer relu_bn_Conv16_5
I0818 13:44:37.175089 22726 net.cpp:434] relu_bn_Conv16_5 <- bn_Conv16_5
I0818 13:44:37.175096 22726 net.cpp:395] relu_bn_Conv16_5 -> bn_Conv16_5 (in-place)
I0818 13:44:37.175106 22726 net.cpp:150] Setting up relu_bn_Conv16_5
I0818 13:44:37.175112 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.175117 22726 net.cpp:165] Memory required for data: 443905500
I0818 13:44:37.175122 22726 layer_factory.hpp:77] Creating layer Conv16_5_b
I0818 13:44:37.175135 22726 net.cpp:100] Creating Layer Conv16_5_b
I0818 13:44:37.175142 22726 net.cpp:434] Conv16_5_b <- bn_Conv16_5
I0818 13:44:37.175153 22726 net.cpp:408] Conv16_5_b -> Conv16_5_b
I0818 13:44:37.175465 22726 net.cpp:150] Setting up Conv16_5_b
I0818 13:44:37.175479 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.175484 22726 net.cpp:165] Memory required for data: 452097500
I0818 13:44:37.175493 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_5_b
I0818 13:44:37.175508 22726 net.cpp:100] Creating Layer batchNorm_Conv16_5_b
I0818 13:44:37.175514 22726 net.cpp:434] batchNorm_Conv16_5_b <- Conv16_5_b
I0818 13:44:37.175524 22726 net.cpp:408] batchNorm_Conv16_5_b -> bn_Conv16_5_b
I0818 13:44:37.175760 22726 net.cpp:150] Setting up batchNorm_Conv16_5_b
I0818 13:44:37.175772 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.175777 22726 net.cpp:165] Memory required for data: 460289500
I0818 13:44:37.175788 22726 layer_factory.hpp:77] Creating layer scale_Conv16_5_b
I0818 13:44:37.175796 22726 net.cpp:100] Creating Layer scale_Conv16_5_b
I0818 13:44:37.175802 22726 net.cpp:434] scale_Conv16_5_b <- bn_Conv16_5_b
I0818 13:44:37.175815 22726 net.cpp:395] scale_Conv16_5_b -> bn_Conv16_5_b (in-place)
I0818 13:44:37.175873 22726 layer_factory.hpp:77] Creating layer scale_Conv16_5_b
I0818 13:44:37.176013 22726 net.cpp:150] Setting up scale_Conv16_5_b
I0818 13:44:37.176026 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.176031 22726 net.cpp:165] Memory required for data: 468481500
I0818 13:44:37.176040 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_4_b
I0818 13:44:37.176054 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_4_b
I0818 13:44:37.176060 22726 net.cpp:434] sum_sum_bn_Conv16_4_b <- sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split_1
I0818 13:44:37.176067 22726 net.cpp:434] sum_sum_bn_Conv16_4_b <- bn_Conv16_5_b
I0818 13:44:37.176075 22726 net.cpp:408] sum_sum_bn_Conv16_4_b -> sum_bn_Conv16_5_b
I0818 13:44:37.176110 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_4_b
I0818 13:44:37.176120 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.176126 22726 net.cpp:165] Memory required for data: 476673500
I0818 13:44:37.176131 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_5_b
I0818 13:44:37.176138 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_5_b
I0818 13:44:37.176143 22726 net.cpp:434] relu_sum_bn_Conv16_5_b <- sum_bn_Conv16_5_b
I0818 13:44:37.176153 22726 net.cpp:395] relu_sum_bn_Conv16_5_b -> sum_bn_Conv16_5_b (in-place)
I0818 13:44:37.176162 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_5_b
I0818 13:44:37.176169 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.176173 22726 net.cpp:165] Memory required for data: 484865500
I0818 13:44:37.176178 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split
I0818 13:44:37.176184 22726 net.cpp:100] Creating Layer sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split
I0818 13:44:37.176190 22726 net.cpp:434] sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split <- sum_bn_Conv16_5_b
I0818 13:44:37.176199 22726 net.cpp:408] sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split -> sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split_0
I0818 13:44:37.176209 22726 net.cpp:408] sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split -> sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split_1
I0818 13:44:37.176259 22726 net.cpp:150] Setting up sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split
I0818 13:44:37.176270 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.176275 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.176280 22726 net.cpp:165] Memory required for data: 501249500
I0818 13:44:37.176285 22726 layer_factory.hpp:77] Creating layer Conv16_6
I0818 13:44:37.176300 22726 net.cpp:100] Creating Layer Conv16_6
I0818 13:44:37.176306 22726 net.cpp:434] Conv16_6 <- sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split_0
I0818 13:44:37.176316 22726 net.cpp:408] Conv16_6 -> Conv16_6
I0818 13:44:37.176626 22726 net.cpp:150] Setting up Conv16_6
I0818 13:44:37.176640 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.176645 22726 net.cpp:165] Memory required for data: 509441500
I0818 13:44:37.176653 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_6
I0818 13:44:37.176664 22726 net.cpp:100] Creating Layer batchNorm_Conv16_6
I0818 13:44:37.176671 22726 net.cpp:434] batchNorm_Conv16_6 <- Conv16_6
I0818 13:44:37.176681 22726 net.cpp:408] batchNorm_Conv16_6 -> bn_Conv16_6
I0818 13:44:37.176928 22726 net.cpp:150] Setting up batchNorm_Conv16_6
I0818 13:44:37.176940 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.176945 22726 net.cpp:165] Memory required for data: 517633500
I0818 13:44:37.176955 22726 layer_factory.hpp:77] Creating layer scale_Conv16_6
I0818 13:44:37.176964 22726 net.cpp:100] Creating Layer scale_Conv16_6
I0818 13:44:37.176970 22726 net.cpp:434] scale_Conv16_6 <- bn_Conv16_6
I0818 13:44:37.176977 22726 net.cpp:395] scale_Conv16_6 -> bn_Conv16_6 (in-place)
I0818 13:44:37.177032 22726 layer_factory.hpp:77] Creating layer scale_Conv16_6
I0818 13:44:37.177175 22726 net.cpp:150] Setting up scale_Conv16_6
I0818 13:44:37.177187 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.177192 22726 net.cpp:165] Memory required for data: 525825500
I0818 13:44:37.177201 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_6
I0818 13:44:37.177211 22726 net.cpp:100] Creating Layer relu_bn_Conv16_6
I0818 13:44:37.177217 22726 net.cpp:434] relu_bn_Conv16_6 <- bn_Conv16_6
I0818 13:44:37.177225 22726 net.cpp:395] relu_bn_Conv16_6 -> bn_Conv16_6 (in-place)
I0818 13:44:37.177234 22726 net.cpp:150] Setting up relu_bn_Conv16_6
I0818 13:44:37.177240 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.177245 22726 net.cpp:165] Memory required for data: 534017500
I0818 13:44:37.177249 22726 layer_factory.hpp:77] Creating layer Conv16_6_b
I0818 13:44:37.177263 22726 net.cpp:100] Creating Layer Conv16_6_b
I0818 13:44:37.177269 22726 net.cpp:434] Conv16_6_b <- bn_Conv16_6
I0818 13:44:37.177280 22726 net.cpp:408] Conv16_6_b -> Conv16_6_b
I0818 13:44:37.177601 22726 net.cpp:150] Setting up Conv16_6_b
I0818 13:44:37.177614 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.177619 22726 net.cpp:165] Memory required for data: 542209500
I0818 13:44:37.177628 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_6_b
I0818 13:44:37.177639 22726 net.cpp:100] Creating Layer batchNorm_Conv16_6_b
I0818 13:44:37.177645 22726 net.cpp:434] batchNorm_Conv16_6_b <- Conv16_6_b
I0818 13:44:37.177654 22726 net.cpp:408] batchNorm_Conv16_6_b -> bn_Conv16_6_b
I0818 13:44:37.177902 22726 net.cpp:150] Setting up batchNorm_Conv16_6_b
I0818 13:44:37.177916 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.177920 22726 net.cpp:165] Memory required for data: 550401500
I0818 13:44:37.177930 22726 layer_factory.hpp:77] Creating layer scale_Conv16_6_b
I0818 13:44:37.177939 22726 net.cpp:100] Creating Layer scale_Conv16_6_b
I0818 13:44:37.177945 22726 net.cpp:434] scale_Conv16_6_b <- bn_Conv16_6_b
I0818 13:44:37.177953 22726 net.cpp:395] scale_Conv16_6_b -> bn_Conv16_6_b (in-place)
I0818 13:44:37.178007 22726 layer_factory.hpp:77] Creating layer scale_Conv16_6_b
I0818 13:44:37.178149 22726 net.cpp:150] Setting up scale_Conv16_6_b
I0818 13:44:37.178169 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.178174 22726 net.cpp:165] Memory required for data: 558593500
I0818 13:44:37.178182 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_5_b
I0818 13:44:37.178200 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_5_b
I0818 13:44:37.178206 22726 net.cpp:434] sum_sum_bn_Conv16_5_b <- sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split_1
I0818 13:44:37.178213 22726 net.cpp:434] sum_sum_bn_Conv16_5_b <- bn_Conv16_6_b
I0818 13:44:37.178223 22726 net.cpp:408] sum_sum_bn_Conv16_5_b -> sum_bn_Conv16_6_b
I0818 13:44:37.178256 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_5_b
I0818 13:44:37.178267 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.178272 22726 net.cpp:165] Memory required for data: 566785500
I0818 13:44:37.178277 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_6_b
I0818 13:44:37.178285 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_6_b
I0818 13:44:37.178290 22726 net.cpp:434] relu_sum_bn_Conv16_6_b <- sum_bn_Conv16_6_b
I0818 13:44:37.178297 22726 net.cpp:395] relu_sum_bn_Conv16_6_b -> sum_bn_Conv16_6_b (in-place)
I0818 13:44:37.178306 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_6_b
I0818 13:44:37.178313 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.178318 22726 net.cpp:165] Memory required for data: 574977500
I0818 13:44:37.178323 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split
I0818 13:44:37.178333 22726 net.cpp:100] Creating Layer sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split
I0818 13:44:37.178339 22726 net.cpp:434] sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split <- sum_bn_Conv16_6_b
I0818 13:44:37.178345 22726 net.cpp:408] sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split -> sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split_0
I0818 13:44:37.178354 22726 net.cpp:408] sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split -> sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split_1
I0818 13:44:37.178397 22726 net.cpp:150] Setting up sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split
I0818 13:44:37.178411 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.178418 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.178423 22726 net.cpp:165] Memory required for data: 591361500
I0818 13:44:37.178428 22726 layer_factory.hpp:77] Creating layer Conv16_7
I0818 13:44:37.178439 22726 net.cpp:100] Creating Layer Conv16_7
I0818 13:44:37.178445 22726 net.cpp:434] Conv16_7 <- sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split_0
I0818 13:44:37.178454 22726 net.cpp:408] Conv16_7 -> Conv16_7
I0818 13:44:37.178768 22726 net.cpp:150] Setting up Conv16_7
I0818 13:44:37.178781 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.178786 22726 net.cpp:165] Memory required for data: 599553500
I0818 13:44:37.178795 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_7
I0818 13:44:37.178807 22726 net.cpp:100] Creating Layer batchNorm_Conv16_7
I0818 13:44:37.178818 22726 net.cpp:434] batchNorm_Conv16_7 <- Conv16_7
I0818 13:44:37.178828 22726 net.cpp:408] batchNorm_Conv16_7 -> bn_Conv16_7
I0818 13:44:37.179083 22726 net.cpp:150] Setting up batchNorm_Conv16_7
I0818 13:44:37.179096 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.179101 22726 net.cpp:165] Memory required for data: 607745500
I0818 13:44:37.179111 22726 layer_factory.hpp:77] Creating layer scale_Conv16_7
I0818 13:44:37.179121 22726 net.cpp:100] Creating Layer scale_Conv16_7
I0818 13:44:37.179126 22726 net.cpp:434] scale_Conv16_7 <- bn_Conv16_7
I0818 13:44:37.179136 22726 net.cpp:395] scale_Conv16_7 -> bn_Conv16_7 (in-place)
I0818 13:44:37.179190 22726 layer_factory.hpp:77] Creating layer scale_Conv16_7
I0818 13:44:37.179332 22726 net.cpp:150] Setting up scale_Conv16_7
I0818 13:44:37.179345 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.179349 22726 net.cpp:165] Memory required for data: 615937500
I0818 13:44:37.179358 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_7
I0818 13:44:37.179368 22726 net.cpp:100] Creating Layer relu_bn_Conv16_7
I0818 13:44:37.179381 22726 net.cpp:434] relu_bn_Conv16_7 <- bn_Conv16_7
I0818 13:44:37.179389 22726 net.cpp:395] relu_bn_Conv16_7 -> bn_Conv16_7 (in-place)
I0818 13:44:37.179399 22726 net.cpp:150] Setting up relu_bn_Conv16_7
I0818 13:44:37.179405 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.179409 22726 net.cpp:165] Memory required for data: 624129500
I0818 13:44:37.179414 22726 layer_factory.hpp:77] Creating layer Conv16_7_b
I0818 13:44:37.179428 22726 net.cpp:100] Creating Layer Conv16_7_b
I0818 13:44:37.179435 22726 net.cpp:434] Conv16_7_b <- bn_Conv16_7
I0818 13:44:37.179445 22726 net.cpp:408] Conv16_7_b -> Conv16_7_b
I0818 13:44:37.179761 22726 net.cpp:150] Setting up Conv16_7_b
I0818 13:44:37.179775 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.179780 22726 net.cpp:165] Memory required for data: 632321500
I0818 13:44:37.179788 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_7_b
I0818 13:44:37.179800 22726 net.cpp:100] Creating Layer batchNorm_Conv16_7_b
I0818 13:44:37.179806 22726 net.cpp:434] batchNorm_Conv16_7_b <- Conv16_7_b
I0818 13:44:37.179824 22726 net.cpp:408] batchNorm_Conv16_7_b -> bn_Conv16_7_b
I0818 13:44:37.180066 22726 net.cpp:150] Setting up batchNorm_Conv16_7_b
I0818 13:44:37.180079 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.180083 22726 net.cpp:165] Memory required for data: 640513500
I0818 13:44:37.180094 22726 layer_factory.hpp:77] Creating layer scale_Conv16_7_b
I0818 13:44:37.180102 22726 net.cpp:100] Creating Layer scale_Conv16_7_b
I0818 13:44:37.180109 22726 net.cpp:434] scale_Conv16_7_b <- bn_Conv16_7_b
I0818 13:44:37.180116 22726 net.cpp:395] scale_Conv16_7_b -> bn_Conv16_7_b (in-place)
I0818 13:44:37.180171 22726 layer_factory.hpp:77] Creating layer scale_Conv16_7_b
I0818 13:44:37.180311 22726 net.cpp:150] Setting up scale_Conv16_7_b
I0818 13:44:37.180323 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.180328 22726 net.cpp:165] Memory required for data: 648705500
I0818 13:44:37.180337 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_6_b
I0818 13:44:37.180349 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_6_b
I0818 13:44:37.180356 22726 net.cpp:434] sum_sum_bn_Conv16_6_b <- sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split_1
I0818 13:44:37.180363 22726 net.cpp:434] sum_sum_bn_Conv16_6_b <- bn_Conv16_7_b
I0818 13:44:37.180371 22726 net.cpp:408] sum_sum_bn_Conv16_6_b -> sum_bn_Conv16_7_b
I0818 13:44:37.180408 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_6_b
I0818 13:44:37.180419 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.180424 22726 net.cpp:165] Memory required for data: 656897500
I0818 13:44:37.180429 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_7_b
I0818 13:44:37.180438 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_7_b
I0818 13:44:37.180443 22726 net.cpp:434] relu_sum_bn_Conv16_7_b <- sum_bn_Conv16_7_b
I0818 13:44:37.180452 22726 net.cpp:395] relu_sum_bn_Conv16_7_b -> sum_bn_Conv16_7_b (in-place)
I0818 13:44:37.180462 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_7_b
I0818 13:44:37.180469 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.180474 22726 net.cpp:165] Memory required for data: 665089500
I0818 13:44:37.180477 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split
I0818 13:44:37.180485 22726 net.cpp:100] Creating Layer sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split
I0818 13:44:37.180490 22726 net.cpp:434] sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split <- sum_bn_Conv16_7_b
I0818 13:44:37.180500 22726 net.cpp:408] sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split -> sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split_0
I0818 13:44:37.180510 22726 net.cpp:408] sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split -> sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split_1
I0818 13:44:37.180552 22726 net.cpp:150] Setting up sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split
I0818 13:44:37.180563 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.180577 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.180582 22726 net.cpp:165] Memory required for data: 681473500
I0818 13:44:37.180586 22726 layer_factory.hpp:77] Creating layer Conv16_8
I0818 13:44:37.180600 22726 net.cpp:100] Creating Layer Conv16_8
I0818 13:44:37.180606 22726 net.cpp:434] Conv16_8 <- sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split_0
I0818 13:44:37.180616 22726 net.cpp:408] Conv16_8 -> Conv16_8
I0818 13:44:37.180948 22726 net.cpp:150] Setting up Conv16_8
I0818 13:44:37.180963 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.180968 22726 net.cpp:165] Memory required for data: 689665500
I0818 13:44:37.180976 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_8
I0818 13:44:37.180985 22726 net.cpp:100] Creating Layer batchNorm_Conv16_8
I0818 13:44:37.180991 22726 net.cpp:434] batchNorm_Conv16_8 <- Conv16_8
I0818 13:44:37.181005 22726 net.cpp:408] batchNorm_Conv16_8 -> bn_Conv16_8
I0818 13:44:37.181249 22726 net.cpp:150] Setting up batchNorm_Conv16_8
I0818 13:44:37.181262 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.181267 22726 net.cpp:165] Memory required for data: 697857500
I0818 13:44:37.181277 22726 layer_factory.hpp:77] Creating layer scale_Conv16_8
I0818 13:44:37.181287 22726 net.cpp:100] Creating Layer scale_Conv16_8
I0818 13:44:37.181291 22726 net.cpp:434] scale_Conv16_8 <- bn_Conv16_8
I0818 13:44:37.181303 22726 net.cpp:395] scale_Conv16_8 -> bn_Conv16_8 (in-place)
I0818 13:44:37.181355 22726 layer_factory.hpp:77] Creating layer scale_Conv16_8
I0818 13:44:37.181494 22726 net.cpp:150] Setting up scale_Conv16_8
I0818 13:44:37.181509 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.181514 22726 net.cpp:165] Memory required for data: 706049500
I0818 13:44:37.181524 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_8
I0818 13:44:37.181531 22726 net.cpp:100] Creating Layer relu_bn_Conv16_8
I0818 13:44:37.181537 22726 net.cpp:434] relu_bn_Conv16_8 <- bn_Conv16_8
I0818 13:44:37.181545 22726 net.cpp:395] relu_bn_Conv16_8 -> bn_Conv16_8 (in-place)
I0818 13:44:37.181553 22726 net.cpp:150] Setting up relu_bn_Conv16_8
I0818 13:44:37.181560 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.181565 22726 net.cpp:165] Memory required for data: 714241500
I0818 13:44:37.181569 22726 layer_factory.hpp:77] Creating layer Conv16_8_b
I0818 13:44:37.181584 22726 net.cpp:100] Creating Layer Conv16_8_b
I0818 13:44:37.181591 22726 net.cpp:434] Conv16_8_b <- bn_Conv16_8
I0818 13:44:37.181602 22726 net.cpp:408] Conv16_8_b -> Conv16_8_b
I0818 13:44:37.181929 22726 net.cpp:150] Setting up Conv16_8_b
I0818 13:44:37.181943 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.181948 22726 net.cpp:165] Memory required for data: 722433500
I0818 13:44:37.181957 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_8_b
I0818 13:44:37.181968 22726 net.cpp:100] Creating Layer batchNorm_Conv16_8_b
I0818 13:44:37.181974 22726 net.cpp:434] batchNorm_Conv16_8_b <- Conv16_8_b
I0818 13:44:37.181983 22726 net.cpp:408] batchNorm_Conv16_8_b -> bn_Conv16_8_b
I0818 13:44:37.182268 22726 net.cpp:150] Setting up batchNorm_Conv16_8_b
I0818 13:44:37.182282 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.182287 22726 net.cpp:165] Memory required for data: 730625500
I0818 13:44:37.182297 22726 layer_factory.hpp:77] Creating layer scale_Conv16_8_b
I0818 13:44:37.182307 22726 net.cpp:100] Creating Layer scale_Conv16_8_b
I0818 13:44:37.182312 22726 net.cpp:434] scale_Conv16_8_b <- bn_Conv16_8_b
I0818 13:44:37.182319 22726 net.cpp:395] scale_Conv16_8_b -> bn_Conv16_8_b (in-place)
I0818 13:44:37.182382 22726 layer_factory.hpp:77] Creating layer scale_Conv16_8_b
I0818 13:44:37.182524 22726 net.cpp:150] Setting up scale_Conv16_8_b
I0818 13:44:37.182538 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.182543 22726 net.cpp:165] Memory required for data: 738817500
I0818 13:44:37.182551 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_7_b
I0818 13:44:37.182567 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_7_b
I0818 13:44:37.182576 22726 net.cpp:434] sum_sum_bn_Conv16_7_b <- sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split_1
I0818 13:44:37.182585 22726 net.cpp:434] sum_sum_bn_Conv16_7_b <- bn_Conv16_8_b
I0818 13:44:37.182591 22726 net.cpp:408] sum_sum_bn_Conv16_7_b -> sum_bn_Conv16_8_b
I0818 13:44:37.182624 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_7_b
I0818 13:44:37.182636 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.182641 22726 net.cpp:165] Memory required for data: 747009500
I0818 13:44:37.182646 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_8_b
I0818 13:44:37.182657 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_8_b
I0818 13:44:37.182662 22726 net.cpp:434] relu_sum_bn_Conv16_8_b <- sum_bn_Conv16_8_b
I0818 13:44:37.182672 22726 net.cpp:395] relu_sum_bn_Conv16_8_b -> sum_bn_Conv16_8_b (in-place)
I0818 13:44:37.182682 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_8_b
I0818 13:44:37.182688 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.182693 22726 net.cpp:165] Memory required for data: 755201500
I0818 13:44:37.182698 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split
I0818 13:44:37.182704 22726 net.cpp:100] Creating Layer sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split
I0818 13:44:37.182709 22726 net.cpp:434] sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split <- sum_bn_Conv16_8_b
I0818 13:44:37.182716 22726 net.cpp:408] sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split -> sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split_0
I0818 13:44:37.182725 22726 net.cpp:408] sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split -> sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split_1
I0818 13:44:37.182773 22726 net.cpp:150] Setting up sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split
I0818 13:44:37.182785 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.182790 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.182796 22726 net.cpp:165] Memory required for data: 771585500
I0818 13:44:37.182801 22726 layer_factory.hpp:77] Creating layer Conv16_9
I0818 13:44:37.182821 22726 net.cpp:100] Creating Layer Conv16_9
I0818 13:44:37.182827 22726 net.cpp:434] Conv16_9 <- sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split_0
I0818 13:44:37.182837 22726 net.cpp:408] Conv16_9 -> Conv16_9
I0818 13:44:37.183164 22726 net.cpp:150] Setting up Conv16_9
I0818 13:44:37.183182 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.183187 22726 net.cpp:165] Memory required for data: 779777500
I0818 13:44:37.183195 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_9
I0818 13:44:37.183205 22726 net.cpp:100] Creating Layer batchNorm_Conv16_9
I0818 13:44:37.183210 22726 net.cpp:434] batchNorm_Conv16_9 <- Conv16_9
I0818 13:44:37.183219 22726 net.cpp:408] batchNorm_Conv16_9 -> bn_Conv16_9
I0818 13:44:37.183465 22726 net.cpp:150] Setting up batchNorm_Conv16_9
I0818 13:44:37.183478 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.183482 22726 net.cpp:165] Memory required for data: 787969500
I0818 13:44:37.183493 22726 layer_factory.hpp:77] Creating layer scale_Conv16_9
I0818 13:44:37.183507 22726 net.cpp:100] Creating Layer scale_Conv16_9
I0818 13:44:37.183513 22726 net.cpp:434] scale_Conv16_9 <- bn_Conv16_9
I0818 13:44:37.183521 22726 net.cpp:395] scale_Conv16_9 -> bn_Conv16_9 (in-place)
I0818 13:44:37.183576 22726 layer_factory.hpp:77] Creating layer scale_Conv16_9
I0818 13:44:37.183722 22726 net.cpp:150] Setting up scale_Conv16_9
I0818 13:44:37.183734 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.183739 22726 net.cpp:165] Memory required for data: 796161500
I0818 13:44:37.183748 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_9
I0818 13:44:37.183756 22726 net.cpp:100] Creating Layer relu_bn_Conv16_9
I0818 13:44:37.183761 22726 net.cpp:434] relu_bn_Conv16_9 <- bn_Conv16_9
I0818 13:44:37.183773 22726 net.cpp:395] relu_bn_Conv16_9 -> bn_Conv16_9 (in-place)
I0818 13:44:37.183781 22726 net.cpp:150] Setting up relu_bn_Conv16_9
I0818 13:44:37.183794 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.183799 22726 net.cpp:165] Memory required for data: 804353500
I0818 13:44:37.183804 22726 layer_factory.hpp:77] Creating layer Conv16_9_b
I0818 13:44:37.183825 22726 net.cpp:100] Creating Layer Conv16_9_b
I0818 13:44:37.183831 22726 net.cpp:434] Conv16_9_b <- bn_Conv16_9
I0818 13:44:37.183840 22726 net.cpp:408] Conv16_9_b -> Conv16_9_b
I0818 13:44:37.184165 22726 net.cpp:150] Setting up Conv16_9_b
I0818 13:44:37.184178 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.184182 22726 net.cpp:165] Memory required for data: 812545500
I0818 13:44:37.184191 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_9_b
I0818 13:44:37.184202 22726 net.cpp:100] Creating Layer batchNorm_Conv16_9_b
I0818 13:44:37.184208 22726 net.cpp:434] batchNorm_Conv16_9_b <- Conv16_9_b
I0818 13:44:37.184217 22726 net.cpp:408] batchNorm_Conv16_9_b -> bn_Conv16_9_b
I0818 13:44:37.184460 22726 net.cpp:150] Setting up batchNorm_Conv16_9_b
I0818 13:44:37.184473 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.184478 22726 net.cpp:165] Memory required for data: 820737500
I0818 13:44:37.184509 22726 layer_factory.hpp:77] Creating layer scale_Conv16_9_b
I0818 13:44:37.184521 22726 net.cpp:100] Creating Layer scale_Conv16_9_b
I0818 13:44:37.184527 22726 net.cpp:434] scale_Conv16_9_b <- bn_Conv16_9_b
I0818 13:44:37.184535 22726 net.cpp:395] scale_Conv16_9_b -> bn_Conv16_9_b (in-place)
I0818 13:44:37.184592 22726 layer_factory.hpp:77] Creating layer scale_Conv16_9_b
I0818 13:44:37.184732 22726 net.cpp:150] Setting up scale_Conv16_9_b
I0818 13:44:37.184746 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.184751 22726 net.cpp:165] Memory required for data: 828929500
I0818 13:44:37.184758 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_8_b
I0818 13:44:37.184767 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_8_b
I0818 13:44:37.184774 22726 net.cpp:434] sum_sum_bn_Conv16_8_b <- sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split_1
I0818 13:44:37.184782 22726 net.cpp:434] sum_sum_bn_Conv16_8_b <- bn_Conv16_9_b
I0818 13:44:37.184788 22726 net.cpp:408] sum_sum_bn_Conv16_8_b -> sum_bn_Conv16_9_b
I0818 13:44:37.184834 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_8_b
I0818 13:44:37.184845 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.184850 22726 net.cpp:165] Memory required for data: 837121500
I0818 13:44:37.184855 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_9_b
I0818 13:44:37.184864 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_9_b
I0818 13:44:37.184869 22726 net.cpp:434] relu_sum_bn_Conv16_9_b <- sum_bn_Conv16_9_b
I0818 13:44:37.184878 22726 net.cpp:395] relu_sum_bn_Conv16_9_b -> sum_bn_Conv16_9_b (in-place)
I0818 13:44:37.184888 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_9_b
I0818 13:44:37.184895 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.184900 22726 net.cpp:165] Memory required for data: 845313500
I0818 13:44:37.184906 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split
I0818 13:44:37.184911 22726 net.cpp:100] Creating Layer sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split
I0818 13:44:37.184916 22726 net.cpp:434] sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split <- sum_bn_Conv16_9_b
I0818 13:44:37.184926 22726 net.cpp:408] sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split -> sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split_0
I0818 13:44:37.184937 22726 net.cpp:408] sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split -> sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split_1
I0818 13:44:37.184980 22726 net.cpp:150] Setting up sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split
I0818 13:44:37.184991 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.184998 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.185003 22726 net.cpp:165] Memory required for data: 861697500
I0818 13:44:37.185008 22726 layer_factory.hpp:77] Creating layer resblk32
I0818 13:44:37.185029 22726 net.cpp:100] Creating Layer resblk32
I0818 13:44:37.185036 22726 net.cpp:434] resblk32 <- sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split_0
I0818 13:44:37.185045 22726 net.cpp:408] resblk32 -> resblk32
I0818 13:44:37.185369 22726 net.cpp:150] Setting up resblk32
I0818 13:44:37.185382 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.185387 22726 net.cpp:165] Memory required for data: 863745500
I0818 13:44:37.185395 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32
I0818 13:44:37.185405 22726 net.cpp:100] Creating Layer batchNorm_resblk32
I0818 13:44:37.185413 22726 net.cpp:434] batchNorm_resblk32 <- resblk32
I0818 13:44:37.185421 22726 net.cpp:408] batchNorm_resblk32 -> bn_resblk32
I0818 13:44:37.185657 22726 net.cpp:150] Setting up batchNorm_resblk32
I0818 13:44:37.185669 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.185674 22726 net.cpp:165] Memory required for data: 865793500
I0818 13:44:37.185684 22726 layer_factory.hpp:77] Creating layer scale_resblk32
I0818 13:44:37.185693 22726 net.cpp:100] Creating Layer scale_resblk32
I0818 13:44:37.185698 22726 net.cpp:434] scale_resblk32 <- bn_resblk32
I0818 13:44:37.185706 22726 net.cpp:395] scale_resblk32 -> bn_resblk32 (in-place)
I0818 13:44:37.185763 22726 layer_factory.hpp:77] Creating layer scale_resblk32
I0818 13:44:37.185912 22726 net.cpp:150] Setting up scale_resblk32
I0818 13:44:37.185928 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.185933 22726 net.cpp:165] Memory required for data: 867841500
I0818 13:44:37.185942 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32
I0818 13:44:37.185950 22726 net.cpp:100] Creating Layer relu_bn_resblk32
I0818 13:44:37.185956 22726 net.cpp:434] relu_bn_resblk32 <- bn_resblk32
I0818 13:44:37.185963 22726 net.cpp:395] relu_bn_resblk32 -> bn_resblk32 (in-place)
I0818 13:44:37.185972 22726 net.cpp:150] Setting up relu_bn_resblk32
I0818 13:44:37.185978 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.185983 22726 net.cpp:165] Memory required for data: 869889500
I0818 13:44:37.185987 22726 layer_factory.hpp:77] Creating layer resblk32_b
I0818 13:44:37.186002 22726 net.cpp:100] Creating Layer resblk32_b
I0818 13:44:37.186007 22726 net.cpp:434] resblk32_b <- bn_resblk32
I0818 13:44:37.186017 22726 net.cpp:408] resblk32_b -> resblk32_b
I0818 13:44:37.186341 22726 net.cpp:150] Setting up resblk32_b
I0818 13:44:37.186354 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.186358 22726 net.cpp:165] Memory required for data: 871937500
I0818 13:44:37.186367 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_b
I0818 13:44:37.186379 22726 net.cpp:100] Creating Layer batchNorm_resblk32_b
I0818 13:44:37.186385 22726 net.cpp:434] batchNorm_resblk32_b <- resblk32_b
I0818 13:44:37.186399 22726 net.cpp:408] batchNorm_resblk32_b -> bn_resblk32_b
I0818 13:44:37.186643 22726 net.cpp:150] Setting up batchNorm_resblk32_b
I0818 13:44:37.186656 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.186661 22726 net.cpp:165] Memory required for data: 873985500
I0818 13:44:37.186671 22726 layer_factory.hpp:77] Creating layer scale_resblk32_b
I0818 13:44:37.186679 22726 net.cpp:100] Creating Layer scale_resblk32_b
I0818 13:44:37.186686 22726 net.cpp:434] scale_resblk32_b <- bn_resblk32_b
I0818 13:44:37.186693 22726 net.cpp:395] scale_resblk32_b -> bn_resblk32_b (in-place)
I0818 13:44:37.186750 22726 layer_factory.hpp:77] Creating layer scale_resblk32_b
I0818 13:44:37.186900 22726 net.cpp:150] Setting up scale_resblk32_b
I0818 13:44:37.186913 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.186918 22726 net.cpp:165] Memory required for data: 876033500
I0818 13:44:37.186928 22726 layer_factory.hpp:77] Creating layer avePooling_resblk32
I0818 13:44:37.186940 22726 net.cpp:100] Creating Layer avePooling_resblk32
I0818 13:44:37.186947 22726 net.cpp:434] avePooling_resblk32 <- sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split_1
I0818 13:44:37.186955 22726 net.cpp:408] avePooling_resblk32 -> avgPool_resblk32
I0818 13:44:37.187046 22726 net.cpp:150] Setting up avePooling_resblk32
I0818 13:44:37.187062 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.187067 22726 net.cpp:165] Memory required for data: 878081500
I0818 13:44:37.187072 22726 layer_factory.hpp:77] Creating layer sum_avgPool_resblk32
I0818 13:44:37.187086 22726 net.cpp:100] Creating Layer sum_avgPool_resblk32
I0818 13:44:37.187093 22726 net.cpp:434] sum_avgPool_resblk32 <- avgPool_resblk32
I0818 13:44:37.187099 22726 net.cpp:434] sum_avgPool_resblk32 <- bn_resblk32_b
I0818 13:44:37.187108 22726 net.cpp:408] sum_avgPool_resblk32 -> sum_bn_resblk32_b
I0818 13:44:37.187141 22726 net.cpp:150] Setting up sum_avgPool_resblk32
I0818 13:44:37.187153 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.187158 22726 net.cpp:165] Memory required for data: 880129500
I0818 13:44:37.187163 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_b
I0818 13:44:37.187173 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_b
I0818 13:44:37.187180 22726 net.cpp:434] relu_sum_bn_resblk32_b <- sum_bn_resblk32_b
I0818 13:44:37.187186 22726 net.cpp:395] relu_sum_bn_resblk32_b -> sum_bn_resblk32_b (in-place)
I0818 13:44:37.187196 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_b
I0818 13:44:37.187202 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.187207 22726 net.cpp:165] Memory required for data: 882177500
I0818 13:44:37.187211 22726 layer_factory.hpp:77] Creating layer zeros_sum_bn_resblk32_b
I0818 13:44:37.187258 22726 net.cpp:100] Creating Layer zeros_sum_bn_resblk32_b
I0818 13:44:37.187273 22726 net.cpp:408] zeros_sum_bn_resblk32_b -> zeros_sum_bn_resblk32_b
I0818 13:44:37.189713 22726 net.cpp:150] Setting up zeros_sum_bn_resblk32_b
I0818 13:44:37.189735 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.189740 22726 net.cpp:165] Memory required for data: 884225500
I0818 13:44:37.189746 22726 layer_factory.hpp:77] Creating layer CC_sum_bn_resblk32_b
I0818 13:44:37.189759 22726 net.cpp:100] Creating Layer CC_sum_bn_resblk32_b
I0818 13:44:37.189764 22726 net.cpp:434] CC_sum_bn_resblk32_b <- sum_bn_resblk32_b
I0818 13:44:37.189771 22726 net.cpp:434] CC_sum_bn_resblk32_b <- zeros_sum_bn_resblk32_b
I0818 13:44:37.189782 22726 net.cpp:408] CC_sum_bn_resblk32_b -> CC_sum_bn_resblk32_b
I0818 13:44:37.189864 22726 net.cpp:150] Setting up CC_sum_bn_resblk32_b
I0818 13:44:37.189879 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.189884 22726 net.cpp:165] Memory required for data: 888321500
I0818 13:44:37.189890 22726 layer_factory.hpp:77] Creating layer CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split
I0818 13:44:37.189903 22726 net.cpp:100] Creating Layer CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split
I0818 13:44:37.189908 22726 net.cpp:434] CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split <- CC_sum_bn_resblk32_b
I0818 13:44:37.189916 22726 net.cpp:408] CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split -> CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split_0
I0818 13:44:37.189926 22726 net.cpp:408] CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split -> CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split_1
I0818 13:44:37.189977 22726 net.cpp:150] Setting up CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split
I0818 13:44:37.189990 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.189996 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.190001 22726 net.cpp:165] Memory required for data: 896513500
I0818 13:44:37.190006 22726 layer_factory.hpp:77] Creating layer resblk32_1
I0818 13:44:37.190019 22726 net.cpp:100] Creating Layer resblk32_1
I0818 13:44:37.190026 22726 net.cpp:434] resblk32_1 <- CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split_0
I0818 13:44:37.190037 22726 net.cpp:408] resblk32_1 -> resblk32_1
I0818 13:44:37.191506 22726 net.cpp:150] Setting up resblk32_1
I0818 13:44:37.191524 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.191529 22726 net.cpp:165] Memory required for data: 900609500
I0818 13:44:37.191546 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_1
I0818 13:44:37.191556 22726 net.cpp:100] Creating Layer batchNorm_resblk32_1
I0818 13:44:37.191562 22726 net.cpp:434] batchNorm_resblk32_1 <- resblk32_1
I0818 13:44:37.191575 22726 net.cpp:408] batchNorm_resblk32_1 -> bn_resblk32_1
I0818 13:44:37.191833 22726 net.cpp:150] Setting up batchNorm_resblk32_1
I0818 13:44:37.191845 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.191850 22726 net.cpp:165] Memory required for data: 904705500
I0818 13:44:37.191861 22726 layer_factory.hpp:77] Creating layer scale_resblk32_1
I0818 13:44:37.191870 22726 net.cpp:100] Creating Layer scale_resblk32_1
I0818 13:44:37.191876 22726 net.cpp:434] scale_resblk32_1 <- bn_resblk32_1
I0818 13:44:37.191884 22726 net.cpp:395] scale_resblk32_1 -> bn_resblk32_1 (in-place)
I0818 13:44:37.191943 22726 layer_factory.hpp:77] Creating layer scale_resblk32_1
I0818 13:44:37.192090 22726 net.cpp:150] Setting up scale_resblk32_1
I0818 13:44:37.192106 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.192111 22726 net.cpp:165] Memory required for data: 908801500
I0818 13:44:37.192121 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_1
I0818 13:44:37.192129 22726 net.cpp:100] Creating Layer relu_bn_resblk32_1
I0818 13:44:37.192136 22726 net.cpp:434] relu_bn_resblk32_1 <- bn_resblk32_1
I0818 13:44:37.192142 22726 net.cpp:395] relu_bn_resblk32_1 -> bn_resblk32_1 (in-place)
I0818 13:44:37.192152 22726 net.cpp:150] Setting up relu_bn_resblk32_1
I0818 13:44:37.192159 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.192163 22726 net.cpp:165] Memory required for data: 912897500
I0818 13:44:37.192168 22726 layer_factory.hpp:77] Creating layer resblk32_1_b
I0818 13:44:37.192183 22726 net.cpp:100] Creating Layer resblk32_1_b
I0818 13:44:37.192189 22726 net.cpp:434] resblk32_1_b <- bn_resblk32_1
I0818 13:44:37.192200 22726 net.cpp:408] resblk32_1_b -> resblk32_1_b
I0818 13:44:37.192662 22726 net.cpp:150] Setting up resblk32_1_b
I0818 13:44:37.192677 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.192680 22726 net.cpp:165] Memory required for data: 916993500
I0818 13:44:37.192689 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_1_b
I0818 13:44:37.192701 22726 net.cpp:100] Creating Layer batchNorm_resblk32_1_b
I0818 13:44:37.192708 22726 net.cpp:434] batchNorm_resblk32_1_b <- resblk32_1_b
I0818 13:44:37.192715 22726 net.cpp:408] batchNorm_resblk32_1_b -> bn_resblk32_1_b
I0818 13:44:37.192973 22726 net.cpp:150] Setting up batchNorm_resblk32_1_b
I0818 13:44:37.192987 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.192992 22726 net.cpp:165] Memory required for data: 921089500
I0818 13:44:37.193002 22726 layer_factory.hpp:77] Creating layer scale_resblk32_1_b
I0818 13:44:37.193011 22726 net.cpp:100] Creating Layer scale_resblk32_1_b
I0818 13:44:37.193017 22726 net.cpp:434] scale_resblk32_1_b <- bn_resblk32_1_b
I0818 13:44:37.193024 22726 net.cpp:395] scale_resblk32_1_b -> bn_resblk32_1_b (in-place)
I0818 13:44:37.193081 22726 layer_factory.hpp:77] Creating layer scale_resblk32_1_b
I0818 13:44:37.193224 22726 net.cpp:150] Setting up scale_resblk32_1_b
I0818 13:44:37.193236 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.193241 22726 net.cpp:165] Memory required for data: 925185500
I0818 13:44:37.193250 22726 layer_factory.hpp:77] Creating layer sum_CC_sum_bn_resblk32_b
I0818 13:44:37.193262 22726 net.cpp:100] Creating Layer sum_CC_sum_bn_resblk32_b
I0818 13:44:37.193269 22726 net.cpp:434] sum_CC_sum_bn_resblk32_b <- CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split_1
I0818 13:44:37.193275 22726 net.cpp:434] sum_CC_sum_bn_resblk32_b <- bn_resblk32_1_b
I0818 13:44:37.193284 22726 net.cpp:408] sum_CC_sum_bn_resblk32_b -> sum_bn_resblk32_1_b
I0818 13:44:37.193310 22726 net.cpp:150] Setting up sum_CC_sum_bn_resblk32_b
I0818 13:44:37.193320 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.193325 22726 net.cpp:165] Memory required for data: 929281500
I0818 13:44:37.193336 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_1_b
I0818 13:44:37.193347 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_1_b
I0818 13:44:37.193353 22726 net.cpp:434] relu_sum_bn_resblk32_1_b <- sum_bn_resblk32_1_b
I0818 13:44:37.193361 22726 net.cpp:395] relu_sum_bn_resblk32_1_b -> sum_bn_resblk32_1_b (in-place)
I0818 13:44:37.193370 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_1_b
I0818 13:44:37.193377 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.193382 22726 net.cpp:165] Memory required for data: 933377500
I0818 13:44:37.193387 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split
I0818 13:44:37.193393 22726 net.cpp:100] Creating Layer sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split
I0818 13:44:37.193398 22726 net.cpp:434] sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split <- sum_bn_resblk32_1_b
I0818 13:44:37.193405 22726 net.cpp:408] sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split -> sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split_0
I0818 13:44:37.193414 22726 net.cpp:408] sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split -> sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split_1
I0818 13:44:37.193461 22726 net.cpp:150] Setting up sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split
I0818 13:44:37.193473 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.193480 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.193483 22726 net.cpp:165] Memory required for data: 941569500
I0818 13:44:37.193488 22726 layer_factory.hpp:77] Creating layer resblk32_2
I0818 13:44:37.193502 22726 net.cpp:100] Creating Layer resblk32_2
I0818 13:44:37.193508 22726 net.cpp:434] resblk32_2 <- sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split_0
I0818 13:44:37.193517 22726 net.cpp:408] resblk32_2 -> resblk32_2
I0818 13:44:37.193991 22726 net.cpp:150] Setting up resblk32_2
I0818 13:44:37.194005 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.194010 22726 net.cpp:165] Memory required for data: 945665500
I0818 13:44:37.194020 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_2
I0818 13:44:37.194031 22726 net.cpp:100] Creating Layer batchNorm_resblk32_2
I0818 13:44:37.194037 22726 net.cpp:434] batchNorm_resblk32_2 <- resblk32_2
I0818 13:44:37.194048 22726 net.cpp:408] batchNorm_resblk32_2 -> bn_resblk32_2
I0818 13:44:37.194293 22726 net.cpp:150] Setting up batchNorm_resblk32_2
I0818 13:44:37.194306 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.194311 22726 net.cpp:165] Memory required for data: 949761500
I0818 13:44:37.194321 22726 layer_factory.hpp:77] Creating layer scale_resblk32_2
I0818 13:44:37.194330 22726 net.cpp:100] Creating Layer scale_resblk32_2
I0818 13:44:37.194336 22726 net.cpp:434] scale_resblk32_2 <- bn_resblk32_2
I0818 13:44:37.194344 22726 net.cpp:395] scale_resblk32_2 -> bn_resblk32_2 (in-place)
I0818 13:44:37.194401 22726 layer_factory.hpp:77] Creating layer scale_resblk32_2
I0818 13:44:37.194546 22726 net.cpp:150] Setting up scale_resblk32_2
I0818 13:44:37.194558 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.194563 22726 net.cpp:165] Memory required for data: 953857500
I0818 13:44:37.194572 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_2
I0818 13:44:37.194581 22726 net.cpp:100] Creating Layer relu_bn_resblk32_2
I0818 13:44:37.194589 22726 net.cpp:434] relu_bn_resblk32_2 <- bn_resblk32_2
I0818 13:44:37.194597 22726 net.cpp:395] relu_bn_resblk32_2 -> bn_resblk32_2 (in-place)
I0818 13:44:37.194607 22726 net.cpp:150] Setting up relu_bn_resblk32_2
I0818 13:44:37.194612 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.194617 22726 net.cpp:165] Memory required for data: 957953500
I0818 13:44:37.194622 22726 layer_factory.hpp:77] Creating layer resblk32_2_b
I0818 13:44:37.194636 22726 net.cpp:100] Creating Layer resblk32_2_b
I0818 13:44:37.194643 22726 net.cpp:434] resblk32_2_b <- bn_resblk32_2
I0818 13:44:37.194650 22726 net.cpp:408] resblk32_2_b -> resblk32_2_b
I0818 13:44:37.195124 22726 net.cpp:150] Setting up resblk32_2_b
I0818 13:44:37.195138 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.195143 22726 net.cpp:165] Memory required for data: 962049500
I0818 13:44:37.195152 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_2_b
I0818 13:44:37.195164 22726 net.cpp:100] Creating Layer batchNorm_resblk32_2_b
I0818 13:44:37.195170 22726 net.cpp:434] batchNorm_resblk32_2_b <- resblk32_2_b
I0818 13:44:37.195179 22726 net.cpp:408] batchNorm_resblk32_2_b -> bn_resblk32_2_b
I0818 13:44:37.195430 22726 net.cpp:150] Setting up batchNorm_resblk32_2_b
I0818 13:44:37.195444 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.195449 22726 net.cpp:165] Memory required for data: 966145500
I0818 13:44:37.195459 22726 layer_factory.hpp:77] Creating layer scale_resblk32_2_b
I0818 13:44:37.195468 22726 net.cpp:100] Creating Layer scale_resblk32_2_b
I0818 13:44:37.195474 22726 net.cpp:434] scale_resblk32_2_b <- bn_resblk32_2_b
I0818 13:44:37.195482 22726 net.cpp:395] scale_resblk32_2_b -> bn_resblk32_2_b (in-place)
I0818 13:44:37.195536 22726 layer_factory.hpp:77] Creating layer scale_resblk32_2_b
I0818 13:44:37.195688 22726 net.cpp:150] Setting up scale_resblk32_2_b
I0818 13:44:37.195700 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.195705 22726 net.cpp:165] Memory required for data: 970241500
I0818 13:44:37.195713 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_1_b
I0818 13:44:37.195722 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_1_b
I0818 13:44:37.195729 22726 net.cpp:434] sum_sum_bn_resblk32_1_b <- sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split_1
I0818 13:44:37.195736 22726 net.cpp:434] sum_sum_bn_resblk32_1_b <- bn_resblk32_2_b
I0818 13:44:37.195746 22726 net.cpp:408] sum_sum_bn_resblk32_1_b -> sum_bn_resblk32_2_b
I0818 13:44:37.195775 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_1_b
I0818 13:44:37.195783 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.195787 22726 net.cpp:165] Memory required for data: 974337500
I0818 13:44:37.195792 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_2_b
I0818 13:44:37.195823 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_2_b
I0818 13:44:37.195832 22726 net.cpp:434] relu_sum_bn_resblk32_2_b <- sum_bn_resblk32_2_b
I0818 13:44:37.195842 22726 net.cpp:395] relu_sum_bn_resblk32_2_b -> sum_bn_resblk32_2_b (in-place)
I0818 13:44:37.195852 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_2_b
I0818 13:44:37.195859 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.195864 22726 net.cpp:165] Memory required for data: 978433500
I0818 13:44:37.195869 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split
I0818 13:44:37.195876 22726 net.cpp:100] Creating Layer sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split
I0818 13:44:37.195881 22726 net.cpp:434] sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split <- sum_bn_resblk32_2_b
I0818 13:44:37.195889 22726 net.cpp:408] sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split -> sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split_0
I0818 13:44:37.195899 22726 net.cpp:408] sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split -> sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split_1
I0818 13:44:37.195948 22726 net.cpp:150] Setting up sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split
I0818 13:44:37.195960 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.195966 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.195971 22726 net.cpp:165] Memory required for data: 986625500
I0818 13:44:37.195976 22726 layer_factory.hpp:77] Creating layer resblk32_3
I0818 13:44:37.195987 22726 net.cpp:100] Creating Layer resblk32_3
I0818 13:44:37.195993 22726 net.cpp:434] resblk32_3 <- sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split_0
I0818 13:44:37.196005 22726 net.cpp:408] resblk32_3 -> resblk32_3
I0818 13:44:37.196466 22726 net.cpp:150] Setting up resblk32_3
I0818 13:44:37.196480 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.196491 22726 net.cpp:165] Memory required for data: 990721500
I0818 13:44:37.196501 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_3
I0818 13:44:37.196509 22726 net.cpp:100] Creating Layer batchNorm_resblk32_3
I0818 13:44:37.196516 22726 net.cpp:434] batchNorm_resblk32_3 <- resblk32_3
I0818 13:44:37.196527 22726 net.cpp:408] batchNorm_resblk32_3 -> bn_resblk32_3
I0818 13:44:37.196775 22726 net.cpp:150] Setting up batchNorm_resblk32_3
I0818 13:44:37.196789 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.196794 22726 net.cpp:165] Memory required for data: 994817500
I0818 13:44:37.196805 22726 layer_factory.hpp:77] Creating layer scale_resblk32_3
I0818 13:44:37.196823 22726 net.cpp:100] Creating Layer scale_resblk32_3
I0818 13:44:37.196830 22726 net.cpp:434] scale_resblk32_3 <- bn_resblk32_3
I0818 13:44:37.196838 22726 net.cpp:395] scale_resblk32_3 -> bn_resblk32_3 (in-place)
I0818 13:44:37.196893 22726 layer_factory.hpp:77] Creating layer scale_resblk32_3
I0818 13:44:37.197041 22726 net.cpp:150] Setting up scale_resblk32_3
I0818 13:44:37.197053 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.197057 22726 net.cpp:165] Memory required for data: 998913500
I0818 13:44:37.197067 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_3
I0818 13:44:37.197077 22726 net.cpp:100] Creating Layer relu_bn_resblk32_3
I0818 13:44:37.197084 22726 net.cpp:434] relu_bn_resblk32_3 <- bn_resblk32_3
I0818 13:44:37.197091 22726 net.cpp:395] relu_bn_resblk32_3 -> bn_resblk32_3 (in-place)
I0818 13:44:37.197101 22726 net.cpp:150] Setting up relu_bn_resblk32_3
I0818 13:44:37.197108 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.197113 22726 net.cpp:165] Memory required for data: 1003009500
I0818 13:44:37.197118 22726 layer_factory.hpp:77] Creating layer resblk32_3_b
I0818 13:44:37.197131 22726 net.cpp:100] Creating Layer resblk32_3_b
I0818 13:44:37.197137 22726 net.cpp:434] resblk32_3_b <- bn_resblk32_3
I0818 13:44:37.197149 22726 net.cpp:408] resblk32_3_b -> resblk32_3_b
I0818 13:44:37.197607 22726 net.cpp:150] Setting up resblk32_3_b
I0818 13:44:37.197620 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.197625 22726 net.cpp:165] Memory required for data: 1007105500
I0818 13:44:37.197633 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_3_b
I0818 13:44:37.197643 22726 net.cpp:100] Creating Layer batchNorm_resblk32_3_b
I0818 13:44:37.197649 22726 net.cpp:434] batchNorm_resblk32_3_b <- resblk32_3_b
I0818 13:44:37.197657 22726 net.cpp:408] batchNorm_resblk32_3_b -> bn_resblk32_3_b
I0818 13:44:37.197918 22726 net.cpp:150] Setting up batchNorm_resblk32_3_b
I0818 13:44:37.197932 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.197937 22726 net.cpp:165] Memory required for data: 1011201500
I0818 13:44:37.197948 22726 layer_factory.hpp:77] Creating layer scale_resblk32_3_b
I0818 13:44:37.197957 22726 net.cpp:100] Creating Layer scale_resblk32_3_b
I0818 13:44:37.197963 22726 net.cpp:434] scale_resblk32_3_b <- bn_resblk32_3_b
I0818 13:44:37.197973 22726 net.cpp:395] scale_resblk32_3_b -> bn_resblk32_3_b (in-place)
I0818 13:44:37.198029 22726 layer_factory.hpp:77] Creating layer scale_resblk32_3_b
I0818 13:44:37.198177 22726 net.cpp:150] Setting up scale_resblk32_3_b
I0818 13:44:37.198189 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.198194 22726 net.cpp:165] Memory required for data: 1015297500
I0818 13:44:37.198204 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_2_b
I0818 13:44:37.198212 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_2_b
I0818 13:44:37.198218 22726 net.cpp:434] sum_sum_bn_resblk32_2_b <- sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split_1
I0818 13:44:37.198225 22726 net.cpp:434] sum_sum_bn_resblk32_2_b <- bn_resblk32_3_b
I0818 13:44:37.198237 22726 net.cpp:408] sum_sum_bn_resblk32_2_b -> sum_bn_resblk32_3_b
I0818 13:44:37.198266 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_2_b
I0818 13:44:37.198277 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.198288 22726 net.cpp:165] Memory required for data: 1019393500
I0818 13:44:37.198294 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_3_b
I0818 13:44:37.198302 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_3_b
I0818 13:44:37.198307 22726 net.cpp:434] relu_sum_bn_resblk32_3_b <- sum_bn_resblk32_3_b
I0818 13:44:37.198314 22726 net.cpp:395] relu_sum_bn_resblk32_3_b -> sum_bn_resblk32_3_b (in-place)
I0818 13:44:37.198323 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_3_b
I0818 13:44:37.198330 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.198334 22726 net.cpp:165] Memory required for data: 1023489500
I0818 13:44:37.198338 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split
I0818 13:44:37.198348 22726 net.cpp:100] Creating Layer sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split
I0818 13:44:37.198354 22726 net.cpp:434] sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split <- sum_bn_resblk32_3_b
I0818 13:44:37.198361 22726 net.cpp:408] sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split -> sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split_0
I0818 13:44:37.198371 22726 net.cpp:408] sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split -> sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split_1
I0818 13:44:37.198415 22726 net.cpp:150] Setting up sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split
I0818 13:44:37.198431 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.198437 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.198441 22726 net.cpp:165] Memory required for data: 1031681500
I0818 13:44:37.198446 22726 layer_factory.hpp:77] Creating layer resblk32_4
I0818 13:44:37.198457 22726 net.cpp:100] Creating Layer resblk32_4
I0818 13:44:37.198463 22726 net.cpp:434] resblk32_4 <- sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split_0
I0818 13:44:37.198472 22726 net.cpp:408] resblk32_4 -> resblk32_4
I0818 13:44:37.198946 22726 net.cpp:150] Setting up resblk32_4
I0818 13:44:37.198963 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.198968 22726 net.cpp:165] Memory required for data: 1035777500
I0818 13:44:37.198977 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_4
I0818 13:44:37.198987 22726 net.cpp:100] Creating Layer batchNorm_resblk32_4
I0818 13:44:37.198992 22726 net.cpp:434] batchNorm_resblk32_4 <- resblk32_4
I0818 13:44:37.199000 22726 net.cpp:408] batchNorm_resblk32_4 -> bn_resblk32_4
I0818 13:44:37.199250 22726 net.cpp:150] Setting up batchNorm_resblk32_4
I0818 13:44:37.199262 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.199267 22726 net.cpp:165] Memory required for data: 1039873500
I0818 13:44:37.199277 22726 layer_factory.hpp:77] Creating layer scale_resblk32_4
I0818 13:44:37.199286 22726 net.cpp:100] Creating Layer scale_resblk32_4
I0818 13:44:37.199292 22726 net.cpp:434] scale_resblk32_4 <- bn_resblk32_4
I0818 13:44:37.199303 22726 net.cpp:395] scale_resblk32_4 -> bn_resblk32_4 (in-place)
I0818 13:44:37.199358 22726 layer_factory.hpp:77] Creating layer scale_resblk32_4
I0818 13:44:37.199512 22726 net.cpp:150] Setting up scale_resblk32_4
I0818 13:44:37.199523 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.199528 22726 net.cpp:165] Memory required for data: 1043969500
I0818 13:44:37.199537 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_4
I0818 13:44:37.199545 22726 net.cpp:100] Creating Layer relu_bn_resblk32_4
I0818 13:44:37.199551 22726 net.cpp:434] relu_bn_resblk32_4 <- bn_resblk32_4
I0818 13:44:37.199561 22726 net.cpp:395] relu_bn_resblk32_4 -> bn_resblk32_4 (in-place)
I0818 13:44:37.199571 22726 net.cpp:150] Setting up relu_bn_resblk32_4
I0818 13:44:37.199578 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.199582 22726 net.cpp:165] Memory required for data: 1048065500
I0818 13:44:37.199586 22726 layer_factory.hpp:77] Creating layer resblk32_4_b
I0818 13:44:37.199600 22726 net.cpp:100] Creating Layer resblk32_4_b
I0818 13:44:37.199612 22726 net.cpp:434] resblk32_4_b <- bn_resblk32_4
I0818 13:44:37.199622 22726 net.cpp:408] resblk32_4_b -> resblk32_4_b
I0818 13:44:37.200103 22726 net.cpp:150] Setting up resblk32_4_b
I0818 13:44:37.200117 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.200122 22726 net.cpp:165] Memory required for data: 1052161500
I0818 13:44:37.200131 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_4_b
I0818 13:44:37.200143 22726 net.cpp:100] Creating Layer batchNorm_resblk32_4_b
I0818 13:44:37.200150 22726 net.cpp:434] batchNorm_resblk32_4_b <- resblk32_4_b
I0818 13:44:37.200158 22726 net.cpp:408] batchNorm_resblk32_4_b -> bn_resblk32_4_b
I0818 13:44:37.200407 22726 net.cpp:150] Setting up batchNorm_resblk32_4_b
I0818 13:44:37.200418 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.200423 22726 net.cpp:165] Memory required for data: 1056257500
I0818 13:44:37.200433 22726 layer_factory.hpp:77] Creating layer scale_resblk32_4_b
I0818 13:44:37.200443 22726 net.cpp:100] Creating Layer scale_resblk32_4_b
I0818 13:44:37.200448 22726 net.cpp:434] scale_resblk32_4_b <- bn_resblk32_4_b
I0818 13:44:37.200459 22726 net.cpp:395] scale_resblk32_4_b -> bn_resblk32_4_b (in-place)
I0818 13:44:37.200515 22726 layer_factory.hpp:77] Creating layer scale_resblk32_4_b
I0818 13:44:37.200661 22726 net.cpp:150] Setting up scale_resblk32_4_b
I0818 13:44:37.200675 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.200678 22726 net.cpp:165] Memory required for data: 1060353500
I0818 13:44:37.200687 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_3_b
I0818 13:44:37.200696 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_3_b
I0818 13:44:37.200702 22726 net.cpp:434] sum_sum_bn_resblk32_3_b <- sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split_1
I0818 13:44:37.200711 22726 net.cpp:434] sum_sum_bn_resblk32_3_b <- bn_resblk32_4_b
I0818 13:44:37.200721 22726 net.cpp:408] sum_sum_bn_resblk32_3_b -> sum_bn_resblk32_4_b
I0818 13:44:37.200748 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_3_b
I0818 13:44:37.200757 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.200762 22726 net.cpp:165] Memory required for data: 1064449500
I0818 13:44:37.200767 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_4_b
I0818 13:44:37.200778 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_4_b
I0818 13:44:37.200783 22726 net.cpp:434] relu_sum_bn_resblk32_4_b <- sum_bn_resblk32_4_b
I0818 13:44:37.200790 22726 net.cpp:395] relu_sum_bn_resblk32_4_b -> sum_bn_resblk32_4_b (in-place)
I0818 13:44:37.200799 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_4_b
I0818 13:44:37.200806 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.200817 22726 net.cpp:165] Memory required for data: 1068545500
I0818 13:44:37.200822 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split
I0818 13:44:37.200829 22726 net.cpp:100] Creating Layer sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split
I0818 13:44:37.200835 22726 net.cpp:434] sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split <- sum_bn_resblk32_4_b
I0818 13:44:37.200845 22726 net.cpp:408] sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split -> sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split_0
I0818 13:44:37.200855 22726 net.cpp:408] sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split -> sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split_1
I0818 13:44:37.200901 22726 net.cpp:150] Setting up sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split
I0818 13:44:37.200915 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.200922 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.200927 22726 net.cpp:165] Memory required for data: 1076737500
I0818 13:44:37.200932 22726 layer_factory.hpp:77] Creating layer resblk32_5
I0818 13:44:37.200942 22726 net.cpp:100] Creating Layer resblk32_5
I0818 13:44:37.200948 22726 net.cpp:434] resblk32_5 <- sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split_0
I0818 13:44:37.200958 22726 net.cpp:408] resblk32_5 -> resblk32_5
I0818 13:44:37.201437 22726 net.cpp:150] Setting up resblk32_5
I0818 13:44:37.201452 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.201457 22726 net.cpp:165] Memory required for data: 1080833500
I0818 13:44:37.201465 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_5
I0818 13:44:37.201477 22726 net.cpp:100] Creating Layer batchNorm_resblk32_5
I0818 13:44:37.201483 22726 net.cpp:434] batchNorm_resblk32_5 <- resblk32_5
I0818 13:44:37.201491 22726 net.cpp:408] batchNorm_resblk32_5 -> bn_resblk32_5
I0818 13:44:37.201742 22726 net.cpp:150] Setting up batchNorm_resblk32_5
I0818 13:44:37.201756 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.201759 22726 net.cpp:165] Memory required for data: 1084929500
I0818 13:44:37.201769 22726 layer_factory.hpp:77] Creating layer scale_resblk32_5
I0818 13:44:37.201778 22726 net.cpp:100] Creating Layer scale_resblk32_5
I0818 13:44:37.201784 22726 net.cpp:434] scale_resblk32_5 <- bn_resblk32_5
I0818 13:44:37.201794 22726 net.cpp:395] scale_resblk32_5 -> bn_resblk32_5 (in-place)
I0818 13:44:37.201858 22726 layer_factory.hpp:77] Creating layer scale_resblk32_5
I0818 13:44:37.202016 22726 net.cpp:150] Setting up scale_resblk32_5
I0818 13:44:37.202029 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.202034 22726 net.cpp:165] Memory required for data: 1089025500
I0818 13:44:37.202044 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_5
I0818 13:44:37.202050 22726 net.cpp:100] Creating Layer relu_bn_resblk32_5
I0818 13:44:37.202056 22726 net.cpp:434] relu_bn_resblk32_5 <- bn_resblk32_5
I0818 13:44:37.202067 22726 net.cpp:395] relu_bn_resblk32_5 -> bn_resblk32_5 (in-place)
I0818 13:44:37.202076 22726 net.cpp:150] Setting up relu_bn_resblk32_5
I0818 13:44:37.202083 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.202088 22726 net.cpp:165] Memory required for data: 1093121500
I0818 13:44:37.202092 22726 layer_factory.hpp:77] Creating layer resblk32_5_b
I0818 13:44:37.202106 22726 net.cpp:100] Creating Layer resblk32_5_b
I0818 13:44:37.202112 22726 net.cpp:434] resblk32_5_b <- bn_resblk32_5
I0818 13:44:37.202121 22726 net.cpp:408] resblk32_5_b -> resblk32_5_b
I0818 13:44:37.202585 22726 net.cpp:150] Setting up resblk32_5_b
I0818 13:44:37.202600 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.202603 22726 net.cpp:165] Memory required for data: 1097217500
I0818 13:44:37.202612 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_5_b
I0818 13:44:37.202620 22726 net.cpp:100] Creating Layer batchNorm_resblk32_5_b
I0818 13:44:37.202626 22726 net.cpp:434] batchNorm_resblk32_5_b <- resblk32_5_b
I0818 13:44:37.202638 22726 net.cpp:408] batchNorm_resblk32_5_b -> bn_resblk32_5_b
I0818 13:44:37.202893 22726 net.cpp:150] Setting up batchNorm_resblk32_5_b
I0818 13:44:37.202905 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.202910 22726 net.cpp:165] Memory required for data: 1101313500
I0818 13:44:37.202920 22726 layer_factory.hpp:77] Creating layer scale_resblk32_5_b
I0818 13:44:37.202929 22726 net.cpp:100] Creating Layer scale_resblk32_5_b
I0818 13:44:37.202935 22726 net.cpp:434] scale_resblk32_5_b <- bn_resblk32_5_b
I0818 13:44:37.202942 22726 net.cpp:395] scale_resblk32_5_b -> bn_resblk32_5_b (in-place)
I0818 13:44:37.202999 22726 layer_factory.hpp:77] Creating layer scale_resblk32_5_b
I0818 13:44:37.203147 22726 net.cpp:150] Setting up scale_resblk32_5_b
I0818 13:44:37.203163 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.203168 22726 net.cpp:165] Memory required for data: 1105409500
I0818 13:44:37.203184 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_4_b
I0818 13:44:37.203193 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_4_b
I0818 13:44:37.203200 22726 net.cpp:434] sum_sum_bn_resblk32_4_b <- sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split_1
I0818 13:44:37.203207 22726 net.cpp:434] sum_sum_bn_resblk32_4_b <- bn_resblk32_5_b
I0818 13:44:37.203215 22726 net.cpp:408] sum_sum_bn_resblk32_4_b -> sum_bn_resblk32_5_b
I0818 13:44:37.203253 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_4_b
I0818 13:44:37.203263 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.203266 22726 net.cpp:165] Memory required for data: 1109505500
I0818 13:44:37.203271 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_5_b
I0818 13:44:37.203279 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_5_b
I0818 13:44:37.203284 22726 net.cpp:434] relu_sum_bn_resblk32_5_b <- sum_bn_resblk32_5_b
I0818 13:44:37.203294 22726 net.cpp:395] relu_sum_bn_resblk32_5_b -> sum_bn_resblk32_5_b (in-place)
I0818 13:44:37.203305 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_5_b
I0818 13:44:37.203311 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.203315 22726 net.cpp:165] Memory required for data: 1113601500
I0818 13:44:37.203320 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split
I0818 13:44:37.203326 22726 net.cpp:100] Creating Layer sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split
I0818 13:44:37.203332 22726 net.cpp:434] sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split <- sum_bn_resblk32_5_b
I0818 13:44:37.203342 22726 net.cpp:408] sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split -> sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split_0
I0818 13:44:37.203352 22726 net.cpp:408] sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split -> sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split_1
I0818 13:44:37.203397 22726 net.cpp:150] Setting up sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split
I0818 13:44:37.203408 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.203414 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.203419 22726 net.cpp:165] Memory required for data: 1121793500
I0818 13:44:37.203424 22726 layer_factory.hpp:77] Creating layer resblk32_6
I0818 13:44:37.203438 22726 net.cpp:100] Creating Layer resblk32_6
I0818 13:44:37.203445 22726 net.cpp:434] resblk32_6 <- sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split_0
I0818 13:44:37.203454 22726 net.cpp:408] resblk32_6 -> resblk32_6
I0818 13:44:37.203930 22726 net.cpp:150] Setting up resblk32_6
I0818 13:44:37.203944 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.203949 22726 net.cpp:165] Memory required for data: 1125889500
I0818 13:44:37.203958 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_6
I0818 13:44:37.203966 22726 net.cpp:100] Creating Layer batchNorm_resblk32_6
I0818 13:44:37.203972 22726 net.cpp:434] batchNorm_resblk32_6 <- resblk32_6
I0818 13:44:37.203984 22726 net.cpp:408] batchNorm_resblk32_6 -> bn_resblk32_6
I0818 13:44:37.204236 22726 net.cpp:150] Setting up batchNorm_resblk32_6
I0818 13:44:37.204249 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.204254 22726 net.cpp:165] Memory required for data: 1129985500
I0818 13:44:37.204264 22726 layer_factory.hpp:77] Creating layer scale_resblk32_6
I0818 13:44:37.204272 22726 net.cpp:100] Creating Layer scale_resblk32_6
I0818 13:44:37.204278 22726 net.cpp:434] scale_resblk32_6 <- bn_resblk32_6
I0818 13:44:37.204286 22726 net.cpp:395] scale_resblk32_6 -> bn_resblk32_6 (in-place)
I0818 13:44:37.204345 22726 layer_factory.hpp:77] Creating layer scale_resblk32_6
I0818 13:44:37.204495 22726 net.cpp:150] Setting up scale_resblk32_6
I0818 13:44:37.204510 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.204515 22726 net.cpp:165] Memory required for data: 1134081500
I0818 13:44:37.204524 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_6
I0818 13:44:37.204532 22726 net.cpp:100] Creating Layer relu_bn_resblk32_6
I0818 13:44:37.204538 22726 net.cpp:434] relu_bn_resblk32_6 <- bn_resblk32_6
I0818 13:44:37.204545 22726 net.cpp:395] relu_bn_resblk32_6 -> bn_resblk32_6 (in-place)
I0818 13:44:37.204555 22726 net.cpp:150] Setting up relu_bn_resblk32_6
I0818 13:44:37.204561 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.204566 22726 net.cpp:165] Memory required for data: 1138177500
I0818 13:44:37.204571 22726 layer_factory.hpp:77] Creating layer resblk32_6_b
I0818 13:44:37.204591 22726 net.cpp:100] Creating Layer resblk32_6_b
I0818 13:44:37.204596 22726 net.cpp:434] resblk32_6_b <- bn_resblk32_6
I0818 13:44:37.204609 22726 net.cpp:408] resblk32_6_b -> resblk32_6_b
I0818 13:44:37.205083 22726 net.cpp:150] Setting up resblk32_6_b
I0818 13:44:37.205097 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.205102 22726 net.cpp:165] Memory required for data: 1142273500
I0818 13:44:37.205111 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_6_b
I0818 13:44:37.205122 22726 net.cpp:100] Creating Layer batchNorm_resblk32_6_b
I0818 13:44:37.205129 22726 net.cpp:434] batchNorm_resblk32_6_b <- resblk32_6_b
I0818 13:44:37.205140 22726 net.cpp:408] batchNorm_resblk32_6_b -> bn_resblk32_6_b
I0818 13:44:37.205390 22726 net.cpp:150] Setting up batchNorm_resblk32_6_b
I0818 13:44:37.205402 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.205407 22726 net.cpp:165] Memory required for data: 1146369500
I0818 13:44:37.205417 22726 layer_factory.hpp:77] Creating layer scale_resblk32_6_b
I0818 13:44:37.205425 22726 net.cpp:100] Creating Layer scale_resblk32_6_b
I0818 13:44:37.205431 22726 net.cpp:434] scale_resblk32_6_b <- bn_resblk32_6_b
I0818 13:44:37.205440 22726 net.cpp:395] scale_resblk32_6_b -> bn_resblk32_6_b (in-place)
I0818 13:44:37.205498 22726 layer_factory.hpp:77] Creating layer scale_resblk32_6_b
I0818 13:44:37.205646 22726 net.cpp:150] Setting up scale_resblk32_6_b
I0818 13:44:37.205658 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.205663 22726 net.cpp:165] Memory required for data: 1150465500
I0818 13:44:37.205672 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_5_b
I0818 13:44:37.205683 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_5_b
I0818 13:44:37.205690 22726 net.cpp:434] sum_sum_bn_resblk32_5_b <- sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split_1
I0818 13:44:37.205698 22726 net.cpp:434] sum_sum_bn_resblk32_5_b <- bn_resblk32_6_b
I0818 13:44:37.205705 22726 net.cpp:408] sum_sum_bn_resblk32_5_b -> sum_bn_resblk32_6_b
I0818 13:44:37.205732 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_5_b
I0818 13:44:37.205742 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.205746 22726 net.cpp:165] Memory required for data: 1154561500
I0818 13:44:37.205751 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_6_b
I0818 13:44:37.205762 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_6_b
I0818 13:44:37.205768 22726 net.cpp:434] relu_sum_bn_resblk32_6_b <- sum_bn_resblk32_6_b
I0818 13:44:37.205775 22726 net.cpp:395] relu_sum_bn_resblk32_6_b -> sum_bn_resblk32_6_b (in-place)
I0818 13:44:37.205785 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_6_b
I0818 13:44:37.205791 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.205796 22726 net.cpp:165] Memory required for data: 1158657500
I0818 13:44:37.205801 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split
I0818 13:44:37.205813 22726 net.cpp:100] Creating Layer sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split
I0818 13:44:37.205819 22726 net.cpp:434] sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split <- sum_bn_resblk32_6_b
I0818 13:44:37.205827 22726 net.cpp:408] sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split -> sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split_0
I0818 13:44:37.205837 22726 net.cpp:408] sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split -> sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split_1
I0818 13:44:37.205891 22726 net.cpp:150] Setting up sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split
I0818 13:44:37.205904 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.205910 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.205914 22726 net.cpp:165] Memory required for data: 1166849500
I0818 13:44:37.205919 22726 layer_factory.hpp:77] Creating layer resblk32_7
I0818 13:44:37.205934 22726 net.cpp:100] Creating Layer resblk32_7
I0818 13:44:37.205947 22726 net.cpp:434] resblk32_7 <- sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split_0
I0818 13:44:37.205957 22726 net.cpp:408] resblk32_7 -> resblk32_7
I0818 13:44:37.206440 22726 net.cpp:150] Setting up resblk32_7
I0818 13:44:37.206455 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.206460 22726 net.cpp:165] Memory required for data: 1170945500
I0818 13:44:37.206468 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_7
I0818 13:44:37.206481 22726 net.cpp:100] Creating Layer batchNorm_resblk32_7
I0818 13:44:37.206488 22726 net.cpp:434] batchNorm_resblk32_7 <- resblk32_7
I0818 13:44:37.206499 22726 net.cpp:408] batchNorm_resblk32_7 -> bn_resblk32_7
I0818 13:44:37.206750 22726 net.cpp:150] Setting up batchNorm_resblk32_7
I0818 13:44:37.206763 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.206768 22726 net.cpp:165] Memory required for data: 1175041500
I0818 13:44:37.206779 22726 layer_factory.hpp:77] Creating layer scale_resblk32_7
I0818 13:44:37.206786 22726 net.cpp:100] Creating Layer scale_resblk32_7
I0818 13:44:37.206792 22726 net.cpp:434] scale_resblk32_7 <- bn_resblk32_7
I0818 13:44:37.206800 22726 net.cpp:395] scale_resblk32_7 -> bn_resblk32_7 (in-place)
I0818 13:44:37.206866 22726 layer_factory.hpp:77] Creating layer scale_resblk32_7
I0818 13:44:37.207018 22726 net.cpp:150] Setting up scale_resblk32_7
I0818 13:44:37.207031 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.207036 22726 net.cpp:165] Memory required for data: 1179137500
I0818 13:44:37.207044 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_7
I0818 13:44:37.207054 22726 net.cpp:100] Creating Layer relu_bn_resblk32_7
I0818 13:44:37.207062 22726 net.cpp:434] relu_bn_resblk32_7 <- bn_resblk32_7
I0818 13:44:37.207068 22726 net.cpp:395] relu_bn_resblk32_7 -> bn_resblk32_7 (in-place)
I0818 13:44:37.207077 22726 net.cpp:150] Setting up relu_bn_resblk32_7
I0818 13:44:37.207084 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.207089 22726 net.cpp:165] Memory required for data: 1183233500
I0818 13:44:37.207094 22726 layer_factory.hpp:77] Creating layer resblk32_7_b
I0818 13:44:37.207108 22726 net.cpp:100] Creating Layer resblk32_7_b
I0818 13:44:37.207113 22726 net.cpp:434] resblk32_7_b <- bn_resblk32_7
I0818 13:44:37.207123 22726 net.cpp:408] resblk32_7_b -> resblk32_7_b
I0818 13:44:37.207592 22726 net.cpp:150] Setting up resblk32_7_b
I0818 13:44:37.207605 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.207610 22726 net.cpp:165] Memory required for data: 1187329500
I0818 13:44:37.207618 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_7_b
I0818 13:44:37.207630 22726 net.cpp:100] Creating Layer batchNorm_resblk32_7_b
I0818 13:44:37.207636 22726 net.cpp:434] batchNorm_resblk32_7_b <- resblk32_7_b
I0818 13:44:37.207645 22726 net.cpp:408] batchNorm_resblk32_7_b -> bn_resblk32_7_b
I0818 13:44:37.207909 22726 net.cpp:150] Setting up batchNorm_resblk32_7_b
I0818 13:44:37.207926 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.207931 22726 net.cpp:165] Memory required for data: 1191425500
I0818 13:44:37.207942 22726 layer_factory.hpp:77] Creating layer scale_resblk32_7_b
I0818 13:44:37.207950 22726 net.cpp:100] Creating Layer scale_resblk32_7_b
I0818 13:44:37.207957 22726 net.cpp:434] scale_resblk32_7_b <- bn_resblk32_7_b
I0818 13:44:37.207964 22726 net.cpp:395] scale_resblk32_7_b -> bn_resblk32_7_b (in-place)
I0818 13:44:37.208020 22726 layer_factory.hpp:77] Creating layer scale_resblk32_7_b
I0818 13:44:37.208173 22726 net.cpp:150] Setting up scale_resblk32_7_b
I0818 13:44:37.208185 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.208190 22726 net.cpp:165] Memory required for data: 1195521500
I0818 13:44:37.208199 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_6_b
I0818 13:44:37.208209 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_6_b
I0818 13:44:37.208214 22726 net.cpp:434] sum_sum_bn_resblk32_6_b <- sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split_1
I0818 13:44:37.208228 22726 net.cpp:434] sum_sum_bn_resblk32_6_b <- bn_resblk32_7_b
I0818 13:44:37.208240 22726 net.cpp:408] sum_sum_bn_resblk32_6_b -> sum_bn_resblk32_7_b
I0818 13:44:37.208268 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_6_b
I0818 13:44:37.208277 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.208282 22726 net.cpp:165] Memory required for data: 1199617500
I0818 13:44:37.208287 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_7_b
I0818 13:44:37.208297 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_7_b
I0818 13:44:37.208303 22726 net.cpp:434] relu_sum_bn_resblk32_7_b <- sum_bn_resblk32_7_b
I0818 13:44:37.208310 22726 net.cpp:395] relu_sum_bn_resblk32_7_b -> sum_bn_resblk32_7_b (in-place)
I0818 13:44:37.208319 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_7_b
I0818 13:44:37.208326 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.208330 22726 net.cpp:165] Memory required for data: 1203713500
I0818 13:44:37.208335 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split
I0818 13:44:37.208343 22726 net.cpp:100] Creating Layer sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split
I0818 13:44:37.208348 22726 net.cpp:434] sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split <- sum_bn_resblk32_7_b
I0818 13:44:37.208354 22726 net.cpp:408] sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split -> sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split_0
I0818 13:44:37.208377 22726 net.cpp:408] sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split -> sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split_1
I0818 13:44:37.208428 22726 net.cpp:150] Setting up sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split
I0818 13:44:37.208441 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.208447 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.208451 22726 net.cpp:165] Memory required for data: 1211905500
I0818 13:44:37.208456 22726 layer_factory.hpp:77] Creating layer resblk32_8
I0818 13:44:37.208467 22726 net.cpp:100] Creating Layer resblk32_8
I0818 13:44:37.208474 22726 net.cpp:434] resblk32_8 <- sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split_0
I0818 13:44:37.208487 22726 net.cpp:408] resblk32_8 -> resblk32_8
I0818 13:44:37.208964 22726 net.cpp:150] Setting up resblk32_8
I0818 13:44:37.208979 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.208984 22726 net.cpp:165] Memory required for data: 1216001500
I0818 13:44:37.208992 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_8
I0818 13:44:37.209004 22726 net.cpp:100] Creating Layer batchNorm_resblk32_8
I0818 13:44:37.209010 22726 net.cpp:434] batchNorm_resblk32_8 <- resblk32_8
I0818 13:44:37.209019 22726 net.cpp:408] batchNorm_resblk32_8 -> bn_resblk32_8
I0818 13:44:37.209269 22726 net.cpp:150] Setting up batchNorm_resblk32_8
I0818 13:44:37.209281 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.209285 22726 net.cpp:165] Memory required for data: 1220097500
I0818 13:44:37.209296 22726 layer_factory.hpp:77] Creating layer scale_resblk32_8
I0818 13:44:37.209308 22726 net.cpp:100] Creating Layer scale_resblk32_8
I0818 13:44:37.209314 22726 net.cpp:434] scale_resblk32_8 <- bn_resblk32_8
I0818 13:44:37.209321 22726 net.cpp:395] scale_resblk32_8 -> bn_resblk32_8 (in-place)
I0818 13:44:37.209378 22726 layer_factory.hpp:77] Creating layer scale_resblk32_8
I0818 13:44:37.209532 22726 net.cpp:150] Setting up scale_resblk32_8
I0818 13:44:37.209544 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.209548 22726 net.cpp:165] Memory required for data: 1224193500
I0818 13:44:37.209558 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_8
I0818 13:44:37.209568 22726 net.cpp:100] Creating Layer relu_bn_resblk32_8
I0818 13:44:37.209574 22726 net.cpp:434] relu_bn_resblk32_8 <- bn_resblk32_8
I0818 13:44:37.209584 22726 net.cpp:395] relu_bn_resblk32_8 -> bn_resblk32_8 (in-place)
I0818 13:44:37.209594 22726 net.cpp:150] Setting up relu_bn_resblk32_8
I0818 13:44:37.209601 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.209612 22726 net.cpp:165] Memory required for data: 1228289500
I0818 13:44:37.209617 22726 layer_factory.hpp:77] Creating layer resblk32_8_b
I0818 13:44:37.209628 22726 net.cpp:100] Creating Layer resblk32_8_b
I0818 13:44:37.209635 22726 net.cpp:434] resblk32_8_b <- bn_resblk32_8
I0818 13:44:37.209646 22726 net.cpp:408] resblk32_8_b -> resblk32_8_b
I0818 13:44:37.210121 22726 net.cpp:150] Setting up resblk32_8_b
I0818 13:44:37.210135 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.210140 22726 net.cpp:165] Memory required for data: 1232385500
I0818 13:44:37.210150 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_8_b
I0818 13:44:37.210157 22726 net.cpp:100] Creating Layer batchNorm_resblk32_8_b
I0818 13:44:37.210165 22726 net.cpp:434] batchNorm_resblk32_8_b <- resblk32_8_b
I0818 13:44:37.210177 22726 net.cpp:408] batchNorm_resblk32_8_b -> bn_resblk32_8_b
I0818 13:44:37.210431 22726 net.cpp:150] Setting up batchNorm_resblk32_8_b
I0818 13:44:37.210444 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.210449 22726 net.cpp:165] Memory required for data: 1236481500
I0818 13:44:37.210490 22726 layer_factory.hpp:77] Creating layer scale_resblk32_8_b
I0818 13:44:37.210505 22726 net.cpp:100] Creating Layer scale_resblk32_8_b
I0818 13:44:37.210512 22726 net.cpp:434] scale_resblk32_8_b <- bn_resblk32_8_b
I0818 13:44:37.210520 22726 net.cpp:395] scale_resblk32_8_b -> bn_resblk32_8_b (in-place)
I0818 13:44:37.210579 22726 layer_factory.hpp:77] Creating layer scale_resblk32_8_b
I0818 13:44:37.210727 22726 net.cpp:150] Setting up scale_resblk32_8_b
I0818 13:44:37.210739 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.210744 22726 net.cpp:165] Memory required for data: 1240577500
I0818 13:44:37.210753 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_7_b
I0818 13:44:37.210764 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_7_b
I0818 13:44:37.210772 22726 net.cpp:434] sum_sum_bn_resblk32_7_b <- sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split_1
I0818 13:44:37.210778 22726 net.cpp:434] sum_sum_bn_resblk32_7_b <- bn_resblk32_8_b
I0818 13:44:37.210786 22726 net.cpp:408] sum_sum_bn_resblk32_7_b -> sum_bn_resblk32_8_b
I0818 13:44:37.210824 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_7_b
I0818 13:44:37.210837 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.210841 22726 net.cpp:165] Memory required for data: 1244673500
I0818 13:44:37.210847 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_8_b
I0818 13:44:37.210855 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_8_b
I0818 13:44:37.210860 22726 net.cpp:434] relu_sum_bn_resblk32_8_b <- sum_bn_resblk32_8_b
I0818 13:44:37.210870 22726 net.cpp:395] relu_sum_bn_resblk32_8_b -> sum_bn_resblk32_8_b (in-place)
I0818 13:44:37.210880 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_8_b
I0818 13:44:37.210887 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.210891 22726 net.cpp:165] Memory required for data: 1248769500
I0818 13:44:37.210896 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split
I0818 13:44:37.210903 22726 net.cpp:100] Creating Layer sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split
I0818 13:44:37.210908 22726 net.cpp:434] sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split <- sum_bn_resblk32_8_b
I0818 13:44:37.210918 22726 net.cpp:408] sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split -> sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split_0
I0818 13:44:37.210928 22726 net.cpp:408] sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split -> sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split_1
I0818 13:44:37.210974 22726 net.cpp:150] Setting up sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split
I0818 13:44:37.210985 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.210992 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.210996 22726 net.cpp:165] Memory required for data: 1256961500
I0818 13:44:37.211002 22726 layer_factory.hpp:77] Creating layer resblk64
I0818 13:44:37.211025 22726 net.cpp:100] Creating Layer resblk64
I0818 13:44:37.211033 22726 net.cpp:434] resblk64 <- sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split_0
I0818 13:44:37.211042 22726 net.cpp:408] resblk64 -> resblk64
I0818 13:44:37.211519 22726 net.cpp:150] Setting up resblk64
I0818 13:44:37.211532 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.211537 22726 net.cpp:165] Memory required for data: 1257985500
I0818 13:44:37.211546 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64
I0818 13:44:37.211555 22726 net.cpp:100] Creating Layer batchNorm_resblk64
I0818 13:44:37.211560 22726 net.cpp:434] batchNorm_resblk64 <- resblk64
I0818 13:44:37.211572 22726 net.cpp:408] batchNorm_resblk64 -> bn_resblk64
I0818 13:44:37.211840 22726 net.cpp:150] Setting up batchNorm_resblk64
I0818 13:44:37.211854 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.211859 22726 net.cpp:165] Memory required for data: 1259009500
I0818 13:44:37.211869 22726 layer_factory.hpp:77] Creating layer scale_resblk64
I0818 13:44:37.211879 22726 net.cpp:100] Creating Layer scale_resblk64
I0818 13:44:37.211884 22726 net.cpp:434] scale_resblk64 <- bn_resblk64
I0818 13:44:37.211895 22726 net.cpp:395] scale_resblk64 -> bn_resblk64 (in-place)
I0818 13:44:37.211952 22726 layer_factory.hpp:77] Creating layer scale_resblk64
I0818 13:44:37.212174 22726 net.cpp:150] Setting up scale_resblk64
I0818 13:44:37.212195 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.212201 22726 net.cpp:165] Memory required for data: 1260033500
I0818 13:44:37.212211 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64
I0818 13:44:37.212219 22726 net.cpp:100] Creating Layer relu_bn_resblk64
I0818 13:44:37.212226 22726 net.cpp:434] relu_bn_resblk64 <- bn_resblk64
I0818 13:44:37.212236 22726 net.cpp:395] relu_bn_resblk64 -> bn_resblk64 (in-place)
I0818 13:44:37.212247 22726 net.cpp:150] Setting up relu_bn_resblk64
I0818 13:44:37.212255 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.212260 22726 net.cpp:165] Memory required for data: 1261057500
I0818 13:44:37.212263 22726 layer_factory.hpp:77] Creating layer resblk64_b
I0818 13:44:37.212277 22726 net.cpp:100] Creating Layer resblk64_b
I0818 13:44:37.212283 22726 net.cpp:434] resblk64_b <- bn_resblk64
I0818 13:44:37.212296 22726 net.cpp:408] resblk64_b -> resblk64_b
I0818 13:44:37.212774 22726 net.cpp:150] Setting up resblk64_b
I0818 13:44:37.212787 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.212792 22726 net.cpp:165] Memory required for data: 1262081500
I0818 13:44:37.212801 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_b
I0818 13:44:37.212816 22726 net.cpp:100] Creating Layer batchNorm_resblk64_b
I0818 13:44:37.212823 22726 net.cpp:434] batchNorm_resblk64_b <- resblk64_b
I0818 13:44:37.212832 22726 net.cpp:408] batchNorm_resblk64_b -> bn_resblk64_b
I0818 13:44:37.213104 22726 net.cpp:150] Setting up batchNorm_resblk64_b
I0818 13:44:37.213116 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.213121 22726 net.cpp:165] Memory required for data: 1263105500
I0818 13:44:37.213131 22726 layer_factory.hpp:77] Creating layer scale_resblk64_b
I0818 13:44:37.213143 22726 net.cpp:100] Creating Layer scale_resblk64_b
I0818 13:44:37.213150 22726 net.cpp:434] scale_resblk64_b <- bn_resblk64_b
I0818 13:44:37.213160 22726 net.cpp:395] scale_resblk64_b -> bn_resblk64_b (in-place)
I0818 13:44:37.213215 22726 layer_factory.hpp:77] Creating layer scale_resblk64_b
I0818 13:44:37.213372 22726 net.cpp:150] Setting up scale_resblk64_b
I0818 13:44:37.213385 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.213390 22726 net.cpp:165] Memory required for data: 1264129500
I0818 13:44:37.213399 22726 layer_factory.hpp:77] Creating layer avePooling_resblk64
I0818 13:44:37.213408 22726 net.cpp:100] Creating Layer avePooling_resblk64
I0818 13:44:37.213415 22726 net.cpp:434] avePooling_resblk64 <- sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split_1
I0818 13:44:37.213434 22726 net.cpp:408] avePooling_resblk64 -> avgPool_resblk64
I0818 13:44:37.213472 22726 net.cpp:150] Setting up avePooling_resblk64
I0818 13:44:37.213482 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.213486 22726 net.cpp:165] Memory required for data: 1265153500
I0818 13:44:37.213492 22726 layer_factory.hpp:77] Creating layer sum_avgPool_resblk64
I0818 13:44:37.213500 22726 net.cpp:100] Creating Layer sum_avgPool_resblk64
I0818 13:44:37.213506 22726 net.cpp:434] sum_avgPool_resblk64 <- avgPool_resblk64
I0818 13:44:37.213513 22726 net.cpp:434] sum_avgPool_resblk64 <- bn_resblk64_b
I0818 13:44:37.213521 22726 net.cpp:408] sum_avgPool_resblk64 -> sum_bn_resblk64_b
I0818 13:44:37.213554 22726 net.cpp:150] Setting up sum_avgPool_resblk64
I0818 13:44:37.213565 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.213569 22726 net.cpp:165] Memory required for data: 1266177500
I0818 13:44:37.213574 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_b
I0818 13:44:37.213585 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_b
I0818 13:44:37.213593 22726 net.cpp:434] relu_sum_bn_resblk64_b <- sum_bn_resblk64_b
I0818 13:44:37.213599 22726 net.cpp:395] relu_sum_bn_resblk64_b -> sum_bn_resblk64_b (in-place)
I0818 13:44:37.213608 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_b
I0818 13:44:37.213615 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.213619 22726 net.cpp:165] Memory required for data: 1267201500
I0818 13:44:37.213624 22726 layer_factory.hpp:77] Creating layer zeros_sum_bn_resblk64_b
I0818 13:44:37.213632 22726 net.cpp:100] Creating Layer zeros_sum_bn_resblk64_b
I0818 13:44:37.213640 22726 net.cpp:408] zeros_sum_bn_resblk64_b -> zeros_sum_bn_resblk64_b
I0818 13:44:37.214884 22726 net.cpp:150] Setting up zeros_sum_bn_resblk64_b
I0818 13:44:37.214905 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.214910 22726 net.cpp:165] Memory required for data: 1268225500
I0818 13:44:37.214916 22726 layer_factory.hpp:77] Creating layer CC_sum_bn_resblk64_b
I0818 13:44:37.214926 22726 net.cpp:100] Creating Layer CC_sum_bn_resblk64_b
I0818 13:44:37.214932 22726 net.cpp:434] CC_sum_bn_resblk64_b <- sum_bn_resblk64_b
I0818 13:44:37.214939 22726 net.cpp:434] CC_sum_bn_resblk64_b <- zeros_sum_bn_resblk64_b
I0818 13:44:37.214951 22726 net.cpp:408] CC_sum_bn_resblk64_b -> CC_sum_bn_resblk64_b
I0818 13:44:37.214992 22726 net.cpp:150] Setting up CC_sum_bn_resblk64_b
I0818 13:44:37.215003 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.215008 22726 net.cpp:165] Memory required for data: 1270273500
I0818 13:44:37.215013 22726 layer_factory.hpp:77] Creating layer CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split
I0818 13:44:37.215024 22726 net.cpp:100] Creating Layer CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split
I0818 13:44:37.215030 22726 net.cpp:434] CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split <- CC_sum_bn_resblk64_b
I0818 13:44:37.215037 22726 net.cpp:408] CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split -> CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split_0
I0818 13:44:37.215050 22726 net.cpp:408] CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split -> CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split_1
I0818 13:44:37.215101 22726 net.cpp:150] Setting up CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split
I0818 13:44:37.215113 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.215119 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.215124 22726 net.cpp:165] Memory required for data: 1274369500
I0818 13:44:37.215129 22726 layer_factory.hpp:77] Creating layer resblk64_1
I0818 13:44:37.215143 22726 net.cpp:100] Creating Layer resblk64_1
I0818 13:44:37.215149 22726 net.cpp:434] resblk64_1 <- CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split_0
I0818 13:44:37.215162 22726 net.cpp:408] resblk64_1 -> resblk64_1
I0818 13:44:37.217167 22726 net.cpp:150] Setting up resblk64_1
I0818 13:44:37.217185 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.217190 22726 net.cpp:165] Memory required for data: 1276417500
I0818 13:44:37.217206 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_1
I0818 13:44:37.217216 22726 net.cpp:100] Creating Layer batchNorm_resblk64_1
I0818 13:44:37.217226 22726 net.cpp:434] batchNorm_resblk64_1 <- resblk64_1
I0818 13:44:37.217236 22726 net.cpp:408] batchNorm_resblk64_1 -> bn_resblk64_1
I0818 13:44:37.217496 22726 net.cpp:150] Setting up batchNorm_resblk64_1
I0818 13:44:37.217509 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.217514 22726 net.cpp:165] Memory required for data: 1278465500
I0818 13:44:37.217525 22726 layer_factory.hpp:77] Creating layer scale_resblk64_1
I0818 13:44:37.217535 22726 net.cpp:100] Creating Layer scale_resblk64_1
I0818 13:44:37.217540 22726 net.cpp:434] scale_resblk64_1 <- bn_resblk64_1
I0818 13:44:37.217551 22726 net.cpp:395] scale_resblk64_1 -> bn_resblk64_1 (in-place)
I0818 13:44:37.217609 22726 layer_factory.hpp:77] Creating layer scale_resblk64_1
I0818 13:44:37.217767 22726 net.cpp:150] Setting up scale_resblk64_1
I0818 13:44:37.217779 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.217783 22726 net.cpp:165] Memory required for data: 1280513500
I0818 13:44:37.217793 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_1
I0818 13:44:37.217804 22726 net.cpp:100] Creating Layer relu_bn_resblk64_1
I0818 13:44:37.217816 22726 net.cpp:434] relu_bn_resblk64_1 <- bn_resblk64_1
I0818 13:44:37.217825 22726 net.cpp:395] relu_bn_resblk64_1 -> bn_resblk64_1 (in-place)
I0818 13:44:37.217835 22726 net.cpp:150] Setting up relu_bn_resblk64_1
I0818 13:44:37.217842 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.217846 22726 net.cpp:165] Memory required for data: 1282561500
I0818 13:44:37.217851 22726 layer_factory.hpp:77] Creating layer resblk64_1_b
I0818 13:44:37.217865 22726 net.cpp:100] Creating Layer resblk64_1_b
I0818 13:44:37.217871 22726 net.cpp:434] resblk64_1_b <- bn_resblk64_1
I0818 13:44:37.217883 22726 net.cpp:408] resblk64_1_b -> resblk64_1_b
I0818 13:44:37.218909 22726 net.cpp:150] Setting up resblk64_1_b
I0818 13:44:37.218924 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.218928 22726 net.cpp:165] Memory required for data: 1284609500
I0818 13:44:37.218937 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_1_b
I0818 13:44:37.218945 22726 net.cpp:100] Creating Layer batchNorm_resblk64_1_b
I0818 13:44:37.218952 22726 net.cpp:434] batchNorm_resblk64_1_b <- resblk64_1_b
I0818 13:44:37.218963 22726 net.cpp:408] batchNorm_resblk64_1_b -> bn_resblk64_1_b
I0818 13:44:37.219230 22726 net.cpp:150] Setting up batchNorm_resblk64_1_b
I0818 13:44:37.219246 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.219251 22726 net.cpp:165] Memory required for data: 1286657500
I0818 13:44:37.219261 22726 layer_factory.hpp:77] Creating layer scale_resblk64_1_b
I0818 13:44:37.219270 22726 net.cpp:100] Creating Layer scale_resblk64_1_b
I0818 13:44:37.219276 22726 net.cpp:434] scale_resblk64_1_b <- bn_resblk64_1_b
I0818 13:44:37.219285 22726 net.cpp:395] scale_resblk64_1_b -> bn_resblk64_1_b (in-place)
I0818 13:44:37.219341 22726 layer_factory.hpp:77] Creating layer scale_resblk64_1_b
I0818 13:44:37.219496 22726 net.cpp:150] Setting up scale_resblk64_1_b
I0818 13:44:37.219507 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.219512 22726 net.cpp:165] Memory required for data: 1288705500
I0818 13:44:37.219521 22726 layer_factory.hpp:77] Creating layer sum_CC_sum_bn_resblk64_b
I0818 13:44:37.219533 22726 net.cpp:100] Creating Layer sum_CC_sum_bn_resblk64_b
I0818 13:44:37.219539 22726 net.cpp:434] sum_CC_sum_bn_resblk64_b <- CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split_1
I0818 13:44:37.219547 22726 net.cpp:434] sum_CC_sum_bn_resblk64_b <- bn_resblk64_1_b
I0818 13:44:37.219555 22726 net.cpp:408] sum_CC_sum_bn_resblk64_b -> sum_bn_resblk64_1_b
I0818 13:44:37.219593 22726 net.cpp:150] Setting up sum_CC_sum_bn_resblk64_b
I0818 13:44:37.219604 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.219609 22726 net.cpp:165] Memory required for data: 1290753500
I0818 13:44:37.219620 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_1_b
I0818 13:44:37.219629 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_1_b
I0818 13:44:37.219635 22726 net.cpp:434] relu_sum_bn_resblk64_1_b <- sum_bn_resblk64_1_b
I0818 13:44:37.219641 22726 net.cpp:395] relu_sum_bn_resblk64_1_b -> sum_bn_resblk64_1_b (in-place)
I0818 13:44:37.219650 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_1_b
I0818 13:44:37.219657 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.219661 22726 net.cpp:165] Memory required for data: 1292801500
I0818 13:44:37.219666 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split
I0818 13:44:37.219673 22726 net.cpp:100] Creating Layer sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split
I0818 13:44:37.219678 22726 net.cpp:434] sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split <- sum_bn_resblk64_1_b
I0818 13:44:37.219688 22726 net.cpp:408] sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split -> sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split_0
I0818 13:44:37.219698 22726 net.cpp:408] sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split -> sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split_1
I0818 13:44:37.219745 22726 net.cpp:150] Setting up sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split
I0818 13:44:37.219756 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.219763 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.219768 22726 net.cpp:165] Memory required for data: 1296897500
I0818 13:44:37.219772 22726 layer_factory.hpp:77] Creating layer resblk64_2
I0818 13:44:37.219789 22726 net.cpp:100] Creating Layer resblk64_2
I0818 13:44:37.219795 22726 net.cpp:434] resblk64_2 <- sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split_0
I0818 13:44:37.219805 22726 net.cpp:408] resblk64_2 -> resblk64_2
I0818 13:44:37.220841 22726 net.cpp:150] Setting up resblk64_2
I0818 13:44:37.220856 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.220861 22726 net.cpp:165] Memory required for data: 1298945500
I0818 13:44:37.220870 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_2
I0818 13:44:37.220878 22726 net.cpp:100] Creating Layer batchNorm_resblk64_2
I0818 13:44:37.220885 22726 net.cpp:434] batchNorm_resblk64_2 <- resblk64_2
I0818 13:44:37.220896 22726 net.cpp:408] batchNorm_resblk64_2 -> bn_resblk64_2
I0818 13:44:37.221158 22726 net.cpp:150] Setting up batchNorm_resblk64_2
I0818 13:44:37.221171 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.221176 22726 net.cpp:165] Memory required for data: 1300993500
I0818 13:44:37.221186 22726 layer_factory.hpp:77] Creating layer scale_resblk64_2
I0818 13:44:37.221194 22726 net.cpp:100] Creating Layer scale_resblk64_2
I0818 13:44:37.221201 22726 net.cpp:434] scale_resblk64_2 <- bn_resblk64_2
I0818 13:44:37.221211 22726 net.cpp:395] scale_resblk64_2 -> bn_resblk64_2 (in-place)
I0818 13:44:37.221271 22726 layer_factory.hpp:77] Creating layer scale_resblk64_2
I0818 13:44:37.221426 22726 net.cpp:150] Setting up scale_resblk64_2
I0818 13:44:37.221439 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.221443 22726 net.cpp:165] Memory required for data: 1303041500
I0818 13:44:37.221452 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_2
I0818 13:44:37.221463 22726 net.cpp:100] Creating Layer relu_bn_resblk64_2
I0818 13:44:37.221470 22726 net.cpp:434] relu_bn_resblk64_2 <- bn_resblk64_2
I0818 13:44:37.221477 22726 net.cpp:395] relu_bn_resblk64_2 -> bn_resblk64_2 (in-place)
I0818 13:44:37.221487 22726 net.cpp:150] Setting up relu_bn_resblk64_2
I0818 13:44:37.221493 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.221498 22726 net.cpp:165] Memory required for data: 1305089500
I0818 13:44:37.221503 22726 layer_factory.hpp:77] Creating layer resblk64_2_b
I0818 13:44:37.221516 22726 net.cpp:100] Creating Layer resblk64_2_b
I0818 13:44:37.221523 22726 net.cpp:434] resblk64_2_b <- bn_resblk64_2
I0818 13:44:37.221534 22726 net.cpp:408] resblk64_2_b -> resblk64_2_b
I0818 13:44:37.222563 22726 net.cpp:150] Setting up resblk64_2_b
I0818 13:44:37.222578 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.222582 22726 net.cpp:165] Memory required for data: 1307137500
I0818 13:44:37.222590 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_2_b
I0818 13:44:37.222599 22726 net.cpp:100] Creating Layer batchNorm_resblk64_2_b
I0818 13:44:37.222605 22726 net.cpp:434] batchNorm_resblk64_2_b <- resblk64_2_b
I0818 13:44:37.222617 22726 net.cpp:408] batchNorm_resblk64_2_b -> bn_resblk64_2_b
I0818 13:44:37.222892 22726 net.cpp:150] Setting up batchNorm_resblk64_2_b
I0818 13:44:37.222908 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.222913 22726 net.cpp:165] Memory required for data: 1309185500
I0818 13:44:37.222924 22726 layer_factory.hpp:77] Creating layer scale_resblk64_2_b
I0818 13:44:37.222934 22726 net.cpp:100] Creating Layer scale_resblk64_2_b
I0818 13:44:37.222939 22726 net.cpp:434] scale_resblk64_2_b <- bn_resblk64_2_b
I0818 13:44:37.222947 22726 net.cpp:395] scale_resblk64_2_b -> bn_resblk64_2_b (in-place)
I0818 13:44:37.223004 22726 layer_factory.hpp:77] Creating layer scale_resblk64_2_b
I0818 13:44:37.223165 22726 net.cpp:150] Setting up scale_resblk64_2_b
I0818 13:44:37.223177 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.223181 22726 net.cpp:165] Memory required for data: 1311233500
I0818 13:44:37.223191 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_1_b
I0818 13:44:37.223203 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_1_b
I0818 13:44:37.223211 22726 net.cpp:434] sum_sum_bn_resblk64_1_b <- sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split_1
I0818 13:44:37.223218 22726 net.cpp:434] sum_sum_bn_resblk64_1_b <- bn_resblk64_2_b
I0818 13:44:37.223227 22726 net.cpp:408] sum_sum_bn_resblk64_1_b -> sum_bn_resblk64_2_b
I0818 13:44:37.223263 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_1_b
I0818 13:44:37.223274 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.223278 22726 net.cpp:165] Memory required for data: 1313281500
I0818 13:44:37.223284 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_2_b
I0818 13:44:37.223291 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_2_b
I0818 13:44:37.223297 22726 net.cpp:434] relu_sum_bn_resblk64_2_b <- sum_bn_resblk64_2_b
I0818 13:44:37.223304 22726 net.cpp:395] relu_sum_bn_resblk64_2_b -> sum_bn_resblk64_2_b (in-place)
I0818 13:44:37.223314 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_2_b
I0818 13:44:37.223320 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.223325 22726 net.cpp:165] Memory required for data: 1315329500
I0818 13:44:37.223330 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split
I0818 13:44:37.223335 22726 net.cpp:100] Creating Layer sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split
I0818 13:44:37.223341 22726 net.cpp:434] sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split <- sum_bn_resblk64_2_b
I0818 13:44:37.223351 22726 net.cpp:408] sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split -> sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split_0
I0818 13:44:37.223361 22726 net.cpp:408] sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split -> sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split_1
I0818 13:44:37.223407 22726 net.cpp:150] Setting up sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split
I0818 13:44:37.223418 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.223425 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.223429 22726 net.cpp:165] Memory required for data: 1319425500
I0818 13:44:37.223434 22726 layer_factory.hpp:77] Creating layer resblk64_3
I0818 13:44:37.223448 22726 net.cpp:100] Creating Layer resblk64_3
I0818 13:44:37.223455 22726 net.cpp:434] resblk64_3 <- sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split_0
I0818 13:44:37.223464 22726 net.cpp:408] resblk64_3 -> resblk64_3
I0818 13:44:37.224485 22726 net.cpp:150] Setting up resblk64_3
I0818 13:44:37.224500 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.224511 22726 net.cpp:165] Memory required for data: 1321473500
I0818 13:44:37.224521 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_3
I0818 13:44:37.224529 22726 net.cpp:100] Creating Layer batchNorm_resblk64_3
I0818 13:44:37.224536 22726 net.cpp:434] batchNorm_resblk64_3 <- resblk64_3
I0818 13:44:37.224547 22726 net.cpp:408] batchNorm_resblk64_3 -> bn_resblk64_3
I0818 13:44:37.224824 22726 net.cpp:150] Setting up batchNorm_resblk64_3
I0818 13:44:37.224838 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.224843 22726 net.cpp:165] Memory required for data: 1323521500
I0818 13:44:37.224853 22726 layer_factory.hpp:77] Creating layer scale_resblk64_3
I0818 13:44:37.224861 22726 net.cpp:100] Creating Layer scale_resblk64_3
I0818 13:44:37.224867 22726 net.cpp:434] scale_resblk64_3 <- bn_resblk64_3
I0818 13:44:37.224879 22726 net.cpp:395] scale_resblk64_3 -> bn_resblk64_3 (in-place)
I0818 13:44:37.224936 22726 layer_factory.hpp:77] Creating layer scale_resblk64_3
I0818 13:44:37.225097 22726 net.cpp:150] Setting up scale_resblk64_3
I0818 13:44:37.225111 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.225114 22726 net.cpp:165] Memory required for data: 1325569500
I0818 13:44:37.225123 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_3
I0818 13:44:37.225136 22726 net.cpp:100] Creating Layer relu_bn_resblk64_3
I0818 13:44:37.225142 22726 net.cpp:434] relu_bn_resblk64_3 <- bn_resblk64_3
I0818 13:44:37.225148 22726 net.cpp:395] relu_bn_resblk64_3 -> bn_resblk64_3 (in-place)
I0818 13:44:37.225158 22726 net.cpp:150] Setting up relu_bn_resblk64_3
I0818 13:44:37.225165 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.225169 22726 net.cpp:165] Memory required for data: 1327617500
I0818 13:44:37.225174 22726 layer_factory.hpp:77] Creating layer resblk64_3_b
I0818 13:44:37.225188 22726 net.cpp:100] Creating Layer resblk64_3_b
I0818 13:44:37.225194 22726 net.cpp:434] resblk64_3_b <- bn_resblk64_3
I0818 13:44:37.225205 22726 net.cpp:408] resblk64_3_b -> resblk64_3_b
I0818 13:44:37.226239 22726 net.cpp:150] Setting up resblk64_3_b
I0818 13:44:37.226254 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.226259 22726 net.cpp:165] Memory required for data: 1329665500
I0818 13:44:37.226269 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_3_b
I0818 13:44:37.226277 22726 net.cpp:100] Creating Layer batchNorm_resblk64_3_b
I0818 13:44:37.226284 22726 net.cpp:434] batchNorm_resblk64_3_b <- resblk64_3_b
I0818 13:44:37.226292 22726 net.cpp:408] batchNorm_resblk64_3_b -> bn_resblk64_3_b
I0818 13:44:37.226564 22726 net.cpp:150] Setting up batchNorm_resblk64_3_b
I0818 13:44:37.226577 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.226583 22726 net.cpp:165] Memory required for data: 1331713500
I0818 13:44:37.226593 22726 layer_factory.hpp:77] Creating layer scale_resblk64_3_b
I0818 13:44:37.226604 22726 net.cpp:100] Creating Layer scale_resblk64_3_b
I0818 13:44:37.226611 22726 net.cpp:434] scale_resblk64_3_b <- bn_resblk64_3_b
I0818 13:44:37.226621 22726 net.cpp:395] scale_resblk64_3_b -> bn_resblk64_3_b (in-place)
I0818 13:44:37.226680 22726 layer_factory.hpp:77] Creating layer scale_resblk64_3_b
I0818 13:44:37.226850 22726 net.cpp:150] Setting up scale_resblk64_3_b
I0818 13:44:37.226863 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.226868 22726 net.cpp:165] Memory required for data: 1333761500
I0818 13:44:37.226878 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_2_b
I0818 13:44:37.226887 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_2_b
I0818 13:44:37.226897 22726 net.cpp:434] sum_sum_bn_resblk64_2_b <- sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split_1
I0818 13:44:37.226904 22726 net.cpp:434] sum_sum_bn_resblk64_2_b <- bn_resblk64_3_b
I0818 13:44:37.226912 22726 net.cpp:408] sum_sum_bn_resblk64_2_b -> sum_bn_resblk64_3_b
I0818 13:44:37.226948 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_2_b
I0818 13:44:37.226956 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.226968 22726 net.cpp:165] Memory required for data: 1335809500
I0818 13:44:37.226974 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_3_b
I0818 13:44:37.226984 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_3_b
I0818 13:44:37.226989 22726 net.cpp:434] relu_sum_bn_resblk64_3_b <- sum_bn_resblk64_3_b
I0818 13:44:37.226997 22726 net.cpp:395] relu_sum_bn_resblk64_3_b -> sum_bn_resblk64_3_b (in-place)
I0818 13:44:37.227006 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_3_b
I0818 13:44:37.227013 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.227018 22726 net.cpp:165] Memory required for data: 1337857500
I0818 13:44:37.227023 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split
I0818 13:44:37.227030 22726 net.cpp:100] Creating Layer sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split
I0818 13:44:37.227035 22726 net.cpp:434] sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split <- sum_bn_resblk64_3_b
I0818 13:44:37.227042 22726 net.cpp:408] sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split -> sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split_0
I0818 13:44:37.227051 22726 net.cpp:408] sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split -> sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split_1
I0818 13:44:37.227102 22726 net.cpp:150] Setting up sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split
I0818 13:44:37.227114 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.227120 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.227125 22726 net.cpp:165] Memory required for data: 1341953500
I0818 13:44:37.227130 22726 layer_factory.hpp:77] Creating layer resblk64_4
I0818 13:44:37.227144 22726 net.cpp:100] Creating Layer resblk64_4
I0818 13:44:37.227150 22726 net.cpp:434] resblk64_4 <- sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split_0
I0818 13:44:37.227160 22726 net.cpp:408] resblk64_4 -> resblk64_4
I0818 13:44:37.228193 22726 net.cpp:150] Setting up resblk64_4
I0818 13:44:37.228207 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.228211 22726 net.cpp:165] Memory required for data: 1344001500
I0818 13:44:37.228220 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_4
I0818 13:44:37.228235 22726 net.cpp:100] Creating Layer batchNorm_resblk64_4
I0818 13:44:37.228241 22726 net.cpp:434] batchNorm_resblk64_4 <- resblk64_4
I0818 13:44:37.228252 22726 net.cpp:408] batchNorm_resblk64_4 -> bn_resblk64_4
I0818 13:44:37.229522 22726 net.cpp:150] Setting up batchNorm_resblk64_4
I0818 13:44:37.229539 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.229544 22726 net.cpp:165] Memory required for data: 1346049500
I0818 13:44:37.229557 22726 layer_factory.hpp:77] Creating layer scale_resblk64_4
I0818 13:44:37.229569 22726 net.cpp:100] Creating Layer scale_resblk64_4
I0818 13:44:37.229575 22726 net.cpp:434] scale_resblk64_4 <- bn_resblk64_4
I0818 13:44:37.229586 22726 net.cpp:395] scale_resblk64_4 -> bn_resblk64_4 (in-place)
I0818 13:44:37.229647 22726 layer_factory.hpp:77] Creating layer scale_resblk64_4
I0818 13:44:37.229816 22726 net.cpp:150] Setting up scale_resblk64_4
I0818 13:44:37.229830 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.229835 22726 net.cpp:165] Memory required for data: 1348097500
I0818 13:44:37.229845 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_4
I0818 13:44:37.229852 22726 net.cpp:100] Creating Layer relu_bn_resblk64_4
I0818 13:44:37.229858 22726 net.cpp:434] relu_bn_resblk64_4 <- bn_resblk64_4
I0818 13:44:37.229869 22726 net.cpp:395] relu_bn_resblk64_4 -> bn_resblk64_4 (in-place)
I0818 13:44:37.229879 22726 net.cpp:150] Setting up relu_bn_resblk64_4
I0818 13:44:37.229887 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.229890 22726 net.cpp:165] Memory required for data: 1350145500
I0818 13:44:37.229895 22726 layer_factory.hpp:77] Creating layer resblk64_4_b
I0818 13:44:37.229909 22726 net.cpp:100] Creating Layer resblk64_4_b
I0818 13:44:37.229915 22726 net.cpp:434] resblk64_4_b <- bn_resblk64_4
I0818 13:44:37.229933 22726 net.cpp:408] resblk64_4_b -> resblk64_4_b
I0818 13:44:37.231948 22726 net.cpp:150] Setting up resblk64_4_b
I0818 13:44:37.231966 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.231971 22726 net.cpp:165] Memory required for data: 1352193500
I0818 13:44:37.231981 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_4_b
I0818 13:44:37.231993 22726 net.cpp:100] Creating Layer batchNorm_resblk64_4_b
I0818 13:44:37.232000 22726 net.cpp:434] batchNorm_resblk64_4_b <- resblk64_4_b
I0818 13:44:37.232009 22726 net.cpp:408] batchNorm_resblk64_4_b -> bn_resblk64_4_b
I0818 13:44:37.232271 22726 net.cpp:150] Setting up batchNorm_resblk64_4_b
I0818 13:44:37.232285 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.232290 22726 net.cpp:165] Memory required for data: 1354241500
I0818 13:44:37.232300 22726 layer_factory.hpp:77] Creating layer scale_resblk64_4_b
I0818 13:44:37.232311 22726 net.cpp:100] Creating Layer scale_resblk64_4_b
I0818 13:44:37.232317 22726 net.cpp:434] scale_resblk64_4_b <- bn_resblk64_4_b
I0818 13:44:37.232328 22726 net.cpp:395] scale_resblk64_4_b -> bn_resblk64_4_b (in-place)
I0818 13:44:37.232403 22726 layer_factory.hpp:77] Creating layer scale_resblk64_4_b
I0818 13:44:37.232568 22726 net.cpp:150] Setting up scale_resblk64_4_b
I0818 13:44:37.232581 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.232586 22726 net.cpp:165] Memory required for data: 1356289500
I0818 13:44:37.232595 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_3_b
I0818 13:44:37.232605 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_3_b
I0818 13:44:37.232611 22726 net.cpp:434] sum_sum_bn_resblk64_3_b <- sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split_1
I0818 13:44:37.232620 22726 net.cpp:434] sum_sum_bn_resblk64_3_b <- bn_resblk64_4_b
I0818 13:44:37.232630 22726 net.cpp:408] sum_sum_bn_resblk64_3_b -> sum_bn_resblk64_4_b
I0818 13:44:37.232666 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_3_b
I0818 13:44:37.232676 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.232681 22726 net.cpp:165] Memory required for data: 1358337500
I0818 13:44:37.232686 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_4_b
I0818 13:44:37.232697 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_4_b
I0818 13:44:37.232703 22726 net.cpp:434] relu_sum_bn_resblk64_4_b <- sum_bn_resblk64_4_b
I0818 13:44:37.232710 22726 net.cpp:395] relu_sum_bn_resblk64_4_b -> sum_bn_resblk64_4_b (in-place)
I0818 13:44:37.232720 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_4_b
I0818 13:44:37.232728 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.232731 22726 net.cpp:165] Memory required for data: 1360385500
I0818 13:44:37.232736 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split
I0818 13:44:37.232743 22726 net.cpp:100] Creating Layer sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split
I0818 13:44:37.232748 22726 net.cpp:434] sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split <- sum_bn_resblk64_4_b
I0818 13:44:37.232755 22726 net.cpp:408] sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split -> sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split_0
I0818 13:44:37.232765 22726 net.cpp:408] sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split -> sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split_1
I0818 13:44:37.232820 22726 net.cpp:150] Setting up sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split
I0818 13:44:37.232833 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.232839 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.232844 22726 net.cpp:165] Memory required for data: 1364481500
I0818 13:44:37.232849 22726 layer_factory.hpp:77] Creating layer resblk64_5
I0818 13:44:37.232863 22726 net.cpp:100] Creating Layer resblk64_5
I0818 13:44:37.232869 22726 net.cpp:434] resblk64_5 <- sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split_0
I0818 13:44:37.232879 22726 net.cpp:408] resblk64_5 -> resblk64_5
I0818 13:44:37.233894 22726 net.cpp:150] Setting up resblk64_5
I0818 13:44:37.233916 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.233922 22726 net.cpp:165] Memory required for data: 1366529500
I0818 13:44:37.233932 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_5
I0818 13:44:37.233943 22726 net.cpp:100] Creating Layer batchNorm_resblk64_5
I0818 13:44:37.233949 22726 net.cpp:434] batchNorm_resblk64_5 <- resblk64_5
I0818 13:44:37.233963 22726 net.cpp:408] batchNorm_resblk64_5 -> bn_resblk64_5
I0818 13:44:37.234225 22726 net.cpp:150] Setting up batchNorm_resblk64_5
I0818 13:44:37.234237 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.234242 22726 net.cpp:165] Memory required for data: 1368577500
I0818 13:44:37.234252 22726 layer_factory.hpp:77] Creating layer scale_resblk64_5
I0818 13:44:37.234261 22726 net.cpp:100] Creating Layer scale_resblk64_5
I0818 13:44:37.234267 22726 net.cpp:434] scale_resblk64_5 <- bn_resblk64_5
I0818 13:44:37.234278 22726 net.cpp:395] scale_resblk64_5 -> bn_resblk64_5 (in-place)
I0818 13:44:37.234336 22726 layer_factory.hpp:77] Creating layer scale_resblk64_5
I0818 13:44:37.234493 22726 net.cpp:150] Setting up scale_resblk64_5
I0818 13:44:37.234505 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.234509 22726 net.cpp:165] Memory required for data: 1370625500
I0818 13:44:37.234519 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_5
I0818 13:44:37.234526 22726 net.cpp:100] Creating Layer relu_bn_resblk64_5
I0818 13:44:37.234534 22726 net.cpp:434] relu_bn_resblk64_5 <- bn_resblk64_5
I0818 13:44:37.234544 22726 net.cpp:395] relu_bn_resblk64_5 -> bn_resblk64_5 (in-place)
I0818 13:44:37.234555 22726 net.cpp:150] Setting up relu_bn_resblk64_5
I0818 13:44:37.234562 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.234566 22726 net.cpp:165] Memory required for data: 1372673500
I0818 13:44:37.234571 22726 layer_factory.hpp:77] Creating layer resblk64_5_b
I0818 13:44:37.234586 22726 net.cpp:100] Creating Layer resblk64_5_b
I0818 13:44:37.234591 22726 net.cpp:434] resblk64_5_b <- bn_resblk64_5
I0818 13:44:37.234601 22726 net.cpp:408] resblk64_5_b -> resblk64_5_b
I0818 13:44:37.235616 22726 net.cpp:150] Setting up resblk64_5_b
I0818 13:44:37.235631 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.235636 22726 net.cpp:165] Memory required for data: 1374721500
I0818 13:44:37.235646 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_5_b
I0818 13:44:37.235656 22726 net.cpp:100] Creating Layer batchNorm_resblk64_5_b
I0818 13:44:37.235663 22726 net.cpp:434] batchNorm_resblk64_5_b <- resblk64_5_b
I0818 13:44:37.235671 22726 net.cpp:408] batchNorm_resblk64_5_b -> bn_resblk64_5_b
I0818 13:44:37.235942 22726 net.cpp:150] Setting up batchNorm_resblk64_5_b
I0818 13:44:37.235956 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.235961 22726 net.cpp:165] Memory required for data: 1376769500
I0818 13:44:37.235971 22726 layer_factory.hpp:77] Creating layer scale_resblk64_5_b
I0818 13:44:37.235985 22726 net.cpp:100] Creating Layer scale_resblk64_5_b
I0818 13:44:37.235992 22726 net.cpp:434] scale_resblk64_5_b <- bn_resblk64_5_b
I0818 13:44:37.235999 22726 net.cpp:395] scale_resblk64_5_b -> bn_resblk64_5_b (in-place)
I0818 13:44:37.236060 22726 layer_factory.hpp:77] Creating layer scale_resblk64_5_b
I0818 13:44:37.236219 22726 net.cpp:150] Setting up scale_resblk64_5_b
I0818 13:44:37.236232 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.236238 22726 net.cpp:165] Memory required for data: 1378817500
I0818 13:44:37.236245 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_4_b
I0818 13:44:37.236254 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_4_b
I0818 13:44:37.236261 22726 net.cpp:434] sum_sum_bn_resblk64_4_b <- sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split_1
I0818 13:44:37.236268 22726 net.cpp:434] sum_sum_bn_resblk64_4_b <- bn_resblk64_5_b
I0818 13:44:37.236279 22726 net.cpp:408] sum_sum_bn_resblk64_4_b -> sum_bn_resblk64_5_b
I0818 13:44:37.236313 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_4_b
I0818 13:44:37.236330 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.236333 22726 net.cpp:165] Memory required for data: 1380865500
I0818 13:44:37.236340 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_5_b
I0818 13:44:37.236351 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_5_b
I0818 13:44:37.236356 22726 net.cpp:434] relu_sum_bn_resblk64_5_b <- sum_bn_resblk64_5_b
I0818 13:44:37.236363 22726 net.cpp:395] relu_sum_bn_resblk64_5_b -> sum_bn_resblk64_5_b (in-place)
I0818 13:44:37.236373 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_5_b
I0818 13:44:37.236380 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.236384 22726 net.cpp:165] Memory required for data: 1382913500
I0818 13:44:37.236389 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split
I0818 13:44:37.236397 22726 net.cpp:100] Creating Layer sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split
I0818 13:44:37.236402 22726 net.cpp:434] sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split <- sum_bn_resblk64_5_b
I0818 13:44:37.236409 22726 net.cpp:408] sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split -> sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split_0
I0818 13:44:37.236419 22726 net.cpp:408] sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split -> sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split_1
I0818 13:44:37.236469 22726 net.cpp:150] Setting up sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split
I0818 13:44:37.236479 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.236486 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.236490 22726 net.cpp:165] Memory required for data: 1387009500
I0818 13:44:37.236495 22726 layer_factory.hpp:77] Creating layer resblk64_6
I0818 13:44:37.236510 22726 net.cpp:100] Creating Layer resblk64_6
I0818 13:44:37.236516 22726 net.cpp:434] resblk64_6 <- sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split_0
I0818 13:44:37.236526 22726 net.cpp:408] resblk64_6 -> resblk64_6
I0818 13:44:37.237540 22726 net.cpp:150] Setting up resblk64_6
I0818 13:44:37.237553 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.237558 22726 net.cpp:165] Memory required for data: 1389057500
I0818 13:44:37.237567 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_6
I0818 13:44:37.237578 22726 net.cpp:100] Creating Layer batchNorm_resblk64_6
I0818 13:44:37.237586 22726 net.cpp:434] batchNorm_resblk64_6 <- resblk64_6
I0818 13:44:37.237596 22726 net.cpp:408] batchNorm_resblk64_6 -> bn_resblk64_6
I0818 13:44:37.237866 22726 net.cpp:150] Setting up batchNorm_resblk64_6
I0818 13:44:37.237879 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.237884 22726 net.cpp:165] Memory required for data: 1391105500
I0818 13:44:37.237895 22726 layer_factory.hpp:77] Creating layer scale_resblk64_6
I0818 13:44:37.237903 22726 net.cpp:100] Creating Layer scale_resblk64_6
I0818 13:44:37.237910 22726 net.cpp:434] scale_resblk64_6 <- bn_resblk64_6
I0818 13:44:37.237920 22726 net.cpp:395] scale_resblk64_6 -> bn_resblk64_6 (in-place)
I0818 13:44:37.237978 22726 layer_factory.hpp:77] Creating layer scale_resblk64_6
I0818 13:44:37.238134 22726 net.cpp:150] Setting up scale_resblk64_6
I0818 13:44:37.238147 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.238152 22726 net.cpp:165] Memory required for data: 1393153500
I0818 13:44:37.238160 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_6
I0818 13:44:37.238194 22726 net.cpp:100] Creating Layer relu_bn_resblk64_6
I0818 13:44:37.238204 22726 net.cpp:434] relu_bn_resblk64_6 <- bn_resblk64_6
I0818 13:44:37.238211 22726 net.cpp:395] relu_bn_resblk64_6 -> bn_resblk64_6 (in-place)
I0818 13:44:37.238221 22726 net.cpp:150] Setting up relu_bn_resblk64_6
I0818 13:44:37.238229 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.238232 22726 net.cpp:165] Memory required for data: 1395201500
I0818 13:44:37.238239 22726 layer_factory.hpp:77] Creating layer resblk64_6_b
I0818 13:44:37.238253 22726 net.cpp:100] Creating Layer resblk64_6_b
I0818 13:44:37.238265 22726 net.cpp:434] resblk64_6_b <- bn_resblk64_6
I0818 13:44:37.238276 22726 net.cpp:408] resblk64_6_b -> resblk64_6_b
I0818 13:44:37.239306 22726 net.cpp:150] Setting up resblk64_6_b
I0818 13:44:37.239321 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.239326 22726 net.cpp:165] Memory required for data: 1397249500
I0818 13:44:37.239336 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_6_b
I0818 13:44:37.239346 22726 net.cpp:100] Creating Layer batchNorm_resblk64_6_b
I0818 13:44:37.239353 22726 net.cpp:434] batchNorm_resblk64_6_b <- resblk64_6_b
I0818 13:44:37.239362 22726 net.cpp:408] batchNorm_resblk64_6_b -> bn_resblk64_6_b
I0818 13:44:37.239629 22726 net.cpp:150] Setting up batchNorm_resblk64_6_b
I0818 13:44:37.239641 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.239645 22726 net.cpp:165] Memory required for data: 1399297500
I0818 13:44:37.239656 22726 layer_factory.hpp:77] Creating layer scale_resblk64_6_b
I0818 13:44:37.239665 22726 net.cpp:100] Creating Layer scale_resblk64_6_b
I0818 13:44:37.239671 22726 net.cpp:434] scale_resblk64_6_b <- bn_resblk64_6_b
I0818 13:44:37.239678 22726 net.cpp:395] scale_resblk64_6_b -> bn_resblk64_6_b (in-place)
I0818 13:44:37.239738 22726 layer_factory.hpp:77] Creating layer scale_resblk64_6_b
I0818 13:44:37.239903 22726 net.cpp:150] Setting up scale_resblk64_6_b
I0818 13:44:37.239917 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.239922 22726 net.cpp:165] Memory required for data: 1401345500
I0818 13:44:37.239930 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_5_b
I0818 13:44:37.239939 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_5_b
I0818 13:44:37.239945 22726 net.cpp:434] sum_sum_bn_resblk64_5_b <- sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split_1
I0818 13:44:37.239953 22726 net.cpp:434] sum_sum_bn_resblk64_5_b <- bn_resblk64_6_b
I0818 13:44:37.239964 22726 net.cpp:408] sum_sum_bn_resblk64_5_b -> sum_bn_resblk64_6_b
I0818 13:44:37.239997 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_5_b
I0818 13:44:37.240010 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.240015 22726 net.cpp:165] Memory required for data: 1403393500
I0818 13:44:37.240020 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_6_b
I0818 13:44:37.240027 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_6_b
I0818 13:44:37.240033 22726 net.cpp:434] relu_sum_bn_resblk64_6_b <- sum_bn_resblk64_6_b
I0818 13:44:37.240039 22726 net.cpp:395] relu_sum_bn_resblk64_6_b -> sum_bn_resblk64_6_b (in-place)
I0818 13:44:37.240049 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_6_b
I0818 13:44:37.240056 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.240061 22726 net.cpp:165] Memory required for data: 1405441500
I0818 13:44:37.240065 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split
I0818 13:44:37.240077 22726 net.cpp:100] Creating Layer sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split
I0818 13:44:37.240082 22726 net.cpp:434] sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split <- sum_bn_resblk64_6_b
I0818 13:44:37.240089 22726 net.cpp:408] sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split -> sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split_0
I0818 13:44:37.240099 22726 net.cpp:408] sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split -> sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split_1
I0818 13:44:37.240149 22726 net.cpp:150] Setting up sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split
I0818 13:44:37.240159 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.240165 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.240170 22726 net.cpp:165] Memory required for data: 1409537500
I0818 13:44:37.240175 22726 layer_factory.hpp:77] Creating layer resblk64_7
I0818 13:44:37.240185 22726 net.cpp:100] Creating Layer resblk64_7
I0818 13:44:37.240192 22726 net.cpp:434] resblk64_7 <- sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split_0
I0818 13:44:37.240205 22726 net.cpp:408] resblk64_7 -> resblk64_7
I0818 13:44:37.241235 22726 net.cpp:150] Setting up resblk64_7
I0818 13:44:37.241250 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.241255 22726 net.cpp:165] Memory required for data: 1411585500
I0818 13:44:37.241263 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_7
I0818 13:44:37.241272 22726 net.cpp:100] Creating Layer batchNorm_resblk64_7
I0818 13:44:37.241278 22726 net.cpp:434] batchNorm_resblk64_7 <- resblk64_7
I0818 13:44:37.241287 22726 net.cpp:408] batchNorm_resblk64_7 -> bn_resblk64_7
I0818 13:44:37.241556 22726 net.cpp:150] Setting up batchNorm_resblk64_7
I0818 13:44:37.241569 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.241574 22726 net.cpp:165] Memory required for data: 1413633500
I0818 13:44:37.241583 22726 layer_factory.hpp:77] Creating layer scale_resblk64_7
I0818 13:44:37.241596 22726 net.cpp:100] Creating Layer scale_resblk64_7
I0818 13:44:37.241603 22726 net.cpp:434] scale_resblk64_7 <- bn_resblk64_7
I0818 13:44:37.241613 22726 net.cpp:395] scale_resblk64_7 -> bn_resblk64_7 (in-place)
I0818 13:44:37.241674 22726 layer_factory.hpp:77] Creating layer scale_resblk64_7
I0818 13:44:37.241844 22726 net.cpp:150] Setting up scale_resblk64_7
I0818 13:44:37.241858 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.241863 22726 net.cpp:165] Memory required for data: 1415681500
I0818 13:44:37.241873 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_7
I0818 13:44:37.241880 22726 net.cpp:100] Creating Layer relu_bn_resblk64_7
I0818 13:44:37.241886 22726 net.cpp:434] relu_bn_resblk64_7 <- bn_resblk64_7
I0818 13:44:37.241896 22726 net.cpp:395] relu_bn_resblk64_7 -> bn_resblk64_7 (in-place)
I0818 13:44:37.241906 22726 net.cpp:150] Setting up relu_bn_resblk64_7
I0818 13:44:37.241914 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.241917 22726 net.cpp:165] Memory required for data: 1417729500
I0818 13:44:37.241922 22726 layer_factory.hpp:77] Creating layer resblk64_7_b
I0818 13:44:37.241935 22726 net.cpp:100] Creating Layer resblk64_7_b
I0818 13:44:37.241942 22726 net.cpp:434] resblk64_7_b <- bn_resblk64_7
I0818 13:44:37.241951 22726 net.cpp:408] resblk64_7_b -> resblk64_7_b
I0818 13:44:37.242965 22726 net.cpp:150] Setting up resblk64_7_b
I0818 13:44:37.242980 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.242985 22726 net.cpp:165] Memory required for data: 1419777500
I0818 13:44:37.242995 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_7_b
I0818 13:44:37.243006 22726 net.cpp:100] Creating Layer batchNorm_resblk64_7_b
I0818 13:44:37.243013 22726 net.cpp:434] batchNorm_resblk64_7_b <- resblk64_7_b
I0818 13:44:37.243022 22726 net.cpp:408] batchNorm_resblk64_7_b -> bn_resblk64_7_b
I0818 13:44:37.243286 22726 net.cpp:150] Setting up batchNorm_resblk64_7_b
I0818 13:44:37.243299 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.243304 22726 net.cpp:165] Memory required for data: 1421825500
I0818 13:44:37.243314 22726 layer_factory.hpp:77] Creating layer scale_resblk64_7_b
I0818 13:44:37.243322 22726 net.cpp:100] Creating Layer scale_resblk64_7_b
I0818 13:44:37.243330 22726 net.cpp:434] scale_resblk64_7_b <- bn_resblk64_7_b
I0818 13:44:37.243336 22726 net.cpp:395] scale_resblk64_7_b -> bn_resblk64_7_b (in-place)
I0818 13:44:37.243396 22726 layer_factory.hpp:77] Creating layer scale_resblk64_7_b
I0818 13:44:37.243556 22726 net.cpp:150] Setting up scale_resblk64_7_b
I0818 13:44:37.243567 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.243572 22726 net.cpp:165] Memory required for data: 1423873500
I0818 13:44:37.243582 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_6_b
I0818 13:44:37.243590 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_6_b
I0818 13:44:37.243597 22726 net.cpp:434] sum_sum_bn_resblk64_6_b <- sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split_1
I0818 13:44:37.243604 22726 net.cpp:434] sum_sum_bn_resblk64_6_b <- bn_resblk64_7_b
I0818 13:44:37.243615 22726 net.cpp:408] sum_sum_bn_resblk64_6_b -> sum_bn_resblk64_7_b
I0818 13:44:37.243649 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_6_b
I0818 13:44:37.243667 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.243672 22726 net.cpp:165] Memory required for data: 1425921500
I0818 13:44:37.243677 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_7_b
I0818 13:44:37.243685 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_7_b
I0818 13:44:37.243691 22726 net.cpp:434] relu_sum_bn_resblk64_7_b <- sum_bn_resblk64_7_b
I0818 13:44:37.243698 22726 net.cpp:395] relu_sum_bn_resblk64_7_b -> sum_bn_resblk64_7_b (in-place)
I0818 13:44:37.243707 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_7_b
I0818 13:44:37.243715 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.243718 22726 net.cpp:165] Memory required for data: 1427969500
I0818 13:44:37.243722 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split
I0818 13:44:37.243732 22726 net.cpp:100] Creating Layer sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split
I0818 13:44:37.243738 22726 net.cpp:434] sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split <- sum_bn_resblk64_7_b
I0818 13:44:37.243746 22726 net.cpp:408] sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split -> sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split_0
I0818 13:44:37.243755 22726 net.cpp:408] sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split -> sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split_1
I0818 13:44:37.243801 22726 net.cpp:150] Setting up sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split
I0818 13:44:37.243822 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.243829 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.243834 22726 net.cpp:165] Memory required for data: 1432065500
I0818 13:44:37.243839 22726 layer_factory.hpp:77] Creating layer resblk64_8
I0818 13:44:37.243849 22726 net.cpp:100] Creating Layer resblk64_8
I0818 13:44:37.243855 22726 net.cpp:434] resblk64_8 <- sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split_0
I0818 13:44:37.243865 22726 net.cpp:408] resblk64_8 -> resblk64_8
I0818 13:44:37.245904 22726 net.cpp:150] Setting up resblk64_8
I0818 13:44:37.245923 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.245928 22726 net.cpp:165] Memory required for data: 1434113500
I0818 13:44:37.245936 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_8
I0818 13:44:37.245949 22726 net.cpp:100] Creating Layer batchNorm_resblk64_8
I0818 13:44:37.245955 22726 net.cpp:434] batchNorm_resblk64_8 <- resblk64_8
I0818 13:44:37.245967 22726 net.cpp:408] batchNorm_resblk64_8 -> bn_resblk64_8
I0818 13:44:37.246234 22726 net.cpp:150] Setting up batchNorm_resblk64_8
I0818 13:44:37.246248 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.246251 22726 net.cpp:165] Memory required for data: 1436161500
I0818 13:44:37.246263 22726 layer_factory.hpp:77] Creating layer scale_resblk64_8
I0818 13:44:37.246271 22726 net.cpp:100] Creating Layer scale_resblk64_8
I0818 13:44:37.246278 22726 net.cpp:434] scale_resblk64_8 <- bn_resblk64_8
I0818 13:44:37.246289 22726 net.cpp:395] scale_resblk64_8 -> bn_resblk64_8 (in-place)
I0818 13:44:37.246348 22726 layer_factory.hpp:77] Creating layer scale_resblk64_8
I0818 13:44:37.246512 22726 net.cpp:150] Setting up scale_resblk64_8
I0818 13:44:37.246526 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.246531 22726 net.cpp:165] Memory required for data: 1438209500
I0818 13:44:37.246539 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_8
I0818 13:44:37.246547 22726 net.cpp:100] Creating Layer relu_bn_resblk64_8
I0818 13:44:37.246553 22726 net.cpp:434] relu_bn_resblk64_8 <- bn_resblk64_8
I0818 13:44:37.246563 22726 net.cpp:395] relu_bn_resblk64_8 -> bn_resblk64_8 (in-place)
I0818 13:44:37.246573 22726 net.cpp:150] Setting up relu_bn_resblk64_8
I0818 13:44:37.246580 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.246584 22726 net.cpp:165] Memory required for data: 1440257500
I0818 13:44:37.246589 22726 layer_factory.hpp:77] Creating layer resblk64_8_b
I0818 13:44:37.246611 22726 net.cpp:100] Creating Layer resblk64_8_b
I0818 13:44:37.246618 22726 net.cpp:434] resblk64_8_b <- bn_resblk64_8
I0818 13:44:37.246628 22726 net.cpp:408] resblk64_8_b -> resblk64_8_b
I0818 13:44:37.247656 22726 net.cpp:150] Setting up resblk64_8_b
I0818 13:44:37.247671 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.247676 22726 net.cpp:165] Memory required for data: 1442305500
I0818 13:44:37.247685 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_8_b
I0818 13:44:37.247696 22726 net.cpp:100] Creating Layer batchNorm_resblk64_8_b
I0818 13:44:37.247704 22726 net.cpp:434] batchNorm_resblk64_8_b <- resblk64_8_b
I0818 13:44:37.247712 22726 net.cpp:408] batchNorm_resblk64_8_b -> bn_resblk64_8_b
I0818 13:44:37.247992 22726 net.cpp:150] Setting up batchNorm_resblk64_8_b
I0818 13:44:37.248006 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.248010 22726 net.cpp:165] Memory required for data: 1444353500
I0818 13:44:37.248021 22726 layer_factory.hpp:77] Creating layer scale_resblk64_8_b
I0818 13:44:37.248033 22726 net.cpp:100] Creating Layer scale_resblk64_8_b
I0818 13:44:37.248039 22726 net.cpp:434] scale_resblk64_8_b <- bn_resblk64_8_b
I0818 13:44:37.248047 22726 net.cpp:395] scale_resblk64_8_b -> bn_resblk64_8_b (in-place)
I0818 13:44:37.248108 22726 layer_factory.hpp:77] Creating layer scale_resblk64_8_b
I0818 13:44:37.248266 22726 net.cpp:150] Setting up scale_resblk64_8_b
I0818 13:44:37.248280 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.248284 22726 net.cpp:165] Memory required for data: 1446401500
I0818 13:44:37.248293 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_7_b
I0818 13:44:37.248304 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_7_b
I0818 13:44:37.248311 22726 net.cpp:434] sum_sum_bn_resblk64_7_b <- sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split_1
I0818 13:44:37.248319 22726 net.cpp:434] sum_sum_bn_resblk64_7_b <- bn_resblk64_8_b
I0818 13:44:37.248330 22726 net.cpp:408] sum_sum_bn_resblk64_7_b -> sum_bn_resblk64_8_b
I0818 13:44:37.248364 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_7_b
I0818 13:44:37.248376 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.248380 22726 net.cpp:165] Memory required for data: 1448449500
I0818 13:44:37.248386 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_8_b
I0818 13:44:37.248399 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_8_b
I0818 13:44:37.248404 22726 net.cpp:434] relu_sum_bn_resblk64_8_b <- sum_bn_resblk64_8_b
I0818 13:44:37.248411 22726 net.cpp:395] relu_sum_bn_resblk64_8_b -> sum_bn_resblk64_8_b (in-place)
I0818 13:44:37.248421 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_8_b
I0818 13:44:37.248428 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.248432 22726 net.cpp:165] Memory required for data: 1450497500
I0818 13:44:37.248437 22726 layer_factory.hpp:77] Creating layer avePooling_resblk64_8
I0818 13:44:37.248445 22726 net.cpp:100] Creating Layer avePooling_resblk64_8
I0818 13:44:37.248451 22726 net.cpp:434] avePooling_resblk64_8 <- sum_bn_resblk64_8_b
I0818 13:44:37.248459 22726 net.cpp:408] avePooling_resblk64_8 -> avgPool_resblk64_8
I0818 13:44:37.248502 22726 net.cpp:150] Setting up avePooling_resblk64_8
I0818 13:44:37.248513 22726 net.cpp:157] Top shape: 125 64 1 1 (8000)
I0818 13:44:37.248517 22726 net.cpp:165] Memory required for data: 1450529500
I0818 13:44:37.248522 22726 layer_factory.hpp:77] Creating layer FC_final
I0818 13:44:37.248605 22726 net.cpp:100] Creating Layer FC_final
I0818 13:44:37.248618 22726 net.cpp:434] FC_final <- avgPool_resblk64_8
I0818 13:44:37.248627 22726 net.cpp:408] FC_final -> FC_final
I0818 13:44:37.248884 22726 net.cpp:150] Setting up FC_final
I0818 13:44:37.248900 22726 net.cpp:157] Top shape: 125 10 (1250)
I0818 13:44:37.248905 22726 net.cpp:165] Memory required for data: 1450534500
I0818 13:44:37.248914 22726 layer_factory.hpp:77] Creating layer FC_final_FC_final_0_split
I0818 13:44:37.248924 22726 net.cpp:100] Creating Layer FC_final_FC_final_0_split
I0818 13:44:37.248936 22726 net.cpp:434] FC_final_FC_final_0_split <- FC_final
I0818 13:44:37.248947 22726 net.cpp:408] FC_final_FC_final_0_split -> FC_final_FC_final_0_split_0
I0818 13:44:37.248958 22726 net.cpp:408] FC_final_FC_final_0_split -> FC_final_FC_final_0_split_1
I0818 13:44:37.249007 22726 net.cpp:150] Setting up FC_final_FC_final_0_split
I0818 13:44:37.249019 22726 net.cpp:157] Top shape: 125 10 (1250)
I0818 13:44:37.249025 22726 net.cpp:157] Top shape: 125 10 (1250)
I0818 13:44:37.249030 22726 net.cpp:165] Memory required for data: 1450544500
I0818 13:44:37.249035 22726 layer_factory.hpp:77] Creating layer accuracy
I0818 13:44:37.249081 22726 net.cpp:100] Creating Layer accuracy
I0818 13:44:37.249094 22726 net.cpp:434] accuracy <- FC_final_FC_final_0_split_0
I0818 13:44:37.249101 22726 net.cpp:434] accuracy <- label_dataLayer_1_split_0
I0818 13:44:37.249109 22726 net.cpp:408] accuracy -> accuracy
I0818 13:44:37.249152 22726 net.cpp:150] Setting up accuracy
I0818 13:44:37.249166 22726 net.cpp:157] Top shape: (1)
I0818 13:44:37.249171 22726 net.cpp:165] Memory required for data: 1450544504
I0818 13:44:37.249176 22726 layer_factory.hpp:77] Creating layer loss
I0818 13:44:37.249186 22726 net.cpp:100] Creating Layer loss
I0818 13:44:37.249191 22726 net.cpp:434] loss <- FC_final_FC_final_0_split_1
I0818 13:44:37.249197 22726 net.cpp:434] loss <- label_dataLayer_1_split_1
I0818 13:44:37.249205 22726 net.cpp:408] loss -> loss
I0818 13:44:37.249248 22726 layer_factory.hpp:77] Creating layer loss
I0818 13:44:37.249413 22726 net.cpp:150] Setting up loss
I0818 13:44:37.249428 22726 net.cpp:157] Top shape: (1)
I0818 13:44:37.249433 22726 net.cpp:160]     with loss weight 1
I0818 13:44:37.249508 22726 net.cpp:165] Memory required for data: 1450544508
I0818 13:44:37.249517 22726 net.cpp:226] loss needs backward computation.
I0818 13:44:37.249523 22726 net.cpp:228] accuracy does not need backward computation.
I0818 13:44:37.249529 22726 net.cpp:226] FC_final_FC_final_0_split needs backward computation.
I0818 13:44:37.249534 22726 net.cpp:226] FC_final needs backward computation.
I0818 13:44:37.249539 22726 net.cpp:226] avePooling_resblk64_8 needs backward computation.
I0818 13:44:37.249544 22726 net.cpp:226] relu_sum_bn_resblk64_8_b needs backward computation.
I0818 13:44:37.249549 22726 net.cpp:226] sum_sum_bn_resblk64_7_b needs backward computation.
I0818 13:44:37.249554 22726 net.cpp:226] scale_resblk64_8_b needs backward computation.
I0818 13:44:37.249559 22726 net.cpp:226] batchNorm_resblk64_8_b needs backward computation.
I0818 13:44:37.249563 22726 net.cpp:226] resblk64_8_b needs backward computation.
I0818 13:44:37.249568 22726 net.cpp:226] relu_bn_resblk64_8 needs backward computation.
I0818 13:44:37.249573 22726 net.cpp:226] scale_resblk64_8 needs backward computation.
I0818 13:44:37.249578 22726 net.cpp:226] batchNorm_resblk64_8 needs backward computation.
I0818 13:44:37.249583 22726 net.cpp:226] resblk64_8 needs backward computation.
I0818 13:44:37.249588 22726 net.cpp:226] sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split needs backward computation.
I0818 13:44:37.249593 22726 net.cpp:226] relu_sum_bn_resblk64_7_b needs backward computation.
I0818 13:44:37.249598 22726 net.cpp:226] sum_sum_bn_resblk64_6_b needs backward computation.
I0818 13:44:37.249603 22726 net.cpp:226] scale_resblk64_7_b needs backward computation.
I0818 13:44:37.249608 22726 net.cpp:226] batchNorm_resblk64_7_b needs backward computation.
I0818 13:44:37.249613 22726 net.cpp:226] resblk64_7_b needs backward computation.
I0818 13:44:37.249617 22726 net.cpp:226] relu_bn_resblk64_7 needs backward computation.
I0818 13:44:37.249622 22726 net.cpp:226] scale_resblk64_7 needs backward computation.
I0818 13:44:37.249627 22726 net.cpp:226] batchNorm_resblk64_7 needs backward computation.
I0818 13:44:37.249632 22726 net.cpp:226] resblk64_7 needs backward computation.
I0818 13:44:37.249637 22726 net.cpp:226] sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split needs backward computation.
I0818 13:44:37.249642 22726 net.cpp:226] relu_sum_bn_resblk64_6_b needs backward computation.
I0818 13:44:37.249655 22726 net.cpp:226] sum_sum_bn_resblk64_5_b needs backward computation.
I0818 13:44:37.249660 22726 net.cpp:226] scale_resblk64_6_b needs backward computation.
I0818 13:44:37.249665 22726 net.cpp:226] batchNorm_resblk64_6_b needs backward computation.
I0818 13:44:37.249670 22726 net.cpp:226] resblk64_6_b needs backward computation.
I0818 13:44:37.249675 22726 net.cpp:226] relu_bn_resblk64_6 needs backward computation.
I0818 13:44:37.249680 22726 net.cpp:226] scale_resblk64_6 needs backward computation.
I0818 13:44:37.249686 22726 net.cpp:226] batchNorm_resblk64_6 needs backward computation.
I0818 13:44:37.249691 22726 net.cpp:226] resblk64_6 needs backward computation.
I0818 13:44:37.249696 22726 net.cpp:226] sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split needs backward computation.
I0818 13:44:37.249701 22726 net.cpp:226] relu_sum_bn_resblk64_5_b needs backward computation.
I0818 13:44:37.249706 22726 net.cpp:226] sum_sum_bn_resblk64_4_b needs backward computation.
I0818 13:44:37.249711 22726 net.cpp:226] scale_resblk64_5_b needs backward computation.
I0818 13:44:37.249716 22726 net.cpp:226] batchNorm_resblk64_5_b needs backward computation.
I0818 13:44:37.249722 22726 net.cpp:226] resblk64_5_b needs backward computation.
I0818 13:44:37.249727 22726 net.cpp:226] relu_bn_resblk64_5 needs backward computation.
I0818 13:44:37.249732 22726 net.cpp:226] scale_resblk64_5 needs backward computation.
I0818 13:44:37.249737 22726 net.cpp:226] batchNorm_resblk64_5 needs backward computation.
I0818 13:44:37.249742 22726 net.cpp:226] resblk64_5 needs backward computation.
I0818 13:44:37.249747 22726 net.cpp:226] sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split needs backward computation.
I0818 13:44:37.249752 22726 net.cpp:226] relu_sum_bn_resblk64_4_b needs backward computation.
I0818 13:44:37.249756 22726 net.cpp:226] sum_sum_bn_resblk64_3_b needs backward computation.
I0818 13:44:37.249763 22726 net.cpp:226] scale_resblk64_4_b needs backward computation.
I0818 13:44:37.249768 22726 net.cpp:226] batchNorm_resblk64_4_b needs backward computation.
I0818 13:44:37.249773 22726 net.cpp:226] resblk64_4_b needs backward computation.
I0818 13:44:37.249781 22726 net.cpp:226] relu_bn_resblk64_4 needs backward computation.
I0818 13:44:37.249786 22726 net.cpp:226] scale_resblk64_4 needs backward computation.
I0818 13:44:37.249791 22726 net.cpp:226] batchNorm_resblk64_4 needs backward computation.
I0818 13:44:37.249796 22726 net.cpp:226] resblk64_4 needs backward computation.
I0818 13:44:37.249802 22726 net.cpp:226] sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split needs backward computation.
I0818 13:44:37.249814 22726 net.cpp:226] relu_sum_bn_resblk64_3_b needs backward computation.
I0818 13:44:37.249820 22726 net.cpp:226] sum_sum_bn_resblk64_2_b needs backward computation.
I0818 13:44:37.249826 22726 net.cpp:226] scale_resblk64_3_b needs backward computation.
I0818 13:44:37.249831 22726 net.cpp:226] batchNorm_resblk64_3_b needs backward computation.
I0818 13:44:37.249836 22726 net.cpp:226] resblk64_3_b needs backward computation.
I0818 13:44:37.249841 22726 net.cpp:226] relu_bn_resblk64_3 needs backward computation.
I0818 13:44:37.249846 22726 net.cpp:226] scale_resblk64_3 needs backward computation.
I0818 13:44:37.249851 22726 net.cpp:226] batchNorm_resblk64_3 needs backward computation.
I0818 13:44:37.249856 22726 net.cpp:226] resblk64_3 needs backward computation.
I0818 13:44:37.249862 22726 net.cpp:226] sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split needs backward computation.
I0818 13:44:37.249867 22726 net.cpp:226] relu_sum_bn_resblk64_2_b needs backward computation.
I0818 13:44:37.249872 22726 net.cpp:226] sum_sum_bn_resblk64_1_b needs backward computation.
I0818 13:44:37.249878 22726 net.cpp:226] scale_resblk64_2_b needs backward computation.
I0818 13:44:37.249883 22726 net.cpp:226] batchNorm_resblk64_2_b needs backward computation.
I0818 13:44:37.249888 22726 net.cpp:226] resblk64_2_b needs backward computation.
I0818 13:44:37.249893 22726 net.cpp:226] relu_bn_resblk64_2 needs backward computation.
I0818 13:44:37.249909 22726 net.cpp:226] scale_resblk64_2 needs backward computation.
I0818 13:44:37.249914 22726 net.cpp:226] batchNorm_resblk64_2 needs backward computation.
I0818 13:44:37.249920 22726 net.cpp:226] resblk64_2 needs backward computation.
I0818 13:44:37.249925 22726 net.cpp:226] sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split needs backward computation.
I0818 13:44:37.249932 22726 net.cpp:226] relu_sum_bn_resblk64_1_b needs backward computation.
I0818 13:44:37.249936 22726 net.cpp:226] sum_CC_sum_bn_resblk64_b needs backward computation.
I0818 13:44:37.249941 22726 net.cpp:226] scale_resblk64_1_b needs backward computation.
I0818 13:44:37.249946 22726 net.cpp:226] batchNorm_resblk64_1_b needs backward computation.
I0818 13:44:37.249951 22726 net.cpp:226] resblk64_1_b needs backward computation.
I0818 13:44:37.249958 22726 net.cpp:226] relu_bn_resblk64_1 needs backward computation.
I0818 13:44:37.249963 22726 net.cpp:226] scale_resblk64_1 needs backward computation.
I0818 13:44:37.249967 22726 net.cpp:226] batchNorm_resblk64_1 needs backward computation.
I0818 13:44:37.249972 22726 net.cpp:226] resblk64_1 needs backward computation.
I0818 13:44:37.249977 22726 net.cpp:226] CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split needs backward computation.
I0818 13:44:37.249982 22726 net.cpp:226] CC_sum_bn_resblk64_b needs backward computation.
I0818 13:44:37.249989 22726 net.cpp:228] zeros_sum_bn_resblk64_b does not need backward computation.
I0818 13:44:37.249994 22726 net.cpp:226] relu_sum_bn_resblk64_b needs backward computation.
I0818 13:44:37.249999 22726 net.cpp:226] sum_avgPool_resblk64 needs backward computation.
I0818 13:44:37.250005 22726 net.cpp:226] avePooling_resblk64 needs backward computation.
I0818 13:44:37.250010 22726 net.cpp:226] scale_resblk64_b needs backward computation.
I0818 13:44:37.250015 22726 net.cpp:226] batchNorm_resblk64_b needs backward computation.
I0818 13:44:37.250020 22726 net.cpp:226] resblk64_b needs backward computation.
I0818 13:44:37.250025 22726 net.cpp:226] relu_bn_resblk64 needs backward computation.
I0818 13:44:37.250030 22726 net.cpp:226] scale_resblk64 needs backward computation.
I0818 13:44:37.250036 22726 net.cpp:226] batchNorm_resblk64 needs backward computation.
I0818 13:44:37.250041 22726 net.cpp:226] resblk64 needs backward computation.
I0818 13:44:37.250046 22726 net.cpp:226] sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split needs backward computation.
I0818 13:44:37.250051 22726 net.cpp:226] relu_sum_bn_resblk32_8_b needs backward computation.
I0818 13:44:37.250056 22726 net.cpp:226] sum_sum_bn_resblk32_7_b needs backward computation.
I0818 13:44:37.250062 22726 net.cpp:226] scale_resblk32_8_b needs backward computation.
I0818 13:44:37.250072 22726 net.cpp:226] batchNorm_resblk32_8_b needs backward computation.
I0818 13:44:37.250077 22726 net.cpp:226] resblk32_8_b needs backward computation.
I0818 13:44:37.250082 22726 net.cpp:226] relu_bn_resblk32_8 needs backward computation.
I0818 13:44:37.250087 22726 net.cpp:226] scale_resblk32_8 needs backward computation.
I0818 13:44:37.250092 22726 net.cpp:226] batchNorm_resblk32_8 needs backward computation.
I0818 13:44:37.250098 22726 net.cpp:226] resblk32_8 needs backward computation.
I0818 13:44:37.250103 22726 net.cpp:226] sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split needs backward computation.
I0818 13:44:37.250108 22726 net.cpp:226] relu_sum_bn_resblk32_7_b needs backward computation.
I0818 13:44:37.250114 22726 net.cpp:226] sum_sum_bn_resblk32_6_b needs backward computation.
I0818 13:44:37.250120 22726 net.cpp:226] scale_resblk32_7_b needs backward computation.
I0818 13:44:37.250125 22726 net.cpp:226] batchNorm_resblk32_7_b needs backward computation.
I0818 13:44:37.250130 22726 net.cpp:226] resblk32_7_b needs backward computation.
I0818 13:44:37.250136 22726 net.cpp:226] relu_bn_resblk32_7 needs backward computation.
I0818 13:44:37.250141 22726 net.cpp:226] scale_resblk32_7 needs backward computation.
I0818 13:44:37.250146 22726 net.cpp:226] batchNorm_resblk32_7 needs backward computation.
I0818 13:44:37.250157 22726 net.cpp:226] resblk32_7 needs backward computation.
I0818 13:44:37.250164 22726 net.cpp:226] sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split needs backward computation.
I0818 13:44:37.250169 22726 net.cpp:226] relu_sum_bn_resblk32_6_b needs backward computation.
I0818 13:44:37.250174 22726 net.cpp:226] sum_sum_bn_resblk32_5_b needs backward computation.
I0818 13:44:37.250180 22726 net.cpp:226] scale_resblk32_6_b needs backward computation.
I0818 13:44:37.250185 22726 net.cpp:226] batchNorm_resblk32_6_b needs backward computation.
I0818 13:44:37.250190 22726 net.cpp:226] resblk32_6_b needs backward computation.
I0818 13:44:37.250196 22726 net.cpp:226] relu_bn_resblk32_6 needs backward computation.
I0818 13:44:37.250201 22726 net.cpp:226] scale_resblk32_6 needs backward computation.
I0818 13:44:37.250206 22726 net.cpp:226] batchNorm_resblk32_6 needs backward computation.
I0818 13:44:37.250211 22726 net.cpp:226] resblk32_6 needs backward computation.
I0818 13:44:37.250217 22726 net.cpp:226] sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split needs backward computation.
I0818 13:44:37.250223 22726 net.cpp:226] relu_sum_bn_resblk32_5_b needs backward computation.
I0818 13:44:37.250228 22726 net.cpp:226] sum_sum_bn_resblk32_4_b needs backward computation.
I0818 13:44:37.250234 22726 net.cpp:226] scale_resblk32_5_b needs backward computation.
I0818 13:44:37.250239 22726 net.cpp:226] batchNorm_resblk32_5_b needs backward computation.
I0818 13:44:37.250246 22726 net.cpp:226] resblk32_5_b needs backward computation.
I0818 13:44:37.250250 22726 net.cpp:226] relu_bn_resblk32_5 needs backward computation.
I0818 13:44:37.250255 22726 net.cpp:226] scale_resblk32_5 needs backward computation.
I0818 13:44:37.250260 22726 net.cpp:226] batchNorm_resblk32_5 needs backward computation.
I0818 13:44:37.250265 22726 net.cpp:226] resblk32_5 needs backward computation.
I0818 13:44:37.250272 22726 net.cpp:226] sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split needs backward computation.
I0818 13:44:37.250277 22726 net.cpp:226] relu_sum_bn_resblk32_4_b needs backward computation.
I0818 13:44:37.250282 22726 net.cpp:226] sum_sum_bn_resblk32_3_b needs backward computation.
I0818 13:44:37.250288 22726 net.cpp:226] scale_resblk32_4_b needs backward computation.
I0818 13:44:37.250293 22726 net.cpp:226] batchNorm_resblk32_4_b needs backward computation.
I0818 13:44:37.250298 22726 net.cpp:226] resblk32_4_b needs backward computation.
I0818 13:44:37.250303 22726 net.cpp:226] relu_bn_resblk32_4 needs backward computation.
I0818 13:44:37.250308 22726 net.cpp:226] scale_resblk32_4 needs backward computation.
I0818 13:44:37.250313 22726 net.cpp:226] batchNorm_resblk32_4 needs backward computation.
I0818 13:44:37.250319 22726 net.cpp:226] resblk32_4 needs backward computation.
I0818 13:44:37.250324 22726 net.cpp:226] sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split needs backward computation.
I0818 13:44:37.250330 22726 net.cpp:226] relu_sum_bn_resblk32_3_b needs backward computation.
I0818 13:44:37.250335 22726 net.cpp:226] sum_sum_bn_resblk32_2_b needs backward computation.
I0818 13:44:37.250341 22726 net.cpp:226] scale_resblk32_3_b needs backward computation.
I0818 13:44:37.250346 22726 net.cpp:226] batchNorm_resblk32_3_b needs backward computation.
I0818 13:44:37.250352 22726 net.cpp:226] resblk32_3_b needs backward computation.
I0818 13:44:37.250357 22726 net.cpp:226] relu_bn_resblk32_3 needs backward computation.
I0818 13:44:37.250362 22726 net.cpp:226] scale_resblk32_3 needs backward computation.
I0818 13:44:37.250367 22726 net.cpp:226] batchNorm_resblk32_3 needs backward computation.
I0818 13:44:37.250373 22726 net.cpp:226] resblk32_3 needs backward computation.
I0818 13:44:37.250378 22726 net.cpp:226] sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split needs backward computation.
I0818 13:44:37.250385 22726 net.cpp:226] relu_sum_bn_resblk32_2_b needs backward computation.
I0818 13:44:37.250389 22726 net.cpp:226] sum_sum_bn_resblk32_1_b needs backward computation.
I0818 13:44:37.250396 22726 net.cpp:226] scale_resblk32_2_b needs backward computation.
I0818 13:44:37.250406 22726 net.cpp:226] batchNorm_resblk32_2_b needs backward computation.
I0818 13:44:37.250412 22726 net.cpp:226] resblk32_2_b needs backward computation.
I0818 13:44:37.250418 22726 net.cpp:226] relu_bn_resblk32_2 needs backward computation.
I0818 13:44:37.250423 22726 net.cpp:226] scale_resblk32_2 needs backward computation.
I0818 13:44:37.250428 22726 net.cpp:226] batchNorm_resblk32_2 needs backward computation.
I0818 13:44:37.250434 22726 net.cpp:226] resblk32_2 needs backward computation.
I0818 13:44:37.250440 22726 net.cpp:226] sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split needs backward computation.
I0818 13:44:37.250445 22726 net.cpp:226] relu_sum_bn_resblk32_1_b needs backward computation.
I0818 13:44:37.250452 22726 net.cpp:226] sum_CC_sum_bn_resblk32_b needs backward computation.
I0818 13:44:37.250459 22726 net.cpp:226] scale_resblk32_1_b needs backward computation.
I0818 13:44:37.250465 22726 net.cpp:226] batchNorm_resblk32_1_b needs backward computation.
I0818 13:44:37.250471 22726 net.cpp:226] resblk32_1_b needs backward computation.
I0818 13:44:37.250476 22726 net.cpp:226] relu_bn_resblk32_1 needs backward computation.
I0818 13:44:37.250483 22726 net.cpp:226] scale_resblk32_1 needs backward computation.
I0818 13:44:37.250488 22726 net.cpp:226] batchNorm_resblk32_1 needs backward computation.
I0818 13:44:37.250493 22726 net.cpp:226] resblk32_1 needs backward computation.
I0818 13:44:37.250499 22726 net.cpp:226] CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split needs backward computation.
I0818 13:44:37.250504 22726 net.cpp:226] CC_sum_bn_resblk32_b needs backward computation.
I0818 13:44:37.250510 22726 net.cpp:228] zeros_sum_bn_resblk32_b does not need backward computation.
I0818 13:44:37.250515 22726 net.cpp:226] relu_sum_bn_resblk32_b needs backward computation.
I0818 13:44:37.250520 22726 net.cpp:226] sum_avgPool_resblk32 needs backward computation.
I0818 13:44:37.250526 22726 net.cpp:226] avePooling_resblk32 needs backward computation.
I0818 13:44:37.250531 22726 net.cpp:226] scale_resblk32_b needs backward computation.
I0818 13:44:37.250536 22726 net.cpp:226] batchNorm_resblk32_b needs backward computation.
I0818 13:44:37.250542 22726 net.cpp:226] resblk32_b needs backward computation.
I0818 13:44:37.250547 22726 net.cpp:226] relu_bn_resblk32 needs backward computation.
I0818 13:44:37.250553 22726 net.cpp:226] scale_resblk32 needs backward computation.
I0818 13:44:37.250558 22726 net.cpp:226] batchNorm_resblk32 needs backward computation.
I0818 13:44:37.250563 22726 net.cpp:226] resblk32 needs backward computation.
I0818 13:44:37.250569 22726 net.cpp:226] sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split needs backward computation.
I0818 13:44:37.250576 22726 net.cpp:226] relu_sum_bn_Conv16_9_b needs backward computation.
I0818 13:44:37.250581 22726 net.cpp:226] sum_sum_bn_Conv16_8_b needs backward computation.
I0818 13:44:37.250587 22726 net.cpp:226] scale_Conv16_9_b needs backward computation.
I0818 13:44:37.250592 22726 net.cpp:226] batchNorm_Conv16_9_b needs backward computation.
I0818 13:44:37.250597 22726 net.cpp:226] Conv16_9_b needs backward computation.
I0818 13:44:37.250603 22726 net.cpp:226] relu_bn_Conv16_9 needs backward computation.
I0818 13:44:37.250608 22726 net.cpp:226] scale_Conv16_9 needs backward computation.
I0818 13:44:37.250613 22726 net.cpp:226] batchNorm_Conv16_9 needs backward computation.
I0818 13:44:37.250619 22726 net.cpp:226] Conv16_9 needs backward computation.
I0818 13:44:37.250624 22726 net.cpp:226] sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split needs backward computation.
I0818 13:44:37.250630 22726 net.cpp:226] relu_sum_bn_Conv16_8_b needs backward computation.
I0818 13:44:37.250636 22726 net.cpp:226] sum_sum_bn_Conv16_7_b needs backward computation.
I0818 13:44:37.250643 22726 net.cpp:226] scale_Conv16_8_b needs backward computation.
I0818 13:44:37.250648 22726 net.cpp:226] batchNorm_Conv16_8_b needs backward computation.
I0818 13:44:37.250653 22726 net.cpp:226] Conv16_8_b needs backward computation.
I0818 13:44:37.250663 22726 net.cpp:226] relu_bn_Conv16_8 needs backward computation.
I0818 13:44:37.250669 22726 net.cpp:226] scale_Conv16_8 needs backward computation.
I0818 13:44:37.250674 22726 net.cpp:226] batchNorm_Conv16_8 needs backward computation.
I0818 13:44:37.250679 22726 net.cpp:226] Conv16_8 needs backward computation.
I0818 13:44:37.250685 22726 net.cpp:226] sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split needs backward computation.
I0818 13:44:37.250690 22726 net.cpp:226] relu_sum_bn_Conv16_7_b needs backward computation.
I0818 13:44:37.250696 22726 net.cpp:226] sum_sum_bn_Conv16_6_b needs backward computation.
I0818 13:44:37.250702 22726 net.cpp:226] scale_Conv16_7_b needs backward computation.
I0818 13:44:37.250708 22726 net.cpp:226] batchNorm_Conv16_7_b needs backward computation.
I0818 13:44:37.250713 22726 net.cpp:226] Conv16_7_b needs backward computation.
I0818 13:44:37.250720 22726 net.cpp:226] relu_bn_Conv16_7 needs backward computation.
I0818 13:44:37.250725 22726 net.cpp:226] scale_Conv16_7 needs backward computation.
I0818 13:44:37.250730 22726 net.cpp:226] batchNorm_Conv16_7 needs backward computation.
I0818 13:44:37.250735 22726 net.cpp:226] Conv16_7 needs backward computation.
I0818 13:44:37.250741 22726 net.cpp:226] sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split needs backward computation.
I0818 13:44:37.250747 22726 net.cpp:226] relu_sum_bn_Conv16_6_b needs backward computation.
I0818 13:44:37.250752 22726 net.cpp:226] sum_sum_bn_Conv16_5_b needs backward computation.
I0818 13:44:37.250758 22726 net.cpp:226] scale_Conv16_6_b needs backward computation.
I0818 13:44:37.250764 22726 net.cpp:226] batchNorm_Conv16_6_b needs backward computation.
I0818 13:44:37.250769 22726 net.cpp:226] Conv16_6_b needs backward computation.
I0818 13:44:37.250775 22726 net.cpp:226] relu_bn_Conv16_6 needs backward computation.
I0818 13:44:37.250780 22726 net.cpp:226] scale_Conv16_6 needs backward computation.
I0818 13:44:37.250785 22726 net.cpp:226] batchNorm_Conv16_6 needs backward computation.
I0818 13:44:37.250790 22726 net.cpp:226] Conv16_6 needs backward computation.
I0818 13:44:37.250797 22726 net.cpp:226] sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split needs backward computation.
I0818 13:44:37.250802 22726 net.cpp:226] relu_sum_bn_Conv16_5_b needs backward computation.
I0818 13:44:37.250813 22726 net.cpp:226] sum_sum_bn_Conv16_4_b needs backward computation.
I0818 13:44:37.250820 22726 net.cpp:226] scale_Conv16_5_b needs backward computation.
I0818 13:44:37.250826 22726 net.cpp:226] batchNorm_Conv16_5_b needs backward computation.
I0818 13:44:37.250833 22726 net.cpp:226] Conv16_5_b needs backward computation.
I0818 13:44:37.250838 22726 net.cpp:226] relu_bn_Conv16_5 needs backward computation.
I0818 13:44:37.250844 22726 net.cpp:226] scale_Conv16_5 needs backward computation.
I0818 13:44:37.250849 22726 net.cpp:226] batchNorm_Conv16_5 needs backward computation.
I0818 13:44:37.250854 22726 net.cpp:226] Conv16_5 needs backward computation.
I0818 13:44:37.250860 22726 net.cpp:226] sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split needs backward computation.
I0818 13:44:37.250866 22726 net.cpp:226] relu_sum_bn_Conv16_4_b needs backward computation.
I0818 13:44:37.250871 22726 net.cpp:226] sum_sum_bn_Conv16_3_b needs backward computation.
I0818 13:44:37.250879 22726 net.cpp:226] scale_Conv16_4_b needs backward computation.
I0818 13:44:37.250883 22726 net.cpp:226] batchNorm_Conv16_4_b needs backward computation.
I0818 13:44:37.250888 22726 net.cpp:226] Conv16_4_b needs backward computation.
I0818 13:44:37.250895 22726 net.cpp:226] relu_bn_Conv16_4 needs backward computation.
I0818 13:44:37.250900 22726 net.cpp:226] scale_Conv16_4 needs backward computation.
I0818 13:44:37.250905 22726 net.cpp:226] batchNorm_Conv16_4 needs backward computation.
I0818 13:44:37.250910 22726 net.cpp:226] Conv16_4 needs backward computation.
I0818 13:44:37.250916 22726 net.cpp:226] sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split needs backward computation.
I0818 13:44:37.250922 22726 net.cpp:226] relu_sum_bn_Conv16_3_b needs backward computation.
I0818 13:44:37.250933 22726 net.cpp:226] sum_sum_bn_Conv16_2_b needs backward computation.
I0818 13:44:37.250939 22726 net.cpp:226] scale_Conv16_3_b needs backward computation.
I0818 13:44:37.250946 22726 net.cpp:226] batchNorm_Conv16_3_b needs backward computation.
I0818 13:44:37.250952 22726 net.cpp:226] Conv16_3_b needs backward computation.
I0818 13:44:37.250957 22726 net.cpp:226] relu_bn_Conv16_3 needs backward computation.
I0818 13:44:37.250962 22726 net.cpp:226] scale_Conv16_3 needs backward computation.
I0818 13:44:37.250967 22726 net.cpp:226] batchNorm_Conv16_3 needs backward computation.
I0818 13:44:37.250972 22726 net.cpp:226] Conv16_3 needs backward computation.
I0818 13:44:37.250978 22726 net.cpp:226] sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split needs backward computation.
I0818 13:44:37.250984 22726 net.cpp:226] relu_sum_bn_Conv16_2_b needs backward computation.
I0818 13:44:37.250990 22726 net.cpp:226] sum_sum_bn_Conv16_1_b needs backward computation.
I0818 13:44:37.250996 22726 net.cpp:226] scale_Conv16_2_b needs backward computation.
I0818 13:44:37.251003 22726 net.cpp:226] batchNorm_Conv16_2_b needs backward computation.
I0818 13:44:37.251008 22726 net.cpp:226] Conv16_2_b needs backward computation.
I0818 13:44:37.251013 22726 net.cpp:226] relu_bn_Conv16_2 needs backward computation.
I0818 13:44:37.251019 22726 net.cpp:226] scale_Conv16_2 needs backward computation.
I0818 13:44:37.251024 22726 net.cpp:226] batchNorm_Conv16_2 needs backward computation.
I0818 13:44:37.251029 22726 net.cpp:226] Conv16_2 needs backward computation.
I0818 13:44:37.251036 22726 net.cpp:226] sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split needs backward computation.
I0818 13:44:37.251041 22726 net.cpp:226] relu_sum_bn_Conv16_1_b needs backward computation.
I0818 13:44:37.251047 22726 net.cpp:226] sum_bn_conv needs backward computation.
I0818 13:44:37.251054 22726 net.cpp:226] scale_Conv16_1_b needs backward computation.
I0818 13:44:37.251058 22726 net.cpp:226] batchNorm_Conv16_1_b needs backward computation.
I0818 13:44:37.251065 22726 net.cpp:226] Conv16_1_b needs backward computation.
I0818 13:44:37.251070 22726 net.cpp:226] relu_bn_Conv16_1 needs backward computation.
I0818 13:44:37.251075 22726 net.cpp:226] scale_Conv16_1 needs backward computation.
I0818 13:44:37.251080 22726 net.cpp:226] batchNorm_Conv16_1 needs backward computation.
I0818 13:44:37.251085 22726 net.cpp:226] Conv16_1 needs backward computation.
I0818 13:44:37.251091 22726 net.cpp:226] bn_conv_relu_bn_conv_0_split needs backward computation.
I0818 13:44:37.251096 22726 net.cpp:226] relu_bn_conv needs backward computation.
I0818 13:44:37.251101 22726 net.cpp:226] scale_conv needs backward computation.
I0818 13:44:37.251106 22726 net.cpp:226] batchNorm_conv needs backward computation.
I0818 13:44:37.251111 22726 net.cpp:226] conv needs backward computation.
I0818 13:44:37.251118 22726 net.cpp:228] label_dataLayer_1_split does not need backward computation.
I0818 13:44:37.251128 22726 net.cpp:228] dataLayer does not need backward computation.
I0818 13:44:37.251132 22726 net.cpp:270] This network produces output accuracy
I0818 13:44:37.251139 22726 net.cpp:270] This network produces output loss
I0818 13:44:37.251526 22726 net.cpp:283] Network initialization done.
I0818 13:44:37.258756 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:37.258790 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:37.258854 22726 solver.cpp:181] Creating test net (#0) specified by net file: examples/sc/architectures/arch.prototxt
I0818 13:44:37.259176 22726 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dataLayer
I0818 13:44:37.260951 22726 net.cpp:58] Initializing net from parameters: 
name: "Cifar-Resnet"
state {
  phase: TEST
}
layer {
  name: "dataLayer"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 125
    backend: LMDB
  }
}
layer {
  name: "conv"
  type: "Convolution"
  bottom: "data"
  top: "conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_conv"
  type: "BatchNorm"
  bottom: "conv"
  top: "bn_conv"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv"
  type: "Scale"
  bottom: "bn_conv"
  top: "bn_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_conv"
  type: "ReLU"
  bottom: "bn_conv"
  top: "bn_conv"
}
layer {
  name: "Conv16_1"
  type: "Convolution"
  bottom: "bn_conv"
  top: "Conv16_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_1"
  type: "BatchNorm"
  bottom: "Conv16_1"
  top: "bn_Conv16_1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_1"
  type: "Scale"
  bottom: "bn_Conv16_1"
  top: "bn_Conv16_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_1"
  type: "ReLU"
  bottom: "bn_Conv16_1"
  top: "bn_Conv16_1"
}
layer {
  name: "Conv16_1_b"
  type: "Convolution"
  bottom: "bn_Conv16_1"
  top: "Conv16_1_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_1_b"
  type: "BatchNorm"
  bottom: "Conv16_1_b"
  top: "bn_Conv16_1_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_1_b"
  type: "Scale"
  bottom: "bn_Conv16_1_b"
  top: "bn_Conv16_1_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_bn_conv"
  type: "Eltwise"
  bottom: "bn_conv"
  bottom: "bn_Conv16_1_b"
  top: "sum_bn_Conv16_1_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_1_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_1_b"
  top: "sum_bn_Conv16_1_b"
}
layer {
  name: "Conv16_2"
  type: "Convolution"
  bottom: "sum_bn_Conv16_1_b"
  top: "Conv16_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_2"
  type: "BatchNorm"
  bottom: "Conv16_2"
  top: "bn_Conv16_2"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_2"
  type: "Scale"
  bottom: "bn_Conv16_2"
  top: "bn_Conv16_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_2"
  type: "ReLU"
  bottom: "bn_Conv16_2"
  top: "bn_Conv16_2"
}
layer {
  name: "Conv16_2_b"
  type: "Convolution"
  bottom: "bn_Conv16_2"
  top: "Conv16_2_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_2_b"
  type: "BatchNorm"
  bottom: "Conv16_2_b"
  top: "bn_Conv16_2_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_2_b"
  type: "Scale"
  bottom: "bn_Conv16_2_b"
  top: "bn_Conv16_2_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_1_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_1_b"
  bottom: "bn_Conv16_2_b"
  top: "sum_bn_Conv16_2_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_2_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_2_b"
  top: "sum_bn_Conv16_2_b"
}
layer {
  name: "Conv16_3"
  type: "Convolution"
  bottom: "sum_bn_Conv16_2_b"
  top: "Conv16_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_3"
  type: "BatchNorm"
  bottom: "Conv16_3"
  top: "bn_Conv16_3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_3"
  type: "Scale"
  bottom: "bn_Conv16_3"
  top: "bn_Conv16_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_3"
  type: "ReLU"
  bottom: "bn_Conv16_3"
  top: "bn_Conv16_3"
}
layer {
  name: "Conv16_3_b"
  type: "Convolution"
  bottom: "bn_Conv16_3"
  top: "Conv16_3_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_3_b"
  type: "BatchNorm"
  bottom: "Conv16_3_b"
  top: "bn_Conv16_3_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_3_b"
  type: "Scale"
  bottom: "bn_Conv16_3_b"
  top: "bn_Conv16_3_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_2_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_2_b"
  bottom: "bn_Conv16_3_b"
  top: "sum_bn_Conv16_3_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_3_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_3_b"
  top: "sum_bn_Conv16_3_b"
}
layer {
  name: "Conv16_4"
  type: "Convolution"
  bottom: "sum_bn_Conv16_3_b"
  top: "Conv16_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_4"
  type: "BatchNorm"
  bottom: "Conv16_4"
  top: "bn_Conv16_4"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_4"
  type: "Scale"
  bottom: "bn_Conv16_4"
  top: "bn_Conv16_4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_4"
  type: "ReLU"
  bottom: "bn_Conv16_4"
  top: "bn_Conv16_4"
}
layer {
  name: "Conv16_4_b"
  type: "Convolution"
  bottom: "bn_Conv16_4"
  top: "Conv16_4_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_4_b"
  type: "BatchNorm"
  bottom: "Conv16_4_b"
  top: "bn_Conv16_4_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_4_b"
  type: "Scale"
  bottom: "bn_Conv16_4_b"
  top: "bn_Conv16_4_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_3_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_3_b"
  bottom: "bn_Conv16_4_b"
  top: "sum_bn_Conv16_4_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_4_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_4_b"
  top: "sum_bn_Conv16_4_b"
}
layer {
  name: "Conv16_5"
  type: "Convolution"
  bottom: "sum_bn_Conv16_4_b"
  top: "Conv16_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_5"
  type: "BatchNorm"
  bottom: "Conv16_5"
  top: "bn_Conv16_5"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_5"
  type: "Scale"
  bottom: "bn_Conv16_5"
  top: "bn_Conv16_5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_5"
  type: "ReLU"
  bottom: "bn_Conv16_5"
  top: "bn_Conv16_5"
}
layer {
  name: "Conv16_5_b"
  type: "Convolution"
  bottom: "bn_Conv16_5"
  top: "Conv16_5_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_5_b"
  type: "BatchNorm"
  bottom: "Conv16_5_b"
  top: "bn_Conv16_5_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_5_b"
  type: "Scale"
  bottom: "bn_Conv16_5_b"
  top: "bn_Conv16_5_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_4_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_4_b"
  bottom: "bn_Conv16_5_b"
  top: "sum_bn_Conv16_5_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_5_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_5_b"
  top: "sum_bn_Conv16_5_b"
}
layer {
  name: "Conv16_6"
  type: "Convolution"
  bottom: "sum_bn_Conv16_5_b"
  top: "Conv16_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_6"
  type: "BatchNorm"
  bottom: "Conv16_6"
  top: "bn_Conv16_6"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_6"
  type: "Scale"
  bottom: "bn_Conv16_6"
  top: "bn_Conv16_6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_6"
  type: "ReLU"
  bottom: "bn_Conv16_6"
  top: "bn_Conv16_6"
}
layer {
  name: "Conv16_6_b"
  type: "Convolution"
  bottom: "bn_Conv16_6"
  top: "Conv16_6_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_6_b"
  type: "BatchNorm"
  bottom: "Conv16_6_b"
  top: "bn_Conv16_6_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_6_b"
  type: "Scale"
  bottom: "bn_Conv16_6_b"
  top: "bn_Conv16_6_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_5_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_5_b"
  bottom: "bn_Conv16_6_b"
  top: "sum_bn_Conv16_6_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_6_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_6_b"
  top: "sum_bn_Conv16_6_b"
}
layer {
  name: "Conv16_7"
  type: "Convolution"
  bottom: "sum_bn_Conv16_6_b"
  top: "Conv16_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_7"
  type: "BatchNorm"
  bottom: "Conv16_7"
  top: "bn_Conv16_7"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_7"
  type: "Scale"
  bottom: "bn_Conv16_7"
  top: "bn_Conv16_7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_7"
  type: "ReLU"
  bottom: "bn_Conv16_7"
  top: "bn_Conv16_7"
}
layer {
  name: "Conv16_7_b"
  type: "Convolution"
  bottom: "bn_Conv16_7"
  top: "Conv16_7_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_7_b"
  type: "BatchNorm"
  bottom: "Conv16_7_b"
  top: "bn_Conv16_7_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_7_b"
  type: "Scale"
  bottom: "bn_Conv16_7_b"
  top: "bn_Conv16_7_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_6_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_6_b"
  bottom: "bn_Conv16_7_b"
  top: "sum_bn_Conv16_7_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_7_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_7_b"
  top: "sum_bn_Conv16_7_b"
}
layer {
  name: "Conv16_8"
  type: "Convolution"
  bottom: "sum_bn_Conv16_7_b"
  top: "Conv16_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_8"
  type: "BatchNorm"
  bottom: "Conv16_8"
  top: "bn_Conv16_8"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_8"
  type: "Scale"
  bottom: "bn_Conv16_8"
  top: "bn_Conv16_8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_8"
  type: "ReLU"
  bottom: "bn_Conv16_8"
  top: "bn_Conv16_8"
}
layer {
  name: "Conv16_8_b"
  type: "Convolution"
  bottom: "bn_Conv16_8"
  top: "Conv16_8_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_8_b"
  type: "BatchNorm"
  bottom: "Conv16_8_b"
  top: "bn_Conv16_8_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_8_b"
  type: "Scale"
  bottom: "bn_Conv16_8_b"
  top: "bn_Conv16_8_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_7_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_7_b"
  bottom: "bn_Conv16_8_b"
  top: "sum_bn_Conv16_8_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_8_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_8_b"
  top: "sum_bn_Conv16_8_b"
}
layer {
  name: "Conv16_9"
  type: "Convolution"
  bottom: "sum_bn_Conv16_8_b"
  top: "Conv16_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_9"
  type: "BatchNorm"
  bottom: "Conv16_9"
  top: "bn_Conv16_9"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_9"
  type: "Scale"
  bottom: "bn_Conv16_9"
  top: "bn_Conv16_9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_Conv16_9"
  type: "ReLU"
  bottom: "bn_Conv16_9"
  top: "bn_Conv16_9"
}
layer {
  name: "Conv16_9_b"
  type: "Convolution"
  bottom: "bn_Conv16_9"
  top: "Conv16_9_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_Conv16_9_b"
  type: "BatchNorm"
  bottom: "Conv16_9_b"
  top: "bn_Conv16_9_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_Conv16_9_b"
  type: "Scale"
  bottom: "bn_Conv16_9_b"
  top: "bn_Conv16_9_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_Conv16_8_b"
  type: "Eltwise"
  bottom: "sum_bn_Conv16_8_b"
  bottom: "bn_Conv16_9_b"
  top: "sum_bn_Conv16_9_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_Conv16_9_b"
  type: "ReLU"
  bottom: "sum_bn_Conv16_9_b"
  top: "sum_bn_Conv16_9_b"
}
layer {
  name: "resblk32"
  type: "Convolution"
  bottom: "sum_bn_Conv16_9_b"
  top: "resblk32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32"
  type: "BatchNorm"
  bottom: "resblk32"
  top: "bn_resblk32"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32"
  type: "Scale"
  bottom: "bn_resblk32"
  top: "bn_resblk32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32"
  type: "ReLU"
  bottom: "bn_resblk32"
  top: "bn_resblk32"
}
layer {
  name: "resblk32_b"
  type: "Convolution"
  bottom: "bn_resblk32"
  top: "resblk32_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_b"
  type: "BatchNorm"
  bottom: "resblk32_b"
  top: "bn_resblk32_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_b"
  type: "Scale"
  bottom: "bn_resblk32_b"
  top: "bn_resblk32_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "avePooling_resblk32"
  type: "Pooling"
  bottom: "sum_bn_Conv16_9_b"
  top: "avgPool_resblk32"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "sum_avgPool_resblk32"
  type: "Eltwise"
  bottom: "avgPool_resblk32"
  bottom: "bn_resblk32_b"
  top: "sum_bn_resblk32_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_b"
  top: "sum_bn_resblk32_b"
}
layer {
  name: "zeros_sum_bn_resblk32_b"
  type: "DummyData"
  top: "zeros_sum_bn_resblk32_b"
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 125
      dim: 16
      dim: 16
      dim: 16
    }
  }
}
layer {
  name: "CC_sum_bn_resblk32_b"
  type: "Concat"
  bottom: "sum_bn_resblk32_b"
  bottom: "zeros_sum_bn_resblk32_b"
  top: "CC_sum_bn_resblk32_b"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resblk32_1"
  type: "Convolution"
  bottom: "CC_sum_bn_resblk32_b"
  top: "resblk32_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_1"
  type: "BatchNorm"
  bottom: "resblk32_1"
  top: "bn_resblk32_1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_1"
  type: "Scale"
  bottom: "bn_resblk32_1"
  top: "bn_resblk32_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_1"
  type: "ReLU"
  bottom: "bn_resblk32_1"
  top: "bn_resblk32_1"
}
layer {
  name: "resblk32_1_b"
  type: "Convolution"
  bottom: "bn_resblk32_1"
  top: "resblk32_1_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_1_b"
  type: "BatchNorm"
  bottom: "resblk32_1_b"
  top: "bn_resblk32_1_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_1_b"
  type: "Scale"
  bottom: "bn_resblk32_1_b"
  top: "bn_resblk32_1_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_CC_sum_bn_resblk32_b"
  type: "Eltwise"
  bottom: "CC_sum_bn_resblk32_b"
  bottom: "bn_resblk32_1_b"
  top: "sum_bn_resblk32_1_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_1_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_1_b"
  top: "sum_bn_resblk32_1_b"
}
layer {
  name: "resblk32_2"
  type: "Convolution"
  bottom: "sum_bn_resblk32_1_b"
  top: "resblk32_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_2"
  type: "BatchNorm"
  bottom: "resblk32_2"
  top: "bn_resblk32_2"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_2"
  type: "Scale"
  bottom: "bn_resblk32_2"
  top: "bn_resblk32_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_2"
  type: "ReLU"
  bottom: "bn_resblk32_2"
  top: "bn_resblk32_2"
}
layer {
  name: "resblk32_2_b"
  type: "Convolution"
  bottom: "bn_resblk32_2"
  top: "resblk32_2_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_2_b"
  type: "BatchNorm"
  bottom: "resblk32_2_b"
  top: "bn_resblk32_2_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_2_b"
  type: "Scale"
  bottom: "bn_resblk32_2_b"
  top: "bn_resblk32_2_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_resblk32_1_b"
  type: "Eltwise"
  bottom: "sum_bn_resblk32_1_b"
  bottom: "bn_resblk32_2_b"
  top: "sum_bn_resblk32_2_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_2_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_2_b"
  top: "sum_bn_resblk32_2_b"
}
layer {
  name: "resblk32_3"
  type: "Convolution"
  bottom: "sum_bn_resblk32_2_b"
  top: "resblk32_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_3"
  type: "BatchNorm"
  bottom: "resblk32_3"
  top: "bn_resblk32_3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_3"
  type: "Scale"
  bottom: "bn_resblk32_3"
  top: "bn_resblk32_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_3"
  type: "ReLU"
  bottom: "bn_resblk32_3"
  top: "bn_resblk32_3"
}
layer {
  name: "resblk32_3_b"
  type: "Convolution"
  bottom: "bn_resblk32_3"
  top: "resblk32_3_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_3_b"
  type: "BatchNorm"
  bottom: "resblk32_3_b"
  top: "bn_resblk32_3_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_3_b"
  type: "Scale"
  bottom: "bn_resblk32_3_b"
  top: "bn_resblk32_3_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_resblk32_2_b"
  type: "Eltwise"
  bottom: "sum_bn_resblk32_2_b"
  bottom: "bn_resblk32_3_b"
  top: "sum_bn_resblk32_3_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_3_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_3_b"
  top: "sum_bn_resblk32_3_b"
}
layer {
  name: "resblk32_4"
  type: "Convolution"
  bottom: "sum_bn_resblk32_3_b"
  top: "resblk32_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_4"
  type: "BatchNorm"
  bottom: "resblk32_4"
  top: "bn_resblk32_4"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_4"
  type: "Scale"
  bottom: "bn_resblk32_4"
  top: "bn_resblk32_4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_4"
  type: "ReLU"
  bottom: "bn_resblk32_4"
  top: "bn_resblk32_4"
}
layer {
  name: "resblk32_4_b"
  type: "Convolution"
  bottom: "bn_resblk32_4"
  top: "resblk32_4_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_4_b"
  type: "BatchNorm"
  bottom: "resblk32_4_b"
  top: "bn_resblk32_4_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_4_b"
  type: "Scale"
  bottom: "bn_resblk32_4_b"
  top: "bn_resblk32_4_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_resblk32_3_b"
  type: "Eltwise"
  bottom: "sum_bn_resblk32_3_b"
  bottom: "bn_resblk32_4_b"
  top: "sum_bn_resblk32_4_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_4_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_4_b"
  top: "sum_bn_resblk32_4_b"
}
layer {
  name: "resblk32_5"
  type: "Convolution"
  bottom: "sum_bn_resblk32_4_b"
  top: "resblk32_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_5"
  type: "BatchNorm"
  bottom: "resblk32_5"
  top: "bn_resblk32_5"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_5"
  type: "Scale"
  bottom: "bn_resblk32_5"
  top: "bn_resblk32_5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_5"
  type: "ReLU"
  bottom: "bn_resblk32_5"
  top: "bn_resblk32_5"
}
layer {
  name: "resblk32_5_b"
  type: "Convolution"
  bottom: "bn_resblk32_5"
  top: "resblk32_5_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_5_b"
  type: "BatchNorm"
  bottom: "resblk32_5_b"
  top: "bn_resblk32_5_b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_5_b"
  type: "Scale"
  bottom: "bn_resblk32_5_b"
  top: "bn_resblk32_5_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "sum_sum_bn_resblk32_4_b"
  type: "Eltwise"
  bottom: "sum_bn_resblk32_4_b"
  bottom: "bn_resblk32_5_b"
  top: "sum_bn_resblk32_5_b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu_sum_bn_resblk32_5_b"
  type: "ReLU"
  bottom: "sum_bn_resblk32_5_b"
  top: "sum_bn_resblk32_5_b"
}
layer {
  name: "resblk32_6"
  type: "Convolution"
  bottom: "sum_bn_resblk32_5_b"
  top: "resblk32_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchNorm_resblk32_6"
  type: "BatchNorm"
  bottom: "resblk32_6"
  top: "bn_resblk32_6"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_resblk32_6"
  type: "Scale"
  bottom: "bn_resblk32_6"
  top: "bn_resblk32_6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_bn_resblk32_6"
  type: "ReLU"
  bottom: "bn_resblk32_6"
  top: "bn_resblk32_6"
}
layer {
  name: "resblk32_6_b"
  type: "Convolution"
  bottom: "bn_resblk32_6"
  top: "r
I0818 13:44:37.262527 22726 layer_factory.hpp:77] Creating layer dataLayer
I0818 13:44:37.262760 22726 net.cpp:100] Creating Layer dataLayer
I0818 13:44:37.262783 22726 net.cpp:408] dataLayer -> data
I0818 13:44:37.262801 22726 net.cpp:408] dataLayer -> label
I0818 13:44:37.262820 22726 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0818 13:44:37.272661 22733 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0818 13:44:37.272941 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:37.280246 22726 net.cpp:150] Setting up dataLayer
I0818 13:44:37.280266 22726 net.cpp:157] Top shape: 125 3 32 32 (384000)
I0818 13:44:37.280274 22726 net.cpp:157] Top shape: 125 (125)
I0818 13:44:37.280279 22726 net.cpp:165] Memory required for data: 1536500
I0818 13:44:37.280285 22726 layer_factory.hpp:77] Creating layer label_dataLayer_1_split
I0818 13:44:37.280316 22726 net.cpp:100] Creating Layer label_dataLayer_1_split
I0818 13:44:37.280324 22726 net.cpp:434] label_dataLayer_1_split <- label
I0818 13:44:37.280333 22726 net.cpp:408] label_dataLayer_1_split -> label_dataLayer_1_split_0
I0818 13:44:37.280344 22726 net.cpp:408] label_dataLayer_1_split -> label_dataLayer_1_split_1
I0818 13:44:37.280480 22726 net.cpp:150] Setting up label_dataLayer_1_split
I0818 13:44:37.280496 22726 net.cpp:157] Top shape: 125 (125)
I0818 13:44:37.280503 22726 net.cpp:157] Top shape: 125 (125)
I0818 13:44:37.280508 22726 net.cpp:165] Memory required for data: 1537500
I0818 13:44:37.280513 22726 layer_factory.hpp:77] Creating layer conv
I0818 13:44:37.280534 22726 net.cpp:100] Creating Layer conv
I0818 13:44:37.280540 22726 net.cpp:434] conv <- data
I0818 13:44:37.280552 22726 net.cpp:408] conv -> conv
I0818 13:44:37.281033 22726 net.cpp:150] Setting up conv
I0818 13:44:37.281050 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.281057 22726 net.cpp:165] Memory required for data: 9729500
I0818 13:44:37.281072 22726 layer_factory.hpp:77] Creating layer batchNorm_conv
I0818 13:44:37.281082 22726 net.cpp:100] Creating Layer batchNorm_conv
I0818 13:44:37.281087 22726 net.cpp:434] batchNorm_conv <- conv
I0818 13:44:37.281100 22726 net.cpp:408] batchNorm_conv -> bn_conv
I0818 13:44:37.281510 22726 net.cpp:150] Setting up batchNorm_conv
I0818 13:44:37.281524 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.281533 22726 net.cpp:165] Memory required for data: 17921500
I0818 13:44:37.281548 22726 layer_factory.hpp:77] Creating layer scale_conv
I0818 13:44:37.281561 22726 net.cpp:100] Creating Layer scale_conv
I0818 13:44:37.281568 22726 net.cpp:434] scale_conv <- bn_conv
I0818 13:44:37.281575 22726 net.cpp:395] scale_conv -> bn_conv (in-place)
I0818 13:44:37.281641 22726 layer_factory.hpp:77] Creating layer scale_conv
I0818 13:44:37.281908 22726 net.cpp:150] Setting up scale_conv
I0818 13:44:37.281924 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.281929 22726 net.cpp:165] Memory required for data: 26113500
I0818 13:44:37.281949 22726 layer_factory.hpp:77] Creating layer relu_bn_conv
I0818 13:44:37.281961 22726 net.cpp:100] Creating Layer relu_bn_conv
I0818 13:44:37.281967 22726 net.cpp:434] relu_bn_conv <- bn_conv
I0818 13:44:37.281975 22726 net.cpp:395] relu_bn_conv -> bn_conv (in-place)
I0818 13:44:37.281985 22726 net.cpp:150] Setting up relu_bn_conv
I0818 13:44:37.281991 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.281996 22726 net.cpp:165] Memory required for data: 34305500
I0818 13:44:37.282003 22726 layer_factory.hpp:77] Creating layer bn_conv_relu_bn_conv_0_split
I0818 13:44:37.282014 22726 net.cpp:100] Creating Layer bn_conv_relu_bn_conv_0_split
I0818 13:44:37.282019 22726 net.cpp:434] bn_conv_relu_bn_conv_0_split <- bn_conv
I0818 13:44:37.282027 22726 net.cpp:408] bn_conv_relu_bn_conv_0_split -> bn_conv_relu_bn_conv_0_split_0
I0818 13:44:37.282038 22726 net.cpp:408] bn_conv_relu_bn_conv_0_split -> bn_conv_relu_bn_conv_0_split_1
I0818 13:44:37.282122 22726 net.cpp:150] Setting up bn_conv_relu_bn_conv_0_split
I0818 13:44:37.282136 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.282142 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.282147 22726 net.cpp:165] Memory required for data: 50689500
I0818 13:44:37.282152 22726 layer_factory.hpp:77] Creating layer Conv16_1
I0818 13:44:37.282166 22726 net.cpp:100] Creating Layer Conv16_1
I0818 13:44:37.282172 22726 net.cpp:434] Conv16_1 <- bn_conv_relu_bn_conv_0_split_0
I0818 13:44:37.282181 22726 net.cpp:408] Conv16_1 -> Conv16_1
I0818 13:44:37.282609 22726 net.cpp:150] Setting up Conv16_1
I0818 13:44:37.282624 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.282629 22726 net.cpp:165] Memory required for data: 58881500
I0818 13:44:37.282645 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_1
I0818 13:44:37.282660 22726 net.cpp:100] Creating Layer batchNorm_Conv16_1
I0818 13:44:37.282666 22726 net.cpp:434] batchNorm_Conv16_1 <- Conv16_1
I0818 13:44:37.282701 22726 net.cpp:408] batchNorm_Conv16_1 -> bn_Conv16_1
I0818 13:44:37.283304 22726 net.cpp:150] Setting up batchNorm_Conv16_1
I0818 13:44:37.283320 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.283325 22726 net.cpp:165] Memory required for data: 67073500
I0818 13:44:37.283336 22726 layer_factory.hpp:77] Creating layer scale_Conv16_1
I0818 13:44:37.283345 22726 net.cpp:100] Creating Layer scale_Conv16_1
I0818 13:44:37.283351 22726 net.cpp:434] scale_Conv16_1 <- bn_Conv16_1
I0818 13:44:37.283360 22726 net.cpp:395] scale_Conv16_1 -> bn_Conv16_1 (in-place)
I0818 13:44:37.283432 22726 layer_factory.hpp:77] Creating layer scale_Conv16_1
I0818 13:44:37.283612 22726 net.cpp:150] Setting up scale_Conv16_1
I0818 13:44:37.283627 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.283632 22726 net.cpp:165] Memory required for data: 75265500
I0818 13:44:37.283640 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_1
I0818 13:44:37.283653 22726 net.cpp:100] Creating Layer relu_bn_Conv16_1
I0818 13:44:37.283659 22726 net.cpp:434] relu_bn_Conv16_1 <- bn_Conv16_1
I0818 13:44:37.283670 22726 net.cpp:395] relu_bn_Conv16_1 -> bn_Conv16_1 (in-place)
I0818 13:44:37.283684 22726 net.cpp:150] Setting up relu_bn_Conv16_1
I0818 13:44:37.283690 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.283704 22726 net.cpp:165] Memory required for data: 83457500
I0818 13:44:37.283709 22726 layer_factory.hpp:77] Creating layer Conv16_1_b
I0818 13:44:37.283721 22726 net.cpp:100] Creating Layer Conv16_1_b
I0818 13:44:37.283728 22726 net.cpp:434] Conv16_1_b <- bn_Conv16_1
I0818 13:44:37.283740 22726 net.cpp:408] Conv16_1_b -> Conv16_1_b
I0818 13:44:37.284155 22726 net.cpp:150] Setting up Conv16_1_b
I0818 13:44:37.284173 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.284179 22726 net.cpp:165] Memory required for data: 91649500
I0818 13:44:37.284188 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_1_b
I0818 13:44:37.284200 22726 net.cpp:100] Creating Layer batchNorm_Conv16_1_b
I0818 13:44:37.284216 22726 net.cpp:434] batchNorm_Conv16_1_b <- Conv16_1_b
I0818 13:44:37.284225 22726 net.cpp:408] batchNorm_Conv16_1_b -> bn_Conv16_1_b
I0818 13:44:37.284540 22726 net.cpp:150] Setting up batchNorm_Conv16_1_b
I0818 13:44:37.284554 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.284559 22726 net.cpp:165] Memory required for data: 99841500
I0818 13:44:37.284580 22726 layer_factory.hpp:77] Creating layer scale_Conv16_1_b
I0818 13:44:37.284590 22726 net.cpp:100] Creating Layer scale_Conv16_1_b
I0818 13:44:37.284595 22726 net.cpp:434] scale_Conv16_1_b <- bn_Conv16_1_b
I0818 13:44:37.284606 22726 net.cpp:395] scale_Conv16_1_b -> bn_Conv16_1_b (in-place)
I0818 13:44:37.284672 22726 layer_factory.hpp:77] Creating layer scale_Conv16_1_b
I0818 13:44:37.284893 22726 net.cpp:150] Setting up scale_Conv16_1_b
I0818 13:44:37.284909 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.284915 22726 net.cpp:165] Memory required for data: 108033500
I0818 13:44:37.284924 22726 layer_factory.hpp:77] Creating layer sum_bn_conv
I0818 13:44:37.284934 22726 net.cpp:100] Creating Layer sum_bn_conv
I0818 13:44:37.284939 22726 net.cpp:434] sum_bn_conv <- bn_conv_relu_bn_conv_0_split_1
I0818 13:44:37.284948 22726 net.cpp:434] sum_bn_conv <- bn_Conv16_1_b
I0818 13:44:37.284960 22726 net.cpp:408] sum_bn_conv -> sum_bn_Conv16_1_b
I0818 13:44:37.285001 22726 net.cpp:150] Setting up sum_bn_conv
I0818 13:44:37.285010 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.285017 22726 net.cpp:165] Memory required for data: 116225500
I0818 13:44:37.285022 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_1_b
I0818 13:44:37.285032 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_1_b
I0818 13:44:37.285038 22726 net.cpp:434] relu_sum_bn_Conv16_1_b <- sum_bn_Conv16_1_b
I0818 13:44:37.285048 22726 net.cpp:395] relu_sum_bn_Conv16_1_b -> sum_bn_Conv16_1_b (in-place)
I0818 13:44:37.285058 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_1_b
I0818 13:44:37.285065 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.285069 22726 net.cpp:165] Memory required for data: 124417500
I0818 13:44:37.285074 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split
I0818 13:44:37.285085 22726 net.cpp:100] Creating Layer sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split
I0818 13:44:37.285091 22726 net.cpp:434] sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split <- sum_bn_Conv16_1_b
I0818 13:44:37.285099 22726 net.cpp:408] sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split -> sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split_0
I0818 13:44:37.285107 22726 net.cpp:408] sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split -> sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split_1
I0818 13:44:37.285167 22726 net.cpp:150] Setting up sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split
I0818 13:44:37.285181 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.285187 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.285192 22726 net.cpp:165] Memory required for data: 140801500
I0818 13:44:37.285200 22726 layer_factory.hpp:77] Creating layer Conv16_2
I0818 13:44:37.285215 22726 net.cpp:100] Creating Layer Conv16_2
I0818 13:44:37.285223 22726 net.cpp:434] Conv16_2 <- sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split_0
I0818 13:44:37.285235 22726 net.cpp:408] Conv16_2 -> Conv16_2
I0818 13:44:37.285635 22726 net.cpp:150] Setting up Conv16_2
I0818 13:44:37.285650 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.285653 22726 net.cpp:165] Memory required for data: 148993500
I0818 13:44:37.285665 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_2
I0818 13:44:37.285678 22726 net.cpp:100] Creating Layer batchNorm_Conv16_2
I0818 13:44:37.285686 22726 net.cpp:434] batchNorm_Conv16_2 <- Conv16_2
I0818 13:44:37.285696 22726 net.cpp:408] batchNorm_Conv16_2 -> bn_Conv16_2
I0818 13:44:37.286061 22726 net.cpp:150] Setting up batchNorm_Conv16_2
I0818 13:44:37.286075 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.286088 22726 net.cpp:165] Memory required for data: 157185500
I0818 13:44:37.286103 22726 layer_factory.hpp:77] Creating layer scale_Conv16_2
I0818 13:44:37.286113 22726 net.cpp:100] Creating Layer scale_Conv16_2
I0818 13:44:37.286118 22726 net.cpp:434] scale_Conv16_2 <- bn_Conv16_2
I0818 13:44:37.286126 22726 net.cpp:395] scale_Conv16_2 -> bn_Conv16_2 (in-place)
I0818 13:44:37.286300 22726 layer_factory.hpp:77] Creating layer scale_Conv16_2
I0818 13:44:37.286485 22726 net.cpp:150] Setting up scale_Conv16_2
I0818 13:44:37.286501 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.286506 22726 net.cpp:165] Memory required for data: 165377500
I0818 13:44:37.286515 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_2
I0818 13:44:37.286523 22726 net.cpp:100] Creating Layer relu_bn_Conv16_2
I0818 13:44:37.286538 22726 net.cpp:434] relu_bn_Conv16_2 <- bn_Conv16_2
I0818 13:44:37.286547 22726 net.cpp:395] relu_bn_Conv16_2 -> bn_Conv16_2 (in-place)
I0818 13:44:37.286558 22726 net.cpp:150] Setting up relu_bn_Conv16_2
I0818 13:44:37.286566 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.286569 22726 net.cpp:165] Memory required for data: 173569500
I0818 13:44:37.286577 22726 layer_factory.hpp:77] Creating layer Conv16_2_b
I0818 13:44:37.286592 22726 net.cpp:100] Creating Layer Conv16_2_b
I0818 13:44:37.286597 22726 net.cpp:434] Conv16_2_b <- bn_Conv16_2
I0818 13:44:37.286609 22726 net.cpp:408] Conv16_2_b -> Conv16_2_b
I0818 13:44:37.287034 22726 net.cpp:150] Setting up Conv16_2_b
I0818 13:44:37.287050 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.287055 22726 net.cpp:165] Memory required for data: 181761500
I0818 13:44:37.287063 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_2_b
I0818 13:44:37.287078 22726 net.cpp:100] Creating Layer batchNorm_Conv16_2_b
I0818 13:44:37.287086 22726 net.cpp:434] batchNorm_Conv16_2_b <- Conv16_2_b
I0818 13:44:37.287093 22726 net.cpp:408] batchNorm_Conv16_2_b -> bn_Conv16_2_b
I0818 13:44:37.287470 22726 net.cpp:150] Setting up batchNorm_Conv16_2_b
I0818 13:44:37.287488 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.287493 22726 net.cpp:165] Memory required for data: 189953500
I0818 13:44:37.287513 22726 layer_factory.hpp:77] Creating layer scale_Conv16_2_b
I0818 13:44:37.287521 22726 net.cpp:100] Creating Layer scale_Conv16_2_b
I0818 13:44:37.287528 22726 net.cpp:434] scale_Conv16_2_b <- bn_Conv16_2_b
I0818 13:44:37.287539 22726 net.cpp:395] scale_Conv16_2_b -> bn_Conv16_2_b (in-place)
I0818 13:44:37.287613 22726 layer_factory.hpp:77] Creating layer scale_Conv16_2_b
I0818 13:44:37.287798 22726 net.cpp:150] Setting up scale_Conv16_2_b
I0818 13:44:37.287823 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.287830 22726 net.cpp:165] Memory required for data: 198145500
I0818 13:44:37.287839 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_1_b
I0818 13:44:37.287849 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_1_b
I0818 13:44:37.287858 22726 net.cpp:434] sum_sum_bn_Conv16_1_b <- sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split_1
I0818 13:44:37.287865 22726 net.cpp:434] sum_sum_bn_Conv16_1_b <- bn_Conv16_2_b
I0818 13:44:37.287873 22726 net.cpp:408] sum_sum_bn_Conv16_1_b -> sum_bn_Conv16_2_b
I0818 13:44:37.287916 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_1_b
I0818 13:44:37.287928 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.287935 22726 net.cpp:165] Memory required for data: 206337500
I0818 13:44:37.287940 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_2_b
I0818 13:44:37.287946 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_2_b
I0818 13:44:37.287951 22726 net.cpp:434] relu_sum_bn_Conv16_2_b <- sum_bn_Conv16_2_b
I0818 13:44:37.287958 22726 net.cpp:395] relu_sum_bn_Conv16_2_b -> sum_bn_Conv16_2_b (in-place)
I0818 13:44:37.287967 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_2_b
I0818 13:44:37.287974 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.287979 22726 net.cpp:165] Memory required for data: 214529500
I0818 13:44:37.287994 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split
I0818 13:44:37.288003 22726 net.cpp:100] Creating Layer sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split
I0818 13:44:37.288008 22726 net.cpp:434] sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split <- sum_bn_Conv16_2_b
I0818 13:44:37.288018 22726 net.cpp:408] sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split -> sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split_0
I0818 13:44:37.288031 22726 net.cpp:408] sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split -> sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split_1
I0818 13:44:37.288087 22726 net.cpp:150] Setting up sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split
I0818 13:44:37.288096 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.288103 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.288107 22726 net.cpp:165] Memory required for data: 230913500
I0818 13:44:37.288112 22726 layer_factory.hpp:77] Creating layer Conv16_3
I0818 13:44:37.288130 22726 net.cpp:100] Creating Layer Conv16_3
I0818 13:44:37.288141 22726 net.cpp:434] Conv16_3 <- sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split_0
I0818 13:44:37.288151 22726 net.cpp:408] Conv16_3 -> Conv16_3
I0818 13:44:37.288589 22726 net.cpp:150] Setting up Conv16_3
I0818 13:44:37.288604 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.288611 22726 net.cpp:165] Memory required for data: 239105500
I0818 13:44:37.288621 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_3
I0818 13:44:37.288630 22726 net.cpp:100] Creating Layer batchNorm_Conv16_3
I0818 13:44:37.288636 22726 net.cpp:434] batchNorm_Conv16_3 <- Conv16_3
I0818 13:44:37.288650 22726 net.cpp:408] batchNorm_Conv16_3 -> bn_Conv16_3
I0818 13:44:37.288983 22726 net.cpp:150] Setting up batchNorm_Conv16_3
I0818 13:44:37.288998 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.289005 22726 net.cpp:165] Memory required for data: 247297500
I0818 13:44:37.289014 22726 layer_factory.hpp:77] Creating layer scale_Conv16_3
I0818 13:44:37.289026 22726 net.cpp:100] Creating Layer scale_Conv16_3
I0818 13:44:37.289032 22726 net.cpp:434] scale_Conv16_3 <- bn_Conv16_3
I0818 13:44:37.289043 22726 net.cpp:395] scale_Conv16_3 -> bn_Conv16_3 (in-place)
I0818 13:44:37.289113 22726 layer_factory.hpp:77] Creating layer scale_Conv16_3
I0818 13:44:37.289499 22726 net.cpp:150] Setting up scale_Conv16_3
I0818 13:44:37.289515 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.289520 22726 net.cpp:165] Memory required for data: 255489500
I0818 13:44:37.289528 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_3
I0818 13:44:37.289539 22726 net.cpp:100] Creating Layer relu_bn_Conv16_3
I0818 13:44:37.289546 22726 net.cpp:434] relu_bn_Conv16_3 <- bn_Conv16_3
I0818 13:44:37.289553 22726 net.cpp:395] relu_bn_Conv16_3 -> bn_Conv16_3 (in-place)
I0818 13:44:37.289562 22726 net.cpp:150] Setting up relu_bn_Conv16_3
I0818 13:44:37.289572 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.289579 22726 net.cpp:165] Memory required for data: 263681500
I0818 13:44:37.289584 22726 layer_factory.hpp:77] Creating layer Conv16_3_b
I0818 13:44:37.289599 22726 net.cpp:100] Creating Layer Conv16_3_b
I0818 13:44:37.289605 22726 net.cpp:434] Conv16_3_b <- bn_Conv16_3
I0818 13:44:37.289620 22726 net.cpp:408] Conv16_3_b -> Conv16_3_b
I0818 13:44:37.290082 22726 net.cpp:150] Setting up Conv16_3_b
I0818 13:44:37.290097 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.290102 22726 net.cpp:165] Memory required for data: 271873500
I0818 13:44:37.290113 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_3_b
I0818 13:44:37.290129 22726 net.cpp:100] Creating Layer batchNorm_Conv16_3_b
I0818 13:44:37.290136 22726 net.cpp:434] batchNorm_Conv16_3_b <- Conv16_3_b
I0818 13:44:37.290151 22726 net.cpp:408] batchNorm_Conv16_3_b -> bn_Conv16_3_b
I0818 13:44:37.290467 22726 net.cpp:150] Setting up batchNorm_Conv16_3_b
I0818 13:44:37.290482 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.290495 22726 net.cpp:165] Memory required for data: 280065500
I0818 13:44:37.290506 22726 layer_factory.hpp:77] Creating layer scale_Conv16_3_b
I0818 13:44:37.290518 22726 net.cpp:100] Creating Layer scale_Conv16_3_b
I0818 13:44:37.290524 22726 net.cpp:434] scale_Conv16_3_b <- bn_Conv16_3_b
I0818 13:44:37.290532 22726 net.cpp:395] scale_Conv16_3_b -> bn_Conv16_3_b (in-place)
I0818 13:44:37.290601 22726 layer_factory.hpp:77] Creating layer scale_Conv16_3_b
I0818 13:44:37.290793 22726 net.cpp:150] Setting up scale_Conv16_3_b
I0818 13:44:37.290813 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.290819 22726 net.cpp:165] Memory required for data: 288257500
I0818 13:44:37.290830 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_2_b
I0818 13:44:37.290843 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_2_b
I0818 13:44:37.290850 22726 net.cpp:434] sum_sum_bn_Conv16_2_b <- sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split_1
I0818 13:44:37.290858 22726 net.cpp:434] sum_sum_bn_Conv16_2_b <- bn_Conv16_3_b
I0818 13:44:37.290864 22726 net.cpp:408] sum_sum_bn_Conv16_2_b -> sum_bn_Conv16_3_b
I0818 13:44:37.290908 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_2_b
I0818 13:44:37.290918 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.290923 22726 net.cpp:165] Memory required for data: 296449500
I0818 13:44:37.290928 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_3_b
I0818 13:44:37.290935 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_3_b
I0818 13:44:37.290940 22726 net.cpp:434] relu_sum_bn_Conv16_3_b <- sum_bn_Conv16_3_b
I0818 13:44:37.290951 22726 net.cpp:395] relu_sum_bn_Conv16_3_b -> sum_bn_Conv16_3_b (in-place)
I0818 13:44:37.290961 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_3_b
I0818 13:44:37.290967 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.290972 22726 net.cpp:165] Memory required for data: 304641500
I0818 13:44:37.290977 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split
I0818 13:44:37.290983 22726 net.cpp:100] Creating Layer sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split
I0818 13:44:37.290988 22726 net.cpp:434] sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split <- sum_bn_Conv16_3_b
I0818 13:44:37.290997 22726 net.cpp:408] sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split -> sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split_0
I0818 13:44:37.291007 22726 net.cpp:408] sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split -> sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split_1
I0818 13:44:37.291057 22726 net.cpp:150] Setting up sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split
I0818 13:44:37.291066 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.291074 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.291079 22726 net.cpp:165] Memory required for data: 321025500
I0818 13:44:37.291084 22726 layer_factory.hpp:77] Creating layer Conv16_4
I0818 13:44:37.291097 22726 net.cpp:100] Creating Layer Conv16_4
I0818 13:44:37.291105 22726 net.cpp:434] Conv16_4 <- sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split_0
I0818 13:44:37.291113 22726 net.cpp:408] Conv16_4 -> Conv16_4
I0818 13:44:37.291472 22726 net.cpp:150] Setting up Conv16_4
I0818 13:44:37.291486 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.291491 22726 net.cpp:165] Memory required for data: 329217500
I0818 13:44:37.291501 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_4
I0818 13:44:37.291512 22726 net.cpp:100] Creating Layer batchNorm_Conv16_4
I0818 13:44:37.291518 22726 net.cpp:434] batchNorm_Conv16_4 <- Conv16_4
I0818 13:44:37.291527 22726 net.cpp:408] batchNorm_Conv16_4 -> bn_Conv16_4
I0818 13:44:37.291800 22726 net.cpp:150] Setting up batchNorm_Conv16_4
I0818 13:44:37.291817 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.291823 22726 net.cpp:165] Memory required for data: 337409500
I0818 13:44:37.291833 22726 layer_factory.hpp:77] Creating layer scale_Conv16_4
I0818 13:44:37.291841 22726 net.cpp:100] Creating Layer scale_Conv16_4
I0818 13:44:37.291854 22726 net.cpp:434] scale_Conv16_4 <- bn_Conv16_4
I0818 13:44:37.291862 22726 net.cpp:395] scale_Conv16_4 -> bn_Conv16_4 (in-place)
I0818 13:44:37.291924 22726 layer_factory.hpp:77] Creating layer scale_Conv16_4
I0818 13:44:37.292111 22726 net.cpp:150] Setting up scale_Conv16_4
I0818 13:44:37.292126 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.292130 22726 net.cpp:165] Memory required for data: 345601500
I0818 13:44:37.292140 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_4
I0818 13:44:37.292147 22726 net.cpp:100] Creating Layer relu_bn_Conv16_4
I0818 13:44:37.292153 22726 net.cpp:434] relu_bn_Conv16_4 <- bn_Conv16_4
I0818 13:44:37.292163 22726 net.cpp:395] relu_bn_Conv16_4 -> bn_Conv16_4 (in-place)
I0818 13:44:37.292173 22726 net.cpp:150] Setting up relu_bn_Conv16_4
I0818 13:44:37.292181 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.292184 22726 net.cpp:165] Memory required for data: 353793500
I0818 13:44:37.292189 22726 layer_factory.hpp:77] Creating layer Conv16_4_b
I0818 13:44:37.292202 22726 net.cpp:100] Creating Layer Conv16_4_b
I0818 13:44:37.292208 22726 net.cpp:434] Conv16_4_b <- bn_Conv16_4
I0818 13:44:37.292217 22726 net.cpp:408] Conv16_4_b -> Conv16_4_b
I0818 13:44:37.292579 22726 net.cpp:150] Setting up Conv16_4_b
I0818 13:44:37.292593 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.292598 22726 net.cpp:165] Memory required for data: 361985500
I0818 13:44:37.292606 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_4_b
I0818 13:44:37.292618 22726 net.cpp:100] Creating Layer batchNorm_Conv16_4_b
I0818 13:44:37.292623 22726 net.cpp:434] batchNorm_Conv16_4_b <- Conv16_4_b
I0818 13:44:37.292631 22726 net.cpp:408] batchNorm_Conv16_4_b -> bn_Conv16_4_b
I0818 13:44:37.292915 22726 net.cpp:150] Setting up batchNorm_Conv16_4_b
I0818 13:44:37.292930 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.292934 22726 net.cpp:165] Memory required for data: 370177500
I0818 13:44:37.292944 22726 layer_factory.hpp:77] Creating layer scale_Conv16_4_b
I0818 13:44:37.292953 22726 net.cpp:100] Creating Layer scale_Conv16_4_b
I0818 13:44:37.292959 22726 net.cpp:434] scale_Conv16_4_b <- bn_Conv16_4_b
I0818 13:44:37.292966 22726 net.cpp:395] scale_Conv16_4_b -> bn_Conv16_4_b (in-place)
I0818 13:44:37.293027 22726 layer_factory.hpp:77] Creating layer scale_Conv16_4_b
I0818 13:44:37.293184 22726 net.cpp:150] Setting up scale_Conv16_4_b
I0818 13:44:37.293197 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.293201 22726 net.cpp:165] Memory required for data: 378369500
I0818 13:44:37.293210 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_3_b
I0818 13:44:37.293222 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_3_b
I0818 13:44:37.293228 22726 net.cpp:434] sum_sum_bn_Conv16_3_b <- sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split_1
I0818 13:44:37.293236 22726 net.cpp:434] sum_sum_bn_Conv16_3_b <- bn_Conv16_4_b
I0818 13:44:37.293242 22726 net.cpp:408] sum_sum_bn_Conv16_3_b -> sum_bn_Conv16_4_b
I0818 13:44:37.293280 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_3_b
I0818 13:44:37.293292 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.293296 22726 net.cpp:165] Memory required for data: 386561500
I0818 13:44:37.293301 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_4_b
I0818 13:44:37.293308 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_4_b
I0818 13:44:37.293314 22726 net.cpp:434] relu_sum_bn_Conv16_4_b <- sum_bn_Conv16_4_b
I0818 13:44:37.293324 22726 net.cpp:395] relu_sum_bn_Conv16_4_b -> sum_bn_Conv16_4_b (in-place)
I0818 13:44:37.293334 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_4_b
I0818 13:44:37.293340 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.293345 22726 net.cpp:165] Memory required for data: 394753500
I0818 13:44:37.293350 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split
I0818 13:44:37.293357 22726 net.cpp:100] Creating Layer sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split
I0818 13:44:37.293370 22726 net.cpp:434] sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split <- sum_bn_Conv16_4_b
I0818 13:44:37.293380 22726 net.cpp:408] sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split -> sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split_0
I0818 13:44:37.293390 22726 net.cpp:408] sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split -> sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split_1
I0818 13:44:37.293437 22726 net.cpp:150] Setting up sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split
I0818 13:44:37.293447 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.293452 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.293457 22726 net.cpp:165] Memory required for data: 411137500
I0818 13:44:37.293462 22726 layer_factory.hpp:77] Creating layer Conv16_5
I0818 13:44:37.293475 22726 net.cpp:100] Creating Layer Conv16_5
I0818 13:44:37.293483 22726 net.cpp:434] Conv16_5 <- sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split_0
I0818 13:44:37.293491 22726 net.cpp:408] Conv16_5 -> Conv16_5
I0818 13:44:37.293860 22726 net.cpp:150] Setting up Conv16_5
I0818 13:44:37.293875 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.293880 22726 net.cpp:165] Memory required for data: 419329500
I0818 13:44:37.293907 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_5
I0818 13:44:37.293916 22726 net.cpp:100] Creating Layer batchNorm_Conv16_5
I0818 13:44:37.293922 22726 net.cpp:434] batchNorm_Conv16_5 <- Conv16_5
I0818 13:44:37.293933 22726 net.cpp:408] batchNorm_Conv16_5 -> bn_Conv16_5
I0818 13:44:37.294209 22726 net.cpp:150] Setting up batchNorm_Conv16_5
I0818 13:44:37.294221 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.294226 22726 net.cpp:165] Memory required for data: 427521500
I0818 13:44:37.294237 22726 layer_factory.hpp:77] Creating layer scale_Conv16_5
I0818 13:44:37.294245 22726 net.cpp:100] Creating Layer scale_Conv16_5
I0818 13:44:37.294251 22726 net.cpp:434] scale_Conv16_5 <- bn_Conv16_5
I0818 13:44:37.294258 22726 net.cpp:395] scale_Conv16_5 -> bn_Conv16_5 (in-place)
I0818 13:44:37.294320 22726 layer_factory.hpp:77] Creating layer scale_Conv16_5
I0818 13:44:37.294479 22726 net.cpp:150] Setting up scale_Conv16_5
I0818 13:44:37.294493 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.294497 22726 net.cpp:165] Memory required for data: 435713500
I0818 13:44:37.294507 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_5
I0818 13:44:37.294514 22726 net.cpp:100] Creating Layer relu_bn_Conv16_5
I0818 13:44:37.294520 22726 net.cpp:434] relu_bn_Conv16_5 <- bn_Conv16_5
I0818 13:44:37.294530 22726 net.cpp:395] relu_bn_Conv16_5 -> bn_Conv16_5 (in-place)
I0818 13:44:37.294540 22726 net.cpp:150] Setting up relu_bn_Conv16_5
I0818 13:44:37.294546 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.294551 22726 net.cpp:165] Memory required for data: 443905500
I0818 13:44:37.294555 22726 layer_factory.hpp:77] Creating layer Conv16_5_b
I0818 13:44:37.294569 22726 net.cpp:100] Creating Layer Conv16_5_b
I0818 13:44:37.294574 22726 net.cpp:434] Conv16_5_b <- bn_Conv16_5
I0818 13:44:37.294584 22726 net.cpp:408] Conv16_5_b -> Conv16_5_b
I0818 13:44:37.294950 22726 net.cpp:150] Setting up Conv16_5_b
I0818 13:44:37.294965 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.294970 22726 net.cpp:165] Memory required for data: 452097500
I0818 13:44:37.294977 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_5_b
I0818 13:44:37.294986 22726 net.cpp:100] Creating Layer batchNorm_Conv16_5_b
I0818 13:44:37.294991 22726 net.cpp:434] batchNorm_Conv16_5_b <- Conv16_5_b
I0818 13:44:37.295003 22726 net.cpp:408] batchNorm_Conv16_5_b -> bn_Conv16_5_b
I0818 13:44:37.295284 22726 net.cpp:150] Setting up batchNorm_Conv16_5_b
I0818 13:44:37.295301 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.295307 22726 net.cpp:165] Memory required for data: 460289500
I0818 13:44:37.295317 22726 layer_factory.hpp:77] Creating layer scale_Conv16_5_b
I0818 13:44:37.295325 22726 net.cpp:100] Creating Layer scale_Conv16_5_b
I0818 13:44:37.295337 22726 net.cpp:434] scale_Conv16_5_b <- bn_Conv16_5_b
I0818 13:44:37.295346 22726 net.cpp:395] scale_Conv16_5_b -> bn_Conv16_5_b (in-place)
I0818 13:44:37.295405 22726 layer_factory.hpp:77] Creating layer scale_Conv16_5_b
I0818 13:44:37.295568 22726 net.cpp:150] Setting up scale_Conv16_5_b
I0818 13:44:37.295581 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.295586 22726 net.cpp:165] Memory required for data: 468481500
I0818 13:44:37.295595 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_4_b
I0818 13:44:37.295616 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_4_b
I0818 13:44:37.295624 22726 net.cpp:434] sum_sum_bn_Conv16_4_b <- sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split_1
I0818 13:44:37.295631 22726 net.cpp:434] sum_sum_bn_Conv16_4_b <- bn_Conv16_5_b
I0818 13:44:37.295642 22726 net.cpp:408] sum_sum_bn_Conv16_4_b -> sum_bn_Conv16_5_b
I0818 13:44:37.295678 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_4_b
I0818 13:44:37.295687 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.295692 22726 net.cpp:165] Memory required for data: 476673500
I0818 13:44:37.295697 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_5_b
I0818 13:44:37.295709 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_5_b
I0818 13:44:37.295716 22726 net.cpp:434] relu_sum_bn_Conv16_5_b <- sum_bn_Conv16_5_b
I0818 13:44:37.295722 22726 net.cpp:395] relu_sum_bn_Conv16_5_b -> sum_bn_Conv16_5_b (in-place)
I0818 13:44:37.295732 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_5_b
I0818 13:44:37.295738 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.295742 22726 net.cpp:165] Memory required for data: 484865500
I0818 13:44:37.295747 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split
I0818 13:44:37.295753 22726 net.cpp:100] Creating Layer sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split
I0818 13:44:37.295758 22726 net.cpp:434] sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split <- sum_bn_Conv16_5_b
I0818 13:44:37.295766 22726 net.cpp:408] sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split -> sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split_0
I0818 13:44:37.295775 22726 net.cpp:408] sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split -> sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split_1
I0818 13:44:37.295835 22726 net.cpp:150] Setting up sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split
I0818 13:44:37.295847 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.295853 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.295861 22726 net.cpp:165] Memory required for data: 501249500
I0818 13:44:37.295866 22726 layer_factory.hpp:77] Creating layer Conv16_6
I0818 13:44:37.295881 22726 net.cpp:100] Creating Layer Conv16_6
I0818 13:44:37.295887 22726 net.cpp:434] Conv16_6 <- sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split_0
I0818 13:44:37.295897 22726 net.cpp:408] Conv16_6 -> Conv16_6
I0818 13:44:37.296253 22726 net.cpp:150] Setting up Conv16_6
I0818 13:44:37.296267 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.296272 22726 net.cpp:165] Memory required for data: 509441500
I0818 13:44:37.296281 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_6
I0818 13:44:37.296293 22726 net.cpp:100] Creating Layer batchNorm_Conv16_6
I0818 13:44:37.296298 22726 net.cpp:434] batchNorm_Conv16_6 <- Conv16_6
I0818 13:44:37.296306 22726 net.cpp:408] batchNorm_Conv16_6 -> bn_Conv16_6
I0818 13:44:37.296583 22726 net.cpp:150] Setting up batchNorm_Conv16_6
I0818 13:44:37.296602 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.296607 22726 net.cpp:165] Memory required for data: 517633500
I0818 13:44:37.296617 22726 layer_factory.hpp:77] Creating layer scale_Conv16_6
I0818 13:44:37.296624 22726 net.cpp:100] Creating Layer scale_Conv16_6
I0818 13:44:37.296630 22726 net.cpp:434] scale_Conv16_6 <- bn_Conv16_6
I0818 13:44:37.296638 22726 net.cpp:395] scale_Conv16_6 -> bn_Conv16_6 (in-place)
I0818 13:44:37.296695 22726 layer_factory.hpp:77] Creating layer scale_Conv16_6
I0818 13:44:37.296877 22726 net.cpp:150] Setting up scale_Conv16_6
I0818 13:44:37.296891 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.296895 22726 net.cpp:165] Memory required for data: 525825500
I0818 13:44:37.296905 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_6
I0818 13:44:37.296916 22726 net.cpp:100] Creating Layer relu_bn_Conv16_6
I0818 13:44:37.296922 22726 net.cpp:434] relu_bn_Conv16_6 <- bn_Conv16_6
I0818 13:44:37.296932 22726 net.cpp:395] relu_bn_Conv16_6 -> bn_Conv16_6 (in-place)
I0818 13:44:37.296942 22726 net.cpp:150] Setting up relu_bn_Conv16_6
I0818 13:44:37.296949 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.296954 22726 net.cpp:165] Memory required for data: 534017500
I0818 13:44:37.296958 22726 layer_factory.hpp:77] Creating layer Conv16_6_b
I0818 13:44:37.296968 22726 net.cpp:100] Creating Layer Conv16_6_b
I0818 13:44:37.296974 22726 net.cpp:434] Conv16_6_b <- bn_Conv16_6
I0818 13:44:37.296986 22726 net.cpp:408] Conv16_6_b -> Conv16_6_b
I0818 13:44:37.297338 22726 net.cpp:150] Setting up Conv16_6_b
I0818 13:44:37.297351 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.297356 22726 net.cpp:165] Memory required for data: 542209500
I0818 13:44:37.297364 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_6_b
I0818 13:44:37.297374 22726 net.cpp:100] Creating Layer batchNorm_Conv16_6_b
I0818 13:44:37.297379 22726 net.cpp:434] batchNorm_Conv16_6_b <- Conv16_6_b
I0818 13:44:37.297390 22726 net.cpp:408] batchNorm_Conv16_6_b -> bn_Conv16_6_b
I0818 13:44:37.297693 22726 net.cpp:150] Setting up batchNorm_Conv16_6_b
I0818 13:44:37.297706 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.297711 22726 net.cpp:165] Memory required for data: 550401500
I0818 13:44:37.297721 22726 layer_factory.hpp:77] Creating layer scale_Conv16_6_b
I0818 13:44:37.297734 22726 net.cpp:100] Creating Layer scale_Conv16_6_b
I0818 13:44:37.297740 22726 net.cpp:434] scale_Conv16_6_b <- bn_Conv16_6_b
I0818 13:44:37.297749 22726 net.cpp:395] scale_Conv16_6_b -> bn_Conv16_6_b (in-place)
I0818 13:44:37.297813 22726 layer_factory.hpp:77] Creating layer scale_Conv16_6_b
I0818 13:44:37.297976 22726 net.cpp:150] Setting up scale_Conv16_6_b
I0818 13:44:37.297988 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.297993 22726 net.cpp:165] Memory required for data: 558593500
I0818 13:44:37.298002 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_5_b
I0818 13:44:37.298022 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_5_b
I0818 13:44:37.298029 22726 net.cpp:434] sum_sum_bn_Conv16_5_b <- sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split_1
I0818 13:44:37.298038 22726 net.cpp:434] sum_sum_bn_Conv16_5_b <- bn_Conv16_6_b
I0818 13:44:37.298044 22726 net.cpp:408] sum_sum_bn_Conv16_5_b -> sum_bn_Conv16_6_b
I0818 13:44:37.298084 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_5_b
I0818 13:44:37.298094 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.298099 22726 net.cpp:165] Memory required for data: 566785500
I0818 13:44:37.298104 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_6_b
I0818 13:44:37.298110 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_6_b
I0818 13:44:37.298115 22726 net.cpp:434] relu_sum_bn_Conv16_6_b <- sum_bn_Conv16_6_b
I0818 13:44:37.298122 22726 net.cpp:395] relu_sum_bn_Conv16_6_b -> sum_bn_Conv16_6_b (in-place)
I0818 13:44:37.298131 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_6_b
I0818 13:44:37.298138 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.298142 22726 net.cpp:165] Memory required for data: 574977500
I0818 13:44:37.298147 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split
I0818 13:44:37.298153 22726 net.cpp:100] Creating Layer sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split
I0818 13:44:37.298158 22726 net.cpp:434] sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split <- sum_bn_Conv16_6_b
I0818 13:44:37.298168 22726 net.cpp:408] sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split -> sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split_0
I0818 13:44:37.298185 22726 net.cpp:408] sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split -> sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split_1
I0818 13:44:37.298234 22726 net.cpp:150] Setting up sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split
I0818 13:44:37.298243 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.298249 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.298254 22726 net.cpp:165] Memory required for data: 591361500
I0818 13:44:37.298259 22726 layer_factory.hpp:77] Creating layer Conv16_7
I0818 13:44:37.298272 22726 net.cpp:100] Creating Layer Conv16_7
I0818 13:44:37.298280 22726 net.cpp:434] Conv16_7 <- sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split_0
I0818 13:44:37.298288 22726 net.cpp:408] Conv16_7 -> Conv16_7
I0818 13:44:37.298648 22726 net.cpp:150] Setting up Conv16_7
I0818 13:44:37.298663 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.298667 22726 net.cpp:165] Memory required for data: 599553500
I0818 13:44:37.298676 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_7
I0818 13:44:37.298691 22726 net.cpp:100] Creating Layer batchNorm_Conv16_7
I0818 13:44:37.298696 22726 net.cpp:434] batchNorm_Conv16_7 <- Conv16_7
I0818 13:44:37.298707 22726 net.cpp:408] batchNorm_Conv16_7 -> bn_Conv16_7
I0818 13:44:37.298995 22726 net.cpp:150] Setting up batchNorm_Conv16_7
I0818 13:44:37.299010 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.299013 22726 net.cpp:165] Memory required for data: 607745500
I0818 13:44:37.299024 22726 layer_factory.hpp:77] Creating layer scale_Conv16_7
I0818 13:44:37.299032 22726 net.cpp:100] Creating Layer scale_Conv16_7
I0818 13:44:37.299038 22726 net.cpp:434] scale_Conv16_7 <- bn_Conv16_7
I0818 13:44:37.299046 22726 net.cpp:395] scale_Conv16_7 -> bn_Conv16_7 (in-place)
I0818 13:44:37.299106 22726 layer_factory.hpp:77] Creating layer scale_Conv16_7
I0818 13:44:37.299266 22726 net.cpp:150] Setting up scale_Conv16_7
I0818 13:44:37.299279 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.299284 22726 net.cpp:165] Memory required for data: 615937500
I0818 13:44:37.299293 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_7
I0818 13:44:37.299300 22726 net.cpp:100] Creating Layer relu_bn_Conv16_7
I0818 13:44:37.299310 22726 net.cpp:434] relu_bn_Conv16_7 <- bn_Conv16_7
I0818 13:44:37.299317 22726 net.cpp:395] relu_bn_Conv16_7 -> bn_Conv16_7 (in-place)
I0818 13:44:37.299326 22726 net.cpp:150] Setting up relu_bn_Conv16_7
I0818 13:44:37.299334 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.299338 22726 net.cpp:165] Memory required for data: 624129500
I0818 13:44:37.299342 22726 layer_factory.hpp:77] Creating layer Conv16_7_b
I0818 13:44:37.299355 22726 net.cpp:100] Creating Layer Conv16_7_b
I0818 13:44:37.299361 22726 net.cpp:434] Conv16_7_b <- bn_Conv16_7
I0818 13:44:37.299372 22726 net.cpp:408] Conv16_7_b -> Conv16_7_b
I0818 13:44:37.299741 22726 net.cpp:150] Setting up Conv16_7_b
I0818 13:44:37.299756 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.299760 22726 net.cpp:165] Memory required for data: 632321500
I0818 13:44:37.299769 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_7_b
I0818 13:44:37.299780 22726 net.cpp:100] Creating Layer batchNorm_Conv16_7_b
I0818 13:44:37.299787 22726 net.cpp:434] batchNorm_Conv16_7_b <- Conv16_7_b
I0818 13:44:37.299794 22726 net.cpp:408] batchNorm_Conv16_7_b -> bn_Conv16_7_b
I0818 13:44:37.300078 22726 net.cpp:150] Setting up batchNorm_Conv16_7_b
I0818 13:44:37.300094 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.300099 22726 net.cpp:165] Memory required for data: 640513500
I0818 13:44:37.300109 22726 layer_factory.hpp:77] Creating layer scale_Conv16_7_b
I0818 13:44:37.300119 22726 net.cpp:100] Creating Layer scale_Conv16_7_b
I0818 13:44:37.300125 22726 net.cpp:434] scale_Conv16_7_b <- bn_Conv16_7_b
I0818 13:44:37.300133 22726 net.cpp:395] scale_Conv16_7_b -> bn_Conv16_7_b (in-place)
I0818 13:44:37.300197 22726 layer_factory.hpp:77] Creating layer scale_Conv16_7_b
I0818 13:44:37.300367 22726 net.cpp:150] Setting up scale_Conv16_7_b
I0818 13:44:37.300381 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.300385 22726 net.cpp:165] Memory required for data: 648705500
I0818 13:44:37.300395 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_6_b
I0818 13:44:37.300403 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_6_b
I0818 13:44:37.300410 22726 net.cpp:434] sum_sum_bn_Conv16_6_b <- sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split_1
I0818 13:44:37.300416 22726 net.cpp:434] sum_sum_bn_Conv16_6_b <- bn_Conv16_7_b
I0818 13:44:37.300427 22726 net.cpp:408] sum_sum_bn_Conv16_6_b -> sum_bn_Conv16_7_b
I0818 13:44:37.300462 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_6_b
I0818 13:44:37.300472 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.300475 22726 net.cpp:165] Memory required for data: 656897500
I0818 13:44:37.300480 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_7_b
I0818 13:44:37.300492 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_7_b
I0818 13:44:37.300498 22726 net.cpp:434] relu_sum_bn_Conv16_7_b <- sum_bn_Conv16_7_b
I0818 13:44:37.300504 22726 net.cpp:395] relu_sum_bn_Conv16_7_b -> sum_bn_Conv16_7_b (in-place)
I0818 13:44:37.300513 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_7_b
I0818 13:44:37.300519 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.300524 22726 net.cpp:165] Memory required for data: 665089500
I0818 13:44:37.300529 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split
I0818 13:44:37.300535 22726 net.cpp:100] Creating Layer sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split
I0818 13:44:37.300540 22726 net.cpp:434] sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split <- sum_bn_Conv16_7_b
I0818 13:44:37.300547 22726 net.cpp:408] sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split -> sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split_0
I0818 13:44:37.300556 22726 net.cpp:408] sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split -> sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split_1
I0818 13:44:37.300606 22726 net.cpp:150] Setting up sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split
I0818 13:44:37.300618 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.300624 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.300629 22726 net.cpp:165] Memory required for data: 681473500
I0818 13:44:37.300634 22726 layer_factory.hpp:77] Creating layer Conv16_8
I0818 13:44:37.300647 22726 net.cpp:100] Creating Layer Conv16_8
I0818 13:44:37.300653 22726 net.cpp:434] Conv16_8 <- sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split_0
I0818 13:44:37.300662 22726 net.cpp:408] Conv16_8 -> Conv16_8
I0818 13:44:37.301030 22726 net.cpp:150] Setting up Conv16_8
I0818 13:44:37.301044 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.301049 22726 net.cpp:165] Memory required for data: 689665500
I0818 13:44:37.301057 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_8
I0818 13:44:37.301069 22726 net.cpp:100] Creating Layer batchNorm_Conv16_8
I0818 13:44:37.301075 22726 net.cpp:434] batchNorm_Conv16_8 <- Conv16_8
I0818 13:44:37.301084 22726 net.cpp:408] batchNorm_Conv16_8 -> bn_Conv16_8
I0818 13:44:37.301367 22726 net.cpp:150] Setting up batchNorm_Conv16_8
I0818 13:44:37.301379 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.301383 22726 net.cpp:165] Memory required for data: 697857500
I0818 13:44:37.301393 22726 layer_factory.hpp:77] Creating layer scale_Conv16_8
I0818 13:44:37.301403 22726 net.cpp:100] Creating Layer scale_Conv16_8
I0818 13:44:37.301409 22726 net.cpp:434] scale_Conv16_8 <- bn_Conv16_8
I0818 13:44:37.301415 22726 net.cpp:395] scale_Conv16_8 -> bn_Conv16_8 (in-place)
I0818 13:44:37.301476 22726 layer_factory.hpp:77] Creating layer scale_Conv16_8
I0818 13:44:37.301645 22726 net.cpp:150] Setting up scale_Conv16_8
I0818 13:44:37.301657 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.301662 22726 net.cpp:165] Memory required for data: 706049500
I0818 13:44:37.301678 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_8
I0818 13:44:37.301687 22726 net.cpp:100] Creating Layer relu_bn_Conv16_8
I0818 13:44:37.301692 22726 net.cpp:434] relu_bn_Conv16_8 <- bn_Conv16_8
I0818 13:44:37.301705 22726 net.cpp:395] relu_bn_Conv16_8 -> bn_Conv16_8 (in-place)
I0818 13:44:37.301714 22726 net.cpp:150] Setting up relu_bn_Conv16_8
I0818 13:44:37.301722 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.301726 22726 net.cpp:165] Memory required for data: 714241500
I0818 13:44:37.301730 22726 layer_factory.hpp:77] Creating layer Conv16_8_b
I0818 13:44:37.301741 22726 net.cpp:100] Creating Layer Conv16_8_b
I0818 13:44:37.301746 22726 net.cpp:434] Conv16_8_b <- bn_Conv16_8
I0818 13:44:37.301758 22726 net.cpp:408] Conv16_8_b -> Conv16_8_b
I0818 13:44:37.302124 22726 net.cpp:150] Setting up Conv16_8_b
I0818 13:44:37.302139 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.302144 22726 net.cpp:165] Memory required for data: 722433500
I0818 13:44:37.302152 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_8_b
I0818 13:44:37.302160 22726 net.cpp:100] Creating Layer batchNorm_Conv16_8_b
I0818 13:44:37.302166 22726 net.cpp:434] batchNorm_Conv16_8_b <- Conv16_8_b
I0818 13:44:37.302177 22726 net.cpp:408] batchNorm_Conv16_8_b -> bn_Conv16_8_b
I0818 13:44:37.302458 22726 net.cpp:150] Setting up batchNorm_Conv16_8_b
I0818 13:44:37.302469 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.302474 22726 net.cpp:165] Memory required for data: 730625500
I0818 13:44:37.302484 22726 layer_factory.hpp:77] Creating layer scale_Conv16_8_b
I0818 13:44:37.302495 22726 net.cpp:100] Creating Layer scale_Conv16_8_b
I0818 13:44:37.302502 22726 net.cpp:434] scale_Conv16_8_b <- bn_Conv16_8_b
I0818 13:44:37.302510 22726 net.cpp:395] scale_Conv16_8_b -> bn_Conv16_8_b (in-place)
I0818 13:44:37.302567 22726 layer_factory.hpp:77] Creating layer scale_Conv16_8_b
I0818 13:44:37.302729 22726 net.cpp:150] Setting up scale_Conv16_8_b
I0818 13:44:37.302742 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.302747 22726 net.cpp:165] Memory required for data: 738817500
I0818 13:44:37.302757 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_7_b
I0818 13:44:37.302767 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_7_b
I0818 13:44:37.302773 22726 net.cpp:434] sum_sum_bn_Conv16_7_b <- sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split_1
I0818 13:44:37.302781 22726 net.cpp:434] sum_sum_bn_Conv16_7_b <- bn_Conv16_8_b
I0818 13:44:37.302788 22726 net.cpp:408] sum_sum_bn_Conv16_7_b -> sum_bn_Conv16_8_b
I0818 13:44:37.302832 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_7_b
I0818 13:44:37.302845 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.302850 22726 net.cpp:165] Memory required for data: 747009500
I0818 13:44:37.302855 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_8_b
I0818 13:44:37.302861 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_8_b
I0818 13:44:37.302867 22726 net.cpp:434] relu_sum_bn_Conv16_8_b <- sum_bn_Conv16_8_b
I0818 13:44:37.302877 22726 net.cpp:395] relu_sum_bn_Conv16_8_b -> sum_bn_Conv16_8_b (in-place)
I0818 13:44:37.302887 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_8_b
I0818 13:44:37.302894 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.302898 22726 net.cpp:165] Memory required for data: 755201500
I0818 13:44:37.302903 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split
I0818 13:44:37.302909 22726 net.cpp:100] Creating Layer sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split
I0818 13:44:37.302914 22726 net.cpp:434] sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split <- sum_bn_Conv16_8_b
I0818 13:44:37.302922 22726 net.cpp:408] sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split -> sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split_0
I0818 13:44:37.302932 22726 net.cpp:408] sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split -> sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split_1
I0818 13:44:37.302983 22726 net.cpp:150] Setting up sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split
I0818 13:44:37.302999 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.303005 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.303009 22726 net.cpp:165] Memory required for data: 771585500
I0818 13:44:37.303014 22726 layer_factory.hpp:77] Creating layer Conv16_9
I0818 13:44:37.303027 22726 net.cpp:100] Creating Layer Conv16_9
I0818 13:44:37.303033 22726 net.cpp:434] Conv16_9 <- sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split_0
I0818 13:44:37.303043 22726 net.cpp:408] Conv16_9 -> Conv16_9
I0818 13:44:37.303412 22726 net.cpp:150] Setting up Conv16_9
I0818 13:44:37.303429 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.303434 22726 net.cpp:165] Memory required for data: 779777500
I0818 13:44:37.303442 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_9
I0818 13:44:37.303453 22726 net.cpp:100] Creating Layer batchNorm_Conv16_9
I0818 13:44:37.303459 22726 net.cpp:434] batchNorm_Conv16_9 <- Conv16_9
I0818 13:44:37.303468 22726 net.cpp:408] batchNorm_Conv16_9 -> bn_Conv16_9
I0818 13:44:37.303752 22726 net.cpp:150] Setting up batchNorm_Conv16_9
I0818 13:44:37.303766 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.303769 22726 net.cpp:165] Memory required for data: 787969500
I0818 13:44:37.303781 22726 layer_factory.hpp:77] Creating layer scale_Conv16_9
I0818 13:44:37.303789 22726 net.cpp:100] Creating Layer scale_Conv16_9
I0818 13:44:37.303794 22726 net.cpp:434] scale_Conv16_9 <- bn_Conv16_9
I0818 13:44:37.303805 22726 net.cpp:395] scale_Conv16_9 -> bn_Conv16_9 (in-place)
I0818 13:44:37.303872 22726 layer_factory.hpp:77] Creating layer scale_Conv16_9
I0818 13:44:37.304035 22726 net.cpp:150] Setting up scale_Conv16_9
I0818 13:44:37.304050 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.304055 22726 net.cpp:165] Memory required for data: 796161500
I0818 13:44:37.304064 22726 layer_factory.hpp:77] Creating layer relu_bn_Conv16_9
I0818 13:44:37.304072 22726 net.cpp:100] Creating Layer relu_bn_Conv16_9
I0818 13:44:37.304078 22726 net.cpp:434] relu_bn_Conv16_9 <- bn_Conv16_9
I0818 13:44:37.304085 22726 net.cpp:395] relu_bn_Conv16_9 -> bn_Conv16_9 (in-place)
I0818 13:44:37.304095 22726 net.cpp:150] Setting up relu_bn_Conv16_9
I0818 13:44:37.304101 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.304105 22726 net.cpp:165] Memory required for data: 804353500
I0818 13:44:37.304111 22726 layer_factory.hpp:77] Creating layer Conv16_9_b
I0818 13:44:37.304123 22726 net.cpp:100] Creating Layer Conv16_9_b
I0818 13:44:37.304129 22726 net.cpp:434] Conv16_9_b <- bn_Conv16_9
I0818 13:44:37.304142 22726 net.cpp:408] Conv16_9_b -> Conv16_9_b
I0818 13:44:37.304502 22726 net.cpp:150] Setting up Conv16_9_b
I0818 13:44:37.304515 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.304520 22726 net.cpp:165] Memory required for data: 812545500
I0818 13:44:37.304528 22726 layer_factory.hpp:77] Creating layer batchNorm_Conv16_9_b
I0818 13:44:37.304539 22726 net.cpp:100] Creating Layer batchNorm_Conv16_9_b
I0818 13:44:37.304545 22726 net.cpp:434] batchNorm_Conv16_9_b <- Conv16_9_b
I0818 13:44:37.304554 22726 net.cpp:408] batchNorm_Conv16_9_b -> bn_Conv16_9_b
I0818 13:44:37.304842 22726 net.cpp:150] Setting up batchNorm_Conv16_9_b
I0818 13:44:37.304855 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.304860 22726 net.cpp:165] Memory required for data: 820737500
I0818 13:44:37.304893 22726 layer_factory.hpp:77] Creating layer scale_Conv16_9_b
I0818 13:44:37.304903 22726 net.cpp:100] Creating Layer scale_Conv16_9_b
I0818 13:44:37.304908 22726 net.cpp:434] scale_Conv16_9_b <- bn_Conv16_9_b
I0818 13:44:37.304919 22726 net.cpp:395] scale_Conv16_9_b -> bn_Conv16_9_b (in-place)
I0818 13:44:37.304976 22726 layer_factory.hpp:77] Creating layer scale_Conv16_9_b
I0818 13:44:37.305145 22726 net.cpp:150] Setting up scale_Conv16_9_b
I0818 13:44:37.305158 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.305163 22726 net.cpp:165] Memory required for data: 828929500
I0818 13:44:37.305179 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_Conv16_8_b
I0818 13:44:37.305191 22726 net.cpp:100] Creating Layer sum_sum_bn_Conv16_8_b
I0818 13:44:37.305197 22726 net.cpp:434] sum_sum_bn_Conv16_8_b <- sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split_1
I0818 13:44:37.305205 22726 net.cpp:434] sum_sum_bn_Conv16_8_b <- bn_Conv16_9_b
I0818 13:44:37.305213 22726 net.cpp:408] sum_sum_bn_Conv16_8_b -> sum_bn_Conv16_9_b
I0818 13:44:37.305248 22726 net.cpp:150] Setting up sum_sum_bn_Conv16_8_b
I0818 13:44:37.305259 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.305264 22726 net.cpp:165] Memory required for data: 837121500
I0818 13:44:37.305269 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_Conv16_9_b
I0818 13:44:37.305279 22726 net.cpp:100] Creating Layer relu_sum_bn_Conv16_9_b
I0818 13:44:37.305285 22726 net.cpp:434] relu_sum_bn_Conv16_9_b <- sum_bn_Conv16_9_b
I0818 13:44:37.305292 22726 net.cpp:395] relu_sum_bn_Conv16_9_b -> sum_bn_Conv16_9_b (in-place)
I0818 13:44:37.305302 22726 net.cpp:150] Setting up relu_sum_bn_Conv16_9_b
I0818 13:44:37.305308 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.305313 22726 net.cpp:165] Memory required for data: 845313500
I0818 13:44:37.305317 22726 layer_factory.hpp:77] Creating layer sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split
I0818 13:44:37.305327 22726 net.cpp:100] Creating Layer sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split
I0818 13:44:37.305332 22726 net.cpp:434] sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split <- sum_bn_Conv16_9_b
I0818 13:44:37.305339 22726 net.cpp:408] sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split -> sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split_0
I0818 13:44:37.305348 22726 net.cpp:408] sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split -> sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split_1
I0818 13:44:37.305402 22726 net.cpp:150] Setting up sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split
I0818 13:44:37.305413 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.305419 22726 net.cpp:157] Top shape: 125 16 32 32 (2048000)
I0818 13:44:37.305423 22726 net.cpp:165] Memory required for data: 861697500
I0818 13:44:37.305428 22726 layer_factory.hpp:77] Creating layer resblk32
I0818 13:44:37.305441 22726 net.cpp:100] Creating Layer resblk32
I0818 13:44:37.305449 22726 net.cpp:434] resblk32 <- sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split_0
I0818 13:44:37.305456 22726 net.cpp:408] resblk32 -> resblk32
I0818 13:44:37.305829 22726 net.cpp:150] Setting up resblk32
I0818 13:44:37.305842 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.305847 22726 net.cpp:165] Memory required for data: 863745500
I0818 13:44:37.305856 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32
I0818 13:44:37.305867 22726 net.cpp:100] Creating Layer batchNorm_resblk32
I0818 13:44:37.305873 22726 net.cpp:434] batchNorm_resblk32 <- resblk32
I0818 13:44:37.305882 22726 net.cpp:408] batchNorm_resblk32 -> bn_resblk32
I0818 13:44:37.306154 22726 net.cpp:150] Setting up batchNorm_resblk32
I0818 13:44:37.306170 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.306175 22726 net.cpp:165] Memory required for data: 865793500
I0818 13:44:37.306185 22726 layer_factory.hpp:77] Creating layer scale_resblk32
I0818 13:44:37.306195 22726 net.cpp:100] Creating Layer scale_resblk32
I0818 13:44:37.306200 22726 net.cpp:434] scale_resblk32 <- bn_resblk32
I0818 13:44:37.306207 22726 net.cpp:395] scale_resblk32 -> bn_resblk32 (in-place)
I0818 13:44:37.306267 22726 layer_factory.hpp:77] Creating layer scale_resblk32
I0818 13:44:37.306430 22726 net.cpp:150] Setting up scale_resblk32
I0818 13:44:37.306443 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.306448 22726 net.cpp:165] Memory required for data: 867841500
I0818 13:44:37.306457 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32
I0818 13:44:37.306464 22726 net.cpp:100] Creating Layer relu_bn_resblk32
I0818 13:44:37.306470 22726 net.cpp:434] relu_bn_resblk32 <- bn_resblk32
I0818 13:44:37.306490 22726 net.cpp:395] relu_bn_resblk32 -> bn_resblk32 (in-place)
I0818 13:44:37.306500 22726 net.cpp:150] Setting up relu_bn_resblk32
I0818 13:44:37.306507 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.306511 22726 net.cpp:165] Memory required for data: 869889500
I0818 13:44:37.306516 22726 layer_factory.hpp:77] Creating layer resblk32_b
I0818 13:44:37.306529 22726 net.cpp:100] Creating Layer resblk32_b
I0818 13:44:37.306535 22726 net.cpp:434] resblk32_b <- bn_resblk32
I0818 13:44:37.306543 22726 net.cpp:408] resblk32_b -> resblk32_b
I0818 13:44:37.306910 22726 net.cpp:150] Setting up resblk32_b
I0818 13:44:37.306924 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.306929 22726 net.cpp:165] Memory required for data: 871937500
I0818 13:44:37.306938 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_b
I0818 13:44:37.306946 22726 net.cpp:100] Creating Layer batchNorm_resblk32_b
I0818 13:44:37.306951 22726 net.cpp:434] batchNorm_resblk32_b <- resblk32_b
I0818 13:44:37.306963 22726 net.cpp:408] batchNorm_resblk32_b -> bn_resblk32_b
I0818 13:44:37.307234 22726 net.cpp:150] Setting up batchNorm_resblk32_b
I0818 13:44:37.307246 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.307251 22726 net.cpp:165] Memory required for data: 873985500
I0818 13:44:37.307261 22726 layer_factory.hpp:77] Creating layer scale_resblk32_b
I0818 13:44:37.307272 22726 net.cpp:100] Creating Layer scale_resblk32_b
I0818 13:44:37.307278 22726 net.cpp:434] scale_resblk32_b <- bn_resblk32_b
I0818 13:44:37.307286 22726 net.cpp:395] scale_resblk32_b -> bn_resblk32_b (in-place)
I0818 13:44:37.307344 22726 layer_factory.hpp:77] Creating layer scale_resblk32_b
I0818 13:44:37.307505 22726 net.cpp:150] Setting up scale_resblk32_b
I0818 13:44:37.307518 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.307523 22726 net.cpp:165] Memory required for data: 876033500
I0818 13:44:37.307533 22726 layer_factory.hpp:77] Creating layer avePooling_resblk32
I0818 13:44:37.307543 22726 net.cpp:100] Creating Layer avePooling_resblk32
I0818 13:44:37.307550 22726 net.cpp:434] avePooling_resblk32 <- sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split_1
I0818 13:44:37.307561 22726 net.cpp:408] avePooling_resblk32 -> avgPool_resblk32
I0818 13:44:37.307591 22726 net.cpp:150] Setting up avePooling_resblk32
I0818 13:44:37.307600 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.307605 22726 net.cpp:165] Memory required for data: 878081500
I0818 13:44:37.307610 22726 layer_factory.hpp:77] Creating layer sum_avgPool_resblk32
I0818 13:44:37.307618 22726 net.cpp:100] Creating Layer sum_avgPool_resblk32
I0818 13:44:37.307623 22726 net.cpp:434] sum_avgPool_resblk32 <- avgPool_resblk32
I0818 13:44:37.307631 22726 net.cpp:434] sum_avgPool_resblk32 <- bn_resblk32_b
I0818 13:44:37.307641 22726 net.cpp:408] sum_avgPool_resblk32 -> sum_bn_resblk32_b
I0818 13:44:37.307677 22726 net.cpp:150] Setting up sum_avgPool_resblk32
I0818 13:44:37.307687 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.307693 22726 net.cpp:165] Memory required for data: 880129500
I0818 13:44:37.307696 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_b
I0818 13:44:37.307704 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_b
I0818 13:44:37.307710 22726 net.cpp:434] relu_sum_bn_resblk32_b <- sum_bn_resblk32_b
I0818 13:44:37.307720 22726 net.cpp:395] relu_sum_bn_resblk32_b -> sum_bn_resblk32_b (in-place)
I0818 13:44:37.307729 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_b
I0818 13:44:37.307736 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.307741 22726 net.cpp:165] Memory required for data: 882177500
I0818 13:44:37.307745 22726 layer_factory.hpp:77] Creating layer zeros_sum_bn_resblk32_b
I0818 13:44:37.307755 22726 net.cpp:100] Creating Layer zeros_sum_bn_resblk32_b
I0818 13:44:37.307762 22726 net.cpp:408] zeros_sum_bn_resblk32_b -> zeros_sum_bn_resblk32_b
I0818 13:44:37.310086 22726 net.cpp:150] Setting up zeros_sum_bn_resblk32_b
I0818 13:44:37.310104 22726 net.cpp:157] Top shape: 125 16 16 16 (512000)
I0818 13:44:37.310118 22726 net.cpp:165] Memory required for data: 884225500
I0818 13:44:37.310124 22726 layer_factory.hpp:77] Creating layer CC_sum_bn_resblk32_b
I0818 13:44:37.310133 22726 net.cpp:100] Creating Layer CC_sum_bn_resblk32_b
I0818 13:44:37.310140 22726 net.cpp:434] CC_sum_bn_resblk32_b <- sum_bn_resblk32_b
I0818 13:44:37.310148 22726 net.cpp:434] CC_sum_bn_resblk32_b <- zeros_sum_bn_resblk32_b
I0818 13:44:37.310158 22726 net.cpp:408] CC_sum_bn_resblk32_b -> CC_sum_bn_resblk32_b
I0818 13:44:37.310209 22726 net.cpp:150] Setting up CC_sum_bn_resblk32_b
I0818 13:44:37.310220 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.310225 22726 net.cpp:165] Memory required for data: 888321500
I0818 13:44:37.310230 22726 layer_factory.hpp:77] Creating layer CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split
I0818 13:44:37.310238 22726 net.cpp:100] Creating Layer CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split
I0818 13:44:37.310245 22726 net.cpp:434] CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split <- CC_sum_bn_resblk32_b
I0818 13:44:37.310255 22726 net.cpp:408] CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split -> CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split_0
I0818 13:44:37.310264 22726 net.cpp:408] CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split -> CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split_1
I0818 13:44:37.310317 22726 net.cpp:150] Setting up CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split
I0818 13:44:37.310330 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.310338 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.310341 22726 net.cpp:165] Memory required for data: 896513500
I0818 13:44:37.310346 22726 layer_factory.hpp:77] Creating layer resblk32_1
I0818 13:44:37.310358 22726 net.cpp:100] Creating Layer resblk32_1
I0818 13:44:37.310364 22726 net.cpp:434] resblk32_1 <- CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split_0
I0818 13:44:37.310374 22726 net.cpp:408] resblk32_1 -> resblk32_1
I0818 13:44:37.310885 22726 net.cpp:150] Setting up resblk32_1
I0818 13:44:37.310899 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.310904 22726 net.cpp:165] Memory required for data: 900609500
I0818 13:44:37.310914 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_1
I0818 13:44:37.310925 22726 net.cpp:100] Creating Layer batchNorm_resblk32_1
I0818 13:44:37.310931 22726 net.cpp:434] batchNorm_resblk32_1 <- resblk32_1
I0818 13:44:37.310940 22726 net.cpp:408] batchNorm_resblk32_1 -> bn_resblk32_1
I0818 13:44:37.311216 22726 net.cpp:150] Setting up batchNorm_resblk32_1
I0818 13:44:37.311228 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.311233 22726 net.cpp:165] Memory required for data: 904705500
I0818 13:44:37.311244 22726 layer_factory.hpp:77] Creating layer scale_resblk32_1
I0818 13:44:37.311252 22726 net.cpp:100] Creating Layer scale_resblk32_1
I0818 13:44:37.311259 22726 net.cpp:434] scale_resblk32_1 <- bn_resblk32_1
I0818 13:44:37.311269 22726 net.cpp:395] scale_resblk32_1 -> bn_resblk32_1 (in-place)
I0818 13:44:37.311329 22726 layer_factory.hpp:77] Creating layer scale_resblk32_1
I0818 13:44:37.311487 22726 net.cpp:150] Setting up scale_resblk32_1
I0818 13:44:37.311501 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.311506 22726 net.cpp:165] Memory required for data: 908801500
I0818 13:44:37.311513 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_1
I0818 13:44:37.311522 22726 net.cpp:100] Creating Layer relu_bn_resblk32_1
I0818 13:44:37.311527 22726 net.cpp:434] relu_bn_resblk32_1 <- bn_resblk32_1
I0818 13:44:37.311538 22726 net.cpp:395] relu_bn_resblk32_1 -> bn_resblk32_1 (in-place)
I0818 13:44:37.311547 22726 net.cpp:150] Setting up relu_bn_resblk32_1
I0818 13:44:37.311554 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.311559 22726 net.cpp:165] Memory required for data: 912897500
I0818 13:44:37.311563 22726 layer_factory.hpp:77] Creating layer resblk32_1_b
I0818 13:44:37.311578 22726 net.cpp:100] Creating Layer resblk32_1_b
I0818 13:44:37.311590 22726 net.cpp:434] resblk32_1_b <- bn_resblk32_1
I0818 13:44:37.311599 22726 net.cpp:408] resblk32_1_b -> resblk32_1_b
I0818 13:44:37.312180 22726 net.cpp:150] Setting up resblk32_1_b
I0818 13:44:37.312196 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.312201 22726 net.cpp:165] Memory required for data: 916993500
I0818 13:44:37.312211 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_1_b
I0818 13:44:37.312219 22726 net.cpp:100] Creating Layer batchNorm_resblk32_1_b
I0818 13:44:37.312225 22726 net.cpp:434] batchNorm_resblk32_1_b <- resblk32_1_b
I0818 13:44:37.312237 22726 net.cpp:408] batchNorm_resblk32_1_b -> bn_resblk32_1_b
I0818 13:44:37.312507 22726 net.cpp:150] Setting up batchNorm_resblk32_1_b
I0818 13:44:37.312520 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.312525 22726 net.cpp:165] Memory required for data: 921089500
I0818 13:44:37.312536 22726 layer_factory.hpp:77] Creating layer scale_resblk32_1_b
I0818 13:44:37.312543 22726 net.cpp:100] Creating Layer scale_resblk32_1_b
I0818 13:44:37.312551 22726 net.cpp:434] scale_resblk32_1_b <- bn_resblk32_1_b
I0818 13:44:37.312557 22726 net.cpp:395] scale_resblk32_1_b -> bn_resblk32_1_b (in-place)
I0818 13:44:37.312619 22726 layer_factory.hpp:77] Creating layer scale_resblk32_1_b
I0818 13:44:37.312777 22726 net.cpp:150] Setting up scale_resblk32_1_b
I0818 13:44:37.312793 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.312798 22726 net.cpp:165] Memory required for data: 925185500
I0818 13:44:37.312813 22726 layer_factory.hpp:77] Creating layer sum_CC_sum_bn_resblk32_b
I0818 13:44:37.312822 22726 net.cpp:100] Creating Layer sum_CC_sum_bn_resblk32_b
I0818 13:44:37.312829 22726 net.cpp:434] sum_CC_sum_bn_resblk32_b <- CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split_1
I0818 13:44:37.312836 22726 net.cpp:434] sum_CC_sum_bn_resblk32_b <- bn_resblk32_1_b
I0818 13:44:37.312844 22726 net.cpp:408] sum_CC_sum_bn_resblk32_b -> sum_bn_resblk32_1_b
I0818 13:44:37.312878 22726 net.cpp:150] Setting up sum_CC_sum_bn_resblk32_b
I0818 13:44:37.312888 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.312893 22726 net.cpp:165] Memory required for data: 929281500
I0818 13:44:37.312898 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_1_b
I0818 13:44:37.312906 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_1_b
I0818 13:44:37.312911 22726 net.cpp:434] relu_sum_bn_resblk32_1_b <- sum_bn_resblk32_1_b
I0818 13:44:37.312922 22726 net.cpp:395] relu_sum_bn_resblk32_1_b -> sum_bn_resblk32_1_b (in-place)
I0818 13:44:37.312932 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_1_b
I0818 13:44:37.312937 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.312942 22726 net.cpp:165] Memory required for data: 933377500
I0818 13:44:37.312947 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split
I0818 13:44:37.312954 22726 net.cpp:100] Creating Layer sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split
I0818 13:44:37.312959 22726 net.cpp:434] sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split <- sum_bn_resblk32_1_b
I0818 13:44:37.312969 22726 net.cpp:408] sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split -> sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split_0
I0818 13:44:37.312979 22726 net.cpp:408] sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split -> sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split_1
I0818 13:44:37.313029 22726 net.cpp:150] Setting up sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split
I0818 13:44:37.313040 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.313046 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.313050 22726 net.cpp:165] Memory required for data: 941569500
I0818 13:44:37.313055 22726 layer_factory.hpp:77] Creating layer resblk32_2
I0818 13:44:37.313069 22726 net.cpp:100] Creating Layer resblk32_2
I0818 13:44:37.313076 22726 net.cpp:434] resblk32_2 <- sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split_0
I0818 13:44:37.313092 22726 net.cpp:408] resblk32_2 -> resblk32_2
I0818 13:44:37.313596 22726 net.cpp:150] Setting up resblk32_2
I0818 13:44:37.313608 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.313613 22726 net.cpp:165] Memory required for data: 945665500
I0818 13:44:37.313622 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_2
I0818 13:44:37.313630 22726 net.cpp:100] Creating Layer batchNorm_resblk32_2
I0818 13:44:37.313637 22726 net.cpp:434] batchNorm_resblk32_2 <- resblk32_2
I0818 13:44:37.313647 22726 net.cpp:408] batchNorm_resblk32_2 -> bn_resblk32_2
I0818 13:44:37.313922 22726 net.cpp:150] Setting up batchNorm_resblk32_2
I0818 13:44:37.313935 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.313941 22726 net.cpp:165] Memory required for data: 949761500
I0818 13:44:37.313951 22726 layer_factory.hpp:77] Creating layer scale_resblk32_2
I0818 13:44:37.313959 22726 net.cpp:100] Creating Layer scale_resblk32_2
I0818 13:44:37.313966 22726 net.cpp:434] scale_resblk32_2 <- bn_resblk32_2
I0818 13:44:37.313972 22726 net.cpp:395] scale_resblk32_2 -> bn_resblk32_2 (in-place)
I0818 13:44:37.314033 22726 layer_factory.hpp:77] Creating layer scale_resblk32_2
I0818 13:44:37.314195 22726 net.cpp:150] Setting up scale_resblk32_2
I0818 13:44:37.314211 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.314216 22726 net.cpp:165] Memory required for data: 953857500
I0818 13:44:37.314225 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_2
I0818 13:44:37.314234 22726 net.cpp:100] Creating Layer relu_bn_resblk32_2
I0818 13:44:37.314239 22726 net.cpp:434] relu_bn_resblk32_2 <- bn_resblk32_2
I0818 13:44:37.314246 22726 net.cpp:395] relu_bn_resblk32_2 -> bn_resblk32_2 (in-place)
I0818 13:44:37.314255 22726 net.cpp:150] Setting up relu_bn_resblk32_2
I0818 13:44:37.314262 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.314266 22726 net.cpp:165] Memory required for data: 957953500
I0818 13:44:37.314271 22726 layer_factory.hpp:77] Creating layer resblk32_2_b
I0818 13:44:37.314285 22726 net.cpp:100] Creating Layer resblk32_2_b
I0818 13:44:37.314291 22726 net.cpp:434] resblk32_2_b <- bn_resblk32_2
I0818 13:44:37.314302 22726 net.cpp:408] resblk32_2_b -> resblk32_2_b
I0818 13:44:37.314803 22726 net.cpp:150] Setting up resblk32_2_b
I0818 13:44:37.314822 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.314827 22726 net.cpp:165] Memory required for data: 962049500
I0818 13:44:37.314836 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_2_b
I0818 13:44:37.314847 22726 net.cpp:100] Creating Layer batchNorm_resblk32_2_b
I0818 13:44:37.314854 22726 net.cpp:434] batchNorm_resblk32_2_b <- resblk32_2_b
I0818 13:44:37.314865 22726 net.cpp:408] batchNorm_resblk32_2_b -> bn_resblk32_2_b
I0818 13:44:37.315135 22726 net.cpp:150] Setting up batchNorm_resblk32_2_b
I0818 13:44:37.315148 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.315153 22726 net.cpp:165] Memory required for data: 966145500
I0818 13:44:37.315163 22726 layer_factory.hpp:77] Creating layer scale_resblk32_2_b
I0818 13:44:37.315172 22726 net.cpp:100] Creating Layer scale_resblk32_2_b
I0818 13:44:37.315178 22726 net.cpp:434] scale_resblk32_2_b <- bn_resblk32_2_b
I0818 13:44:37.315186 22726 net.cpp:395] scale_resblk32_2_b -> bn_resblk32_2_b (in-place)
I0818 13:44:37.315246 22726 layer_factory.hpp:77] Creating layer scale_resblk32_2_b
I0818 13:44:37.315404 22726 net.cpp:150] Setting up scale_resblk32_2_b
I0818 13:44:37.315418 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.315423 22726 net.cpp:165] Memory required for data: 970241500
I0818 13:44:37.315430 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_1_b
I0818 13:44:37.315443 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_1_b
I0818 13:44:37.315448 22726 net.cpp:434] sum_sum_bn_resblk32_1_b <- sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split_1
I0818 13:44:37.315456 22726 net.cpp:434] sum_sum_bn_resblk32_1_b <- bn_resblk32_2_b
I0818 13:44:37.315464 22726 net.cpp:408] sum_sum_bn_resblk32_1_b -> sum_bn_resblk32_2_b
I0818 13:44:37.315501 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_1_b
I0818 13:44:37.315511 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.315515 22726 net.cpp:165] Memory required for data: 974337500
I0818 13:44:37.315521 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_2_b
I0818 13:44:37.315541 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_2_b
I0818 13:44:37.315548 22726 net.cpp:434] relu_sum_bn_resblk32_2_b <- sum_bn_resblk32_2_b
I0818 13:44:37.315556 22726 net.cpp:395] relu_sum_bn_resblk32_2_b -> sum_bn_resblk32_2_b (in-place)
I0818 13:44:37.315564 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_2_b
I0818 13:44:37.315572 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.315575 22726 net.cpp:165] Memory required for data: 978433500
I0818 13:44:37.315582 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split
I0818 13:44:37.315588 22726 net.cpp:100] Creating Layer sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split
I0818 13:44:37.315593 22726 net.cpp:434] sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split <- sum_bn_resblk32_2_b
I0818 13:44:37.315600 22726 net.cpp:408] sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split -> sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split_0
I0818 13:44:37.315610 22726 net.cpp:408] sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split -> sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split_1
I0818 13:44:37.315662 22726 net.cpp:150] Setting up sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split
I0818 13:44:37.315675 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.315681 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.315685 22726 net.cpp:165] Memory required for data: 986625500
I0818 13:44:37.315690 22726 layer_factory.hpp:77] Creating layer resblk32_3
I0818 13:44:37.315701 22726 net.cpp:100] Creating Layer resblk32_3
I0818 13:44:37.315706 22726 net.cpp:434] resblk32_3 <- sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split_0
I0818 13:44:37.315718 22726 net.cpp:408] resblk32_3 -> resblk32_3
I0818 13:44:37.316231 22726 net.cpp:150] Setting up resblk32_3
I0818 13:44:37.316246 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.316251 22726 net.cpp:165] Memory required for data: 990721500
I0818 13:44:37.316259 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_3
I0818 13:44:37.316272 22726 net.cpp:100] Creating Layer batchNorm_resblk32_3
I0818 13:44:37.316279 22726 net.cpp:434] batchNorm_resblk32_3 <- resblk32_3
I0818 13:44:37.316288 22726 net.cpp:408] batchNorm_resblk32_3 -> bn_resblk32_3
I0818 13:44:37.316563 22726 net.cpp:150] Setting up batchNorm_resblk32_3
I0818 13:44:37.316576 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.316581 22726 net.cpp:165] Memory required for data: 994817500
I0818 13:44:37.316591 22726 layer_factory.hpp:77] Creating layer scale_resblk32_3
I0818 13:44:37.316602 22726 net.cpp:100] Creating Layer scale_resblk32_3
I0818 13:44:37.316609 22726 net.cpp:434] scale_resblk32_3 <- bn_resblk32_3
I0818 13:44:37.316617 22726 net.cpp:395] scale_resblk32_3 -> bn_resblk32_3 (in-place)
I0818 13:44:37.316676 22726 layer_factory.hpp:77] Creating layer scale_resblk32_3
I0818 13:44:37.316843 22726 net.cpp:150] Setting up scale_resblk32_3
I0818 13:44:37.316856 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.316860 22726 net.cpp:165] Memory required for data: 998913500
I0818 13:44:37.316869 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_3
I0818 13:44:37.316882 22726 net.cpp:100] Creating Layer relu_bn_resblk32_3
I0818 13:44:37.316889 22726 net.cpp:434] relu_bn_resblk32_3 <- bn_resblk32_3
I0818 13:44:37.316898 22726 net.cpp:395] relu_bn_resblk32_3 -> bn_resblk32_3 (in-place)
I0818 13:44:37.316908 22726 net.cpp:150] Setting up relu_bn_resblk32_3
I0818 13:44:37.316915 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.316920 22726 net.cpp:165] Memory required for data: 1003009500
I0818 13:44:37.316931 22726 layer_factory.hpp:77] Creating layer resblk32_3_b
I0818 13:44:37.316943 22726 net.cpp:100] Creating Layer resblk32_3_b
I0818 13:44:37.316948 22726 net.cpp:434] resblk32_3_b <- bn_resblk32_3
I0818 13:44:37.316961 22726 net.cpp:408] resblk32_3_b -> resblk32_3_b
I0818 13:44:37.317453 22726 net.cpp:150] Setting up resblk32_3_b
I0818 13:44:37.317467 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.317472 22726 net.cpp:165] Memory required for data: 1007105500
I0818 13:44:37.317481 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_3_b
I0818 13:44:37.317489 22726 net.cpp:100] Creating Layer batchNorm_resblk32_3_b
I0818 13:44:37.317495 22726 net.cpp:434] batchNorm_resblk32_3_b <- resblk32_3_b
I0818 13:44:37.317507 22726 net.cpp:408] batchNorm_resblk32_3_b -> bn_resblk32_3_b
I0818 13:44:37.317777 22726 net.cpp:150] Setting up batchNorm_resblk32_3_b
I0818 13:44:37.317790 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.317795 22726 net.cpp:165] Memory required for data: 1011201500
I0818 13:44:37.317806 22726 layer_factory.hpp:77] Creating layer scale_resblk32_3_b
I0818 13:44:37.317824 22726 net.cpp:100] Creating Layer scale_resblk32_3_b
I0818 13:44:37.317831 22726 net.cpp:434] scale_resblk32_3_b <- bn_resblk32_3_b
I0818 13:44:37.317839 22726 net.cpp:395] scale_resblk32_3_b -> bn_resblk32_3_b (in-place)
I0818 13:44:37.317898 22726 layer_factory.hpp:77] Creating layer scale_resblk32_3_b
I0818 13:44:37.318060 22726 net.cpp:150] Setting up scale_resblk32_3_b
I0818 13:44:37.318073 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.318078 22726 net.cpp:165] Memory required for data: 1015297500
I0818 13:44:37.318086 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_2_b
I0818 13:44:37.318100 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_2_b
I0818 13:44:37.318107 22726 net.cpp:434] sum_sum_bn_resblk32_2_b <- sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split_1
I0818 13:44:37.318115 22726 net.cpp:434] sum_sum_bn_resblk32_2_b <- bn_resblk32_3_b
I0818 13:44:37.318122 22726 net.cpp:408] sum_sum_bn_resblk32_2_b -> sum_bn_resblk32_3_b
I0818 13:44:37.318155 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_2_b
I0818 13:44:37.318164 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.318168 22726 net.cpp:165] Memory required for data: 1019393500
I0818 13:44:37.318174 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_3_b
I0818 13:44:37.318182 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_3_b
I0818 13:44:37.318187 22726 net.cpp:434] relu_sum_bn_resblk32_3_b <- sum_bn_resblk32_3_b
I0818 13:44:37.318197 22726 net.cpp:395] relu_sum_bn_resblk32_3_b -> sum_bn_resblk32_3_b (in-place)
I0818 13:44:37.318207 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_3_b
I0818 13:44:37.318213 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.318218 22726 net.cpp:165] Memory required for data: 1023489500
I0818 13:44:37.318222 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split
I0818 13:44:37.318229 22726 net.cpp:100] Creating Layer sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split
I0818 13:44:37.318234 22726 net.cpp:434] sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split <- sum_bn_resblk32_3_b
I0818 13:44:37.318243 22726 net.cpp:408] sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split -> sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split_0
I0818 13:44:37.318251 22726 net.cpp:408] sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split -> sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split_1
I0818 13:44:37.318302 22726 net.cpp:150] Setting up sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split
I0818 13:44:37.318315 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.318320 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.318325 22726 net.cpp:165] Memory required for data: 1031681500
I0818 13:44:37.318330 22726 layer_factory.hpp:77] Creating layer resblk32_4
I0818 13:44:37.318339 22726 net.cpp:100] Creating Layer resblk32_4
I0818 13:44:37.318352 22726 net.cpp:434] resblk32_4 <- sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split_0
I0818 13:44:37.318366 22726 net.cpp:408] resblk32_4 -> resblk32_4
I0818 13:44:37.318871 22726 net.cpp:150] Setting up resblk32_4
I0818 13:44:37.318884 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.318889 22726 net.cpp:165] Memory required for data: 1035777500
I0818 13:44:37.318898 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_4
I0818 13:44:37.318907 22726 net.cpp:100] Creating Layer batchNorm_resblk32_4
I0818 13:44:37.318913 22726 net.cpp:434] batchNorm_resblk32_4 <- resblk32_4
I0818 13:44:37.318924 22726 net.cpp:408] batchNorm_resblk32_4 -> bn_resblk32_4
I0818 13:44:37.319195 22726 net.cpp:150] Setting up batchNorm_resblk32_4
I0818 13:44:37.319207 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.319212 22726 net.cpp:165] Memory required for data: 1039873500
I0818 13:44:37.319222 22726 layer_factory.hpp:77] Creating layer scale_resblk32_4
I0818 13:44:37.319233 22726 net.cpp:100] Creating Layer scale_resblk32_4
I0818 13:44:37.319241 22726 net.cpp:434] scale_resblk32_4 <- bn_resblk32_4
I0818 13:44:37.319248 22726 net.cpp:395] scale_resblk32_4 -> bn_resblk32_4 (in-place)
I0818 13:44:37.319306 22726 layer_factory.hpp:77] Creating layer scale_resblk32_4
I0818 13:44:37.319471 22726 net.cpp:150] Setting up scale_resblk32_4
I0818 13:44:37.319483 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.319489 22726 net.cpp:165] Memory required for data: 1043969500
I0818 13:44:37.319497 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_4
I0818 13:44:37.319509 22726 net.cpp:100] Creating Layer relu_bn_resblk32_4
I0818 13:44:37.319514 22726 net.cpp:434] relu_bn_resblk32_4 <- bn_resblk32_4
I0818 13:44:37.319522 22726 net.cpp:395] relu_bn_resblk32_4 -> bn_resblk32_4 (in-place)
I0818 13:44:37.319531 22726 net.cpp:150] Setting up relu_bn_resblk32_4
I0818 13:44:37.319538 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.319542 22726 net.cpp:165] Memory required for data: 1048065500
I0818 13:44:37.319547 22726 layer_factory.hpp:77] Creating layer resblk32_4_b
I0818 13:44:37.319561 22726 net.cpp:100] Creating Layer resblk32_4_b
I0818 13:44:37.319566 22726 net.cpp:434] resblk32_4_b <- bn_resblk32_4
I0818 13:44:37.319577 22726 net.cpp:408] resblk32_4_b -> resblk32_4_b
I0818 13:44:37.320076 22726 net.cpp:150] Setting up resblk32_4_b
I0818 13:44:37.320091 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.320096 22726 net.cpp:165] Memory required for data: 1052161500
I0818 13:44:37.320104 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_4_b
I0818 13:44:37.320112 22726 net.cpp:100] Creating Layer batchNorm_resblk32_4_b
I0818 13:44:37.320118 22726 net.cpp:434] batchNorm_resblk32_4_b <- resblk32_4_b
I0818 13:44:37.320127 22726 net.cpp:408] batchNorm_resblk32_4_b -> bn_resblk32_4_b
I0818 13:44:37.320406 22726 net.cpp:150] Setting up batchNorm_resblk32_4_b
I0818 13:44:37.320420 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.320425 22726 net.cpp:165] Memory required for data: 1056257500
I0818 13:44:37.320435 22726 layer_factory.hpp:77] Creating layer scale_resblk32_4_b
I0818 13:44:37.320442 22726 net.cpp:100] Creating Layer scale_resblk32_4_b
I0818 13:44:37.320448 22726 net.cpp:434] scale_resblk32_4_b <- bn_resblk32_4_b
I0818 13:44:37.320459 22726 net.cpp:395] scale_resblk32_4_b -> bn_resblk32_4_b (in-place)
I0818 13:44:37.320519 22726 layer_factory.hpp:77] Creating layer scale_resblk32_4_b
I0818 13:44:37.320678 22726 net.cpp:150] Setting up scale_resblk32_4_b
I0818 13:44:37.320691 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.320695 22726 net.cpp:165] Memory required for data: 1060353500
I0818 13:44:37.320704 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_3_b
I0818 13:44:37.320713 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_3_b
I0818 13:44:37.320719 22726 net.cpp:434] sum_sum_bn_resblk32_3_b <- sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split_1
I0818 13:44:37.320734 22726 net.cpp:434] sum_sum_bn_resblk32_3_b <- bn_resblk32_4_b
I0818 13:44:37.320744 22726 net.cpp:408] sum_sum_bn_resblk32_3_b -> sum_bn_resblk32_4_b
I0818 13:44:37.320775 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_3_b
I0818 13:44:37.320787 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.320792 22726 net.cpp:165] Memory required for data: 1064449500
I0818 13:44:37.320797 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_4_b
I0818 13:44:37.320804 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_4_b
I0818 13:44:37.320816 22726 net.cpp:434] relu_sum_bn_resblk32_4_b <- sum_bn_resblk32_4_b
I0818 13:44:37.320823 22726 net.cpp:395] relu_sum_bn_resblk32_4_b -> sum_bn_resblk32_4_b (in-place)
I0818 13:44:37.320833 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_4_b
I0818 13:44:37.320840 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.320845 22726 net.cpp:165] Memory required for data: 1068545500
I0818 13:44:37.320849 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split
I0818 13:44:37.320859 22726 net.cpp:100] Creating Layer sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split
I0818 13:44:37.320864 22726 net.cpp:434] sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split <- sum_bn_resblk32_4_b
I0818 13:44:37.320873 22726 net.cpp:408] sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split -> sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split_0
I0818 13:44:37.320881 22726 net.cpp:408] sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split -> sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split_1
I0818 13:44:37.320935 22726 net.cpp:150] Setting up sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split
I0818 13:44:37.320947 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.320953 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.320957 22726 net.cpp:165] Memory required for data: 1076737500
I0818 13:44:37.320962 22726 layer_factory.hpp:77] Creating layer resblk32_5
I0818 13:44:37.320973 22726 net.cpp:100] Creating Layer resblk32_5
I0818 13:44:37.320981 22726 net.cpp:434] resblk32_5 <- sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split_0
I0818 13:44:37.320992 22726 net.cpp:408] resblk32_5 -> resblk32_5
I0818 13:44:37.321501 22726 net.cpp:150] Setting up resblk32_5
I0818 13:44:37.321516 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.321521 22726 net.cpp:165] Memory required for data: 1080833500
I0818 13:44:37.321529 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_5
I0818 13:44:37.321537 22726 net.cpp:100] Creating Layer batchNorm_resblk32_5
I0818 13:44:37.321543 22726 net.cpp:434] batchNorm_resblk32_5 <- resblk32_5
I0818 13:44:37.321552 22726 net.cpp:408] batchNorm_resblk32_5 -> bn_resblk32_5
I0818 13:44:37.321827 22726 net.cpp:150] Setting up batchNorm_resblk32_5
I0818 13:44:37.321841 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.321846 22726 net.cpp:165] Memory required for data: 1084929500
I0818 13:44:37.321856 22726 layer_factory.hpp:77] Creating layer scale_resblk32_5
I0818 13:44:37.321866 22726 net.cpp:100] Creating Layer scale_resblk32_5
I0818 13:44:37.321872 22726 net.cpp:434] scale_resblk32_5 <- bn_resblk32_5
I0818 13:44:37.321880 22726 net.cpp:395] scale_resblk32_5 -> bn_resblk32_5 (in-place)
I0818 13:44:37.321939 22726 layer_factory.hpp:77] Creating layer scale_resblk32_5
I0818 13:44:37.322098 22726 net.cpp:150] Setting up scale_resblk32_5
I0818 13:44:37.322111 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.322115 22726 net.cpp:165] Memory required for data: 1089025500
I0818 13:44:37.322124 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_5
I0818 13:44:37.322132 22726 net.cpp:100] Creating Layer relu_bn_resblk32_5
I0818 13:44:37.322139 22726 net.cpp:434] relu_bn_resblk32_5 <- bn_resblk32_5
I0818 13:44:37.322149 22726 net.cpp:395] relu_bn_resblk32_5 -> bn_resblk32_5 (in-place)
I0818 13:44:37.322157 22726 net.cpp:150] Setting up relu_bn_resblk32_5
I0818 13:44:37.322165 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.322175 22726 net.cpp:165] Memory required for data: 1093121500
I0818 13:44:37.322180 22726 layer_factory.hpp:77] Creating layer resblk32_5_b
I0818 13:44:37.322193 22726 net.cpp:100] Creating Layer resblk32_5_b
I0818 13:44:37.322199 22726 net.cpp:434] resblk32_5_b <- bn_resblk32_5
I0818 13:44:37.322208 22726 net.cpp:408] resblk32_5_b -> resblk32_5_b
I0818 13:44:37.322707 22726 net.cpp:150] Setting up resblk32_5_b
I0818 13:44:37.322721 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.322726 22726 net.cpp:165] Memory required for data: 1097217500
I0818 13:44:37.322734 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_5_b
I0818 13:44:37.322746 22726 net.cpp:100] Creating Layer batchNorm_resblk32_5_b
I0818 13:44:37.322752 22726 net.cpp:434] batchNorm_resblk32_5_b <- resblk32_5_b
I0818 13:44:37.322760 22726 net.cpp:408] batchNorm_resblk32_5_b -> bn_resblk32_5_b
I0818 13:44:37.323038 22726 net.cpp:150] Setting up batchNorm_resblk32_5_b
I0818 13:44:37.323052 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.323057 22726 net.cpp:165] Memory required for data: 1101313500
I0818 13:44:37.323067 22726 layer_factory.hpp:77] Creating layer scale_resblk32_5_b
I0818 13:44:37.323076 22726 net.cpp:100] Creating Layer scale_resblk32_5_b
I0818 13:44:37.323082 22726 net.cpp:434] scale_resblk32_5_b <- bn_resblk32_5_b
I0818 13:44:37.323096 22726 net.cpp:395] scale_resblk32_5_b -> bn_resblk32_5_b (in-place)
I0818 13:44:37.323155 22726 layer_factory.hpp:77] Creating layer scale_resblk32_5_b
I0818 13:44:37.323314 22726 net.cpp:150] Setting up scale_resblk32_5_b
I0818 13:44:37.323328 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.323333 22726 net.cpp:165] Memory required for data: 1105409500
I0818 13:44:37.323340 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_4_b
I0818 13:44:37.323349 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_4_b
I0818 13:44:37.323355 22726 net.cpp:434] sum_sum_bn_resblk32_4_b <- sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split_1
I0818 13:44:37.323362 22726 net.cpp:434] sum_sum_bn_resblk32_4_b <- bn_resblk32_5_b
I0818 13:44:37.323374 22726 net.cpp:408] sum_sum_bn_resblk32_4_b -> sum_bn_resblk32_5_b
I0818 13:44:37.323402 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_4_b
I0818 13:44:37.323411 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.323416 22726 net.cpp:165] Memory required for data: 1109505500
I0818 13:44:37.323421 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_5_b
I0818 13:44:37.323431 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_5_b
I0818 13:44:37.323437 22726 net.cpp:434] relu_sum_bn_resblk32_5_b <- sum_bn_resblk32_5_b
I0818 13:44:37.323444 22726 net.cpp:395] relu_sum_bn_resblk32_5_b -> sum_bn_resblk32_5_b (in-place)
I0818 13:44:37.323453 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_5_b
I0818 13:44:37.323460 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.323465 22726 net.cpp:165] Memory required for data: 1113601500
I0818 13:44:37.323469 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split
I0818 13:44:37.323477 22726 net.cpp:100] Creating Layer sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split
I0818 13:44:37.323482 22726 net.cpp:434] sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split <- sum_bn_resblk32_5_b
I0818 13:44:37.323492 22726 net.cpp:408] sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split -> sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split_0
I0818 13:44:37.323501 22726 net.cpp:408] sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split -> sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split_1
I0818 13:44:37.323549 22726 net.cpp:150] Setting up sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split
I0818 13:44:37.323563 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.323570 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.323575 22726 net.cpp:165] Memory required for data: 1121793500
I0818 13:44:37.323586 22726 layer_factory.hpp:77] Creating layer resblk32_6
I0818 13:44:37.323597 22726 net.cpp:100] Creating Layer resblk32_6
I0818 13:44:37.323603 22726 net.cpp:434] resblk32_6 <- sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split_0
I0818 13:44:37.323612 22726 net.cpp:408] resblk32_6 -> resblk32_6
I0818 13:44:37.325101 22726 net.cpp:150] Setting up resblk32_6
I0818 13:44:37.325119 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.325124 22726 net.cpp:165] Memory required for data: 1125889500
I0818 13:44:37.325134 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_6
I0818 13:44:37.325145 22726 net.cpp:100] Creating Layer batchNorm_resblk32_6
I0818 13:44:37.325152 22726 net.cpp:434] batchNorm_resblk32_6 <- resblk32_6
I0818 13:44:37.325161 22726 net.cpp:408] batchNorm_resblk32_6 -> bn_resblk32_6
I0818 13:44:37.325434 22726 net.cpp:150] Setting up batchNorm_resblk32_6
I0818 13:44:37.325450 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.325455 22726 net.cpp:165] Memory required for data: 1129985500
I0818 13:44:37.325465 22726 layer_factory.hpp:77] Creating layer scale_resblk32_6
I0818 13:44:37.325474 22726 net.cpp:100] Creating Layer scale_resblk32_6
I0818 13:44:37.325480 22726 net.cpp:434] scale_resblk32_6 <- bn_resblk32_6
I0818 13:44:37.325489 22726 net.cpp:395] scale_resblk32_6 -> bn_resblk32_6 (in-place)
I0818 13:44:37.325549 22726 layer_factory.hpp:77] Creating layer scale_resblk32_6
I0818 13:44:37.325711 22726 net.cpp:150] Setting up scale_resblk32_6
I0818 13:44:37.325723 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.325728 22726 net.cpp:165] Memory required for data: 1134081500
I0818 13:44:37.325737 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_6
I0818 13:44:37.325745 22726 net.cpp:100] Creating Layer relu_bn_resblk32_6
I0818 13:44:37.325752 22726 net.cpp:434] relu_bn_resblk32_6 <- bn_resblk32_6
I0818 13:44:37.325762 22726 net.cpp:395] relu_bn_resblk32_6 -> bn_resblk32_6 (in-place)
I0818 13:44:37.325773 22726 net.cpp:150] Setting up relu_bn_resblk32_6
I0818 13:44:37.325779 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.325783 22726 net.cpp:165] Memory required for data: 1138177500
I0818 13:44:37.325788 22726 layer_factory.hpp:77] Creating layer resblk32_6_b
I0818 13:44:37.325803 22726 net.cpp:100] Creating Layer resblk32_6_b
I0818 13:44:37.325814 22726 net.cpp:434] resblk32_6_b <- bn_resblk32_6
I0818 13:44:37.325824 22726 net.cpp:408] resblk32_6_b -> resblk32_6_b
I0818 13:44:37.326318 22726 net.cpp:150] Setting up resblk32_6_b
I0818 13:44:37.326331 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.326336 22726 net.cpp:165] Memory required for data: 1142273500
I0818 13:44:37.326345 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_6_b
I0818 13:44:37.326356 22726 net.cpp:100] Creating Layer batchNorm_resblk32_6_b
I0818 13:44:37.326364 22726 net.cpp:434] batchNorm_resblk32_6_b <- resblk32_6_b
I0818 13:44:37.326372 22726 net.cpp:408] batchNorm_resblk32_6_b -> bn_resblk32_6_b
I0818 13:44:37.326642 22726 net.cpp:150] Setting up batchNorm_resblk32_6_b
I0818 13:44:37.326654 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.326659 22726 net.cpp:165] Memory required for data: 1146369500
I0818 13:44:37.326670 22726 layer_factory.hpp:77] Creating layer scale_resblk32_6_b
I0818 13:44:37.326681 22726 net.cpp:100] Creating Layer scale_resblk32_6_b
I0818 13:44:37.326687 22726 net.cpp:434] scale_resblk32_6_b <- bn_resblk32_6_b
I0818 13:44:37.326695 22726 net.cpp:395] scale_resblk32_6_b -> bn_resblk32_6_b (in-place)
I0818 13:44:37.326752 22726 layer_factory.hpp:77] Creating layer scale_resblk32_6_b
I0818 13:44:37.326916 22726 net.cpp:150] Setting up scale_resblk32_6_b
I0818 13:44:37.326930 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.326936 22726 net.cpp:165] Memory required for data: 1150465500
I0818 13:44:37.326944 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_5_b
I0818 13:44:37.326956 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_5_b
I0818 13:44:37.326973 22726 net.cpp:434] sum_sum_bn_resblk32_5_b <- sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split_1
I0818 13:44:37.326982 22726 net.cpp:434] sum_sum_bn_resblk32_5_b <- bn_resblk32_6_b
I0818 13:44:37.326992 22726 net.cpp:408] sum_sum_bn_resblk32_5_b -> sum_bn_resblk32_6_b
I0818 13:44:37.327023 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_5_b
I0818 13:44:37.327033 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.327036 22726 net.cpp:165] Memory required for data: 1154561500
I0818 13:44:37.327041 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_6_b
I0818 13:44:37.327049 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_6_b
I0818 13:44:37.327055 22726 net.cpp:434] relu_sum_bn_resblk32_6_b <- sum_bn_resblk32_6_b
I0818 13:44:37.327065 22726 net.cpp:395] relu_sum_bn_resblk32_6_b -> sum_bn_resblk32_6_b (in-place)
I0818 13:44:37.327075 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_6_b
I0818 13:44:37.327082 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.327087 22726 net.cpp:165] Memory required for data: 1158657500
I0818 13:44:37.327091 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split
I0818 13:44:37.327098 22726 net.cpp:100] Creating Layer sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split
I0818 13:44:37.327103 22726 net.cpp:434] sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split <- sum_bn_resblk32_6_b
I0818 13:44:37.327111 22726 net.cpp:408] sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split -> sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split_0
I0818 13:44:37.327121 22726 net.cpp:408] sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split -> sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split_1
I0818 13:44:37.327173 22726 net.cpp:150] Setting up sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split
I0818 13:44:37.327185 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.327193 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.327196 22726 net.cpp:165] Memory required for data: 1166849500
I0818 13:44:37.327201 22726 layer_factory.hpp:77] Creating layer resblk32_7
I0818 13:44:37.327213 22726 net.cpp:100] Creating Layer resblk32_7
I0818 13:44:37.327219 22726 net.cpp:434] resblk32_7 <- sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split_0
I0818 13:44:37.327230 22726 net.cpp:408] resblk32_7 -> resblk32_7
I0818 13:44:37.327720 22726 net.cpp:150] Setting up resblk32_7
I0818 13:44:37.327734 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.327739 22726 net.cpp:165] Memory required for data: 1170945500
I0818 13:44:37.327747 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_7
I0818 13:44:37.327759 22726 net.cpp:100] Creating Layer batchNorm_resblk32_7
I0818 13:44:37.327765 22726 net.cpp:434] batchNorm_resblk32_7 <- resblk32_7
I0818 13:44:37.327774 22726 net.cpp:408] batchNorm_resblk32_7 -> bn_resblk32_7
I0818 13:44:37.328053 22726 net.cpp:150] Setting up batchNorm_resblk32_7
I0818 13:44:37.328069 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.328074 22726 net.cpp:165] Memory required for data: 1175041500
I0818 13:44:37.328085 22726 layer_factory.hpp:77] Creating layer scale_resblk32_7
I0818 13:44:37.328094 22726 net.cpp:100] Creating Layer scale_resblk32_7
I0818 13:44:37.328099 22726 net.cpp:434] scale_resblk32_7 <- bn_resblk32_7
I0818 13:44:37.328107 22726 net.cpp:395] scale_resblk32_7 -> bn_resblk32_7 (in-place)
I0818 13:44:37.328167 22726 layer_factory.hpp:77] Creating layer scale_resblk32_7
I0818 13:44:37.328327 22726 net.cpp:150] Setting up scale_resblk32_7
I0818 13:44:37.328341 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.328346 22726 net.cpp:165] Memory required for data: 1179137500
I0818 13:44:37.328354 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_7
I0818 13:44:37.328361 22726 net.cpp:100] Creating Layer relu_bn_resblk32_7
I0818 13:44:37.328367 22726 net.cpp:434] relu_bn_resblk32_7 <- bn_resblk32_7
I0818 13:44:37.328377 22726 net.cpp:395] relu_bn_resblk32_7 -> bn_resblk32_7 (in-place)
I0818 13:44:37.328394 22726 net.cpp:150] Setting up relu_bn_resblk32_7
I0818 13:44:37.328402 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.328407 22726 net.cpp:165] Memory required for data: 1183233500
I0818 13:44:37.328411 22726 layer_factory.hpp:77] Creating layer resblk32_7_b
I0818 13:44:37.328423 22726 net.cpp:100] Creating Layer resblk32_7_b
I0818 13:44:37.328428 22726 net.cpp:434] resblk32_7_b <- bn_resblk32_7
I0818 13:44:37.328439 22726 net.cpp:408] resblk32_7_b -> resblk32_7_b
I0818 13:44:37.328934 22726 net.cpp:150] Setting up resblk32_7_b
I0818 13:44:37.328949 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.328954 22726 net.cpp:165] Memory required for data: 1187329500
I0818 13:44:37.328963 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_7_b
I0818 13:44:37.328971 22726 net.cpp:100] Creating Layer batchNorm_resblk32_7_b
I0818 13:44:37.328977 22726 net.cpp:434] batchNorm_resblk32_7_b <- resblk32_7_b
I0818 13:44:37.328989 22726 net.cpp:408] batchNorm_resblk32_7_b -> bn_resblk32_7_b
I0818 13:44:37.329267 22726 net.cpp:150] Setting up batchNorm_resblk32_7_b
I0818 13:44:37.329279 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.329284 22726 net.cpp:165] Memory required for data: 1191425500
I0818 13:44:37.329294 22726 layer_factory.hpp:77] Creating layer scale_resblk32_7_b
I0818 13:44:37.329306 22726 net.cpp:100] Creating Layer scale_resblk32_7_b
I0818 13:44:37.329313 22726 net.cpp:434] scale_resblk32_7_b <- bn_resblk32_7_b
I0818 13:44:37.329320 22726 net.cpp:395] scale_resblk32_7_b -> bn_resblk32_7_b (in-place)
I0818 13:44:37.329380 22726 layer_factory.hpp:77] Creating layer scale_resblk32_7_b
I0818 13:44:37.329540 22726 net.cpp:150] Setting up scale_resblk32_7_b
I0818 13:44:37.329552 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.329557 22726 net.cpp:165] Memory required for data: 1195521500
I0818 13:44:37.329566 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_6_b
I0818 13:44:37.329577 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_6_b
I0818 13:44:37.329584 22726 net.cpp:434] sum_sum_bn_resblk32_6_b <- sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split_1
I0818 13:44:37.329591 22726 net.cpp:434] sum_sum_bn_resblk32_6_b <- bn_resblk32_7_b
I0818 13:44:37.329599 22726 net.cpp:408] sum_sum_bn_resblk32_6_b -> sum_bn_resblk32_7_b
I0818 13:44:37.329632 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_6_b
I0818 13:44:37.329643 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.329646 22726 net.cpp:165] Memory required for data: 1199617500
I0818 13:44:37.329651 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_7_b
I0818 13:44:37.329658 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_7_b
I0818 13:44:37.329664 22726 net.cpp:434] relu_sum_bn_resblk32_7_b <- sum_bn_resblk32_7_b
I0818 13:44:37.329674 22726 net.cpp:395] relu_sum_bn_resblk32_7_b -> sum_bn_resblk32_7_b (in-place)
I0818 13:44:37.329684 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_7_b
I0818 13:44:37.329691 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.329695 22726 net.cpp:165] Memory required for data: 1203713500
I0818 13:44:37.329700 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split
I0818 13:44:37.329706 22726 net.cpp:100] Creating Layer sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split
I0818 13:44:37.329712 22726 net.cpp:434] sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split <- sum_bn_resblk32_7_b
I0818 13:44:37.329720 22726 net.cpp:408] sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split -> sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split_0
I0818 13:44:37.329742 22726 net.cpp:408] sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split -> sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split_1
I0818 13:44:37.329793 22726 net.cpp:150] Setting up sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split
I0818 13:44:37.329814 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.329823 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.329833 22726 net.cpp:165] Memory required for data: 1211905500
I0818 13:44:37.329839 22726 layer_factory.hpp:77] Creating layer resblk32_8
I0818 13:44:37.329850 22726 net.cpp:100] Creating Layer resblk32_8
I0818 13:44:37.329857 22726 net.cpp:434] resblk32_8 <- sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split_0
I0818 13:44:37.329869 22726 net.cpp:408] resblk32_8 -> resblk32_8
I0818 13:44:37.330374 22726 net.cpp:150] Setting up resblk32_8
I0818 13:44:37.330387 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.330392 22726 net.cpp:165] Memory required for data: 1216001500
I0818 13:44:37.330401 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_8
I0818 13:44:37.330410 22726 net.cpp:100] Creating Layer batchNorm_resblk32_8
I0818 13:44:37.330416 22726 net.cpp:434] batchNorm_resblk32_8 <- resblk32_8
I0818 13:44:37.330427 22726 net.cpp:408] batchNorm_resblk32_8 -> bn_resblk32_8
I0818 13:44:37.330708 22726 net.cpp:150] Setting up batchNorm_resblk32_8
I0818 13:44:37.330721 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.330726 22726 net.cpp:165] Memory required for data: 1220097500
I0818 13:44:37.330736 22726 layer_factory.hpp:77] Creating layer scale_resblk32_8
I0818 13:44:37.330747 22726 net.cpp:100] Creating Layer scale_resblk32_8
I0818 13:44:37.330754 22726 net.cpp:434] scale_resblk32_8 <- bn_resblk32_8
I0818 13:44:37.330761 22726 net.cpp:395] scale_resblk32_8 -> bn_resblk32_8 (in-place)
I0818 13:44:37.330826 22726 layer_factory.hpp:77] Creating layer scale_resblk32_8
I0818 13:44:37.330991 22726 net.cpp:150] Setting up scale_resblk32_8
I0818 13:44:37.331004 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.331009 22726 net.cpp:165] Memory required for data: 1224193500
I0818 13:44:37.331018 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk32_8
I0818 13:44:37.331027 22726 net.cpp:100] Creating Layer relu_bn_resblk32_8
I0818 13:44:37.331032 22726 net.cpp:434] relu_bn_resblk32_8 <- bn_resblk32_8
I0818 13:44:37.331043 22726 net.cpp:395] relu_bn_resblk32_8 -> bn_resblk32_8 (in-place)
I0818 13:44:37.331053 22726 net.cpp:150] Setting up relu_bn_resblk32_8
I0818 13:44:37.331058 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.331063 22726 net.cpp:165] Memory required for data: 1228289500
I0818 13:44:37.331068 22726 layer_factory.hpp:77] Creating layer resblk32_8_b
I0818 13:44:37.331081 22726 net.cpp:100] Creating Layer resblk32_8_b
I0818 13:44:37.331087 22726 net.cpp:434] resblk32_8_b <- bn_resblk32_8
I0818 13:44:37.331099 22726 net.cpp:408] resblk32_8_b -> resblk32_8_b
I0818 13:44:37.332586 22726 net.cpp:150] Setting up resblk32_8_b
I0818 13:44:37.332603 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.332608 22726 net.cpp:165] Memory required for data: 1232385500
I0818 13:44:37.332617 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk32_8_b
I0818 13:44:37.332628 22726 net.cpp:100] Creating Layer batchNorm_resblk32_8_b
I0818 13:44:37.332633 22726 net.cpp:434] batchNorm_resblk32_8_b <- resblk32_8_b
I0818 13:44:37.332645 22726 net.cpp:408] batchNorm_resblk32_8_b -> bn_resblk32_8_b
I0818 13:44:37.332921 22726 net.cpp:150] Setting up batchNorm_resblk32_8_b
I0818 13:44:37.332934 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.332939 22726 net.cpp:165] Memory required for data: 1236481500
I0818 13:44:37.332994 22726 layer_factory.hpp:77] Creating layer scale_resblk32_8_b
I0818 13:44:37.333008 22726 net.cpp:100] Creating Layer scale_resblk32_8_b
I0818 13:44:37.333014 22726 net.cpp:434] scale_resblk32_8_b <- bn_resblk32_8_b
I0818 13:44:37.333021 22726 net.cpp:395] scale_resblk32_8_b -> bn_resblk32_8_b (in-place)
I0818 13:44:37.333086 22726 layer_factory.hpp:77] Creating layer scale_resblk32_8_b
I0818 13:44:37.333240 22726 net.cpp:150] Setting up scale_resblk32_8_b
I0818 13:44:37.333256 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.333261 22726 net.cpp:165] Memory required for data: 1240577500
I0818 13:44:37.333277 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk32_7_b
I0818 13:44:37.333287 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk32_7_b
I0818 13:44:37.333293 22726 net.cpp:434] sum_sum_bn_resblk32_7_b <- sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split_1
I0818 13:44:37.333302 22726 net.cpp:434] sum_sum_bn_resblk32_7_b <- bn_resblk32_8_b
I0818 13:44:37.333312 22726 net.cpp:408] sum_sum_bn_resblk32_7_b -> sum_bn_resblk32_8_b
I0818 13:44:37.333341 22726 net.cpp:150] Setting up sum_sum_bn_resblk32_7_b
I0818 13:44:37.333351 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.333356 22726 net.cpp:165] Memory required for data: 1244673500
I0818 13:44:37.333360 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk32_8_b
I0818 13:44:37.333369 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk32_8_b
I0818 13:44:37.333377 22726 net.cpp:434] relu_sum_bn_resblk32_8_b <- sum_bn_resblk32_8_b
I0818 13:44:37.333384 22726 net.cpp:395] relu_sum_bn_resblk32_8_b -> sum_bn_resblk32_8_b (in-place)
I0818 13:44:37.333395 22726 net.cpp:150] Setting up relu_sum_bn_resblk32_8_b
I0818 13:44:37.333400 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.333405 22726 net.cpp:165] Memory required for data: 1248769500
I0818 13:44:37.333410 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split
I0818 13:44:37.333416 22726 net.cpp:100] Creating Layer sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split
I0818 13:44:37.333422 22726 net.cpp:434] sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split <- sum_bn_resblk32_8_b
I0818 13:44:37.333432 22726 net.cpp:408] sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split -> sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split_0
I0818 13:44:37.333442 22726 net.cpp:408] sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split -> sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split_1
I0818 13:44:37.333490 22726 net.cpp:150] Setting up sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split
I0818 13:44:37.333503 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.333508 22726 net.cpp:157] Top shape: 125 32 16 16 (1024000)
I0818 13:44:37.333513 22726 net.cpp:165] Memory required for data: 1256961500
I0818 13:44:37.333518 22726 layer_factory.hpp:77] Creating layer resblk64
I0818 13:44:37.333531 22726 net.cpp:100] Creating Layer resblk64
I0818 13:44:37.333539 22726 net.cpp:434] resblk64 <- sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split_0
I0818 13:44:37.333549 22726 net.cpp:408] resblk64 -> resblk64
I0818 13:44:37.334056 22726 net.cpp:150] Setting up resblk64
I0818 13:44:37.334071 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.334076 22726 net.cpp:165] Memory required for data: 1257985500
I0818 13:44:37.334085 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64
I0818 13:44:37.334096 22726 net.cpp:100] Creating Layer batchNorm_resblk64
I0818 13:44:37.334102 22726 net.cpp:434] batchNorm_resblk64 <- resblk64
I0818 13:44:37.334110 22726 net.cpp:408] batchNorm_resblk64 -> bn_resblk64
I0818 13:44:37.334388 22726 net.cpp:150] Setting up batchNorm_resblk64
I0818 13:44:37.334400 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.334405 22726 net.cpp:165] Memory required for data: 1259009500
I0818 13:44:37.334415 22726 layer_factory.hpp:77] Creating layer scale_resblk64
I0818 13:44:37.334426 22726 net.cpp:100] Creating Layer scale_resblk64
I0818 13:44:37.334434 22726 net.cpp:434] scale_resblk64 <- bn_resblk64
I0818 13:44:37.334441 22726 net.cpp:395] scale_resblk64 -> bn_resblk64 (in-place)
I0818 13:44:37.334501 22726 layer_factory.hpp:77] Creating layer scale_resblk64
I0818 13:44:37.334672 22726 net.cpp:150] Setting up scale_resblk64
I0818 13:44:37.334686 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.334691 22726 net.cpp:165] Memory required for data: 1260033500
I0818 13:44:37.334699 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64
I0818 13:44:37.334709 22726 net.cpp:100] Creating Layer relu_bn_resblk64
I0818 13:44:37.334717 22726 net.cpp:434] relu_bn_resblk64 <- bn_resblk64
I0818 13:44:37.334730 22726 net.cpp:395] relu_bn_resblk64 -> bn_resblk64 (in-place)
I0818 13:44:37.334740 22726 net.cpp:150] Setting up relu_bn_resblk64
I0818 13:44:37.334748 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.334753 22726 net.cpp:165] Memory required for data: 1261057500
I0818 13:44:37.334756 22726 layer_factory.hpp:77] Creating layer resblk64_b
I0818 13:44:37.334770 22726 net.cpp:100] Creating Layer resblk64_b
I0818 13:44:37.334776 22726 net.cpp:434] resblk64_b <- bn_resblk64
I0818 13:44:37.334787 22726 net.cpp:408] resblk64_b -> resblk64_b
I0818 13:44:37.335288 22726 net.cpp:150] Setting up resblk64_b
I0818 13:44:37.335302 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.335307 22726 net.cpp:165] Memory required for data: 1262081500
I0818 13:44:37.335315 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_b
I0818 13:44:37.335325 22726 net.cpp:100] Creating Layer batchNorm_resblk64_b
I0818 13:44:37.335330 22726 net.cpp:434] batchNorm_resblk64_b <- resblk64_b
I0818 13:44:37.335341 22726 net.cpp:408] batchNorm_resblk64_b -> bn_resblk64_b
I0818 13:44:37.335619 22726 net.cpp:150] Setting up batchNorm_resblk64_b
I0818 13:44:37.335635 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.335640 22726 net.cpp:165] Memory required for data: 1263105500
I0818 13:44:37.335650 22726 layer_factory.hpp:77] Creating layer scale_resblk64_b
I0818 13:44:37.335659 22726 net.cpp:100] Creating Layer scale_resblk64_b
I0818 13:44:37.335666 22726 net.cpp:434] scale_resblk64_b <- bn_resblk64_b
I0818 13:44:37.335674 22726 net.cpp:395] scale_resblk64_b -> bn_resblk64_b (in-place)
I0818 13:44:37.335732 22726 layer_factory.hpp:77] Creating layer scale_resblk64_b
I0818 13:44:37.335904 22726 net.cpp:150] Setting up scale_resblk64_b
I0818 13:44:37.335917 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.335922 22726 net.cpp:165] Memory required for data: 1264129500
I0818 13:44:37.335932 22726 layer_factory.hpp:77] Creating layer avePooling_resblk64
I0818 13:44:37.335944 22726 net.cpp:100] Creating Layer avePooling_resblk64
I0818 13:44:37.335950 22726 net.cpp:434] avePooling_resblk64 <- sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split_1
I0818 13:44:37.335959 22726 net.cpp:408] avePooling_resblk64 -> avgPool_resblk64
I0818 13:44:37.335997 22726 net.cpp:150] Setting up avePooling_resblk64
I0818 13:44:37.336007 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.336012 22726 net.cpp:165] Memory required for data: 1265153500
I0818 13:44:37.336017 22726 layer_factory.hpp:77] Creating layer sum_avgPool_resblk64
I0818 13:44:37.336025 22726 net.cpp:100] Creating Layer sum_avgPool_resblk64
I0818 13:44:37.336031 22726 net.cpp:434] sum_avgPool_resblk64 <- avgPool_resblk64
I0818 13:44:37.336038 22726 net.cpp:434] sum_avgPool_resblk64 <- bn_resblk64_b
I0818 13:44:37.336046 22726 net.cpp:408] sum_avgPool_resblk64 -> sum_bn_resblk64_b
I0818 13:44:37.336082 22726 net.cpp:150] Setting up sum_avgPool_resblk64
I0818 13:44:37.336094 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.336099 22726 net.cpp:165] Memory required for data: 1266177500
I0818 13:44:37.336104 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_b
I0818 13:44:37.336112 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_b
I0818 13:44:37.336117 22726 net.cpp:434] relu_sum_bn_resblk64_b <- sum_bn_resblk64_b
I0818 13:44:37.336124 22726 net.cpp:395] relu_sum_bn_resblk64_b -> sum_bn_resblk64_b (in-place)
I0818 13:44:37.336133 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_b
I0818 13:44:37.336140 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.336144 22726 net.cpp:165] Memory required for data: 1267201500
I0818 13:44:37.336149 22726 layer_factory.hpp:77] Creating layer zeros_sum_bn_resblk64_b
I0818 13:44:37.336158 22726 net.cpp:100] Creating Layer zeros_sum_bn_resblk64_b
I0818 13:44:37.336169 22726 net.cpp:408] zeros_sum_bn_resblk64_b -> zeros_sum_bn_resblk64_b
I0818 13:44:37.337385 22726 net.cpp:150] Setting up zeros_sum_bn_resblk64_b
I0818 13:44:37.337410 22726 net.cpp:157] Top shape: 125 32 8 8 (256000)
I0818 13:44:37.337415 22726 net.cpp:165] Memory required for data: 1268225500
I0818 13:44:37.337421 22726 layer_factory.hpp:77] Creating layer CC_sum_bn_resblk64_b
I0818 13:44:37.337433 22726 net.cpp:100] Creating Layer CC_sum_bn_resblk64_b
I0818 13:44:37.337440 22726 net.cpp:434] CC_sum_bn_resblk64_b <- sum_bn_resblk64_b
I0818 13:44:37.337448 22726 net.cpp:434] CC_sum_bn_resblk64_b <- zeros_sum_bn_resblk64_b
I0818 13:44:37.337456 22726 net.cpp:408] CC_sum_bn_resblk64_b -> CC_sum_bn_resblk64_b
I0818 13:44:37.337499 22726 net.cpp:150] Setting up CC_sum_bn_resblk64_b
I0818 13:44:37.337514 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.337519 22726 net.cpp:165] Memory required for data: 1270273500
I0818 13:44:37.337524 22726 layer_factory.hpp:77] Creating layer CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split
I0818 13:44:37.337532 22726 net.cpp:100] Creating Layer CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split
I0818 13:44:37.337538 22726 net.cpp:434] CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split <- CC_sum_bn_resblk64_b
I0818 13:44:37.337548 22726 net.cpp:408] CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split -> CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split_0
I0818 13:44:37.337558 22726 net.cpp:408] CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split -> CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split_1
I0818 13:44:37.337610 22726 net.cpp:150] Setting up CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split
I0818 13:44:37.337625 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.337630 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.337635 22726 net.cpp:165] Memory required for data: 1274369500
I0818 13:44:37.337641 22726 layer_factory.hpp:77] Creating layer resblk64_1
I0818 13:44:37.337651 22726 net.cpp:100] Creating Layer resblk64_1
I0818 13:44:37.337657 22726 net.cpp:434] resblk64_1 <- CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split_0
I0818 13:44:37.337669 22726 net.cpp:408] resblk64_1 -> resblk64_1
I0818 13:44:37.338712 22726 net.cpp:150] Setting up resblk64_1
I0818 13:44:37.338727 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.338732 22726 net.cpp:165] Memory required for data: 1276417500
I0818 13:44:37.338742 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_1
I0818 13:44:37.338753 22726 net.cpp:100] Creating Layer batchNorm_resblk64_1
I0818 13:44:37.338760 22726 net.cpp:434] batchNorm_resblk64_1 <- resblk64_1
I0818 13:44:37.338769 22726 net.cpp:408] batchNorm_resblk64_1 -> bn_resblk64_1
I0818 13:44:37.339054 22726 net.cpp:150] Setting up batchNorm_resblk64_1
I0818 13:44:37.339068 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.339073 22726 net.cpp:165] Memory required for data: 1278465500
I0818 13:44:37.339083 22726 layer_factory.hpp:77] Creating layer scale_resblk64_1
I0818 13:44:37.339092 22726 net.cpp:100] Creating Layer scale_resblk64_1
I0818 13:44:37.339098 22726 net.cpp:434] scale_resblk64_1 <- bn_resblk64_1
I0818 13:44:37.339107 22726 net.cpp:395] scale_resblk64_1 -> bn_resblk64_1 (in-place)
I0818 13:44:37.339169 22726 layer_factory.hpp:77] Creating layer scale_resblk64_1
I0818 13:44:37.339332 22726 net.cpp:150] Setting up scale_resblk64_1
I0818 13:44:37.339347 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.339352 22726 net.cpp:165] Memory required for data: 1280513500
I0818 13:44:37.339362 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_1
I0818 13:44:37.339370 22726 net.cpp:100] Creating Layer relu_bn_resblk64_1
I0818 13:44:37.339376 22726 net.cpp:434] relu_bn_resblk64_1 <- bn_resblk64_1
I0818 13:44:37.339383 22726 net.cpp:395] relu_bn_resblk64_1 -> bn_resblk64_1 (in-place)
I0818 13:44:37.339392 22726 net.cpp:150] Setting up relu_bn_resblk64_1
I0818 13:44:37.339399 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.339403 22726 net.cpp:165] Memory required for data: 1282561500
I0818 13:44:37.339408 22726 layer_factory.hpp:77] Creating layer resblk64_1_b
I0818 13:44:37.339422 22726 net.cpp:100] Creating Layer resblk64_1_b
I0818 13:44:37.339439 22726 net.cpp:434] resblk64_1_b <- bn_resblk64_1
I0818 13:44:37.339452 22726 net.cpp:408] resblk64_1_b -> resblk64_1_b
I0818 13:44:37.340507 22726 net.cpp:150] Setting up resblk64_1_b
I0818 13:44:37.340522 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.340526 22726 net.cpp:165] Memory required for data: 1284609500
I0818 13:44:37.340535 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_1_b
I0818 13:44:37.340544 22726 net.cpp:100] Creating Layer batchNorm_resblk64_1_b
I0818 13:44:37.340553 22726 net.cpp:434] batchNorm_resblk64_1_b <- resblk64_1_b
I0818 13:44:37.340562 22726 net.cpp:408] batchNorm_resblk64_1_b -> bn_resblk64_1_b
I0818 13:44:37.340837 22726 net.cpp:150] Setting up batchNorm_resblk64_1_b
I0818 13:44:37.340850 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.340855 22726 net.cpp:165] Memory required for data: 1286657500
I0818 13:44:37.340867 22726 layer_factory.hpp:77] Creating layer scale_resblk64_1_b
I0818 13:44:37.340875 22726 net.cpp:100] Creating Layer scale_resblk64_1_b
I0818 13:44:37.340881 22726 net.cpp:434] scale_resblk64_1_b <- bn_resblk64_1_b
I0818 13:44:37.340891 22726 net.cpp:395] scale_resblk64_1_b -> bn_resblk64_1_b (in-place)
I0818 13:44:37.340951 22726 layer_factory.hpp:77] Creating layer scale_resblk64_1_b
I0818 13:44:37.341114 22726 net.cpp:150] Setting up scale_resblk64_1_b
I0818 13:44:37.341126 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.341131 22726 net.cpp:165] Memory required for data: 1288705500
I0818 13:44:37.341140 22726 layer_factory.hpp:77] Creating layer sum_CC_sum_bn_resblk64_b
I0818 13:44:37.341152 22726 net.cpp:100] Creating Layer sum_CC_sum_bn_resblk64_b
I0818 13:44:37.341159 22726 net.cpp:434] sum_CC_sum_bn_resblk64_b <- CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split_1
I0818 13:44:37.341166 22726 net.cpp:434] sum_CC_sum_bn_resblk64_b <- bn_resblk64_1_b
I0818 13:44:37.341174 22726 net.cpp:408] sum_CC_sum_bn_resblk64_b -> sum_bn_resblk64_1_b
I0818 13:44:37.341213 22726 net.cpp:150] Setting up sum_CC_sum_bn_resblk64_b
I0818 13:44:37.341224 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.341229 22726 net.cpp:165] Memory required for data: 1290753500
I0818 13:44:37.341234 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_1_b
I0818 13:44:37.341241 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_1_b
I0818 13:44:37.341248 22726 net.cpp:434] relu_sum_bn_resblk64_1_b <- sum_bn_resblk64_1_b
I0818 13:44:37.341256 22726 net.cpp:395] relu_sum_bn_resblk64_1_b -> sum_bn_resblk64_1_b (in-place)
I0818 13:44:37.341266 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_1_b
I0818 13:44:37.341274 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.341277 22726 net.cpp:165] Memory required for data: 1292801500
I0818 13:44:37.341282 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split
I0818 13:44:37.341290 22726 net.cpp:100] Creating Layer sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split
I0818 13:44:37.341295 22726 net.cpp:434] sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split <- sum_bn_resblk64_1_b
I0818 13:44:37.341302 22726 net.cpp:408] sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split -> sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split_0
I0818 13:44:37.341311 22726 net.cpp:408] sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split -> sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split_1
I0818 13:44:37.341363 22726 net.cpp:150] Setting up sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split
I0818 13:44:37.341374 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.341380 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.341385 22726 net.cpp:165] Memory required for data: 1296897500
I0818 13:44:37.341390 22726 layer_factory.hpp:77] Creating layer resblk64_2
I0818 13:44:37.341401 22726 net.cpp:100] Creating Layer resblk64_2
I0818 13:44:37.341408 22726 net.cpp:434] resblk64_2 <- sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split_0
I0818 13:44:37.341426 22726 net.cpp:408] resblk64_2 -> resblk64_2
I0818 13:44:37.342479 22726 net.cpp:150] Setting up resblk64_2
I0818 13:44:37.342494 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.342499 22726 net.cpp:165] Memory required for data: 1298945500
I0818 13:44:37.342509 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_2
I0818 13:44:37.342523 22726 net.cpp:100] Creating Layer batchNorm_resblk64_2
I0818 13:44:37.342530 22726 net.cpp:434] batchNorm_resblk64_2 <- resblk64_2
I0818 13:44:37.342538 22726 net.cpp:408] batchNorm_resblk64_2 -> bn_resblk64_2
I0818 13:44:37.342815 22726 net.cpp:150] Setting up batchNorm_resblk64_2
I0818 13:44:37.342828 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.342833 22726 net.cpp:165] Memory required for data: 1300993500
I0818 13:44:37.342844 22726 layer_factory.hpp:77] Creating layer scale_resblk64_2
I0818 13:44:37.342852 22726 net.cpp:100] Creating Layer scale_resblk64_2
I0818 13:44:37.342859 22726 net.cpp:434] scale_resblk64_2 <- bn_resblk64_2
I0818 13:44:37.342866 22726 net.cpp:395] scale_resblk64_2 -> bn_resblk64_2 (in-place)
I0818 13:44:37.342928 22726 layer_factory.hpp:77] Creating layer scale_resblk64_2
I0818 13:44:37.343086 22726 net.cpp:150] Setting up scale_resblk64_2
I0818 13:44:37.343101 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.343106 22726 net.cpp:165] Memory required for data: 1303041500
I0818 13:44:37.343116 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_2
I0818 13:44:37.343123 22726 net.cpp:100] Creating Layer relu_bn_resblk64_2
I0818 13:44:37.343129 22726 net.cpp:434] relu_bn_resblk64_2 <- bn_resblk64_2
I0818 13:44:37.343137 22726 net.cpp:395] relu_bn_resblk64_2 -> bn_resblk64_2 (in-place)
I0818 13:44:37.343147 22726 net.cpp:150] Setting up relu_bn_resblk64_2
I0818 13:44:37.343153 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.343158 22726 net.cpp:165] Memory required for data: 1305089500
I0818 13:44:37.343163 22726 layer_factory.hpp:77] Creating layer resblk64_2_b
I0818 13:44:37.343178 22726 net.cpp:100] Creating Layer resblk64_2_b
I0818 13:44:37.343183 22726 net.cpp:434] resblk64_2_b <- bn_resblk64_2
I0818 13:44:37.343192 22726 net.cpp:408] resblk64_2_b -> resblk64_2_b
I0818 13:44:37.344295 22726 net.cpp:150] Setting up resblk64_2_b
I0818 13:44:37.344312 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.344317 22726 net.cpp:165] Memory required for data: 1307137500
I0818 13:44:37.344326 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_2_b
I0818 13:44:37.344336 22726 net.cpp:100] Creating Layer batchNorm_resblk64_2_b
I0818 13:44:37.344341 22726 net.cpp:434] batchNorm_resblk64_2_b <- resblk64_2_b
I0818 13:44:37.344353 22726 net.cpp:408] batchNorm_resblk64_2_b -> bn_resblk64_2_b
I0818 13:44:37.344624 22726 net.cpp:150] Setting up batchNorm_resblk64_2_b
I0818 13:44:37.344637 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.344642 22726 net.cpp:165] Memory required for data: 1309185500
I0818 13:44:37.344652 22726 layer_factory.hpp:77] Creating layer scale_resblk64_2_b
I0818 13:44:37.344660 22726 net.cpp:100] Creating Layer scale_resblk64_2_b
I0818 13:44:37.344667 22726 net.cpp:434] scale_resblk64_2_b <- bn_resblk64_2_b
I0818 13:44:37.344677 22726 net.cpp:395] scale_resblk64_2_b -> bn_resblk64_2_b (in-place)
I0818 13:44:37.344739 22726 layer_factory.hpp:77] Creating layer scale_resblk64_2_b
I0818 13:44:37.344915 22726 net.cpp:150] Setting up scale_resblk64_2_b
I0818 13:44:37.344928 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.344933 22726 net.cpp:165] Memory required for data: 1311233500
I0818 13:44:37.344944 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_1_b
I0818 13:44:37.344954 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_1_b
I0818 13:44:37.344961 22726 net.cpp:434] sum_sum_bn_resblk64_1_b <- sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split_1
I0818 13:44:37.344969 22726 net.cpp:434] sum_sum_bn_resblk64_1_b <- bn_resblk64_2_b
I0818 13:44:37.344977 22726 net.cpp:408] sum_sum_bn_resblk64_1_b -> sum_bn_resblk64_2_b
I0818 13:44:37.345022 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_1_b
I0818 13:44:37.345032 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.345037 22726 net.cpp:165] Memory required for data: 1313281500
I0818 13:44:37.345042 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_2_b
I0818 13:44:37.345051 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_2_b
I0818 13:44:37.345055 22726 net.cpp:434] relu_sum_bn_resblk64_2_b <- sum_bn_resblk64_2_b
I0818 13:44:37.345065 22726 net.cpp:395] relu_sum_bn_resblk64_2_b -> sum_bn_resblk64_2_b (in-place)
I0818 13:44:37.345075 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_2_b
I0818 13:44:37.345082 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.345086 22726 net.cpp:165] Memory required for data: 1315329500
I0818 13:44:37.345091 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split
I0818 13:44:37.345098 22726 net.cpp:100] Creating Layer sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split
I0818 13:44:37.345103 22726 net.cpp:434] sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split <- sum_bn_resblk64_2_b
I0818 13:44:37.345110 22726 net.cpp:408] sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split -> sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split_0
I0818 13:44:37.345120 22726 net.cpp:408] sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split -> sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split_1
I0818 13:44:37.345170 22726 net.cpp:150] Setting up sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split
I0818 13:44:37.345182 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.345190 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.345193 22726 net.cpp:165] Memory required for data: 1319425500
I0818 13:44:37.345198 22726 layer_factory.hpp:77] Creating layer resblk64_3
I0818 13:44:37.345209 22726 net.cpp:100] Creating Layer resblk64_3
I0818 13:44:37.345216 22726 net.cpp:434] resblk64_3 <- sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split_0
I0818 13:44:37.345227 22726 net.cpp:408] resblk64_3 -> resblk64_3
I0818 13:44:37.346274 22726 net.cpp:150] Setting up resblk64_3
I0818 13:44:37.346289 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.346295 22726 net.cpp:165] Memory required for data: 1321473500
I0818 13:44:37.346303 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_3
I0818 13:44:37.346315 22726 net.cpp:100] Creating Layer batchNorm_resblk64_3
I0818 13:44:37.346323 22726 net.cpp:434] batchNorm_resblk64_3 <- resblk64_3
I0818 13:44:37.346330 22726 net.cpp:408] batchNorm_resblk64_3 -> bn_resblk64_3
I0818 13:44:37.346603 22726 net.cpp:150] Setting up batchNorm_resblk64_3
I0818 13:44:37.346616 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.346621 22726 net.cpp:165] Memory required for data: 1323521500
I0818 13:44:37.346632 22726 layer_factory.hpp:77] Creating layer scale_resblk64_3
I0818 13:44:37.346640 22726 net.cpp:100] Creating Layer scale_resblk64_3
I0818 13:44:37.346647 22726 net.cpp:434] scale_resblk64_3 <- bn_resblk64_3
I0818 13:44:37.346654 22726 net.cpp:395] scale_resblk64_3 -> bn_resblk64_3 (in-place)
I0818 13:44:37.346715 22726 layer_factory.hpp:77] Creating layer scale_resblk64_3
I0818 13:44:37.346881 22726 net.cpp:150] Setting up scale_resblk64_3
I0818 13:44:37.346897 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.346902 22726 net.cpp:165] Memory required for data: 1325569500
I0818 13:44:37.346911 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_3
I0818 13:44:37.346920 22726 net.cpp:100] Creating Layer relu_bn_resblk64_3
I0818 13:44:37.346925 22726 net.cpp:434] relu_bn_resblk64_3 <- bn_resblk64_3
I0818 13:44:37.346933 22726 net.cpp:395] relu_bn_resblk64_3 -> bn_resblk64_3 (in-place)
I0818 13:44:37.346942 22726 net.cpp:150] Setting up relu_bn_resblk64_3
I0818 13:44:37.346949 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.346953 22726 net.cpp:165] Memory required for data: 1327617500
I0818 13:44:37.346958 22726 layer_factory.hpp:77] Creating layer resblk64_3_b
I0818 13:44:37.346982 22726 net.cpp:100] Creating Layer resblk64_3_b
I0818 13:44:37.346988 22726 net.cpp:434] resblk64_3_b <- bn_resblk64_3
I0818 13:44:37.346997 22726 net.cpp:408] resblk64_3_b -> resblk64_3_b
I0818 13:44:37.349017 22726 net.cpp:150] Setting up resblk64_3_b
I0818 13:44:37.349035 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.349040 22726 net.cpp:165] Memory required for data: 1329665500
I0818 13:44:37.349050 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_3_b
I0818 13:44:37.349058 22726 net.cpp:100] Creating Layer batchNorm_resblk64_3_b
I0818 13:44:37.349064 22726 net.cpp:434] batchNorm_resblk64_3_b <- resblk64_3_b
I0818 13:44:37.349076 22726 net.cpp:408] batchNorm_resblk64_3_b -> bn_resblk64_3_b
I0818 13:44:37.349359 22726 net.cpp:150] Setting up batchNorm_resblk64_3_b
I0818 13:44:37.349370 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.349375 22726 net.cpp:165] Memory required for data: 1331713500
I0818 13:44:37.349386 22726 layer_factory.hpp:77] Creating layer scale_resblk64_3_b
I0818 13:44:37.349395 22726 net.cpp:100] Creating Layer scale_resblk64_3_b
I0818 13:44:37.349401 22726 net.cpp:434] scale_resblk64_3_b <- bn_resblk64_3_b
I0818 13:44:37.349409 22726 net.cpp:395] scale_resblk64_3_b -> bn_resblk64_3_b (in-place)
I0818 13:44:37.349472 22726 layer_factory.hpp:77] Creating layer scale_resblk64_3_b
I0818 13:44:37.349632 22726 net.cpp:150] Setting up scale_resblk64_3_b
I0818 13:44:37.349644 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.349649 22726 net.cpp:165] Memory required for data: 1333761500
I0818 13:44:37.349658 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_2_b
I0818 13:44:37.349670 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_2_b
I0818 13:44:37.349678 22726 net.cpp:434] sum_sum_bn_resblk64_2_b <- sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split_1
I0818 13:44:37.349684 22726 net.cpp:434] sum_sum_bn_resblk64_2_b <- bn_resblk64_3_b
I0818 13:44:37.349692 22726 net.cpp:408] sum_sum_bn_resblk64_2_b -> sum_bn_resblk64_3_b
I0818 13:44:37.349735 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_2_b
I0818 13:44:37.349745 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.349750 22726 net.cpp:165] Memory required for data: 1335809500
I0818 13:44:37.349756 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_3_b
I0818 13:44:37.349763 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_3_b
I0818 13:44:37.349769 22726 net.cpp:434] relu_sum_bn_resblk64_3_b <- sum_bn_resblk64_3_b
I0818 13:44:37.349776 22726 net.cpp:395] relu_sum_bn_resblk64_3_b -> sum_bn_resblk64_3_b (in-place)
I0818 13:44:37.349786 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_3_b
I0818 13:44:37.349792 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.349797 22726 net.cpp:165] Memory required for data: 1337857500
I0818 13:44:37.349802 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split
I0818 13:44:37.349814 22726 net.cpp:100] Creating Layer sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split
I0818 13:44:37.349820 22726 net.cpp:434] sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split <- sum_bn_resblk64_3_b
I0818 13:44:37.349831 22726 net.cpp:408] sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split -> sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split_0
I0818 13:44:37.349843 22726 net.cpp:408] sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split -> sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split_1
I0818 13:44:37.349891 22726 net.cpp:150] Setting up sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split
I0818 13:44:37.349902 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.349910 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.349913 22726 net.cpp:165] Memory required for data: 1341953500
I0818 13:44:37.349918 22726 layer_factory.hpp:77] Creating layer resblk64_4
I0818 13:44:37.349933 22726 net.cpp:100] Creating Layer resblk64_4
I0818 13:44:37.349941 22726 net.cpp:434] resblk64_4 <- sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split_0
I0818 13:44:37.349958 22726 net.cpp:408] resblk64_4 -> resblk64_4
I0818 13:44:37.350992 22726 net.cpp:150] Setting up resblk64_4
I0818 13:44:37.351007 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.351012 22726 net.cpp:165] Memory required for data: 1344001500
I0818 13:44:37.351020 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_4
I0818 13:44:37.351032 22726 net.cpp:100] Creating Layer batchNorm_resblk64_4
I0818 13:44:37.351038 22726 net.cpp:434] batchNorm_resblk64_4 <- resblk64_4
I0818 13:44:37.351047 22726 net.cpp:408] batchNorm_resblk64_4 -> bn_resblk64_4
I0818 13:44:37.351323 22726 net.cpp:150] Setting up batchNorm_resblk64_4
I0818 13:44:37.351336 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.351341 22726 net.cpp:165] Memory required for data: 1346049500
I0818 13:44:37.351351 22726 layer_factory.hpp:77] Creating layer scale_resblk64_4
I0818 13:44:37.351362 22726 net.cpp:100] Creating Layer scale_resblk64_4
I0818 13:44:37.351369 22726 net.cpp:434] scale_resblk64_4 <- bn_resblk64_4
I0818 13:44:37.351377 22726 net.cpp:395] scale_resblk64_4 -> bn_resblk64_4 (in-place)
I0818 13:44:37.351441 22726 layer_factory.hpp:77] Creating layer scale_resblk64_4
I0818 13:44:37.351606 22726 net.cpp:150] Setting up scale_resblk64_4
I0818 13:44:37.351619 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.351624 22726 net.cpp:165] Memory required for data: 1348097500
I0818 13:44:37.351634 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_4
I0818 13:44:37.351644 22726 net.cpp:100] Creating Layer relu_bn_resblk64_4
I0818 13:44:37.351651 22726 net.cpp:434] relu_bn_resblk64_4 <- bn_resblk64_4
I0818 13:44:37.351658 22726 net.cpp:395] relu_bn_resblk64_4 -> bn_resblk64_4 (in-place)
I0818 13:44:37.351668 22726 net.cpp:150] Setting up relu_bn_resblk64_4
I0818 13:44:37.351675 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.351680 22726 net.cpp:165] Memory required for data: 1350145500
I0818 13:44:37.351685 22726 layer_factory.hpp:77] Creating layer resblk64_4_b
I0818 13:44:37.351698 22726 net.cpp:100] Creating Layer resblk64_4_b
I0818 13:44:37.351704 22726 net.cpp:434] resblk64_4_b <- bn_resblk64_4
I0818 13:44:37.351716 22726 net.cpp:408] resblk64_4_b -> resblk64_4_b
I0818 13:44:37.352747 22726 net.cpp:150] Setting up resblk64_4_b
I0818 13:44:37.352762 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.352767 22726 net.cpp:165] Memory required for data: 1352193500
I0818 13:44:37.352777 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_4_b
I0818 13:44:37.352784 22726 net.cpp:100] Creating Layer batchNorm_resblk64_4_b
I0818 13:44:37.352792 22726 net.cpp:434] batchNorm_resblk64_4_b <- resblk64_4_b
I0818 13:44:37.352802 22726 net.cpp:408] batchNorm_resblk64_4_b -> bn_resblk64_4_b
I0818 13:44:37.353085 22726 net.cpp:150] Setting up batchNorm_resblk64_4_b
I0818 13:44:37.353101 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.353106 22726 net.cpp:165] Memory required for data: 1354241500
I0818 13:44:37.353116 22726 layer_factory.hpp:77] Creating layer scale_resblk64_4_b
I0818 13:44:37.353126 22726 net.cpp:100] Creating Layer scale_resblk64_4_b
I0818 13:44:37.353132 22726 net.cpp:434] scale_resblk64_4_b <- bn_resblk64_4_b
I0818 13:44:37.353138 22726 net.cpp:395] scale_resblk64_4_b -> bn_resblk64_4_b (in-place)
I0818 13:44:37.353197 22726 layer_factory.hpp:77] Creating layer scale_resblk64_4_b
I0818 13:44:37.353359 22726 net.cpp:150] Setting up scale_resblk64_4_b
I0818 13:44:37.353371 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.353376 22726 net.cpp:165] Memory required for data: 1356289500
I0818 13:44:37.353385 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_3_b
I0818 13:44:37.353396 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_3_b
I0818 13:44:37.353404 22726 net.cpp:434] sum_sum_bn_resblk64_3_b <- sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split_1
I0818 13:44:37.353411 22726 net.cpp:434] sum_sum_bn_resblk64_3_b <- bn_resblk64_4_b
I0818 13:44:37.353426 22726 net.cpp:408] sum_sum_bn_resblk64_3_b -> sum_bn_resblk64_4_b
I0818 13:44:37.353464 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_3_b
I0818 13:44:37.353474 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.353478 22726 net.cpp:165] Memory required for data: 1358337500
I0818 13:44:37.353483 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_4_b
I0818 13:44:37.353492 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_4_b
I0818 13:44:37.353497 22726 net.cpp:434] relu_sum_bn_resblk64_4_b <- sum_bn_resblk64_4_b
I0818 13:44:37.353504 22726 net.cpp:395] relu_sum_bn_resblk64_4_b -> sum_bn_resblk64_4_b (in-place)
I0818 13:44:37.353513 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_4_b
I0818 13:44:37.353520 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.353525 22726 net.cpp:165] Memory required for data: 1360385500
I0818 13:44:37.353529 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split
I0818 13:44:37.353536 22726 net.cpp:100] Creating Layer sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split
I0818 13:44:37.353541 22726 net.cpp:434] sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split <- sum_bn_resblk64_4_b
I0818 13:44:37.353551 22726 net.cpp:408] sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split -> sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split_0
I0818 13:44:37.353561 22726 net.cpp:408] sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split -> sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split_1
I0818 13:44:37.353608 22726 net.cpp:150] Setting up sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split
I0818 13:44:37.353621 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.353626 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.353631 22726 net.cpp:165] Memory required for data: 1364481500
I0818 13:44:37.353636 22726 layer_factory.hpp:77] Creating layer resblk64_5
I0818 13:44:37.353651 22726 net.cpp:100] Creating Layer resblk64_5
I0818 13:44:37.353657 22726 net.cpp:434] resblk64_5 <- sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split_0
I0818 13:44:37.353667 22726 net.cpp:408] resblk64_5 -> resblk64_5
I0818 13:44:37.354724 22726 net.cpp:150] Setting up resblk64_5
I0818 13:44:37.354740 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.354745 22726 net.cpp:165] Memory required for data: 1366529500
I0818 13:44:37.354754 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_5
I0818 13:44:37.354765 22726 net.cpp:100] Creating Layer batchNorm_resblk64_5
I0818 13:44:37.354773 22726 net.cpp:434] batchNorm_resblk64_5 <- resblk64_5
I0818 13:44:37.354781 22726 net.cpp:408] batchNorm_resblk64_5 -> bn_resblk64_5
I0818 13:44:37.355063 22726 net.cpp:150] Setting up batchNorm_resblk64_5
I0818 13:44:37.355077 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.355082 22726 net.cpp:165] Memory required for data: 1368577500
I0818 13:44:37.355093 22726 layer_factory.hpp:77] Creating layer scale_resblk64_5
I0818 13:44:37.355106 22726 net.cpp:100] Creating Layer scale_resblk64_5
I0818 13:44:37.355113 22726 net.cpp:434] scale_resblk64_5 <- bn_resblk64_5
I0818 13:44:37.355121 22726 net.cpp:395] scale_resblk64_5 -> bn_resblk64_5 (in-place)
I0818 13:44:37.355183 22726 layer_factory.hpp:77] Creating layer scale_resblk64_5
I0818 13:44:37.355347 22726 net.cpp:150] Setting up scale_resblk64_5
I0818 13:44:37.355360 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.355365 22726 net.cpp:165] Memory required for data: 1370625500
I0818 13:44:37.355374 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_5
I0818 13:44:37.355386 22726 net.cpp:100] Creating Layer relu_bn_resblk64_5
I0818 13:44:37.355391 22726 net.cpp:434] relu_bn_resblk64_5 <- bn_resblk64_5
I0818 13:44:37.355399 22726 net.cpp:395] relu_bn_resblk64_5 -> bn_resblk64_5 (in-place)
I0818 13:44:37.355408 22726 net.cpp:150] Setting up relu_bn_resblk64_5
I0818 13:44:37.355415 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.355420 22726 net.cpp:165] Memory required for data: 1372673500
I0818 13:44:37.355432 22726 layer_factory.hpp:77] Creating layer resblk64_5_b
I0818 13:44:37.355445 22726 net.cpp:100] Creating Layer resblk64_5_b
I0818 13:44:37.355451 22726 net.cpp:434] resblk64_5_b <- bn_resblk64_5
I0818 13:44:37.355463 22726 net.cpp:408] resblk64_5_b -> resblk64_5_b
I0818 13:44:37.356497 22726 net.cpp:150] Setting up resblk64_5_b
I0818 13:44:37.356511 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.356516 22726 net.cpp:165] Memory required for data: 1374721500
I0818 13:44:37.356525 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_5_b
I0818 13:44:37.356534 22726 net.cpp:100] Creating Layer batchNorm_resblk64_5_b
I0818 13:44:37.356540 22726 net.cpp:434] batchNorm_resblk64_5_b <- resblk64_5_b
I0818 13:44:37.356551 22726 net.cpp:408] batchNorm_resblk64_5_b -> bn_resblk64_5_b
I0818 13:44:37.356833 22726 net.cpp:150] Setting up batchNorm_resblk64_5_b
I0818 13:44:37.356848 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.356854 22726 net.cpp:165] Memory required for data: 1376769500
I0818 13:44:37.356864 22726 layer_factory.hpp:77] Creating layer scale_resblk64_5_b
I0818 13:44:37.356873 22726 net.cpp:100] Creating Layer scale_resblk64_5_b
I0818 13:44:37.356879 22726 net.cpp:434] scale_resblk64_5_b <- bn_resblk64_5_b
I0818 13:44:37.356887 22726 net.cpp:395] scale_resblk64_5_b -> bn_resblk64_5_b (in-place)
I0818 13:44:37.356947 22726 layer_factory.hpp:77] Creating layer scale_resblk64_5_b
I0818 13:44:37.357112 22726 net.cpp:150] Setting up scale_resblk64_5_b
I0818 13:44:37.357125 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.357131 22726 net.cpp:165] Memory required for data: 1378817500
I0818 13:44:37.357139 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_4_b
I0818 13:44:37.357151 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_4_b
I0818 13:44:37.357158 22726 net.cpp:434] sum_sum_bn_resblk64_4_b <- sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split_1
I0818 13:44:37.357165 22726 net.cpp:434] sum_sum_bn_resblk64_4_b <- bn_resblk64_5_b
I0818 13:44:37.357173 22726 net.cpp:408] sum_sum_bn_resblk64_4_b -> sum_bn_resblk64_5_b
I0818 13:44:37.357216 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_4_b
I0818 13:44:37.357228 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.357233 22726 net.cpp:165] Memory required for data: 1380865500
I0818 13:44:37.357237 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_5_b
I0818 13:44:37.357245 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_5_b
I0818 13:44:37.357251 22726 net.cpp:434] relu_sum_bn_resblk64_5_b <- sum_bn_resblk64_5_b
I0818 13:44:37.357259 22726 net.cpp:395] relu_sum_bn_resblk64_5_b -> sum_bn_resblk64_5_b (in-place)
I0818 13:44:37.357267 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_5_b
I0818 13:44:37.357275 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.357280 22726 net.cpp:165] Memory required for data: 1382913500
I0818 13:44:37.357285 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split
I0818 13:44:37.357291 22726 net.cpp:100] Creating Layer sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split
I0818 13:44:37.357296 22726 net.cpp:434] sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split <- sum_bn_resblk64_5_b
I0818 13:44:37.357306 22726 net.cpp:408] sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split -> sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split_0
I0818 13:44:37.357317 22726 net.cpp:408] sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split -> sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split_1
I0818 13:44:37.357367 22726 net.cpp:150] Setting up sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split
I0818 13:44:37.357378 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.357384 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.357389 22726 net.cpp:165] Memory required for data: 1387009500
I0818 13:44:37.357393 22726 layer_factory.hpp:77] Creating layer resblk64_6
I0818 13:44:37.357409 22726 net.cpp:100] Creating Layer resblk64_6
I0818 13:44:37.357424 22726 net.cpp:434] resblk64_6 <- sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split_0
I0818 13:44:37.357434 22726 net.cpp:408] resblk64_6 -> resblk64_6
I0818 13:44:37.358475 22726 net.cpp:150] Setting up resblk64_6
I0818 13:44:37.358490 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.358495 22726 net.cpp:165] Memory required for data: 1389057500
I0818 13:44:37.358505 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_6
I0818 13:44:37.358515 22726 net.cpp:100] Creating Layer batchNorm_resblk64_6
I0818 13:44:37.358522 22726 net.cpp:434] batchNorm_resblk64_6 <- resblk64_6
I0818 13:44:37.358531 22726 net.cpp:408] batchNorm_resblk64_6 -> bn_resblk64_6
I0818 13:44:37.358803 22726 net.cpp:150] Setting up batchNorm_resblk64_6
I0818 13:44:37.358821 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.358827 22726 net.cpp:165] Memory required for data: 1391105500
I0818 13:44:37.358837 22726 layer_factory.hpp:77] Creating layer scale_resblk64_6
I0818 13:44:37.358849 22726 net.cpp:100] Creating Layer scale_resblk64_6
I0818 13:44:37.358855 22726 net.cpp:434] scale_resblk64_6 <- bn_resblk64_6
I0818 13:44:37.358863 22726 net.cpp:395] scale_resblk64_6 -> bn_resblk64_6 (in-place)
I0818 13:44:37.358927 22726 layer_factory.hpp:77] Creating layer scale_resblk64_6
I0818 13:44:37.359089 22726 net.cpp:150] Setting up scale_resblk64_6
I0818 13:44:37.359102 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.359107 22726 net.cpp:165] Memory required for data: 1393153500
I0818 13:44:37.359115 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_6
I0818 13:44:37.359153 22726 net.cpp:100] Creating Layer relu_bn_resblk64_6
I0818 13:44:37.359163 22726 net.cpp:434] relu_bn_resblk64_6 <- bn_resblk64_6
I0818 13:44:37.359170 22726 net.cpp:395] relu_bn_resblk64_6 -> bn_resblk64_6 (in-place)
I0818 13:44:37.359180 22726 net.cpp:150] Setting up relu_bn_resblk64_6
I0818 13:44:37.359187 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.359191 22726 net.cpp:165] Memory required for data: 1395201500
I0818 13:44:37.359196 22726 layer_factory.hpp:77] Creating layer resblk64_6_b
I0818 13:44:37.359207 22726 net.cpp:100] Creating Layer resblk64_6_b
I0818 13:44:37.359213 22726 net.cpp:434] resblk64_6_b <- bn_resblk64_6
I0818 13:44:37.359222 22726 net.cpp:408] resblk64_6_b -> resblk64_6_b
I0818 13:44:37.360256 22726 net.cpp:150] Setting up resblk64_6_b
I0818 13:44:37.360271 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.360275 22726 net.cpp:165] Memory required for data: 1397249500
I0818 13:44:37.360285 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_6_b
I0818 13:44:37.360301 22726 net.cpp:100] Creating Layer batchNorm_resblk64_6_b
I0818 13:44:37.360307 22726 net.cpp:434] batchNorm_resblk64_6_b <- resblk64_6_b
I0818 13:44:37.360318 22726 net.cpp:408] batchNorm_resblk64_6_b -> bn_resblk64_6_b
I0818 13:44:37.360590 22726 net.cpp:150] Setting up batchNorm_resblk64_6_b
I0818 13:44:37.360602 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.360607 22726 net.cpp:165] Memory required for data: 1399297500
I0818 13:44:37.360617 22726 layer_factory.hpp:77] Creating layer scale_resblk64_6_b
I0818 13:44:37.360626 22726 net.cpp:100] Creating Layer scale_resblk64_6_b
I0818 13:44:37.360632 22726 net.cpp:434] scale_resblk64_6_b <- bn_resblk64_6_b
I0818 13:44:37.360643 22726 net.cpp:395] scale_resblk64_6_b -> bn_resblk64_6_b (in-place)
I0818 13:44:37.360703 22726 layer_factory.hpp:77] Creating layer scale_resblk64_6_b
I0818 13:44:37.360872 22726 net.cpp:150] Setting up scale_resblk64_6_b
I0818 13:44:37.360885 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.360890 22726 net.cpp:165] Memory required for data: 1401345500
I0818 13:44:37.360899 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_5_b
I0818 13:44:37.360911 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_5_b
I0818 13:44:37.360918 22726 net.cpp:434] sum_sum_bn_resblk64_5_b <- sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split_1
I0818 13:44:37.360934 22726 net.cpp:434] sum_sum_bn_resblk64_5_b <- bn_resblk64_6_b
I0818 13:44:37.360941 22726 net.cpp:408] sum_sum_bn_resblk64_5_b -> sum_bn_resblk64_6_b
I0818 13:44:37.360980 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_5_b
I0818 13:44:37.360991 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.360996 22726 net.cpp:165] Memory required for data: 1403393500
I0818 13:44:37.361001 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_6_b
I0818 13:44:37.361007 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_6_b
I0818 13:44:37.361013 22726 net.cpp:434] relu_sum_bn_resblk64_6_b <- sum_bn_resblk64_6_b
I0818 13:44:37.361023 22726 net.cpp:395] relu_sum_bn_resblk64_6_b -> sum_bn_resblk64_6_b (in-place)
I0818 13:44:37.361033 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_6_b
I0818 13:44:37.361040 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.361044 22726 net.cpp:165] Memory required for data: 1405441500
I0818 13:44:37.361049 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split
I0818 13:44:37.361057 22726 net.cpp:100] Creating Layer sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split
I0818 13:44:37.361062 22726 net.cpp:434] sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split <- sum_bn_resblk64_6_b
I0818 13:44:37.361069 22726 net.cpp:408] sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split -> sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split_0
I0818 13:44:37.361079 22726 net.cpp:408] sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split -> sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split_1
I0818 13:44:37.361130 22726 net.cpp:150] Setting up sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split
I0818 13:44:37.361142 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.361148 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.361153 22726 net.cpp:165] Memory required for data: 1409537500
I0818 13:44:37.361157 22726 layer_factory.hpp:77] Creating layer resblk64_7
I0818 13:44:37.361168 22726 net.cpp:100] Creating Layer resblk64_7
I0818 13:44:37.361176 22726 net.cpp:434] resblk64_7 <- sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split_0
I0818 13:44:37.361189 22726 net.cpp:408] resblk64_7 -> resblk64_7
I0818 13:44:37.363199 22726 net.cpp:150] Setting up resblk64_7
I0818 13:44:37.363217 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.363222 22726 net.cpp:165] Memory required for data: 1411585500
I0818 13:44:37.363231 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_7
I0818 13:44:37.363245 22726 net.cpp:100] Creating Layer batchNorm_resblk64_7
I0818 13:44:37.363250 22726 net.cpp:434] batchNorm_resblk64_7 <- resblk64_7
I0818 13:44:37.363260 22726 net.cpp:408] batchNorm_resblk64_7 -> bn_resblk64_7
I0818 13:44:37.363539 22726 net.cpp:150] Setting up batchNorm_resblk64_7
I0818 13:44:37.363553 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.363556 22726 net.cpp:165] Memory required for data: 1413633500
I0818 13:44:37.363567 22726 layer_factory.hpp:77] Creating layer scale_resblk64_7
I0818 13:44:37.363581 22726 net.cpp:100] Creating Layer scale_resblk64_7
I0818 13:44:37.363589 22726 net.cpp:434] scale_resblk64_7 <- bn_resblk64_7
I0818 13:44:37.363596 22726 net.cpp:395] scale_resblk64_7 -> bn_resblk64_7 (in-place)
I0818 13:44:37.363662 22726 layer_factory.hpp:77] Creating layer scale_resblk64_7
I0818 13:44:37.363834 22726 net.cpp:150] Setting up scale_resblk64_7
I0818 13:44:37.363847 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.363852 22726 net.cpp:165] Memory required for data: 1415681500
I0818 13:44:37.363862 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_7
I0818 13:44:37.363873 22726 net.cpp:100] Creating Layer relu_bn_resblk64_7
I0818 13:44:37.363879 22726 net.cpp:434] relu_bn_resblk64_7 <- bn_resblk64_7
I0818 13:44:37.363888 22726 net.cpp:395] relu_bn_resblk64_7 -> bn_resblk64_7 (in-place)
I0818 13:44:37.363896 22726 net.cpp:150] Setting up relu_bn_resblk64_7
I0818 13:44:37.363903 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.363916 22726 net.cpp:165] Memory required for data: 1417729500
I0818 13:44:37.363921 22726 layer_factory.hpp:77] Creating layer resblk64_7_b
I0818 13:44:37.363935 22726 net.cpp:100] Creating Layer resblk64_7_b
I0818 13:44:37.363941 22726 net.cpp:434] resblk64_7_b <- bn_resblk64_7
I0818 13:44:37.363953 22726 net.cpp:408] resblk64_7_b -> resblk64_7_b
I0818 13:44:37.364989 22726 net.cpp:150] Setting up resblk64_7_b
I0818 13:44:37.365005 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.365010 22726 net.cpp:165] Memory required for data: 1419777500
I0818 13:44:37.365018 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_7_b
I0818 13:44:37.365027 22726 net.cpp:100] Creating Layer batchNorm_resblk64_7_b
I0818 13:44:37.365033 22726 net.cpp:434] batchNorm_resblk64_7_b <- resblk64_7_b
I0818 13:44:37.365046 22726 net.cpp:408] batchNorm_resblk64_7_b -> bn_resblk64_7_b
I0818 13:44:37.365324 22726 net.cpp:150] Setting up batchNorm_resblk64_7_b
I0818 13:44:37.365339 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.365345 22726 net.cpp:165] Memory required for data: 1421825500
I0818 13:44:37.365355 22726 layer_factory.hpp:77] Creating layer scale_resblk64_7_b
I0818 13:44:37.365365 22726 net.cpp:100] Creating Layer scale_resblk64_7_b
I0818 13:44:37.365370 22726 net.cpp:434] scale_resblk64_7_b <- bn_resblk64_7_b
I0818 13:44:37.365378 22726 net.cpp:395] scale_resblk64_7_b -> bn_resblk64_7_b (in-place)
I0818 13:44:37.365438 22726 layer_factory.hpp:77] Creating layer scale_resblk64_7_b
I0818 13:44:37.365600 22726 net.cpp:150] Setting up scale_resblk64_7_b
I0818 13:44:37.365613 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.365617 22726 net.cpp:165] Memory required for data: 1423873500
I0818 13:44:37.365627 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_6_b
I0818 13:44:37.365638 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_6_b
I0818 13:44:37.365645 22726 net.cpp:434] sum_sum_bn_resblk64_6_b <- sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split_1
I0818 13:44:37.365653 22726 net.cpp:434] sum_sum_bn_resblk64_6_b <- bn_resblk64_7_b
I0818 13:44:37.365661 22726 net.cpp:408] sum_sum_bn_resblk64_6_b -> sum_bn_resblk64_7_b
I0818 13:44:37.365698 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_6_b
I0818 13:44:37.365710 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.365715 22726 net.cpp:165] Memory required for data: 1425921500
I0818 13:44:37.365720 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_7_b
I0818 13:44:37.365728 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_7_b
I0818 13:44:37.365734 22726 net.cpp:434] relu_sum_bn_resblk64_7_b <- sum_bn_resblk64_7_b
I0818 13:44:37.365741 22726 net.cpp:395] relu_sum_bn_resblk64_7_b -> sum_bn_resblk64_7_b (in-place)
I0818 13:44:37.365751 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_7_b
I0818 13:44:37.365757 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.365761 22726 net.cpp:165] Memory required for data: 1427969500
I0818 13:44:37.365767 22726 layer_factory.hpp:77] Creating layer sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split
I0818 13:44:37.365773 22726 net.cpp:100] Creating Layer sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split
I0818 13:44:37.365778 22726 net.cpp:434] sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split <- sum_bn_resblk64_7_b
I0818 13:44:37.365788 22726 net.cpp:408] sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split -> sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split_0
I0818 13:44:37.365798 22726 net.cpp:408] sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split -> sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split_1
I0818 13:44:37.365855 22726 net.cpp:150] Setting up sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split
I0818 13:44:37.365867 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.365873 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.365878 22726 net.cpp:165] Memory required for data: 1432065500
I0818 13:44:37.365883 22726 layer_factory.hpp:77] Creating layer resblk64_8
I0818 13:44:37.365906 22726 net.cpp:100] Creating Layer resblk64_8
I0818 13:44:37.365913 22726 net.cpp:434] resblk64_8 <- sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split_0
I0818 13:44:37.365923 22726 net.cpp:408] resblk64_8 -> resblk64_8
I0818 13:44:37.366960 22726 net.cpp:150] Setting up resblk64_8
I0818 13:44:37.366973 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.366978 22726 net.cpp:165] Memory required for data: 1434113500
I0818 13:44:37.366987 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_8
I0818 13:44:37.366999 22726 net.cpp:100] Creating Layer batchNorm_resblk64_8
I0818 13:44:37.367007 22726 net.cpp:434] batchNorm_resblk64_8 <- resblk64_8
I0818 13:44:37.367014 22726 net.cpp:408] batchNorm_resblk64_8 -> bn_resblk64_8
I0818 13:44:37.367290 22726 net.cpp:150] Setting up batchNorm_resblk64_8
I0818 13:44:37.367303 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.367308 22726 net.cpp:165] Memory required for data: 1436161500
I0818 13:44:37.367318 22726 layer_factory.hpp:77] Creating layer scale_resblk64_8
I0818 13:44:37.367331 22726 net.cpp:100] Creating Layer scale_resblk64_8
I0818 13:44:37.367336 22726 net.cpp:434] scale_resblk64_8 <- bn_resblk64_8
I0818 13:44:37.367344 22726 net.cpp:395] scale_resblk64_8 -> bn_resblk64_8 (in-place)
I0818 13:44:37.367409 22726 layer_factory.hpp:77] Creating layer scale_resblk64_8
I0818 13:44:37.367575 22726 net.cpp:150] Setting up scale_resblk64_8
I0818 13:44:37.367588 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.367594 22726 net.cpp:165] Memory required for data: 1438209500
I0818 13:44:37.367602 22726 layer_factory.hpp:77] Creating layer relu_bn_resblk64_8
I0818 13:44:37.367614 22726 net.cpp:100] Creating Layer relu_bn_resblk64_8
I0818 13:44:37.367620 22726 net.cpp:434] relu_bn_resblk64_8 <- bn_resblk64_8
I0818 13:44:37.367627 22726 net.cpp:395] relu_bn_resblk64_8 -> bn_resblk64_8 (in-place)
I0818 13:44:37.367637 22726 net.cpp:150] Setting up relu_bn_resblk64_8
I0818 13:44:37.367643 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.367648 22726 net.cpp:165] Memory required for data: 1440257500
I0818 13:44:37.367652 22726 layer_factory.hpp:77] Creating layer resblk64_8_b
I0818 13:44:37.367666 22726 net.cpp:100] Creating Layer resblk64_8_b
I0818 13:44:37.367672 22726 net.cpp:434] resblk64_8_b <- bn_resblk64_8
I0818 13:44:37.367684 22726 net.cpp:408] resblk64_8_b -> resblk64_8_b
I0818 13:44:37.368715 22726 net.cpp:150] Setting up resblk64_8_b
I0818 13:44:37.368729 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.368734 22726 net.cpp:165] Memory required for data: 1442305500
I0818 13:44:37.368743 22726 layer_factory.hpp:77] Creating layer batchNorm_resblk64_8_b
I0818 13:44:37.368752 22726 net.cpp:100] Creating Layer batchNorm_resblk64_8_b
I0818 13:44:37.368758 22726 net.cpp:434] batchNorm_resblk64_8_b <- resblk64_8_b
I0818 13:44:37.368769 22726 net.cpp:408] batchNorm_resblk64_8_b -> bn_resblk64_8_b
I0818 13:44:37.369051 22726 net.cpp:150] Setting up batchNorm_resblk64_8_b
I0818 13:44:37.369068 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.369073 22726 net.cpp:165] Memory required for data: 1444353500
I0818 13:44:37.369083 22726 layer_factory.hpp:77] Creating layer scale_resblk64_8_b
I0818 13:44:37.369092 22726 net.cpp:100] Creating Layer scale_resblk64_8_b
I0818 13:44:37.369098 22726 net.cpp:434] scale_resblk64_8_b <- bn_resblk64_8_b
I0818 13:44:37.369105 22726 net.cpp:395] scale_resblk64_8_b -> bn_resblk64_8_b (in-place)
I0818 13:44:37.369164 22726 layer_factory.hpp:77] Creating layer scale_resblk64_8_b
I0818 13:44:37.369329 22726 net.cpp:150] Setting up scale_resblk64_8_b
I0818 13:44:37.369341 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.369346 22726 net.cpp:165] Memory required for data: 1446401500
I0818 13:44:37.369355 22726 layer_factory.hpp:77] Creating layer sum_sum_bn_resblk64_7_b
I0818 13:44:37.369369 22726 net.cpp:100] Creating Layer sum_sum_bn_resblk64_7_b
I0818 13:44:37.369375 22726 net.cpp:434] sum_sum_bn_resblk64_7_b <- sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split_1
I0818 13:44:37.369390 22726 net.cpp:434] sum_sum_bn_resblk64_7_b <- bn_resblk64_8_b
I0818 13:44:37.369398 22726 net.cpp:408] sum_sum_bn_resblk64_7_b -> sum_bn_resblk64_8_b
I0818 13:44:37.369436 22726 net.cpp:150] Setting up sum_sum_bn_resblk64_7_b
I0818 13:44:37.369446 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.369451 22726 net.cpp:165] Memory required for data: 1448449500
I0818 13:44:37.369457 22726 layer_factory.hpp:77] Creating layer relu_sum_bn_resblk64_8_b
I0818 13:44:37.369463 22726 net.cpp:100] Creating Layer relu_sum_bn_resblk64_8_b
I0818 13:44:37.369469 22726 net.cpp:434] relu_sum_bn_resblk64_8_b <- sum_bn_resblk64_8_b
I0818 13:44:37.369477 22726 net.cpp:395] relu_sum_bn_resblk64_8_b -> sum_bn_resblk64_8_b (in-place)
I0818 13:44:37.369485 22726 net.cpp:150] Setting up relu_sum_bn_resblk64_8_b
I0818 13:44:37.369493 22726 net.cpp:157] Top shape: 125 64 8 8 (512000)
I0818 13:44:37.369496 22726 net.cpp:165] Memory required for data: 1450497500
I0818 13:44:37.369501 22726 layer_factory.hpp:77] Creating layer avePooling_resblk64_8
I0818 13:44:37.369509 22726 net.cpp:100] Creating Layer avePooling_resblk64_8
I0818 13:44:37.369514 22726 net.cpp:434] avePooling_resblk64_8 <- sum_bn_resblk64_8_b
I0818 13:44:37.369525 22726 net.cpp:408] avePooling_resblk64_8 -> avgPool_resblk64_8
I0818 13:44:37.369560 22726 net.cpp:150] Setting up avePooling_resblk64_8
I0818 13:44:37.369572 22726 net.cpp:157] Top shape: 125 64 1 1 (8000)
I0818 13:44:37.369577 22726 net.cpp:165] Memory required for data: 1450529500
I0818 13:44:37.369582 22726 layer_factory.hpp:77] Creating layer FC_final
I0818 13:44:37.369593 22726 net.cpp:100] Creating Layer FC_final
I0818 13:44:37.369599 22726 net.cpp:434] FC_final <- avgPool_resblk64_8
I0818 13:44:37.369611 22726 net.cpp:408] FC_final -> FC_final
I0818 13:44:37.369781 22726 net.cpp:150] Setting up FC_final
I0818 13:44:37.369794 22726 net.cpp:157] Top shape: 125 10 (1250)
I0818 13:44:37.369799 22726 net.cpp:165] Memory required for data: 1450534500
I0818 13:44:37.369813 22726 layer_factory.hpp:77] Creating layer FC_final_FC_final_0_split
I0818 13:44:37.369825 22726 net.cpp:100] Creating Layer FC_final_FC_final_0_split
I0818 13:44:37.369832 22726 net.cpp:434] FC_final_FC_final_0_split <- FC_final
I0818 13:44:37.369839 22726 net.cpp:408] FC_final_FC_final_0_split -> FC_final_FC_final_0_split_0
I0818 13:44:37.369849 22726 net.cpp:408] FC_final_FC_final_0_split -> FC_final_FC_final_0_split_1
I0818 13:44:37.369904 22726 net.cpp:150] Setting up FC_final_FC_final_0_split
I0818 13:44:37.369915 22726 net.cpp:157] Top shape: 125 10 (1250)
I0818 13:44:37.369921 22726 net.cpp:157] Top shape: 125 10 (1250)
I0818 13:44:37.369926 22726 net.cpp:165] Memory required for data: 1450544500
I0818 13:44:37.369931 22726 layer_factory.hpp:77] Creating layer accuracy
I0818 13:44:37.369938 22726 net.cpp:100] Creating Layer accuracy
I0818 13:44:37.369945 22726 net.cpp:434] accuracy <- FC_final_FC_final_0_split_0
I0818 13:44:37.369951 22726 net.cpp:434] accuracy <- label_dataLayer_1_split_0
I0818 13:44:37.369958 22726 net.cpp:408] accuracy -> accuracy
I0818 13:44:37.369971 22726 net.cpp:150] Setting up accuracy
I0818 13:44:37.369978 22726 net.cpp:157] Top shape: (1)
I0818 13:44:37.369983 22726 net.cpp:165] Memory required for data: 1450544504
I0818 13:44:37.369987 22726 layer_factory.hpp:77] Creating layer loss
I0818 13:44:37.369998 22726 net.cpp:100] Creating Layer loss
I0818 13:44:37.370003 22726 net.cpp:434] loss <- FC_final_FC_final_0_split_1
I0818 13:44:37.370010 22726 net.cpp:434] loss <- label_dataLayer_1_split_1
I0818 13:44:37.370018 22726 net.cpp:408] loss -> loss
I0818 13:44:37.370029 22726 layer_factory.hpp:77] Creating layer loss
I0818 13:44:37.370152 22726 net.cpp:150] Setting up loss
I0818 13:44:37.370164 22726 net.cpp:157] Top shape: (1)
I0818 13:44:37.370169 22726 net.cpp:160]     with loss weight 1
I0818 13:44:37.370185 22726 net.cpp:165] Memory required for data: 1450544508
I0818 13:44:37.370192 22726 net.cpp:226] loss needs backward computation.
I0818 13:44:37.370204 22726 net.cpp:228] accuracy does not need backward computation.
I0818 13:44:37.370210 22726 net.cpp:226] FC_final_FC_final_0_split needs backward computation.
I0818 13:44:37.370216 22726 net.cpp:226] FC_final needs backward computation.
I0818 13:44:37.370221 22726 net.cpp:226] avePooling_resblk64_8 needs backward computation.
I0818 13:44:37.370226 22726 net.cpp:226] relu_sum_bn_resblk64_8_b needs backward computation.
I0818 13:44:37.370230 22726 net.cpp:226] sum_sum_bn_resblk64_7_b needs backward computation.
I0818 13:44:37.370236 22726 net.cpp:226] scale_resblk64_8_b needs backward computation.
I0818 13:44:37.370240 22726 net.cpp:226] batchNorm_resblk64_8_b needs backward computation.
I0818 13:44:37.370245 22726 net.cpp:226] resblk64_8_b needs backward computation.
I0818 13:44:37.370250 22726 net.cpp:226] relu_bn_resblk64_8 needs backward computation.
I0818 13:44:37.370255 22726 net.cpp:226] scale_resblk64_8 needs backward computation.
I0818 13:44:37.370260 22726 net.cpp:226] batchNorm_resblk64_8 needs backward computation.
I0818 13:44:37.370265 22726 net.cpp:226] resblk64_8 needs backward computation.
I0818 13:44:37.370270 22726 net.cpp:226] sum_bn_resblk64_7_b_relu_sum_bn_resblk64_7_b_0_split needs backward computation.
I0818 13:44:37.370275 22726 net.cpp:226] relu_sum_bn_resblk64_7_b needs backward computation.
I0818 13:44:37.370280 22726 net.cpp:226] sum_sum_bn_resblk64_6_b needs backward computation.
I0818 13:44:37.370285 22726 net.cpp:226] scale_resblk64_7_b needs backward computation.
I0818 13:44:37.370290 22726 net.cpp:226] batchNorm_resblk64_7_b needs backward computation.
I0818 13:44:37.370295 22726 net.cpp:226] resblk64_7_b needs backward computation.
I0818 13:44:37.370302 22726 net.cpp:226] relu_bn_resblk64_7 needs backward computation.
I0818 13:44:37.370307 22726 net.cpp:226] scale_resblk64_7 needs backward computation.
I0818 13:44:37.370312 22726 net.cpp:226] batchNorm_resblk64_7 needs backward computation.
I0818 13:44:37.370317 22726 net.cpp:226] resblk64_7 needs backward computation.
I0818 13:44:37.370322 22726 net.cpp:226] sum_bn_resblk64_6_b_relu_sum_bn_resblk64_6_b_0_split needs backward computation.
I0818 13:44:37.370328 22726 net.cpp:226] relu_sum_bn_resblk64_6_b needs backward computation.
I0818 13:44:37.370332 22726 net.cpp:226] sum_sum_bn_resblk64_5_b needs backward computation.
I0818 13:44:37.370338 22726 net.cpp:226] scale_resblk64_6_b needs backward computation.
I0818 13:44:37.370343 22726 net.cpp:226] batchNorm_resblk64_6_b needs backward computation.
I0818 13:44:37.370348 22726 net.cpp:226] resblk64_6_b needs backward computation.
I0818 13:44:37.370353 22726 net.cpp:226] relu_bn_resblk64_6 needs backward computation.
I0818 13:44:37.370358 22726 net.cpp:226] scale_resblk64_6 needs backward computation.
I0818 13:44:37.370362 22726 net.cpp:226] batchNorm_resblk64_6 needs backward computation.
I0818 13:44:37.370368 22726 net.cpp:226] resblk64_6 needs backward computation.
I0818 13:44:37.370373 22726 net.cpp:226] sum_bn_resblk64_5_b_relu_sum_bn_resblk64_5_b_0_split needs backward computation.
I0818 13:44:37.370378 22726 net.cpp:226] relu_sum_bn_resblk64_5_b needs backward computation.
I0818 13:44:37.370383 22726 net.cpp:226] sum_sum_bn_resblk64_4_b needs backward computation.
I0818 13:44:37.370389 22726 net.cpp:226] scale_resblk64_5_b needs backward computation.
I0818 13:44:37.370394 22726 net.cpp:226] batchNorm_resblk64_5_b needs backward computation.
I0818 13:44:37.370399 22726 net.cpp:226] resblk64_5_b needs backward computation.
I0818 13:44:37.370404 22726 net.cpp:226] relu_bn_resblk64_5 needs backward computation.
I0818 13:44:37.370409 22726 net.cpp:226] scale_resblk64_5 needs backward computation.
I0818 13:44:37.370414 22726 net.cpp:226] batchNorm_resblk64_5 needs backward computation.
I0818 13:44:37.370419 22726 net.cpp:226] resblk64_5 needs backward computation.
I0818 13:44:37.370424 22726 net.cpp:226] sum_bn_resblk64_4_b_relu_sum_bn_resblk64_4_b_0_split needs backward computation.
I0818 13:44:37.370429 22726 net.cpp:226] relu_sum_bn_resblk64_4_b needs backward computation.
I0818 13:44:37.370438 22726 net.cpp:226] sum_sum_bn_resblk64_3_b needs backward computation.
I0818 13:44:37.370445 22726 net.cpp:226] scale_resblk64_4_b needs backward computation.
I0818 13:44:37.370450 22726 net.cpp:226] batchNorm_resblk64_4_b needs backward computation.
I0818 13:44:37.370455 22726 net.cpp:226] resblk64_4_b needs backward computation.
I0818 13:44:37.370460 22726 net.cpp:226] relu_bn_resblk64_4 needs backward computation.
I0818 13:44:37.370465 22726 net.cpp:226] scale_resblk64_4 needs backward computation.
I0818 13:44:37.370471 22726 net.cpp:226] batchNorm_resblk64_4 needs backward computation.
I0818 13:44:37.370476 22726 net.cpp:226] resblk64_4 needs backward computation.
I0818 13:44:37.370481 22726 net.cpp:226] sum_bn_resblk64_3_b_relu_sum_bn_resblk64_3_b_0_split needs backward computation.
I0818 13:44:37.370486 22726 net.cpp:226] relu_sum_bn_resblk64_3_b needs backward computation.
I0818 13:44:37.370491 22726 net.cpp:226] sum_sum_bn_resblk64_2_b needs backward computation.
I0818 13:44:37.370497 22726 net.cpp:226] scale_resblk64_3_b needs backward computation.
I0818 13:44:37.370502 22726 net.cpp:226] batchNorm_resblk64_3_b needs backward computation.
I0818 13:44:37.370507 22726 net.cpp:226] resblk64_3_b needs backward computation.
I0818 13:44:37.370512 22726 net.cpp:226] relu_bn_resblk64_3 needs backward computation.
I0818 13:44:37.370517 22726 net.cpp:226] scale_resblk64_3 needs backward computation.
I0818 13:44:37.370522 22726 net.cpp:226] batchNorm_resblk64_3 needs backward computation.
I0818 13:44:37.370527 22726 net.cpp:226] resblk64_3 needs backward computation.
I0818 13:44:37.370532 22726 net.cpp:226] sum_bn_resblk64_2_b_relu_sum_bn_resblk64_2_b_0_split needs backward computation.
I0818 13:44:37.370537 22726 net.cpp:226] relu_sum_bn_resblk64_2_b needs backward computation.
I0818 13:44:37.370543 22726 net.cpp:226] sum_sum_bn_resblk64_1_b needs backward computation.
I0818 13:44:37.370548 22726 net.cpp:226] scale_resblk64_2_b needs backward computation.
I0818 13:44:37.370553 22726 net.cpp:226] batchNorm_resblk64_2_b needs backward computation.
I0818 13:44:37.370558 22726 net.cpp:226] resblk64_2_b needs backward computation.
I0818 13:44:37.370563 22726 net.cpp:226] relu_bn_resblk64_2 needs backward computation.
I0818 13:44:37.370568 22726 net.cpp:226] scale_resblk64_2 needs backward computation.
I0818 13:44:37.370573 22726 net.cpp:226] batchNorm_resblk64_2 needs backward computation.
I0818 13:44:37.370579 22726 net.cpp:226] resblk64_2 needs backward computation.
I0818 13:44:37.370584 22726 net.cpp:226] sum_bn_resblk64_1_b_relu_sum_bn_resblk64_1_b_0_split needs backward computation.
I0818 13:44:37.370592 22726 net.cpp:226] relu_sum_bn_resblk64_1_b needs backward computation.
I0818 13:44:37.370597 22726 net.cpp:226] sum_CC_sum_bn_resblk64_b needs backward computation.
I0818 13:44:37.370604 22726 net.cpp:226] scale_resblk64_1_b needs backward computation.
I0818 13:44:37.370609 22726 net.cpp:226] batchNorm_resblk64_1_b needs backward computation.
I0818 13:44:37.370613 22726 net.cpp:226] resblk64_1_b needs backward computation.
I0818 13:44:37.370618 22726 net.cpp:226] relu_bn_resblk64_1 needs backward computation.
I0818 13:44:37.370623 22726 net.cpp:226] scale_resblk64_1 needs backward computation.
I0818 13:44:37.370628 22726 net.cpp:226] batchNorm_resblk64_1 needs backward computation.
I0818 13:44:37.370633 22726 net.cpp:226] resblk64_1 needs backward computation.
I0818 13:44:37.370640 22726 net.cpp:226] CC_sum_bn_resblk64_b_CC_sum_bn_resblk64_b_0_split needs backward computation.
I0818 13:44:37.370645 22726 net.cpp:226] CC_sum_bn_resblk64_b needs backward computation.
I0818 13:44:37.370651 22726 net.cpp:228] zeros_sum_bn_resblk64_b does not need backward computation.
I0818 13:44:37.370656 22726 net.cpp:226] relu_sum_bn_resblk64_b needs backward computation.
I0818 13:44:37.370661 22726 net.cpp:226] sum_avgPool_resblk64 needs backward computation.
I0818 13:44:37.370666 22726 net.cpp:226] avePooling_resblk64 needs backward computation.
I0818 13:44:37.370672 22726 net.cpp:226] scale_resblk64_b needs backward computation.
I0818 13:44:37.370682 22726 net.cpp:226] batchNorm_resblk64_b needs backward computation.
I0818 13:44:37.370687 22726 net.cpp:226] resblk64_b needs backward computation.
I0818 13:44:37.370693 22726 net.cpp:226] relu_bn_resblk64 needs backward computation.
I0818 13:44:37.370698 22726 net.cpp:226] scale_resblk64 needs backward computation.
I0818 13:44:37.370702 22726 net.cpp:226] batchNorm_resblk64 needs backward computation.
I0818 13:44:37.370708 22726 net.cpp:226] resblk64 needs backward computation.
I0818 13:44:37.370713 22726 net.cpp:226] sum_bn_resblk32_8_b_relu_sum_bn_resblk32_8_b_0_split needs backward computation.
I0818 13:44:37.370719 22726 net.cpp:226] relu_sum_bn_resblk32_8_b needs backward computation.
I0818 13:44:37.370724 22726 net.cpp:226] sum_sum_bn_resblk32_7_b needs backward computation.
I0818 13:44:37.370730 22726 net.cpp:226] scale_resblk32_8_b needs backward computation.
I0818 13:44:37.370735 22726 net.cpp:226] batchNorm_resblk32_8_b needs backward computation.
I0818 13:44:37.370740 22726 net.cpp:226] resblk32_8_b needs backward computation.
I0818 13:44:37.370746 22726 net.cpp:226] relu_bn_resblk32_8 needs backward computation.
I0818 13:44:37.370750 22726 net.cpp:226] scale_resblk32_8 needs backward computation.
I0818 13:44:37.370755 22726 net.cpp:226] batchNorm_resblk32_8 needs backward computation.
I0818 13:44:37.370761 22726 net.cpp:226] resblk32_8 needs backward computation.
I0818 13:44:37.370766 22726 net.cpp:226] sum_bn_resblk32_7_b_relu_sum_bn_resblk32_7_b_0_split needs backward computation.
I0818 13:44:37.370772 22726 net.cpp:226] relu_sum_bn_resblk32_7_b needs backward computation.
I0818 13:44:37.370777 22726 net.cpp:226] sum_sum_bn_resblk32_6_b needs backward computation.
I0818 13:44:37.370784 22726 net.cpp:226] scale_resblk32_7_b needs backward computation.
I0818 13:44:37.370789 22726 net.cpp:226] batchNorm_resblk32_7_b needs backward computation.
I0818 13:44:37.370795 22726 net.cpp:226] resblk32_7_b needs backward computation.
I0818 13:44:37.370800 22726 net.cpp:226] relu_bn_resblk32_7 needs backward computation.
I0818 13:44:37.370805 22726 net.cpp:226] scale_resblk32_7 needs backward computation.
I0818 13:44:37.370815 22726 net.cpp:226] batchNorm_resblk32_7 needs backward computation.
I0818 13:44:37.370821 22726 net.cpp:226] resblk32_7 needs backward computation.
I0818 13:44:37.370828 22726 net.cpp:226] sum_bn_resblk32_6_b_relu_sum_bn_resblk32_6_b_0_split needs backward computation.
I0818 13:44:37.370833 22726 net.cpp:226] relu_sum_bn_resblk32_6_b needs backward computation.
I0818 13:44:37.370839 22726 net.cpp:226] sum_sum_bn_resblk32_5_b needs backward computation.
I0818 13:44:37.370846 22726 net.cpp:226] scale_resblk32_6_b needs backward computation.
I0818 13:44:37.370851 22726 net.cpp:226] batchNorm_resblk32_6_b needs backward computation.
I0818 13:44:37.370856 22726 net.cpp:226] resblk32_6_b needs backward computation.
I0818 13:44:37.370862 22726 net.cpp:226] relu_bn_resblk32_6 needs backward computation.
I0818 13:44:37.370867 22726 net.cpp:226] scale_resblk32_6 needs backward computation.
I0818 13:44:37.370872 22726 net.cpp:226] batchNorm_resblk32_6 needs backward computation.
I0818 13:44:37.370877 22726 net.cpp:226] resblk32_6 needs backward computation.
I0818 13:44:37.370882 22726 net.cpp:226] sum_bn_resblk32_5_b_relu_sum_bn_resblk32_5_b_0_split needs backward computation.
I0818 13:44:37.370887 22726 net.cpp:226] relu_sum_bn_resblk32_5_b needs backward computation.
I0818 13:44:37.370893 22726 net.cpp:226] sum_sum_bn_resblk32_4_b needs backward computation.
I0818 13:44:37.370899 22726 net.cpp:226] scale_resblk32_5_b needs backward computation.
I0818 13:44:37.370904 22726 net.cpp:226] batchNorm_resblk32_5_b needs backward computation.
I0818 13:44:37.370910 22726 net.cpp:226] resblk32_5_b needs backward computation.
I0818 13:44:37.370915 22726 net.cpp:226] relu_bn_resblk32_5 needs backward computation.
I0818 13:44:37.370920 22726 net.cpp:226] scale_resblk32_5 needs backward computation.
I0818 13:44:37.370925 22726 net.cpp:226] batchNorm_resblk32_5 needs backward computation.
I0818 13:44:37.370936 22726 net.cpp:226] resblk32_5 needs backward computation.
I0818 13:44:37.370942 22726 net.cpp:226] sum_bn_resblk32_4_b_relu_sum_bn_resblk32_4_b_0_split needs backward computation.
I0818 13:44:37.370949 22726 net.cpp:226] relu_sum_bn_resblk32_4_b needs backward computation.
I0818 13:44:37.370954 22726 net.cpp:226] sum_sum_bn_resblk32_3_b needs backward computation.
I0818 13:44:37.370965 22726 net.cpp:226] scale_resblk32_4_b needs backward computation.
I0818 13:44:37.370970 22726 net.cpp:226] batchNorm_resblk32_4_b needs backward computation.
I0818 13:44:37.370975 22726 net.cpp:226] resblk32_4_b needs backward computation.
I0818 13:44:37.370981 22726 net.cpp:226] relu_bn_resblk32_4 needs backward computation.
I0818 13:44:37.370986 22726 net.cpp:226] scale_resblk32_4 needs backward computation.
I0818 13:44:37.370991 22726 net.cpp:226] batchNorm_resblk32_4 needs backward computation.
I0818 13:44:37.370997 22726 net.cpp:226] resblk32_4 needs backward computation.
I0818 13:44:37.371002 22726 net.cpp:226] sum_bn_resblk32_3_b_relu_sum_bn_resblk32_3_b_0_split needs backward computation.
I0818 13:44:37.371008 22726 net.cpp:226] relu_sum_bn_resblk32_3_b needs backward computation.
I0818 13:44:37.371013 22726 net.cpp:226] sum_sum_bn_resblk32_2_b needs backward computation.
I0818 13:44:37.371019 22726 net.cpp:226] scale_resblk32_3_b needs backward computation.
I0818 13:44:37.371024 22726 net.cpp:226] batchNorm_resblk32_3_b needs backward computation.
I0818 13:44:37.371031 22726 net.cpp:226] resblk32_3_b needs backward computation.
I0818 13:44:37.371037 22726 net.cpp:226] relu_bn_resblk32_3 needs backward computation.
I0818 13:44:37.371042 22726 net.cpp:226] scale_resblk32_3 needs backward computation.
I0818 13:44:37.371047 22726 net.cpp:226] batchNorm_resblk32_3 needs backward computation.
I0818 13:44:37.371052 22726 net.cpp:226] resblk32_3 needs backward computation.
I0818 13:44:37.371058 22726 net.cpp:226] sum_bn_resblk32_2_b_relu_sum_bn_resblk32_2_b_0_split needs backward computation.
I0818 13:44:37.371063 22726 net.cpp:226] relu_sum_bn_resblk32_2_b needs backward computation.
I0818 13:44:37.371069 22726 net.cpp:226] sum_sum_bn_resblk32_1_b needs backward computation.
I0818 13:44:37.371075 22726 net.cpp:226] scale_resblk32_2_b needs backward computation.
I0818 13:44:37.371080 22726 net.cpp:226] batchNorm_resblk32_2_b needs backward computation.
I0818 13:44:37.371086 22726 net.cpp:226] resblk32_2_b needs backward computation.
I0818 13:44:37.371091 22726 net.cpp:226] relu_bn_resblk32_2 needs backward computation.
I0818 13:44:37.371098 22726 net.cpp:226] scale_resblk32_2 needs backward computation.
I0818 13:44:37.371103 22726 net.cpp:226] batchNorm_resblk32_2 needs backward computation.
I0818 13:44:37.371107 22726 net.cpp:226] resblk32_2 needs backward computation.
I0818 13:44:37.371114 22726 net.cpp:226] sum_bn_resblk32_1_b_relu_sum_bn_resblk32_1_b_0_split needs backward computation.
I0818 13:44:37.371119 22726 net.cpp:226] relu_sum_bn_resblk32_1_b needs backward computation.
I0818 13:44:37.371124 22726 net.cpp:226] sum_CC_sum_bn_resblk32_b needs backward computation.
I0818 13:44:37.371130 22726 net.cpp:226] scale_resblk32_1_b needs backward computation.
I0818 13:44:37.371135 22726 net.cpp:226] batchNorm_resblk32_1_b needs backward computation.
I0818 13:44:37.371141 22726 net.cpp:226] resblk32_1_b needs backward computation.
I0818 13:44:37.371146 22726 net.cpp:226] relu_bn_resblk32_1 needs backward computation.
I0818 13:44:37.371152 22726 net.cpp:226] scale_resblk32_1 needs backward computation.
I0818 13:44:37.371156 22726 net.cpp:226] batchNorm_resblk32_1 needs backward computation.
I0818 13:44:37.371162 22726 net.cpp:226] resblk32_1 needs backward computation.
I0818 13:44:37.371168 22726 net.cpp:226] CC_sum_bn_resblk32_b_CC_sum_bn_resblk32_b_0_split needs backward computation.
I0818 13:44:37.371173 22726 net.cpp:226] CC_sum_bn_resblk32_b needs backward computation.
I0818 13:44:37.371179 22726 net.cpp:228] zeros_sum_bn_resblk32_b does not need backward computation.
I0818 13:44:37.371189 22726 net.cpp:226] relu_sum_bn_resblk32_b needs backward computation.
I0818 13:44:37.371196 22726 net.cpp:226] sum_avgPool_resblk32 needs backward computation.
I0818 13:44:37.371201 22726 net.cpp:226] avePooling_resblk32 needs backward computation.
I0818 13:44:37.371207 22726 net.cpp:226] scale_resblk32_b needs backward computation.
I0818 13:44:37.371212 22726 net.cpp:226] batchNorm_resblk32_b needs backward computation.
I0818 13:44:37.371218 22726 net.cpp:226] resblk32_b needs backward computation.
I0818 13:44:37.371224 22726 net.cpp:226] relu_bn_resblk32 needs backward computation.
I0818 13:44:37.371229 22726 net.cpp:226] scale_resblk32 needs backward computation.
I0818 13:44:37.371234 22726 net.cpp:226] batchNorm_resblk32 needs backward computation.
I0818 13:44:37.371240 22726 net.cpp:226] resblk32 needs backward computation.
I0818 13:44:37.371246 22726 net.cpp:226] sum_bn_Conv16_9_b_relu_sum_bn_Conv16_9_b_0_split needs backward computation.
I0818 13:44:37.371253 22726 net.cpp:226] relu_sum_bn_Conv16_9_b needs backward computation.
I0818 13:44:37.371258 22726 net.cpp:226] sum_sum_bn_Conv16_8_b needs backward computation.
I0818 13:44:37.371264 22726 net.cpp:226] scale_Conv16_9_b needs backward computation.
I0818 13:44:37.371270 22726 net.cpp:226] batchNorm_Conv16_9_b needs backward computation.
I0818 13:44:37.371275 22726 net.cpp:226] Conv16_9_b needs backward computation.
I0818 13:44:37.371281 22726 net.cpp:226] relu_bn_Conv16_9 needs backward computation.
I0818 13:44:37.371286 22726 net.cpp:226] scale_Conv16_9 needs backward computation.
I0818 13:44:37.371291 22726 net.cpp:226] batchNorm_Conv16_9 needs backward computation.
I0818 13:44:37.371296 22726 net.cpp:226] Conv16_9 needs backward computation.
I0818 13:44:37.371304 22726 net.cpp:226] sum_bn_Conv16_8_b_relu_sum_bn_Conv16_8_b_0_split needs backward computation.
I0818 13:44:37.371309 22726 net.cpp:226] relu_sum_bn_Conv16_8_b needs backward computation.
I0818 13:44:37.371314 22726 net.cpp:226] sum_sum_bn_Conv16_7_b needs backward computation.
I0818 13:44:37.371320 22726 net.cpp:226] scale_Conv16_8_b needs backward computation.
I0818 13:44:37.371325 22726 net.cpp:226] batchNorm_Conv16_8_b needs backward computation.
I0818 13:44:37.371330 22726 net.cpp:226] Conv16_8_b needs backward computation.
I0818 13:44:37.371336 22726 net.cpp:226] relu_bn_Conv16_8 needs backward computation.
I0818 13:44:37.371341 22726 net.cpp:226] scale_Conv16_8 needs backward computation.
I0818 13:44:37.371346 22726 net.cpp:226] batchNorm_Conv16_8 needs backward computation.
I0818 13:44:37.371352 22726 net.cpp:226] Conv16_8 needs backward computation.
I0818 13:44:37.371358 22726 net.cpp:226] sum_bn_Conv16_7_b_relu_sum_bn_Conv16_7_b_0_split needs backward computation.
I0818 13:44:37.371363 22726 net.cpp:226] relu_sum_bn_Conv16_7_b needs backward computation.
I0818 13:44:37.371369 22726 net.cpp:226] sum_sum_bn_Conv16_6_b needs backward computation.
I0818 13:44:37.371376 22726 net.cpp:226] scale_Conv16_7_b needs backward computation.
I0818 13:44:37.371381 22726 net.cpp:226] batchNorm_Conv16_7_b needs backward computation.
I0818 13:44:37.371387 22726 net.cpp:226] Conv16_7_b needs backward computation.
I0818 13:44:37.371392 22726 net.cpp:226] relu_bn_Conv16_7 needs backward computation.
I0818 13:44:37.371397 22726 net.cpp:226] scale_Conv16_7 needs backward computation.
I0818 13:44:37.371402 22726 net.cpp:226] batchNorm_Conv16_7 needs backward computation.
I0818 13:44:37.371408 22726 net.cpp:226] Conv16_7 needs backward computation.
I0818 13:44:37.371413 22726 net.cpp:226] sum_bn_Conv16_6_b_relu_sum_bn_Conv16_6_b_0_split needs backward computation.
I0818 13:44:37.371419 22726 net.cpp:226] relu_sum_bn_Conv16_6_b needs backward computation.
I0818 13:44:37.371424 22726 net.cpp:226] sum_sum_bn_Conv16_5_b needs backward computation.
I0818 13:44:37.371430 22726 net.cpp:226] scale_Conv16_6_b needs backward computation.
I0818 13:44:37.371436 22726 net.cpp:226] batchNorm_Conv16_6_b needs backward computation.
I0818 13:44:37.371443 22726 net.cpp:226] Conv16_6_b needs backward computation.
I0818 13:44:37.371453 22726 net.cpp:226] relu_bn_Conv16_6 needs backward computation.
I0818 13:44:37.371459 22726 net.cpp:226] scale_Conv16_6 needs backward computation.
I0818 13:44:37.371464 22726 net.cpp:226] batchNorm_Conv16_6 needs backward computation.
I0818 13:44:37.371469 22726 net.cpp:226] Conv16_6 needs backward computation.
I0818 13:44:37.371475 22726 net.cpp:226] sum_bn_Conv16_5_b_relu_sum_bn_Conv16_5_b_0_split needs backward computation.
I0818 13:44:37.371480 22726 net.cpp:226] relu_sum_bn_Conv16_5_b needs backward computation.
I0818 13:44:37.371486 22726 net.cpp:226] sum_sum_bn_Conv16_4_b needs backward computation.
I0818 13:44:37.371492 22726 net.cpp:226] scale_Conv16_5_b needs backward computation.
I0818 13:44:37.371498 22726 net.cpp:226] batchNorm_Conv16_5_b needs backward computation.
I0818 13:44:37.371503 22726 net.cpp:226] Conv16_5_b needs backward computation.
I0818 13:44:37.371510 22726 net.cpp:226] relu_bn_Conv16_5 needs backward computation.
I0818 13:44:37.371515 22726 net.cpp:226] scale_Conv16_5 needs backward computation.
I0818 13:44:37.371520 22726 net.cpp:226] batchNorm_Conv16_5 needs backward computation.
I0818 13:44:37.371526 22726 net.cpp:226] Conv16_5 needs backward computation.
I0818 13:44:37.371531 22726 net.cpp:226] sum_bn_Conv16_4_b_relu_sum_bn_Conv16_4_b_0_split needs backward computation.
I0818 13:44:37.371537 22726 net.cpp:226] relu_sum_bn_Conv16_4_b needs backward computation.
I0818 13:44:37.371542 22726 net.cpp:226] sum_sum_bn_Conv16_3_b needs backward computation.
I0818 13:44:37.371549 22726 net.cpp:226] scale_Conv16_4_b needs backward computation.
I0818 13:44:37.371554 22726 net.cpp:226] batchNorm_Conv16_4_b needs backward computation.
I0818 13:44:37.371561 22726 net.cpp:226] Conv16_4_b needs backward computation.
I0818 13:44:37.371565 22726 net.cpp:226] relu_bn_Conv16_4 needs backward computation.
I0818 13:44:37.371572 22726 net.cpp:226] scale_Conv16_4 needs backward computation.
I0818 13:44:37.371577 22726 net.cpp:226] batchNorm_Conv16_4 needs backward computation.
I0818 13:44:37.371582 22726 net.cpp:226] Conv16_4 needs backward computation.
I0818 13:44:37.371587 22726 net.cpp:226] sum_bn_Conv16_3_b_relu_sum_bn_Conv16_3_b_0_split needs backward computation.
I0818 13:44:37.371593 22726 net.cpp:226] relu_sum_bn_Conv16_3_b needs backward computation.
I0818 13:44:37.371599 22726 net.cpp:226] sum_sum_bn_Conv16_2_b needs backward computation.
I0818 13:44:37.371605 22726 net.cpp:226] scale_Conv16_3_b needs backward computation.
I0818 13:44:37.371610 22726 net.cpp:226] batchNorm_Conv16_3_b needs backward computation.
I0818 13:44:37.371616 22726 net.cpp:226] Conv16_3_b needs backward computation.
I0818 13:44:37.371623 22726 net.cpp:226] relu_bn_Conv16_3 needs backward computation.
I0818 13:44:37.371628 22726 net.cpp:226] scale_Conv16_3 needs backward computation.
I0818 13:44:37.371632 22726 net.cpp:226] batchNorm_Conv16_3 needs backward computation.
I0818 13:44:37.371639 22726 net.cpp:226] Conv16_3 needs backward computation.
I0818 13:44:37.371647 22726 net.cpp:226] sum_bn_Conv16_2_b_relu_sum_bn_Conv16_2_b_0_split needs backward computation.
I0818 13:44:37.371654 22726 net.cpp:226] relu_sum_bn_Conv16_2_b needs backward computation.
I0818 13:44:37.371659 22726 net.cpp:226] sum_sum_bn_Conv16_1_b needs backward computation.
I0818 13:44:37.371666 22726 net.cpp:226] scale_Conv16_2_b needs backward computation.
I0818 13:44:37.371671 22726 net.cpp:226] batchNorm_Conv16_2_b needs backward computation.
I0818 13:44:37.371677 22726 net.cpp:226] Conv16_2_b needs backward computation.
I0818 13:44:37.371682 22726 net.cpp:226] relu_bn_Conv16_2 needs backward computation.
I0818 13:44:37.371688 22726 net.cpp:226] scale_Conv16_2 needs backward computation.
I0818 13:44:37.371693 22726 net.cpp:226] batchNorm_Conv16_2 needs backward computation.
I0818 13:44:37.371700 22726 net.cpp:226] Conv16_2 needs backward computation.
I0818 13:44:37.371706 22726 net.cpp:226] sum_bn_Conv16_1_b_relu_sum_bn_Conv16_1_b_0_split needs backward computation.
I0818 13:44:37.371711 22726 net.cpp:226] relu_sum_bn_Conv16_1_b needs backward computation.
I0818 13:44:37.371722 22726 net.cpp:226] sum_bn_conv needs backward computation.
I0818 13:44:37.371729 22726 net.cpp:226] scale_Conv16_1_b needs backward computation.
I0818 13:44:37.371736 22726 net.cpp:226] batchNorm_Conv16_1_b needs backward computation.
I0818 13:44:37.371742 22726 net.cpp:226] Conv16_1_b needs backward computation.
I0818 13:44:37.371747 22726 net.cpp:226] relu_bn_Conv16_1 needs backward computation.
I0818 13:44:37.371752 22726 net.cpp:226] scale_Conv16_1 needs backward computation.
I0818 13:44:37.371757 22726 net.cpp:226] batchNorm_Conv16_1 needs backward computation.
I0818 13:44:37.371763 22726 net.cpp:226] Conv16_1 needs backward computation.
I0818 13:44:37.371768 22726 net.cpp:226] bn_conv_relu_bn_conv_0_split needs backward computation.
I0818 13:44:37.371774 22726 net.cpp:226] relu_bn_conv needs backward computation.
I0818 13:44:37.371779 22726 net.cpp:226] scale_conv needs backward computation.
I0818 13:44:37.371784 22726 net.cpp:226] batchNorm_conv needs backward computation.
I0818 13:44:37.371790 22726 net.cpp:226] conv needs backward computation.
I0818 13:44:37.371798 22726 net.cpp:228] label_dataLayer_1_split does not need backward computation.
I0818 13:44:37.371803 22726 net.cpp:228] dataLayer does not need backward computation.
I0818 13:44:37.371812 22726 net.cpp:270] This network produces output accuracy
I0818 13:44:37.371819 22726 net.cpp:270] This network produces output loss
I0818 13:44:37.372169 22726 net.cpp:283] Network initialization done.
I0818 13:44:37.372987 22726 solver.cpp:60] Solver scaffolding done.
I0818 13:44:37.597445 22726 parallel.cpp:392] GPUs pairs 0:1, 2:3, 4:5, 6:7, 0:2, 4:6, 0:4
I0818 13:44:37.952386 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:37.952440 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:37.959321 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:38.188859 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk32_b from root net
I0818 13:44:38.188949 22726 net.cpp:143] Created top blob 0 (shape: 125 16 16 16 (512000)) for shared layer zeros_sum_bn_resblk32_b
I0818 13:44:38.223711 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk64_b from root net
I0818 13:44:38.223793 22726 net.cpp:143] Created top blob 0 (shape: 125 32 8 8 (256000)) for shared layer zeros_sum_bn_resblk64_b
I0818 13:44:38.667359 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:38.667433 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:38.675403 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:38.916868 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk32_b from root net
I0818 13:44:38.917009 22726 net.cpp:143] Created top blob 0 (shape: 125 16 16 16 (512000)) for shared layer zeros_sum_bn_resblk32_b
I0818 13:44:38.968875 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk64_b from root net
I0818 13:44:38.969010 22726 net.cpp:143] Created top blob 0 (shape: 125 32 8 8 (256000)) for shared layer zeros_sum_bn_resblk64_b
I0818 13:44:39.489924 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:39.489982 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:39.498920 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:39.764749 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk32_b from root net
I0818 13:44:39.764884 22726 net.cpp:143] Created top blob 0 (shape: 125 16 16 16 (512000)) for shared layer zeros_sum_bn_resblk32_b
I0818 13:44:39.836328 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk64_b from root net
I0818 13:44:39.836455 22726 net.cpp:143] Created top blob 0 (shape: 125 32 8 8 (256000)) for shared layer zeros_sum_bn_resblk64_b
I0818 13:44:39.921068 22726 parallel.cpp:234] GPU 4 does not have p2p access to GPU 0
I0818 13:44:40.400476 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:40.400547 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:40.410877 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:40.696154 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk32_b from root net
I0818 13:44:40.696352 22726 net.cpp:143] Created top blob 0 (shape: 125 16 16 16 (512000)) for shared layer zeros_sum_bn_resblk32_b
I0818 13:44:40.788728 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk64_b from root net
I0818 13:44:40.788910 22726 net.cpp:143] Created top blob 0 (shape: 125 32 8 8 (256000)) for shared layer zeros_sum_bn_resblk64_b
I0818 13:44:41.437413 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:41.437486 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:41.447942 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:41.768164 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk32_b from root net
I0818 13:44:41.768389 22726 net.cpp:143] Created top blob 0 (shape: 125 16 16 16 (512000)) for shared layer zeros_sum_bn_resblk32_b
I0818 13:44:41.881996 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk64_b from root net
I0818 13:44:41.882212 22726 net.cpp:143] Created top blob 0 (shape: 125 32 8 8 (256000)) for shared layer zeros_sum_bn_resblk64_b
I0818 13:44:42.598006 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:42.598074 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:42.609498 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:42.947286 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk32_b from root net
I0818 13:44:42.947540 22726 net.cpp:143] Created top blob 0 (shape: 125 16 16 16 (512000)) for shared layer zeros_sum_bn_resblk32_b
I0818 13:44:43.080673 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk64_b from root net
I0818 13:44:43.080914 22726 net.cpp:143] Created top blob 0 (shape: 125 32 8 8 (256000)) for shared layer zeros_sum_bn_resblk64_b
I0818 13:44:43.868228 22726 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/sc/architectures/arch.prototxt
I0818 13:44:43.868283 22726 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0818 13:44:43.880553 22726 data_layer.cpp:41] output data size: 125,3,32,32
I0818 13:44:43.929406 22753 blocking_queue.cpp:50] Waiting for data
I0818 13:44:43.986196 22753 blocking_queue.cpp:50] Waiting for data
I0818 13:44:44.326462 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk32_b from root net
I0818 13:44:44.326748 22726 net.cpp:143] Created top blob 0 (shape: 125 16 16 16 (512000)) for shared layer zeros_sum_bn_resblk32_b
I0818 13:44:44.479307 22726 net.cpp:93] Sharing layer zeros_sum_bn_resblk64_b from root net
I0818 13:44:44.479574 22726 net.cpp:143] Created top blob 0 (shape: 125 32 8 8 (256000)) for shared layer zeros_sum_bn_resblk64_b
I0818 13:44:44.652153 22726 parallel.cpp:425] Starting Optimization
I0818 13:44:44.654618 22726 solver.cpp:279] Solving Cifar-Resnet
I0818 13:44:44.654635 22726 solver.cpp:280] Learning Rate Policy: triangular
I0818 13:44:44.659473 22726 solver.cpp:337] Iteration 0, Testing net (#0)
I0818 13:46:08.790943 22726 solver.cpp:404]     Test net output #0: accuracy = 0.0998
I0818 13:46:08.791191 22726 solver.cpp:404]     Test net output #1: loss = 4.96549 (* 1 = 4.96549 loss)
I0818 13:46:12.731458 22726 solver.cpp:228] Iteration 0, loss = 5.51851
I0818 13:46:12.731499 22726 solver.cpp:244]     Train net output #0: accuracy = 0.08
I0818 13:46:12.731516 22726 solver.cpp:244]     Train net output #1: loss = 5.51851 (* 1 = 5.51851 loss)
I0818 13:46:12.809986 22726 sgd_solver.cpp:166] Iteration 0, lr = 0
I0818 13:48:30.557323 22726 solver.cpp:337] Iteration 100, Testing net (#0)
I0818 13:49:55.096010 22726 solver.cpp:404]     Test net output #0: accuracy = 0.35028
I0818 13:49:55.096271 22726 solver.cpp:404]     Test net output #1: loss = 1.74396 (* 1 = 1.74396 loss)
I0818 13:49:56.424774 22726 solver.cpp:228] Iteration 100, loss = 1.65155
I0818 13:49:56.424825 22726 solver.cpp:244]     Train net output #0: accuracy = 0.384
I0818 13:49:56.424844 22726 solver.cpp:244]     Train net output #1: loss = 1.65155 (* 1 = 1.65155 loss)
I0818 13:49:56.506356 22726 sgd_solver.cpp:166] Iteration 100, lr = 0.00250006
I0818 13:52:14.061103 22726 solver.cpp:337] Iteration 200, Testing net (#0)
I0818 13:53:38.577736 22726 solver.cpp:404]     Test net output #0: accuracy = 0.46284
I0818 13:53:38.578001 22726 solver.cpp:404]     Test net output #1: loss = 1.45916 (* 1 = 1.45916 loss)
I0818 13:53:39.906522 22726 solver.cpp:228] Iteration 200, loss = 1.40548
I0818 13:53:39.906558 22726 solver.cpp:244]     Train net output #0: accuracy = 0.48
I0818 13:53:39.906572 22726 solver.cpp:244]     Train net output #1: loss = 1.40548 (* 1 = 1.40548 loss)
I0818 13:53:39.994278 22726 sgd_solver.cpp:166] Iteration 200, lr = 0.005
I0818 13:55:57.496255 22726 solver.cpp:337] Iteration 300, Testing net (#0)
I0818 13:57:22.011245 22726 solver.cpp:404]     Test net output #0: accuracy = 0.52364
I0818 13:57:22.011498 22726 solver.cpp:404]     Test net output #1: loss = 1.29551 (* 1 = 1.29551 loss)
I0818 13:57:23.339665 22726 solver.cpp:228] Iteration 300, loss = 1.24159
I0818 13:57:23.339700 22726 solver.cpp:244]     Train net output #0: accuracy = 0.584
I0818 13:57:23.339716 22726 solver.cpp:244]     Train net output #1: loss = 1.24159 (* 1 = 1.24159 loss)
I0818 13:57:23.418503 22726 sgd_solver.cpp:166] Iteration 300, lr = 0.00750005
I0818 13:59:40.934136 22726 solver.cpp:337] Iteration 400, Testing net (#0)
I0818 14:01:05.444715 22726 solver.cpp:404]     Test net output #0: accuracy = 0.57968
I0818 14:01:05.444958 22726 solver.cpp:404]     Test net output #1: loss = 1.15349 (* 1 = 1.15349 loss)
I0818 14:01:06.773221 22726 solver.cpp:228] Iteration 400, loss = 1.07444
I0818 14:01:06.773255 22726 solver.cpp:244]     Train net output #0: accuracy = 0.632
I0818 14:01:06.773270 22726 solver.cpp:244]     Train net output #1: loss = 1.07444 (* 1 = 1.07444 loss)
I0818 14:01:06.850921 22726 sgd_solver.cpp:166] Iteration 400, lr = 0.00999999
I0818 14:03:24.392068 22726 solver.cpp:337] Iteration 500, Testing net (#0)
I0818 14:04:48.892432 22726 solver.cpp:404]     Test net output #0: accuracy = 0.63532
I0818 14:04:48.892688 22726 solver.cpp:404]     Test net output #1: loss = 1.01956 (* 1 = 1.01956 loss)
I0818 14:04:50.220181 22726 solver.cpp:228] Iteration 500, loss = 0.865725
I0818 14:04:50.220216 22726 solver.cpp:244]     Train net output #0: accuracy = 0.672
I0818 14:04:50.220232 22726 solver.cpp:244]     Train net output #1: loss = 0.865725 (* 1 = 0.865725 loss)
I0818 14:04:50.306844 22726 sgd_solver.cpp:166] Iteration 500, lr = 0.0125
I0818 14:07:07.860662 22726 solver.cpp:337] Iteration 600, Testing net (#0)
I0818 14:08:32.364720 22726 solver.cpp:404]     Test net output #0: accuracy = 0.6592
I0818 14:08:32.364969 22726 solver.cpp:404]     Test net output #1: loss = 0.95046 (* 1 = 0.95046 loss)
I0818 14:08:33.693845 22726 solver.cpp:228] Iteration 600, loss = 0.813147
I0818 14:08:33.693891 22726 solver.cpp:244]     Train net output #0: accuracy = 0.712
I0818 14:08:33.693907 22726 solver.cpp:244]     Train net output #1: loss = 0.813147 (* 1 = 0.813147 loss)
I0818 14:08:33.776310 22726 sgd_solver.cpp:166] Iteration 600, lr = 0.015
I0818 14:10:51.335870 22726 solver.cpp:337] Iteration 700, Testing net (#0)
I0818 14:12:15.841979 22726 solver.cpp:404]     Test net output #0: accuracy = 0.68156
I0818 14:12:15.842233 22726 solver.cpp:404]     Test net output #1: loss = 0.899195 (* 1 = 0.899195 loss)
I0818 14:12:17.170238 22726 solver.cpp:228] Iteration 700, loss = 0.841192
I0818 14:12:17.170279 22726 solver.cpp:244]     Train net output #0: accuracy = 0.728
I0818 14:12:17.170295 22726 solver.cpp:244]     Train net output #1: loss = 0.841192 (* 1 = 0.841192 loss)
I0818 14:12:17.251514 22726 sgd_solver.cpp:166] Iteration 700, lr = 0.0175
I0818 14:14:34.822834 22726 solver.cpp:337] Iteration 800, Testing net (#0)
I0818 14:15:59.330718 22726 solver.cpp:404]     Test net output #0: accuracy = 0.70076
I0818 14:15:59.330972 22726 solver.cpp:404]     Test net output #1: loss = 0.836304 (* 1 = 0.836304 loss)
I0818 14:16:00.659649 22726 solver.cpp:228] Iteration 800, loss = 0.707116
I0818 14:16:00.659683 22726 solver.cpp:244]     Train net output #0: accuracy = 0.752
I0818 14:16:00.659698 22726 solver.cpp:244]     Train net output #1: loss = 0.707116 (* 1 = 0.707116 loss)
I0818 14:16:00.748286 22726 sgd_solver.cpp:166] Iteration 800, lr = 0.02
I0818 14:18:18.383612 22726 solver.cpp:337] Iteration 900, Testing net (#0)
I0818 14:19:42.894716 22726 solver.cpp:404]     Test net output #0: accuracy = 0.72892
I0818 14:19:42.894973 22726 solver.cpp:404]     Test net output #1: loss = 0.785649 (* 1 = 0.785649 loss)
I0818 14:19:44.223569 22726 solver.cpp:228] Iteration 900, loss = 0.623757
I0818 14:19:44.223613 22726 solver.cpp:244]     Train net output #0: accuracy = 0.744
I0818 14:19:44.223628 22726 solver.cpp:244]     Train net output #1: loss = 0.623757 (* 1 = 0.623757 loss)
I0818 14:19:44.303577 22726 sgd_solver.cpp:166] Iteration 900, lr = 0.0225
I0818 14:22:01.940580 22726 solver.cpp:337] Iteration 1000, Testing net (#0)
I0818 14:23:26.450624 22726 solver.cpp:404]     Test net output #0: accuracy = 0.74656
I0818 14:23:26.450886 22726 solver.cpp:404]     Test net output #1: loss = 0.745317 (* 1 = 0.745317 loss)
I0818 14:23:27.782691 22726 solver.cpp:228] Iteration 1000, loss = 0.575806
I0818 14:23:27.782722 22726 solver.cpp:244]     Train net output #0: accuracy = 0.792
I0818 14:23:27.782737 22726 solver.cpp:244]     Train net output #1: loss = 0.575806 (* 1 = 0.575806 loss)
I0818 14:23:27.865317 22726 sgd_solver.cpp:166] Iteration 1000, lr = 0.025
I0818 14:25:45.634035 22726 solver.cpp:337] Iteration 1100, Testing net (#0)
I0818 14:27:10.142861 22726 solver.cpp:404]     Test net output #0: accuracy = 0.7494
I0818 14:27:10.143120 22726 solver.cpp:404]     Test net output #1: loss = 0.73552 (* 1 = 0.73552 loss)
I0818 14:27:11.475072 22726 solver.cpp:228] Iteration 1100, loss = 0.532521
I0818 14:27:11.475116 22726 solver.cpp:244]     Train net output #0: accuracy = 0.824
I0818 14:27:11.475131 22726 solver.cpp:244]     Train net output #1: loss = 0.532521 (* 1 = 0.532521 loss)
I0818 14:27:11.549281 22726 sgd_solver.cpp:166] Iteration 1100, lr = 0.0275
I0818 14:29:29.486335 22726 solver.cpp:337] Iteration 1200, Testing net (#0)
I0818 14:30:53.987459 22726 solver.cpp:404]     Test net output #0: accuracy = 0.75732
I0818 14:30:53.987712 22726 solver.cpp:404]     Test net output #1: loss = 0.729956 (* 1 = 0.729956 loss)
I0818 14:30:55.319921 22726 solver.cpp:228] Iteration 1200, loss = 0.465514
I0818 14:30:55.319953 22726 solver.cpp:244]     Train net output #0: accuracy = 0.816
I0818 14:30:55.319968 22726 solver.cpp:244]     Train net output #1: loss = 0.465514 (* 1 = 0.465514 loss)
I0818 14:30:55.401332 22726 sgd_solver.cpp:166] Iteration 1200, lr = 0.03
I0818 14:33:13.299944 22726 solver.cpp:337] Iteration 1300, Testing net (#0)
I0818 14:34:37.812235 22726 solver.cpp:404]     Test net output #0: accuracy = 0.76512
I0818 14:34:37.812495 22726 solver.cpp:404]     Test net output #1: loss = 0.713318 (* 1 = 0.713318 loss)
I0818 14:34:39.144080 22726 solver.cpp:228] Iteration 1300, loss = 0.456116
I0818 14:34:39.144114 22726 solver.cpp:244]     Train net output #0: accuracy = 0.856
I0818 14:34:39.144127 22726 solver.cpp:244]     Train net output #1: loss = 0.456116 (* 1 = 0.456116 loss)
I0818 14:34:39.223194 22726 sgd_solver.cpp:166] Iteration 1300, lr = 0.0325
I0818 14:41:44.423815 22726 solver.cpp:337] Iteration 1400, Testing net (#0)
I0818 14:43:08.227960 22726 solver.cpp:404]     Test net output #0: accuracy = 0.77068
I0818 14:43:08.230291 22726 solver.cpp:404]     Test net output #1: loss = 0.702152 (* 1 = 0.702152 loss)
I0818 14:43:09.559574 22726 solver.cpp:228] Iteration 1400, loss = 0.43131
I0818 14:43:09.559607 22726 solver.cpp:244]     Train net output #0: accuracy = 0.888
I0818 14:43:09.559622 22726 solver.cpp:244]     Train net output #1: loss = 0.43131 (* 1 = 0.43131 loss)
I0818 14:43:09.639812 22726 sgd_solver.cpp:166] Iteration 1400, lr = 0.035
I0818 14:45:39.555318 22726 solver.cpp:337] Iteration 1500, Testing net (#0)
I0818 14:47:04.036499 22726 solver.cpp:404]     Test net output #0: accuracy = 0.78136
I0818 14:47:04.036821 22726 solver.cpp:404]     Test net output #1: loss = 0.683945 (* 1 = 0.683945 loss)
I0818 14:47:05.365108 22726 solver.cpp:228] Iteration 1500, loss = 0.433026
I0818 14:47:05.365149 22726 solver.cpp:244]     Train net output #0: accuracy = 0.8
I0818 14:47:05.365170 22726 solver.cpp:244]     Train net output #1: loss = 0.433026 (* 1 = 0.433026 loss)
I0818 14:47:05.447065 22726 sgd_solver.cpp:166] Iteration 1500, lr = 0.0375
I0818 14:49:22.993253 22726 solver.cpp:337] Iteration 1600, Testing net (#0)
I0818 14:50:47.473757 22726 solver.cpp:404]     Test net output #0: accuracy = 0.77032
I0818 14:50:47.474020 22726 solver.cpp:404]     Test net output #1: loss = 0.730083 (* 1 = 0.730083 loss)
I0818 14:50:48.802135 22726 solver.cpp:228] Iteration 1600, loss = 0.378678
I0818 14:50:48.802184 22726 solver.cpp:244]     Train net output #0: accuracy = 0.864
I0818 14:50:48.802199 22726 solver.cpp:244]     Train net output #1: loss = 0.378678 (* 1 = 0.378678 loss)
I0818 14:50:48.883519 22726 sgd_solver.cpp:166] Iteration 1600, lr = 0.04
I0818 14:53:06.436419 22726 solver.cpp:337] Iteration 1700, Testing net (#0)
I0818 14:54:30.907603 22726 solver.cpp:404]     Test net output #0: accuracy = 0.78112
I0818 14:54:30.907840 22726 solver.cpp:404]     Test net output #1: loss = 0.706602 (* 1 = 0.706602 loss)
I0818 14:54:32.235533 22726 solver.cpp:228] Iteration 1700, loss = 0.376541
I0818 14:54:32.235577 22726 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0818 14:54:32.235594 22726 solver.cpp:244]     Train net output #1: loss = 0.376541 (* 1 = 0.376541 loss)
I0818 14:54:32.316201 22726 sgd_solver.cpp:166] Iteration 1700, lr = 0.0425
I0818 14:56:49.862103 22726 solver.cpp:337] Iteration 1800, Testing net (#0)
I0818 14:58:14.331892 22726 solver.cpp:404]     Test net output #0: accuracy = 0.78912
I0818 14:58:14.332154 22726 solver.cpp:404]     Test net output #1: loss = 0.693799 (* 1 = 0.693799 loss)
I0818 14:58:15.659595 22726 solver.cpp:228] Iteration 1800, loss = 0.416455
I0818 14:58:15.659628 22726 solver.cpp:244]     Train net output #0: accuracy = 0.856
I0818 14:58:15.659644 22726 solver.cpp:244]     Train net output #1: loss = 0.416455 (* 1 = 0.416455 loss)
I0818 14:58:15.741722 22726 sgd_solver.cpp:166] Iteration 1800, lr = 0.045
I0818 15:00:33.271752 22726 solver.cpp:337] Iteration 1900, Testing net (#0)
I0818 15:01:57.744223 22726 solver.cpp:404]     Test net output #0: accuracy = 0.79168
I0818 15:01:57.744472 22726 solver.cpp:404]     Test net output #1: loss = 0.682016 (* 1 = 0.682016 loss)
I0818 15:01:59.071837 22726 solver.cpp:228] Iteration 1900, loss = 0.276872
I0818 15:01:59.071877 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0818 15:01:59.071892 22726 solver.cpp:244]     Train net output #1: loss = 0.276872 (* 1 = 0.276872 loss)
I0818 15:01:59.156028 22726 sgd_solver.cpp:166] Iteration 1900, lr = 0.0475
I0818 15:04:16.794026 22726 solver.cpp:337] Iteration 2000, Testing net (#0)
I0818 15:05:41.266757 22726 solver.cpp:404]     Test net output #0: accuracy = 0.7892
I0818 15:05:41.267026 22726 solver.cpp:404]     Test net output #1: loss = 0.715744 (* 1 = 0.715744 loss)
I0818 15:05:42.594614 22726 solver.cpp:228] Iteration 2000, loss = 0.327962
I0818 15:05:42.594647 22726 solver.cpp:244]     Train net output #0: accuracy = 0.896
I0818 15:05:42.594663 22726 solver.cpp:244]     Train net output #1: loss = 0.327962 (* 1 = 0.327962 loss)
I0818 15:05:42.682404 22726 sgd_solver.cpp:166] Iteration 2000, lr = 0.05
I0818 15:08:00.289165 22726 solver.cpp:337] Iteration 2100, Testing net (#0)
I0818 15:09:24.761693 22726 solver.cpp:404]     Test net output #0: accuracy = 0.787
I0818 15:09:24.761960 22726 solver.cpp:404]     Test net output #1: loss = 0.723028 (* 1 = 0.723028 loss)
I0818 15:09:26.089346 22726 solver.cpp:228] Iteration 2100, loss = 0.35675
I0818 15:09:26.089380 22726 solver.cpp:244]     Train net output #0: accuracy = 0.872
I0818 15:09:26.089395 22726 solver.cpp:244]     Train net output #1: loss = 0.35675 (* 1 = 0.35675 loss)
I0818 15:09:26.172641 22726 sgd_solver.cpp:166] Iteration 2100, lr = 0.0525
I0818 15:11:43.728991 22726 solver.cpp:337] Iteration 2200, Testing net (#0)
I0818 15:13:08.213763 22726 solver.cpp:404]     Test net output #0: accuracy = 0.79768
I0818 15:13:08.214032 22726 solver.cpp:404]     Test net output #1: loss = 0.683653 (* 1 = 0.683653 loss)
I0818 15:13:09.541682 22726 solver.cpp:228] Iteration 2200, loss = 0.295536
I0818 15:13:09.541716 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0818 15:13:09.541731 22726 solver.cpp:244]     Train net output #1: loss = 0.295536 (* 1 = 0.295536 loss)
I0818 15:13:09.622472 22726 sgd_solver.cpp:166] Iteration 2200, lr = 0.0549999
I0818 15:15:27.169965 22726 solver.cpp:337] Iteration 2300, Testing net (#0)
I0818 15:16:51.677114 22726 solver.cpp:404]     Test net output #0: accuracy = 0.78264
I0818 15:16:51.677373 22726 solver.cpp:404]     Test net output #1: loss = 0.775648 (* 1 = 0.775648 loss)
I0818 15:16:53.004616 22726 solver.cpp:228] Iteration 2300, loss = 0.37084
I0818 15:16:53.004649 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0818 15:16:53.004665 22726 solver.cpp:244]     Train net output #1: loss = 0.37084 (* 1 = 0.37084 loss)
I0818 15:16:53.084322 22726 sgd_solver.cpp:166] Iteration 2300, lr = 0.0575
I0818 15:19:10.738797 22726 solver.cpp:337] Iteration 2400, Testing net (#0)
I0818 15:20:35.247333 22726 solver.cpp:404]     Test net output #0: accuracy = 0.79708
I0818 15:20:35.247579 22726 solver.cpp:404]     Test net output #1: loss = 0.718263 (* 1 = 0.718263 loss)
I0818 15:20:36.575888 22726 solver.cpp:228] Iteration 2400, loss = 0.264313
I0818 15:20:36.575933 22726 solver.cpp:244]     Train net output #0: accuracy = 0.904
I0818 15:20:36.575949 22726 solver.cpp:244]     Train net output #1: loss = 0.264313 (* 1 = 0.264313 loss)
I0818 15:20:36.657171 22726 sgd_solver.cpp:166] Iteration 2400, lr = 0.0599999
I0818 15:22:54.269399 22726 solver.cpp:337] Iteration 2500, Testing net (#0)
I0818 15:24:18.770242 22726 solver.cpp:404]     Test net output #0: accuracy = 0.7992
I0818 15:24:18.770503 22726 solver.cpp:404]     Test net output #1: loss = 0.714189 (* 1 = 0.714189 loss)
I0818 15:24:20.098539 22726 solver.cpp:228] Iteration 2500, loss = 0.322719
I0818 15:24:20.098574 22726 solver.cpp:244]     Train net output #0: accuracy = 0.848
I0818 15:24:20.098588 22726 solver.cpp:244]     Train net output #1: loss = 0.322719 (* 1 = 0.322719 loss)
I0818 15:24:20.184275 22726 sgd_solver.cpp:166] Iteration 2500, lr = 0.0625
I0818 15:26:37.859017 22726 solver.cpp:337] Iteration 2600, Testing net (#0)
I0818 15:28:02.358302 22726 solver.cpp:404]     Test net output #0: accuracy = 0.79772
I0818 15:28:02.358549 22726 solver.cpp:404]     Test net output #1: loss = 0.721512 (* 1 = 0.721512 loss)
I0818 15:28:03.686050 22726 solver.cpp:228] Iteration 2600, loss = 0.251873
I0818 15:28:03.686086 22726 solver.cpp:244]     Train net output #0: accuracy = 0.888
I0818 15:28:03.686101 22726 solver.cpp:244]     Train net output #1: loss = 0.251873 (* 1 = 0.251873 loss)
I0818 15:28:03.776222 22726 sgd_solver.cpp:166] Iteration 2600, lr = 0.0650001
I0818 15:30:21.442044 22726 solver.cpp:337] Iteration 2700, Testing net (#0)
I0818 15:31:45.944401 22726 solver.cpp:404]     Test net output #0: accuracy = 0.80188
I0818 15:31:45.944651 22726 solver.cpp:404]     Test net output #1: loss = 0.727128 (* 1 = 0.727128 loss)
I0818 15:31:47.272006 22726 solver.cpp:228] Iteration 2700, loss = 0.247028
I0818 15:31:47.272050 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0818 15:31:47.272066 22726 solver.cpp:244]     Train net output #1: loss = 0.247029 (* 1 = 0.247029 loss)
I0818 15:31:47.359074 22726 sgd_solver.cpp:166] Iteration 2700, lr = 0.0675
I0818 15:34:04.976080 22726 solver.cpp:337] Iteration 2800, Testing net (#0)
I0818 15:35:29.469241 22726 solver.cpp:404]     Test net output #0: accuracy = 0.80948
I0818 15:35:29.469483 22726 solver.cpp:404]     Test net output #1: loss = 0.723757 (* 1 = 0.723757 loss)
I0818 15:35:30.796881 22726 solver.cpp:228] Iteration 2800, loss = 0.184658
I0818 15:35:30.796916 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0818 15:35:30.796931 22726 solver.cpp:244]     Train net output #1: loss = 0.184658 (* 1 = 0.184658 loss)
I0818 15:35:30.877235 22726 sgd_solver.cpp:166] Iteration 2800, lr = 0.0700001
I0818 15:37:48.553230 22726 solver.cpp:337] Iteration 2900, Testing net (#0)
I0818 15:39:13.051182 22726 solver.cpp:404]     Test net output #0: accuracy = 0.81116
I0818 15:39:13.051439 22726 solver.cpp:404]     Test net output #1: loss = 0.698704 (* 1 = 0.698704 loss)
I0818 15:39:14.378615 22726 solver.cpp:228] Iteration 2900, loss = 0.192543
I0818 15:39:14.378650 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0818 15:39:14.378664 22726 solver.cpp:244]     Train net output #1: loss = 0.192543 (* 1 = 0.192543 loss)
I0818 15:39:14.460185 22726 sgd_solver.cpp:166] Iteration 2900, lr = 0.0725
I0818 15:41:32.067927 22726 solver.cpp:337] Iteration 3000, Testing net (#0)
I0818 15:42:56.574775 22726 solver.cpp:404]     Test net output #0: accuracy = 0.81272
I0818 15:42:56.575050 22726 solver.cpp:404]     Test net output #1: loss = 0.732422 (* 1 = 0.732422 loss)
I0818 15:42:57.902175 22726 solver.cpp:228] Iteration 3000, loss = 0.140338
I0818 15:42:57.902217 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0818 15:42:57.902232 22726 solver.cpp:244]     Train net output #1: loss = 0.140338 (* 1 = 0.140338 loss)
I0818 15:42:57.988375 22726 sgd_solver.cpp:166] Iteration 3000, lr = 0.075
I0818 15:45:15.553076 22726 solver.cpp:337] Iteration 3100, Testing net (#0)
I0818 15:46:40.050143 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82
I0818 15:46:40.050390 22726 solver.cpp:404]     Test net output #1: loss = 0.679755 (* 1 = 0.679755 loss)
I0818 15:46:41.377849 22726 solver.cpp:228] Iteration 3100, loss = 0.135679
I0818 15:46:41.377882 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0818 15:46:41.377897 22726 solver.cpp:244]     Train net output #1: loss = 0.135679 (* 1 = 0.135679 loss)
I0818 15:46:41.464198 22726 sgd_solver.cpp:166] Iteration 3100, lr = 0.0775
I0818 15:48:58.949457 22726 solver.cpp:337] Iteration 3200, Testing net (#0)
I0818 15:50:23.455474 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82324
I0818 15:50:23.455737 22726 solver.cpp:404]     Test net output #1: loss = 0.700799 (* 1 = 0.700799 loss)
I0818 15:50:24.782732 22726 solver.cpp:228] Iteration 3200, loss = 0.135123
I0818 15:50:24.782773 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 15:50:24.782788 22726 solver.cpp:244]     Train net output #1: loss = 0.135124 (* 1 = 0.135124 loss)
I0818 15:50:24.866549 22726 sgd_solver.cpp:166] Iteration 3200, lr = 0.08
I0818 15:52:42.416275 22726 solver.cpp:337] Iteration 3300, Testing net (#0)
I0818 15:54:06.927924 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82192
I0818 15:54:06.928171 22726 solver.cpp:404]     Test net output #1: loss = 0.736382 (* 1 = 0.736382 loss)
I0818 15:54:08.255947 22726 solver.cpp:228] Iteration 3300, loss = 0.0893335
I0818 15:54:08.255981 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0818 15:54:08.255996 22726 solver.cpp:244]     Train net output #1: loss = 0.0893336 (* 1 = 0.0893336 loss)
I0818 15:54:08.340454 22726 sgd_solver.cpp:166] Iteration 3300, lr = 0.0825
I0818 15:56:25.887794 22726 solver.cpp:337] Iteration 3400, Testing net (#0)
I0818 15:57:50.395982 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82028
I0818 15:57:50.396242 22726 solver.cpp:404]     Test net output #1: loss = 0.747995 (* 1 = 0.747995 loss)
I0818 15:57:51.724390 22726 solver.cpp:228] Iteration 3400, loss = 0.110271
I0818 15:57:51.724426 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 15:57:51.724440 22726 solver.cpp:244]     Train net output #1: loss = 0.110271 (* 1 = 0.110271 loss)
I0818 15:57:51.804664 22726 sgd_solver.cpp:166] Iteration 3400, lr = 0.085
I0818 16:00:09.460642 22726 solver.cpp:337] Iteration 3500, Testing net (#0)
I0818 16:01:33.970741 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82096
I0818 16:01:33.971014 22726 solver.cpp:404]     Test net output #1: loss = 0.725386 (* 1 = 0.725386 loss)
I0818 16:01:35.298913 22726 solver.cpp:228] Iteration 3500, loss = 0.0538424
I0818 16:01:35.298950 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 16:01:35.298965 22726 solver.cpp:244]     Train net output #1: loss = 0.0538424 (* 1 = 0.0538424 loss)
I0818 16:01:35.378144 22726 sgd_solver.cpp:166] Iteration 3500, lr = 0.0875
I0818 16:03:52.936884 22726 solver.cpp:337] Iteration 3600, Testing net (#0)
I0818 16:05:17.440961 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82172
I0818 16:05:17.441205 22726 solver.cpp:404]     Test net output #1: loss = 0.730629 (* 1 = 0.730629 loss)
I0818 16:05:18.768350 22726 solver.cpp:228] Iteration 3600, loss = 0.0504085
I0818 16:05:18.768398 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 16:05:18.768414 22726 solver.cpp:244]     Train net output #1: loss = 0.0504086 (* 1 = 0.0504086 loss)
I0818 16:05:18.864267 22726 sgd_solver.cpp:166] Iteration 3600, lr = 0.09
I0818 16:07:36.205479 22726 solver.cpp:337] Iteration 3700, Testing net (#0)
I0818 16:09:00.707937 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82388
I0818 16:09:00.708200 22726 solver.cpp:404]     Test net output #1: loss = 0.725918 (* 1 = 0.725918 loss)
I0818 16:09:02.036036 22726 solver.cpp:228] Iteration 3700, loss = 0.162736
I0818 16:09:02.036070 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 16:09:02.036085 22726 solver.cpp:244]     Train net output #1: loss = 0.162736 (* 1 = 0.162736 loss)
I0818 16:09:02.121783 22726 sgd_solver.cpp:166] Iteration 3700, lr = 0.0925
I0818 16:11:19.414536 22726 solver.cpp:337] Iteration 3800, Testing net (#0)
I0818 16:12:43.922075 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82648
I0818 16:12:43.922343 22726 solver.cpp:404]     Test net output #1: loss = 0.744189 (* 1 = 0.744189 loss)
I0818 16:12:45.249701 22726 solver.cpp:228] Iteration 3800, loss = 0.132122
I0818 16:12:45.249737 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 16:12:45.249752 22726 solver.cpp:244]     Train net output #1: loss = 0.132122 (* 1 = 0.132122 loss)
I0818 16:12:45.326038 22726 sgd_solver.cpp:166] Iteration 3800, lr = 0.095
I0818 16:15:02.522843 22726 solver.cpp:337] Iteration 3900, Testing net (#0)
I0818 16:16:27.034060 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82136
I0818 16:16:27.034327 22726 solver.cpp:404]     Test net output #1: loss = 0.732456 (* 1 = 0.732456 loss)
I0818 16:16:28.362041 22726 solver.cpp:228] Iteration 3900, loss = 0.194469
I0818 16:16:28.362077 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0818 16:16:28.362092 22726 solver.cpp:244]     Train net output #1: loss = 0.194469 (* 1 = 0.194469 loss)
I0818 16:16:28.446336 22726 sgd_solver.cpp:166] Iteration 3900, lr = 0.0975
I0818 16:18:45.672639 22726 solver.cpp:337] Iteration 4000, Testing net (#0)
I0818 16:20:10.188191 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82296
I0818 16:20:10.188427 22726 solver.cpp:404]     Test net output #1: loss = 0.735436 (* 1 = 0.735436 loss)
I0818 16:20:11.515575 22726 solver.cpp:228] Iteration 4000, loss = 0.123937
I0818 16:20:11.515611 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 16:20:11.515627 22726 solver.cpp:244]     Train net output #1: loss = 0.123937 (* 1 = 0.123937 loss)
I0818 16:20:11.599563 22726 sgd_solver.cpp:166] Iteration 4000, lr = 0.1
I0818 16:22:28.953392 22726 solver.cpp:337] Iteration 4100, Testing net (#0)
I0818 16:23:53.461030 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83048
I0818 16:23:53.461282 22726 solver.cpp:404]     Test net output #1: loss = 0.732219 (* 1 = 0.732219 loss)
I0818 16:23:54.788532 22726 solver.cpp:228] Iteration 4100, loss = 0.128594
I0818 16:23:54.788568 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0818 16:23:54.788583 22726 solver.cpp:244]     Train net output #1: loss = 0.128594 (* 1 = 0.128594 loss)
I0818 16:23:54.871919 22726 sgd_solver.cpp:166] Iteration 4100, lr = 0.1025
I0818 16:26:12.282579 22726 solver.cpp:337] Iteration 4200, Testing net (#0)
I0818 16:27:36.780169 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83008
I0818 16:27:36.780434 22726 solver.cpp:404]     Test net output #1: loss = 0.744088 (* 1 = 0.744088 loss)
I0818 16:27:38.107213 22726 solver.cpp:228] Iteration 4200, loss = 0.0464251
I0818 16:27:38.107246 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 16:27:38.107261 22726 solver.cpp:244]     Train net output #1: loss = 0.0464251 (* 1 = 0.0464251 loss)
I0818 16:27:38.190012 22726 sgd_solver.cpp:166] Iteration 4200, lr = 0.105
I0818 16:29:55.426722 22726 solver.cpp:337] Iteration 4300, Testing net (#0)
I0818 16:31:19.936530 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83168
I0818 16:31:19.936775 22726 solver.cpp:404]     Test net output #1: loss = 0.71768 (* 1 = 0.71768 loss)
I0818 16:31:21.264497 22726 solver.cpp:228] Iteration 4300, loss = 0.081548
I0818 16:31:21.264539 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 16:31:21.264564 22726 solver.cpp:244]     Train net output #1: loss = 0.0815481 (* 1 = 0.0815481 loss)
I0818 16:31:21.354318 22726 sgd_solver.cpp:166] Iteration 4300, lr = 0.1075
I0818 16:33:38.618350 22726 solver.cpp:337] Iteration 4400, Testing net (#0)
I0818 16:35:03.136111 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83176
I0818 16:35:03.136373 22726 solver.cpp:404]     Test net output #1: loss = 0.725194 (* 1 = 0.725194 loss)
I0818 16:35:04.464025 22726 solver.cpp:228] Iteration 4400, loss = 0.0925924
I0818 16:35:04.464061 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 16:35:04.464076 22726 solver.cpp:244]     Train net output #1: loss = 0.0925924 (* 1 = 0.0925924 loss)
I0818 16:35:04.543695 22726 sgd_solver.cpp:166] Iteration 4400, lr = 0.11
I0818 16:37:21.827334 22726 solver.cpp:337] Iteration 4500, Testing net (#0)
I0818 16:38:46.330525 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83344
I0818 16:38:46.330785 22726 solver.cpp:404]     Test net output #1: loss = 0.728585 (* 1 = 0.728585 loss)
I0818 16:38:47.657896 22726 solver.cpp:228] Iteration 4500, loss = 0.101803
I0818 16:38:47.657932 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 16:38:47.657948 22726 solver.cpp:244]     Train net output #1: loss = 0.101803 (* 1 = 0.101803 loss)
I0818 16:38:47.738497 22726 sgd_solver.cpp:166] Iteration 4500, lr = 0.1125
I0818 16:41:05.002769 22726 solver.cpp:337] Iteration 4600, Testing net (#0)
I0818 16:42:29.505033 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83544
I0818 16:42:29.505300 22726 solver.cpp:404]     Test net output #1: loss = 0.730989 (* 1 = 0.730989 loss)
I0818 16:42:30.832492 22726 solver.cpp:228] Iteration 4600, loss = 0.0661556
I0818 16:42:30.832525 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 16:42:30.832540 22726 solver.cpp:244]     Train net output #1: loss = 0.0661557 (* 1 = 0.0661557 loss)
I0818 16:42:30.917814 22726 sgd_solver.cpp:166] Iteration 4600, lr = 0.115
I0818 16:44:48.153477 22726 solver.cpp:337] Iteration 4700, Testing net (#0)
I0818 16:46:12.650143 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82848
I0818 16:46:12.650420 22726 solver.cpp:404]     Test net output #1: loss = 0.744325 (* 1 = 0.744325 loss)
I0818 16:46:13.977531 22726 solver.cpp:228] Iteration 4700, loss = 0.0388921
I0818 16:46:13.977563 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 16:46:13.977578 22726 solver.cpp:244]     Train net output #1: loss = 0.0388922 (* 1 = 0.0388922 loss)
I0818 16:46:14.058544 22726 sgd_solver.cpp:166] Iteration 4700, lr = 0.1175
I0818 16:48:31.347892 22726 solver.cpp:337] Iteration 4800, Testing net (#0)
I0818 16:49:55.855008 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83344
I0818 16:49:55.855276 22726 solver.cpp:404]     Test net output #1: loss = 0.74917 (* 1 = 0.74917 loss)
I0818 16:49:57.183059 22726 solver.cpp:228] Iteration 4800, loss = 0.0934206
I0818 16:49:57.183091 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0818 16:49:57.183106 22726 solver.cpp:244]     Train net output #1: loss = 0.0934207 (* 1 = 0.0934207 loss)
I0818 16:49:57.268280 22726 sgd_solver.cpp:166] Iteration 4800, lr = 0.12
I0818 16:52:14.547785 22726 solver.cpp:337] Iteration 4900, Testing net (#0)
I0818 16:53:39.049548 22726 solver.cpp:404]     Test net output #0: accuracy = 0.82584
I0818 16:53:39.049814 22726 solver.cpp:404]     Test net output #1: loss = 0.774598 (* 1 = 0.774598 loss)
I0818 16:53:40.377630 22726 solver.cpp:228] Iteration 4900, loss = 0.0251254
I0818 16:53:40.377662 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 16:53:40.377677 22726 solver.cpp:244]     Train net output #1: loss = 0.0251255 (* 1 = 0.0251255 loss)
I0818 16:53:40.454710 22726 sgd_solver.cpp:166] Iteration 4900, lr = 0.1225
I0818 16:55:57.683336 22726 solver.cpp:337] Iteration 5000, Testing net (#0)
I0818 16:57:22.178345 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83304
I0818 16:57:22.178586 22726 solver.cpp:404]     Test net output #1: loss = 0.747655 (* 1 = 0.747655 loss)
I0818 16:57:23.505553 22726 solver.cpp:228] Iteration 5000, loss = 0.126295
I0818 16:57:23.505585 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 16:57:23.505600 22726 solver.cpp:244]     Train net output #1: loss = 0.126295 (* 1 = 0.126295 loss)
I0818 16:57:23.588685 22726 sgd_solver.cpp:166] Iteration 5000, lr = 0.125
I0818 16:59:40.809481 22726 solver.cpp:337] Iteration 5100, Testing net (#0)
I0818 17:01:05.279641 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8236
I0818 17:01:05.279896 22726 solver.cpp:404]     Test net output #1: loss = 0.743301 (* 1 = 0.743301 loss)
I0818 17:01:06.607203 22726 solver.cpp:228] Iteration 5100, loss = 0.043186
I0818 17:01:06.607235 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 17:01:06.607250 22726 solver.cpp:244]     Train net output #1: loss = 0.0431861 (* 1 = 0.0431861 loss)
I0818 17:01:06.692243 22726 sgd_solver.cpp:166] Iteration 5100, lr = 0.1275
I0818 17:03:23.971024 22726 solver.cpp:337] Iteration 5200, Testing net (#0)
I0818 17:04:48.446350 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83244
I0818 17:04:48.446604 22726 solver.cpp:404]     Test net output #1: loss = 0.760406 (* 1 = 0.760406 loss)
I0818 17:04:49.774183 22726 solver.cpp:228] Iteration 5200, loss = 0.110369
I0818 17:04:49.774215 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 17:04:49.774231 22726 solver.cpp:244]     Train net output #1: loss = 0.110369 (* 1 = 0.110369 loss)
I0818 17:04:49.856029 22726 sgd_solver.cpp:166] Iteration 5200, lr = 0.13
I0818 17:07:07.131268 22726 solver.cpp:337] Iteration 5300, Testing net (#0)
I0818 17:08:31.609187 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83704
I0818 17:08:31.609450 22726 solver.cpp:404]     Test net output #1: loss = 0.733375 (* 1 = 0.733375 loss)
I0818 17:08:32.937209 22726 solver.cpp:228] Iteration 5300, loss = 0.0696552
I0818 17:08:32.937243 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 17:08:32.937258 22726 solver.cpp:244]     Train net output #1: loss = 0.0696552 (* 1 = 0.0696552 loss)
I0818 17:08:33.018323 22726 sgd_solver.cpp:166] Iteration 5300, lr = 0.1325
I0818 17:10:50.281419 22726 solver.cpp:337] Iteration 5400, Testing net (#0)
I0818 17:12:14.767659 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83332
I0818 17:12:14.767932 22726 solver.cpp:404]     Test net output #1: loss = 0.769743 (* 1 = 0.769743 loss)
I0818 17:12:16.095551 22726 solver.cpp:228] Iteration 5400, loss = 0.0889991
I0818 17:12:16.095585 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 17:12:16.095600 22726 solver.cpp:244]     Train net output #1: loss = 0.0889992 (* 1 = 0.0889992 loss)
I0818 17:12:16.176405 22726 sgd_solver.cpp:166] Iteration 5400, lr = 0.135
I0818 17:14:33.402259 22726 solver.cpp:337] Iteration 5500, Testing net (#0)
I0818 17:15:57.889559 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83236
I0818 17:15:57.889808 22726 solver.cpp:404]     Test net output #1: loss = 0.752743 (* 1 = 0.752743 loss)
I0818 17:15:59.217170 22726 solver.cpp:228] Iteration 5500, loss = 0.0505173
I0818 17:15:59.217206 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 17:15:59.217221 22726 solver.cpp:244]     Train net output #1: loss = 0.0505173 (* 1 = 0.0505173 loss)
I0818 17:15:59.302292 22726 sgd_solver.cpp:166] Iteration 5500, lr = 0.1375
I0818 17:18:16.675343 22726 solver.cpp:337] Iteration 5600, Testing net (#0)
I0818 17:19:41.151553 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83608
I0818 17:19:41.151815 22726 solver.cpp:404]     Test net output #1: loss = 0.732527 (* 1 = 0.732527 loss)
I0818 17:19:42.479455 22726 solver.cpp:228] Iteration 5600, loss = 0.0518501
I0818 17:19:42.479511 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 17:19:42.479529 22726 solver.cpp:244]     Train net output #1: loss = 0.0518502 (* 1 = 0.0518502 loss)
I0818 17:19:42.565871 22726 sgd_solver.cpp:166] Iteration 5600, lr = 0.14
I0818 17:22:00.299021 22726 solver.cpp:337] Iteration 5700, Testing net (#0)
I0818 17:23:25.373019 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83708
I0818 17:23:25.373267 22726 solver.cpp:404]     Test net output #1: loss = 0.758962 (* 1 = 0.758962 loss)
I0818 17:23:26.705314 22726 solver.cpp:228] Iteration 5700, loss = 0.0605293
I0818 17:23:26.705371 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 17:23:26.705394 22726 solver.cpp:244]     Train net output #1: loss = 0.0605293 (* 1 = 0.0605293 loss)
I0818 17:23:26.779352 22726 sgd_solver.cpp:166] Iteration 5700, lr = 0.1425
I0818 17:25:44.714668 22726 solver.cpp:337] Iteration 5800, Testing net (#0)
I0818 17:27:09.884402 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83396
I0818 17:27:09.884615 22726 solver.cpp:404]     Test net output #1: loss = 0.76575 (* 1 = 0.76575 loss)
I0818 17:27:11.214926 22726 solver.cpp:228] Iteration 5800, loss = 0.075576
I0818 17:27:11.214977 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 17:27:11.214999 22726 solver.cpp:244]     Train net output #1: loss = 0.075576 (* 1 = 0.075576 loss)
I0818 17:27:11.296946 22726 sgd_solver.cpp:166] Iteration 5800, lr = 0.145
I0818 17:29:29.420439 22726 solver.cpp:337] Iteration 5900, Testing net (#0)
I0818 17:30:54.479041 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84304
I0818 17:30:54.479257 22726 solver.cpp:404]     Test net output #1: loss = 0.723728 (* 1 = 0.723728 loss)
I0818 17:30:55.810905 22726 solver.cpp:228] Iteration 5900, loss = 0.0438968
I0818 17:30:55.810956 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 17:30:55.810979 22726 solver.cpp:244]     Train net output #1: loss = 0.0438969 (* 1 = 0.0438969 loss)
I0818 17:30:55.892340 22726 sgd_solver.cpp:166] Iteration 5900, lr = 0.1475
I0818 17:33:14.045341 22726 solver.cpp:337] Iteration 6000, Testing net (#0)
I0818 17:34:39.064522 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8368
I0818 17:34:39.064776 22726 solver.cpp:404]     Test net output #1: loss = 0.759479 (* 1 = 0.759479 loss)
I0818 17:34:40.396309 22726 solver.cpp:228] Iteration 6000, loss = 0.0176671
I0818 17:34:40.396365 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0818 17:34:40.396381 22726 solver.cpp:244]     Train net output #1: loss = 0.0176671 (* 1 = 0.0176671 loss)
I0818 17:34:40.478618 22726 sgd_solver.cpp:166] Iteration 6000, lr = 0.15
I0818 17:36:58.632060 22726 solver.cpp:337] Iteration 6100, Testing net (#0)
I0818 17:38:23.549490 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83436
I0818 17:38:23.549731 22726 solver.cpp:404]     Test net output #1: loss = 0.769781 (* 1 = 0.769781 loss)
I0818 17:38:24.881227 22726 solver.cpp:228] Iteration 6100, loss = 0.0912595
I0818 17:38:24.881270 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 17:38:24.881290 22726 solver.cpp:244]     Train net output #1: loss = 0.0912595 (* 1 = 0.0912595 loss)
I0818 17:38:24.959374 22726 sgd_solver.cpp:166] Iteration 6100, lr = 0.1525
I0818 17:40:42.967525 22726 solver.cpp:337] Iteration 6200, Testing net (#0)
I0818 17:42:08.147724 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83616
I0818 17:42:08.147999 22726 solver.cpp:404]     Test net output #1: loss = 0.760957 (* 1 = 0.760957 loss)
I0818 17:42:09.479714 22726 solver.cpp:228] Iteration 6200, loss = 0.109271
I0818 17:42:09.479763 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 17:42:09.479785 22726 solver.cpp:244]     Train net output #1: loss = 0.109271 (* 1 = 0.109271 loss)
I0818 17:42:09.557953 22726 sgd_solver.cpp:166] Iteration 6200, lr = 0.155
I0818 17:44:27.556921 22726 solver.cpp:337] Iteration 6300, Testing net (#0)
I0818 17:45:52.728344 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84016
I0818 17:45:52.728598 22726 solver.cpp:404]     Test net output #1: loss = 0.708762 (* 1 = 0.708762 loss)
I0818 17:45:54.059062 22726 solver.cpp:228] Iteration 6300, loss = 0.0224413
I0818 17:45:54.059108 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 17:45:54.059130 22726 solver.cpp:244]     Train net output #1: loss = 0.0224414 (* 1 = 0.0224414 loss)
I0818 17:45:54.139698 22726 sgd_solver.cpp:166] Iteration 6300, lr = 0.1575
I0818 17:48:12.147606 22726 solver.cpp:337] Iteration 6400, Testing net (#0)
I0818 17:49:37.331274 22726 solver.cpp:404]     Test net output #0: accuracy = 0.846
I0818 17:49:37.331528 22726 solver.cpp:404]     Test net output #1: loss = 0.71715 (* 1 = 0.71715 loss)
I0818 17:49:38.663532 22726 solver.cpp:228] Iteration 6400, loss = 0.0496525
I0818 17:49:38.663578 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 17:49:38.663600 22726 solver.cpp:244]     Train net output #1: loss = 0.0496526 (* 1 = 0.0496526 loss)
I0818 17:49:38.743216 22726 sgd_solver.cpp:166] Iteration 6400, lr = 0.16
I0818 17:51:56.866817 22726 solver.cpp:337] Iteration 6500, Testing net (#0)
I0818 17:53:22.063324 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83532
I0818 17:53:22.063591 22726 solver.cpp:404]     Test net output #1: loss = 0.751844 (* 1 = 0.751844 loss)
I0818 17:53:23.393600 22726 solver.cpp:228] Iteration 6500, loss = 0.0879318
I0818 17:53:23.393647 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 17:53:23.393671 22726 solver.cpp:244]     Train net output #1: loss = 0.0879318 (* 1 = 0.0879318 loss)
I0818 17:53:23.480469 22726 sgd_solver.cpp:166] Iteration 6500, lr = 0.1625
I0818 17:55:41.580214 22726 solver.cpp:337] Iteration 6600, Testing net (#0)
I0818 17:57:06.704402 22726 solver.cpp:404]     Test net output #0: accuracy = 0.83992
I0818 17:57:06.704634 22726 solver.cpp:404]     Test net output #1: loss = 0.751893 (* 1 = 0.751893 loss)
I0818 17:57:08.036309 22726 solver.cpp:228] Iteration 6600, loss = 0.0814455
I0818 17:57:08.036355 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 17:57:08.036378 22726 solver.cpp:244]     Train net output #1: loss = 0.0814456 (* 1 = 0.0814456 loss)
I0818 17:57:08.118108 22726 sgd_solver.cpp:166] Iteration 6600, lr = 0.165
I0818 17:59:26.202986 22726 solver.cpp:337] Iteration 6700, Testing net (#0)
I0818 18:00:51.098157 22726 solver.cpp:404]     Test net output #0: accuracy = 0.840521
I0818 18:00:51.098384 22726 solver.cpp:404]     Test net output #1: loss = 0.727555 (* 1 = 0.727555 loss)
I0818 18:00:52.429585 22726 solver.cpp:228] Iteration 6700, loss = 0.0737519
I0818 18:00:52.429633 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 18:00:52.429656 22726 solver.cpp:244]     Train net output #1: loss = 0.073752 (* 1 = 0.073752 loss)
I0818 18:00:52.512773 22726 sgd_solver.cpp:166] Iteration 6700, lr = 0.1675
I0818 18:03:10.530063 22726 solver.cpp:337] Iteration 6800, Testing net (#0)
I0818 18:04:35.397002 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8496
I0818 18:04:35.397266 22726 solver.cpp:404]     Test net output #1: loss = 0.705462 (* 1 = 0.705462 loss)
I0818 18:04:36.728186 22726 solver.cpp:228] Iteration 6800, loss = 0.0617215
I0818 18:04:36.728233 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 18:04:36.728256 22726 solver.cpp:244]     Train net output #1: loss = 0.0617215 (* 1 = 0.0617215 loss)
I0818 18:04:36.810154 22726 sgd_solver.cpp:166] Iteration 6800, lr = 0.17
I0818 18:06:54.919566 22726 solver.cpp:337] Iteration 6900, Testing net (#0)
I0818 18:08:19.885370 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84612
I0818 18:08:19.885620 22726 solver.cpp:404]     Test net output #1: loss = 0.684281 (* 1 = 0.684281 loss)
I0818 18:08:21.216878 22726 solver.cpp:228] Iteration 6900, loss = 0.0217699
I0818 18:08:21.216924 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0818 18:08:21.216953 22726 solver.cpp:244]     Train net output #1: loss = 0.02177 (* 1 = 0.02177 loss)
I0818 18:08:21.294780 22726 sgd_solver.cpp:166] Iteration 6900, lr = 0.1725
I0818 18:10:39.356871 22726 solver.cpp:337] Iteration 7000, Testing net (#0)
I0818 18:12:04.506824 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84712
I0818 18:12:04.507103 22726 solver.cpp:404]     Test net output #1: loss = 0.709323 (* 1 = 0.709323 loss)
I0818 18:12:05.838762 22726 solver.cpp:228] Iteration 7000, loss = 0.0212007
I0818 18:12:05.838807 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 18:12:05.838830 22726 solver.cpp:244]     Train net output #1: loss = 0.0212008 (* 1 = 0.0212008 loss)
I0818 18:12:05.924917 22726 sgd_solver.cpp:166] Iteration 7000, lr = 0.175
I0818 18:14:24.006451 22726 solver.cpp:337] Iteration 7100, Testing net (#0)
I0818 18:15:49.154940 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84536
I0818 18:15:49.155161 22726 solver.cpp:404]     Test net output #1: loss = 0.706349 (* 1 = 0.706349 loss)
I0818 18:15:50.486261 22726 solver.cpp:228] Iteration 7100, loss = 0.0331489
I0818 18:15:50.486306 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 18:15:50.486322 22726 solver.cpp:244]     Train net output #1: loss = 0.033149 (* 1 = 0.033149 loss)
I0818 18:15:50.569794 22726 sgd_solver.cpp:166] Iteration 7100, lr = 0.1775
I0818 18:18:08.698842 22726 solver.cpp:337] Iteration 7200, Testing net (#0)
I0818 18:19:33.858561 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8432
I0818 18:19:33.858805 22726 solver.cpp:404]     Test net output #1: loss = 0.691206 (* 1 = 0.691206 loss)
I0818 18:19:35.189172 22726 solver.cpp:228] Iteration 7200, loss = 0.0592955
I0818 18:19:35.189218 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 18:19:35.189239 22726 solver.cpp:244]     Train net output #1: loss = 0.0592956 (* 1 = 0.0592956 loss)
I0818 18:19:35.270110 22726 sgd_solver.cpp:166] Iteration 7200, lr = 0.18
I0818 18:21:53.397348 22726 solver.cpp:337] Iteration 7300, Testing net (#0)
I0818 18:23:18.572837 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84456
I0818 18:23:18.573078 22726 solver.cpp:404]     Test net output #1: loss = 0.713217 (* 1 = 0.713217 loss)
I0818 18:23:19.904335 22726 solver.cpp:228] Iteration 7300, loss = 0.0245717
I0818 18:23:19.904382 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 18:23:19.904398 22726 solver.cpp:244]     Train net output #1: loss = 0.0245718 (* 1 = 0.0245718 loss)
I0818 18:23:19.986244 22726 sgd_solver.cpp:166] Iteration 7300, lr = 0.1825
I0818 18:25:38.040313 22726 solver.cpp:337] Iteration 7400, Testing net (#0)
I0818 18:27:03.226361 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84692
I0818 18:27:03.226609 22726 solver.cpp:404]     Test net output #1: loss = 0.702599 (* 1 = 0.702599 loss)
I0818 18:27:04.558135 22726 solver.cpp:228] Iteration 7400, loss = 0.072273
I0818 18:27:04.558178 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 18:27:04.558194 22726 solver.cpp:244]     Train net output #1: loss = 0.0722731 (* 1 = 0.0722731 loss)
I0818 18:27:04.637418 22726 sgd_solver.cpp:166] Iteration 7400, lr = 0.185
I0818 18:29:22.749737 22726 solver.cpp:337] Iteration 7500, Testing net (#0)
I0818 18:30:47.938884 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8426
I0818 18:30:47.939132 22726 solver.cpp:404]     Test net output #1: loss = 0.71965 (* 1 = 0.71965 loss)
I0818 18:30:49.269187 22726 solver.cpp:228] Iteration 7500, loss = 0.101555
I0818 18:30:49.269237 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 18:30:49.269254 22726 solver.cpp:244]     Train net output #1: loss = 0.101555 (* 1 = 0.101555 loss)
I0818 18:30:49.351379 22726 sgd_solver.cpp:166] Iteration 7500, lr = 0.1875
I0818 18:33:07.354632 22726 solver.cpp:337] Iteration 7600, Testing net (#0)
I0818 18:34:32.556358 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84736
I0818 18:34:32.556587 22726 solver.cpp:404]     Test net output #1: loss = 0.705106 (* 1 = 0.705106 loss)
I0818 18:34:33.887753 22726 solver.cpp:228] Iteration 7600, loss = 0.0349902
I0818 18:34:33.887800 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 18:34:33.887822 22726 solver.cpp:244]     Train net output #1: loss = 0.0349903 (* 1 = 0.0349903 loss)
I0818 18:34:33.967409 22726 sgd_solver.cpp:166] Iteration 7600, lr = 0.19
I0818 18:36:52.043977 22726 solver.cpp:337] Iteration 7700, Testing net (#0)
I0818 18:38:17.253489 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8424
I0818 18:38:17.253716 22726 solver.cpp:404]     Test net output #1: loss = 0.689503 (* 1 = 0.689503 loss)
I0818 18:38:18.585551 22726 solver.cpp:228] Iteration 7700, loss = 0.106296
I0818 18:38:18.585598 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 18:38:18.585620 22726 solver.cpp:244]     Train net output #1: loss = 0.106296 (* 1 = 0.106296 loss)
I0818 18:38:18.669435 22726 sgd_solver.cpp:166] Iteration 7700, lr = 0.1925
I0818 18:40:36.917291 22726 solver.cpp:337] Iteration 7800, Testing net (#0)
I0818 18:42:02.126731 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84584
I0818 18:42:02.126960 22726 solver.cpp:404]     Test net output #1: loss = 0.694156 (* 1 = 0.694156 loss)
I0818 18:42:03.457048 22726 solver.cpp:228] Iteration 7800, loss = 0.0988914
I0818 18:42:03.457095 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 18:42:03.457118 22726 solver.cpp:244]     Train net output #1: loss = 0.0988915 (* 1 = 0.0988915 loss)
I0818 18:42:03.535346 22726 sgd_solver.cpp:166] Iteration 7800, lr = 0.195
I0818 18:44:21.659925 22726 solver.cpp:337] Iteration 7900, Testing net (#0)
I0818 18:45:46.868360 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84932
I0818 18:45:46.868602 22726 solver.cpp:404]     Test net output #1: loss = 0.645691 (* 1 = 0.645691 loss)
I0818 18:45:48.200240 22726 solver.cpp:228] Iteration 7900, loss = 0.0433437
I0818 18:45:48.200287 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 18:45:48.200310 22726 solver.cpp:244]     Train net output #1: loss = 0.0433438 (* 1 = 0.0433438 loss)
I0818 18:45:48.280771 22726 sgd_solver.cpp:166] Iteration 7900, lr = 0.1975
I0818 18:48:06.431112 22726 solver.cpp:337] Iteration 8000, Testing net (#0)
I0818 18:49:31.606946 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84596
I0818 18:49:31.607198 22726 solver.cpp:404]     Test net output #1: loss = 0.655478 (* 1 = 0.655478 loss)
I0818 18:49:32.937307 22726 solver.cpp:228] Iteration 8000, loss = 0.0911139
I0818 18:49:32.937353 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 18:49:32.937376 22726 solver.cpp:244]     Train net output #1: loss = 0.091114 (* 1 = 0.091114 loss)
I0818 18:49:33.019453 22726 sgd_solver.cpp:166] Iteration 8000, lr = 0.2
I0818 18:51:51.077689 22726 solver.cpp:337] Iteration 8100, Testing net (#0)
I0818 18:53:16.289762 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84656
I0818 18:53:16.290024 22726 solver.cpp:404]     Test net output #1: loss = 0.68793 (* 1 = 0.68793 loss)
I0818 18:53:17.620975 22726 solver.cpp:228] Iteration 8100, loss = 0.0861403
I0818 18:53:17.621023 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 18:53:17.621047 22726 solver.cpp:244]     Train net output #1: loss = 0.0861404 (* 1 = 0.0861404 loss)
I0818 18:53:17.706980 22726 sgd_solver.cpp:166] Iteration 8100, lr = 0.2025
I0818 18:55:35.664276 22726 solver.cpp:337] Iteration 8200, Testing net (#0)
I0818 18:57:00.887733 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84128
I0818 18:57:00.887995 22726 solver.cpp:404]     Test net output #1: loss = 0.682959 (* 1 = 0.682959 loss)
I0818 18:57:02.218427 22726 solver.cpp:228] Iteration 8200, loss = 0.0265967
I0818 18:57:02.218473 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 18:57:02.218495 22726 solver.cpp:244]     Train net output #1: loss = 0.0265968 (* 1 = 0.0265968 loss)
I0818 18:57:02.305029 22726 sgd_solver.cpp:166] Iteration 8200, lr = 0.205
I0818 18:59:20.276101 22726 solver.cpp:337] Iteration 8300, Testing net (#0)
I0818 19:00:45.496431 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85076
I0818 19:00:45.496662 22726 solver.cpp:404]     Test net output #1: loss = 0.65669 (* 1 = 0.65669 loss)
I0818 19:00:46.826750 22726 solver.cpp:228] Iteration 8300, loss = 0.098622
I0818 19:00:46.826795 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 19:00:46.826818 22726 solver.cpp:244]     Train net output #1: loss = 0.0986221 (* 1 = 0.0986221 loss)
I0818 19:00:46.922039 22726 sgd_solver.cpp:166] Iteration 8300, lr = 0.2075
I0818 19:03:04.910773 22726 solver.cpp:337] Iteration 8400, Testing net (#0)
I0818 19:04:30.119549 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85048
I0818 19:04:30.119799 22726 solver.cpp:404]     Test net output #1: loss = 0.672524 (* 1 = 0.672524 loss)
I0818 19:04:31.450099 22726 solver.cpp:228] Iteration 8400, loss = 0.0374461
I0818 19:04:31.450148 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 19:04:31.450171 22726 solver.cpp:244]     Train net output #1: loss = 0.0374462 (* 1 = 0.0374462 loss)
I0818 19:04:31.539750 22726 sgd_solver.cpp:166] Iteration 8400, lr = 0.21
I0818 19:06:49.573984 22726 solver.cpp:337] Iteration 8500, Testing net (#0)
I0818 19:08:14.714231 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84712
I0818 19:08:14.714468 22726 solver.cpp:404]     Test net output #1: loss = 0.681361 (* 1 = 0.681361 loss)
I0818 19:08:16.044888 22726 solver.cpp:228] Iteration 8500, loss = 0.0292511
I0818 19:08:16.044936 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 19:08:16.044961 22726 solver.cpp:244]     Train net output #1: loss = 0.0292512 (* 1 = 0.0292512 loss)
I0818 19:08:16.132333 22726 sgd_solver.cpp:166] Iteration 8500, lr = 0.2125
I0818 19:10:34.110600 22726 solver.cpp:337] Iteration 8600, Testing net (#0)
I0818 19:11:59.331642 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85632
I0818 19:11:59.331904 22726 solver.cpp:404]     Test net output #1: loss = 0.655543 (* 1 = 0.655543 loss)
I0818 19:12:00.663034 22726 solver.cpp:228] Iteration 8600, loss = 0.045823
I0818 19:12:00.663079 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 19:12:00.663101 22726 solver.cpp:244]     Train net output #1: loss = 0.0458231 (* 1 = 0.0458231 loss)
I0818 19:12:00.744400 22726 sgd_solver.cpp:166] Iteration 8600, lr = 0.215
I0818 19:14:18.674721 22726 solver.cpp:337] Iteration 8700, Testing net (#0)
I0818 19:15:43.784463 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8498
I0818 19:15:43.784716 22726 solver.cpp:404]     Test net output #1: loss = 0.669559 (* 1 = 0.669559 loss)
I0818 19:15:45.114868 22726 solver.cpp:228] Iteration 8700, loss = 0.0588202
I0818 19:15:45.114913 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 19:15:45.114940 22726 solver.cpp:244]     Train net output #1: loss = 0.0588202 (* 1 = 0.0588202 loss)
I0818 19:15:45.203021 22726 sgd_solver.cpp:166] Iteration 8700, lr = 0.2175
I0818 19:18:03.317829 22726 solver.cpp:337] Iteration 8800, Testing net (#0)
I0818 19:19:28.559913 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85068
I0818 19:19:28.560168 22726 solver.cpp:404]     Test net output #1: loss = 0.660987 (* 1 = 0.660987 loss)
I0818 19:19:29.890306 22726 solver.cpp:228] Iteration 8800, loss = 0.161621
I0818 19:19:29.890350 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0818 19:19:29.890367 22726 solver.cpp:244]     Train net output #1: loss = 0.161621 (* 1 = 0.161621 loss)
I0818 19:19:29.979221 22726 sgd_solver.cpp:166] Iteration 8800, lr = 0.22
I0818 19:21:47.950379 22726 solver.cpp:337] Iteration 8900, Testing net (#0)
I0818 19:23:13.178392 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85512
I0818 19:23:13.178658 22726 solver.cpp:404]     Test net output #1: loss = 0.640297 (* 1 = 0.640297 loss)
I0818 19:23:14.509940 22726 solver.cpp:228] Iteration 8900, loss = 0.0366035
I0818 19:23:14.509987 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 19:23:14.510010 22726 solver.cpp:244]     Train net output #1: loss = 0.0366036 (* 1 = 0.0366036 loss)
I0818 19:23:14.589468 22726 sgd_solver.cpp:166] Iteration 8900, lr = 0.2225
I0818 19:25:32.518167 22726 solver.cpp:337] Iteration 9000, Testing net (#0)
I0818 19:26:57.606638 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85064
I0818 19:26:57.606905 22726 solver.cpp:404]     Test net output #1: loss = 0.64411 (* 1 = 0.64411 loss)
I0818 19:26:58.936908 22726 solver.cpp:228] Iteration 9000, loss = 0.0588317
I0818 19:26:58.936957 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 19:26:58.936981 22726 solver.cpp:244]     Train net output #1: loss = 0.0588318 (* 1 = 0.0588318 loss)
I0818 19:26:59.018061 22726 sgd_solver.cpp:166] Iteration 9000, lr = 0.225
I0818 19:29:17.048014 22726 solver.cpp:337] Iteration 9100, Testing net (#0)
I0818 19:30:42.275517 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85056
I0818 19:30:42.275753 22726 solver.cpp:404]     Test net output #1: loss = 0.643737 (* 1 = 0.643737 loss)
I0818 19:30:43.606670 22726 solver.cpp:228] Iteration 9100, loss = 0.0488401
I0818 19:30:43.606715 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 19:30:43.606739 22726 solver.cpp:244]     Train net output #1: loss = 0.0488401 (* 1 = 0.0488401 loss)
I0818 19:30:43.698498 22726 sgd_solver.cpp:166] Iteration 9100, lr = 0.2275
I0818 19:33:01.808413 22726 solver.cpp:337] Iteration 9200, Testing net (#0)
I0818 19:34:27.039768 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84868
I0818 19:34:27.040001 22726 solver.cpp:404]     Test net output #1: loss = 0.67388 (* 1 = 0.67388 loss)
I0818 19:34:28.370421 22726 solver.cpp:228] Iteration 9200, loss = 0.0197324
I0818 19:34:28.370466 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0818 19:34:28.370489 22726 solver.cpp:244]     Train net output #1: loss = 0.0197324 (* 1 = 0.0197324 loss)
I0818 19:34:28.459566 22726 sgd_solver.cpp:166] Iteration 9200, lr = 0.23
I0818 19:36:46.465903 22726 solver.cpp:337] Iteration 9300, Testing net (#0)
I0818 19:38:11.675137 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85144
I0818 19:38:11.675390 22726 solver.cpp:404]     Test net output #1: loss = 0.633219 (* 1 = 0.633219 loss)
I0818 19:38:13.005251 22726 solver.cpp:228] Iteration 9300, loss = 0.0830665
I0818 19:38:13.005296 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0818 19:38:13.005312 22726 solver.cpp:244]     Train net output #1: loss = 0.0830666 (* 1 = 0.0830666 loss)
I0818 19:38:13.090884 22726 sgd_solver.cpp:166] Iteration 9300, lr = 0.2325
I0818 19:40:31.082824 22726 solver.cpp:337] Iteration 9400, Testing net (#0)
I0818 19:41:56.244288 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85492
I0818 19:41:56.244534 22726 solver.cpp:404]     Test net output #1: loss = 0.6388 (* 1 = 0.6388 loss)
I0818 19:41:57.574854 22726 solver.cpp:228] Iteration 9400, loss = 0.0334792
I0818 19:41:57.574897 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 19:41:57.574911 22726 solver.cpp:244]     Train net output #1: loss = 0.0334793 (* 1 = 0.0334793 loss)
I0818 19:41:57.661435 22726 sgd_solver.cpp:166] Iteration 9400, lr = 0.235
I0818 19:44:15.649163 22726 solver.cpp:337] Iteration 9500, Testing net (#0)
I0818 19:45:40.843580 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8474
I0818 19:45:40.843816 22726 solver.cpp:404]     Test net output #1: loss = 0.656249 (* 1 = 0.656249 loss)
I0818 19:45:42.173611 22726 solver.cpp:228] Iteration 9500, loss = 0.119957
I0818 19:45:42.173655 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 19:45:42.173671 22726 solver.cpp:244]     Train net output #1: loss = 0.119957 (* 1 = 0.119957 loss)
I0818 19:45:42.254011 22726 sgd_solver.cpp:166] Iteration 9500, lr = 0.2375
I0818 19:48:00.306996 22726 solver.cpp:337] Iteration 9600, Testing net (#0)
I0818 19:49:25.500551 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85272
I0818 19:49:25.500771 22726 solver.cpp:404]     Test net output #1: loss = 0.668104 (* 1 = 0.668104 loss)
I0818 19:49:26.831041 22726 solver.cpp:228] Iteration 9600, loss = 0.0328171
I0818 19:49:26.831085 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 19:49:26.831101 22726 solver.cpp:244]     Train net output #1: loss = 0.0328171 (* 1 = 0.0328171 loss)
I0818 19:49:26.919994 22726 sgd_solver.cpp:166] Iteration 9600, lr = 0.24
I0818 19:51:45.028527 22726 solver.cpp:337] Iteration 9700, Testing net (#0)
I0818 19:53:10.019242 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85184
I0818 19:53:10.019461 22726 solver.cpp:404]     Test net output #1: loss = 0.645052 (* 1 = 0.645052 loss)
I0818 19:53:11.349659 22726 solver.cpp:228] Iteration 9700, loss = 0.0131564
I0818 19:53:11.349702 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0818 19:53:11.349717 22726 solver.cpp:244]     Train net output #1: loss = 0.0131564 (* 1 = 0.0131564 loss)
I0818 19:53:11.431668 22726 sgd_solver.cpp:166] Iteration 9700, lr = 0.2425
I0818 19:55:29.450274 22726 solver.cpp:337] Iteration 9800, Testing net (#0)
I0818 19:56:54.540925 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85128
I0818 19:56:54.541188 22726 solver.cpp:404]     Test net output #1: loss = 0.659973 (* 1 = 0.659973 loss)
I0818 19:56:55.870882 22726 solver.cpp:228] Iteration 9800, loss = 0.0493322
I0818 19:56:55.870924 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 19:56:55.870939 22726 solver.cpp:244]     Train net output #1: loss = 0.0493323 (* 1 = 0.0493323 loss)
I0818 19:56:55.958405 22726 sgd_solver.cpp:166] Iteration 9800, lr = 0.245
I0818 19:59:14.097896 22726 solver.cpp:337] Iteration 9900, Testing net (#0)
I0818 20:00:39.152446 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85352
I0818 20:00:39.152674 22726 solver.cpp:404]     Test net output #1: loss = 0.651346 (* 1 = 0.651346 loss)
I0818 20:00:40.482733 22726 solver.cpp:228] Iteration 9900, loss = 0.13777
I0818 20:00:40.482776 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0818 20:00:40.482792 22726 solver.cpp:244]     Train net output #1: loss = 0.13777 (* 1 = 0.13777 loss)
I0818 20:00:40.570375 22726 sgd_solver.cpp:166] Iteration 9900, lr = 0.2475
I0818 20:02:58.692926 22726 solver.cpp:337] Iteration 10000, Testing net (#0)
I0818 20:04:23.880759 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85384
I0818 20:04:23.881006 22726 solver.cpp:404]     Test net output #1: loss = 0.646895 (* 1 = 0.646895 loss)
I0818 20:04:25.211343 22726 solver.cpp:228] Iteration 10000, loss = 0.037176
I0818 20:04:25.211385 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 20:04:25.211400 22726 solver.cpp:244]     Train net output #1: loss = 0.037176 (* 1 = 0.037176 loss)
I0818 20:04:25.300983 22726 sgd_solver.cpp:166] Iteration 10000, lr = 0.25
I0818 20:06:43.491082 22726 solver.cpp:337] Iteration 10100, Testing net (#0)
I0818 20:08:08.685355 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85176
I0818 20:08:08.685581 22726 solver.cpp:404]     Test net output #1: loss = 0.633388 (* 1 = 0.633388 loss)
I0818 20:08:10.015789 22726 solver.cpp:228] Iteration 10100, loss = 0.0279549
I0818 20:08:10.015831 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 20:08:10.015846 22726 solver.cpp:244]     Train net output #1: loss = 0.0279549 (* 1 = 0.0279549 loss)
I0818 20:08:10.102573 22726 sgd_solver.cpp:166] Iteration 10100, lr = 0.2525
I0818 20:10:28.277125 22726 solver.cpp:337] Iteration 10200, Testing net (#0)
I0818 20:11:53.394943 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85744
I0818 20:11:53.395203 22726 solver.cpp:404]     Test net output #1: loss = 0.645731 (* 1 = 0.645731 loss)
I0818 20:11:54.725111 22726 solver.cpp:228] Iteration 10200, loss = 0.0333407
I0818 20:11:54.725152 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 20:11:54.725167 22726 solver.cpp:244]     Train net output #1: loss = 0.0333406 (* 1 = 0.0333406 loss)
I0818 20:11:54.806020 22726 sgd_solver.cpp:166] Iteration 10200, lr = 0.255
I0818 20:14:12.976119 22726 solver.cpp:337] Iteration 10300, Testing net (#0)
I0818 20:15:38.033881 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86048
I0818 20:15:38.034113 22726 solver.cpp:404]     Test net output #1: loss = 0.645328 (* 1 = 0.645328 loss)
I0818 20:15:39.364596 22726 solver.cpp:228] Iteration 10300, loss = 0.0732604
I0818 20:15:39.364639 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 20:15:39.364655 22726 solver.cpp:244]     Train net output #1: loss = 0.0732604 (* 1 = 0.0732604 loss)
I0818 20:15:39.453217 22726 sgd_solver.cpp:166] Iteration 10300, lr = 0.2575
I0818 20:17:57.572589 22726 solver.cpp:337] Iteration 10400, Testing net (#0)
I0818 20:19:22.769407 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85772
I0818 20:19:22.769657 22726 solver.cpp:404]     Test net output #1: loss = 0.638992 (* 1 = 0.638992 loss)
I0818 20:19:24.099987 22726 solver.cpp:228] Iteration 10400, loss = 0.0785984
I0818 20:19:24.100028 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 20:19:24.100047 22726 solver.cpp:244]     Train net output #1: loss = 0.0785983 (* 1 = 0.0785983 loss)
I0818 20:19:24.183234 22726 sgd_solver.cpp:166] Iteration 10400, lr = 0.26
I0818 20:21:42.317054 22726 solver.cpp:337] Iteration 10500, Testing net (#0)
I0818 20:23:07.513962 22726 solver.cpp:404]     Test net output #0: accuracy = 0.857601
I0818 20:23:07.514261 22726 solver.cpp:404]     Test net output #1: loss = 0.622076 (* 1 = 0.622076 loss)
I0818 20:23:08.844647 22726 solver.cpp:228] Iteration 10500, loss = 0.172251
I0818 20:23:08.844689 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0818 20:23:08.844704 22726 solver.cpp:244]     Train net output #1: loss = 0.172251 (* 1 = 0.172251 loss)
I0818 20:23:08.926090 22726 sgd_solver.cpp:166] Iteration 10500, lr = 0.2625
I0818 20:25:27.029492 22726 solver.cpp:337] Iteration 10600, Testing net (#0)
I0818 20:26:52.214741 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85064
I0818 20:26:52.215003 22726 solver.cpp:404]     Test net output #1: loss = 0.65446 (* 1 = 0.65446 loss)
I0818 20:26:53.545177 22726 solver.cpp:228] Iteration 10600, loss = 0.0385147
I0818 20:26:53.545218 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 20:26:53.545233 22726 solver.cpp:244]     Train net output #1: loss = 0.0385147 (* 1 = 0.0385147 loss)
I0818 20:26:53.629343 22726 sgd_solver.cpp:166] Iteration 10600, lr = 0.265
I0818 20:29:11.704916 22726 solver.cpp:337] Iteration 10700, Testing net (#0)
I0818 20:30:36.890761 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85092
I0818 20:30:36.891048 22726 solver.cpp:404]     Test net output #1: loss = 0.656244 (* 1 = 0.656244 loss)
I0818 20:30:38.220769 22726 solver.cpp:228] Iteration 10700, loss = 0.126409
I0818 20:30:38.220814 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 20:30:38.220830 22726 solver.cpp:244]     Train net output #1: loss = 0.126409 (* 1 = 0.126409 loss)
I0818 20:30:38.302923 22726 sgd_solver.cpp:166] Iteration 10700, lr = 0.2675
I0818 20:32:56.347484 22726 solver.cpp:337] Iteration 10800, Testing net (#0)
I0818 20:34:21.551213 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85724
I0818 20:34:21.551437 22726 solver.cpp:404]     Test net output #1: loss = 0.632377 (* 1 = 0.632377 loss)
I0818 20:34:22.881584 22726 solver.cpp:228] Iteration 10800, loss = 0.090954
I0818 20:34:22.881628 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 20:34:22.881644 22726 solver.cpp:244]     Train net output #1: loss = 0.090954 (* 1 = 0.090954 loss)
I0818 20:34:22.960676 22726 sgd_solver.cpp:166] Iteration 10800, lr = 0.27
I0818 20:36:41.080157 22726 solver.cpp:337] Iteration 10900, Testing net (#0)
I0818 20:38:06.266187 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86184
I0818 20:38:06.266396 22726 solver.cpp:404]     Test net output #1: loss = 0.596632 (* 1 = 0.596632 loss)
I0818 20:38:07.596468 22726 solver.cpp:228] Iteration 10900, loss = 0.0322899
I0818 20:38:07.596510 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 20:38:07.596526 22726 solver.cpp:244]     Train net output #1: loss = 0.0322898 (* 1 = 0.0322898 loss)
I0818 20:38:07.680279 22726 sgd_solver.cpp:166] Iteration 10900, lr = 0.2725
I0818 20:40:25.896540 22726 solver.cpp:337] Iteration 11000, Testing net (#0)
I0818 20:41:50.919436 22726 solver.cpp:404]     Test net output #0: accuracy = 0.858041
I0818 20:41:50.919646 22726 solver.cpp:404]     Test net output #1: loss = 0.624215 (* 1 = 0.624215 loss)
I0818 20:41:52.252976 22726 solver.cpp:228] Iteration 11000, loss = 0.0760239
I0818 20:41:52.253021 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 20:41:52.253041 22726 solver.cpp:244]     Train net output #1: loss = 0.0760239 (* 1 = 0.0760239 loss)
I0818 20:41:52.328632 22726 sgd_solver.cpp:166] Iteration 11000, lr = 0.275
I0818 20:44:10.369981 22726 solver.cpp:337] Iteration 11100, Testing net (#0)
I0818 20:45:35.527627 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8608
I0818 20:45:35.527851 22726 solver.cpp:404]     Test net output #1: loss = 0.622041 (* 1 = 0.622041 loss)
I0818 20:45:36.861133 22726 solver.cpp:228] Iteration 11100, loss = 0.0520044
I0818 20:45:36.861176 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 20:45:36.861192 22726 solver.cpp:244]     Train net output #1: loss = 0.0520043 (* 1 = 0.0520043 loss)
I0818 20:45:36.939447 22726 sgd_solver.cpp:166] Iteration 11100, lr = 0.2775
I0818 20:47:54.947015 22726 solver.cpp:337] Iteration 11200, Testing net (#0)
I0818 20:49:20.096272 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85448
I0818 20:49:20.096495 22726 solver.cpp:404]     Test net output #1: loss = 0.619157 (* 1 = 0.619157 loss)
I0818 20:49:21.429358 22726 solver.cpp:228] Iteration 11200, loss = 0.0394183
I0818 20:49:21.429402 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 20:49:21.429419 22726 solver.cpp:244]     Train net output #1: loss = 0.0394182 (* 1 = 0.0394182 loss)
I0818 20:49:21.508146 22726 sgd_solver.cpp:166] Iteration 11200, lr = 0.28
I0818 20:51:39.632385 22726 solver.cpp:337] Iteration 11300, Testing net (#0)
I0818 20:53:04.635921 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8568
I0818 20:53:04.636222 22726 solver.cpp:404]     Test net output #1: loss = 0.633431 (* 1 = 0.633431 loss)
I0818 20:53:05.969820 22726 solver.cpp:228] Iteration 11300, loss = 0.0377337
I0818 20:53:05.969866 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 20:53:05.969885 22726 solver.cpp:244]     Train net output #1: loss = 0.0377336 (* 1 = 0.0377336 loss)
I0818 20:53:06.051174 22726 sgd_solver.cpp:166] Iteration 11300, lr = 0.2825
I0818 20:55:24.220829 22726 solver.cpp:337] Iteration 11400, Testing net (#0)
I0818 20:56:49.402659 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86228
I0818 20:56:49.402895 22726 solver.cpp:404]     Test net output #1: loss = 0.586749 (* 1 = 0.586749 loss)
I0818 20:56:50.735976 22726 solver.cpp:228] Iteration 11400, loss = 0.0748914
I0818 20:56:50.736021 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 20:56:50.736037 22726 solver.cpp:244]     Train net output #1: loss = 0.0748913 (* 1 = 0.0748913 loss)
I0818 20:56:50.818527 22726 sgd_solver.cpp:166] Iteration 11400, lr = 0.285
I0818 20:59:08.945103 22726 solver.cpp:337] Iteration 11500, Testing net (#0)
I0818 21:00:34.111260 22726 solver.cpp:404]     Test net output #0: accuracy = 0.84788
I0818 21:00:34.111546 22726 solver.cpp:404]     Test net output #1: loss = 0.65163 (* 1 = 0.65163 loss)
I0818 21:00:35.445282 22726 solver.cpp:228] Iteration 11500, loss = 0.0948463
I0818 21:00:35.445325 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 21:00:35.445341 22726 solver.cpp:244]     Train net output #1: loss = 0.0948463 (* 1 = 0.0948463 loss)
I0818 21:00:35.517163 22726 sgd_solver.cpp:166] Iteration 11500, lr = 0.2875
I0818 21:02:53.545243 22726 solver.cpp:337] Iteration 11600, Testing net (#0)
I0818 21:04:18.725810 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86284
I0818 21:04:18.726069 22726 solver.cpp:404]     Test net output #1: loss = 0.603287 (* 1 = 0.603287 loss)
I0818 21:04:20.059257 22726 solver.cpp:228] Iteration 11600, loss = 0.0666989
I0818 21:04:20.059300 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 21:04:20.059316 22726 solver.cpp:244]     Train net output #1: loss = 0.0666989 (* 1 = 0.0666989 loss)
I0818 21:04:20.142490 22726 sgd_solver.cpp:166] Iteration 11600, lr = 0.29
I0818 21:06:38.173735 22726 solver.cpp:337] Iteration 11700, Testing net (#0)
I0818 21:08:03.173233 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86172
I0818 21:08:03.173486 22726 solver.cpp:404]     Test net output #1: loss = 0.613409 (* 1 = 0.613409 loss)
I0818 21:08:04.506255 22726 solver.cpp:228] Iteration 11700, loss = 0.133054
I0818 21:08:04.506299 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 21:08:04.506314 22726 solver.cpp:244]     Train net output #1: loss = 0.133054 (* 1 = 0.133054 loss)
I0818 21:08:04.589857 22726 sgd_solver.cpp:166] Iteration 11700, lr = 0.2925
I0818 21:10:22.664657 22726 solver.cpp:337] Iteration 11800, Testing net (#0)
I0818 21:11:47.804760 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85884
I0818 21:11:47.804991 22726 solver.cpp:404]     Test net output #1: loss = 0.609471 (* 1 = 0.609471 loss)
I0818 21:11:49.138684 22726 solver.cpp:228] Iteration 11800, loss = 0.0319363
I0818 21:11:49.138725 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 21:11:49.138741 22726 solver.cpp:244]     Train net output #1: loss = 0.0319362 (* 1 = 0.0319362 loss)
I0818 21:11:49.220726 22726 sgd_solver.cpp:166] Iteration 11800, lr = 0.295
I0818 21:14:07.312683 22726 solver.cpp:337] Iteration 11900, Testing net (#0)
I0818 21:15:32.432297 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86112
I0818 21:15:32.432531 22726 solver.cpp:404]     Test net output #1: loss = 0.619075 (* 1 = 0.619075 loss)
I0818 21:15:33.765244 22726 solver.cpp:228] Iteration 11900, loss = 0.087336
I0818 21:15:33.765285 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 21:15:33.765300 22726 solver.cpp:244]     Train net output #1: loss = 0.0873359 (* 1 = 0.0873359 loss)
I0818 21:15:33.845034 22726 sgd_solver.cpp:166] Iteration 11900, lr = 0.2975
I0818 21:17:51.889317 22726 solver.cpp:337] Iteration 12000, Testing net (#0)
I0818 21:19:17.027874 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86444
I0818 21:19:17.028110 22726 solver.cpp:404]     Test net output #1: loss = 0.590575 (* 1 = 0.590575 loss)
I0818 21:19:18.361502 22726 solver.cpp:228] Iteration 12000, loss = 0.043816
I0818 21:19:18.361546 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 21:19:18.361562 22726 solver.cpp:244]     Train net output #1: loss = 0.0438159 (* 1 = 0.0438159 loss)
I0818 21:19:18.441910 22726 sgd_solver.cpp:166] Iteration 12000, lr = 0.3
I0818 21:21:36.617291 22726 solver.cpp:337] Iteration 12100, Testing net (#0)
I0818 21:23:01.804919 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8638
I0818 21:23:01.805225 22726 solver.cpp:404]     Test net output #1: loss = 0.596991 (* 1 = 0.596991 loss)
I0818 21:23:03.138304 22726 solver.cpp:228] Iteration 12100, loss = 0.040026
I0818 21:23:03.138346 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 21:23:03.138361 22726 solver.cpp:244]     Train net output #1: loss = 0.0400259 (* 1 = 0.0400259 loss)
I0818 21:23:03.217839 22726 sgd_solver.cpp:166] Iteration 12100, lr = 0.3025
I0818 21:25:21.208008 22726 solver.cpp:337] Iteration 12200, Testing net (#0)
I0818 21:26:46.299057 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85816
I0818 21:26:46.299291 22726 solver.cpp:404]     Test net output #1: loss = 0.631496 (* 1 = 0.631496 loss)
I0818 21:26:47.632454 22726 solver.cpp:228] Iteration 12200, loss = 0.0652126
I0818 21:26:47.632498 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 21:26:47.632513 22726 solver.cpp:244]     Train net output #1: loss = 0.0652125 (* 1 = 0.0652125 loss)
I0818 21:26:47.718585 22726 sgd_solver.cpp:166] Iteration 12200, lr = 0.305
I0818 21:29:05.753614 22726 solver.cpp:337] Iteration 12300, Testing net (#0)
I0818 21:30:30.921066 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8664
I0818 21:30:30.921329 22726 solver.cpp:404]     Test net output #1: loss = 0.569227 (* 1 = 0.569227 loss)
I0818 21:30:32.254845 22726 solver.cpp:228] Iteration 12300, loss = 0.0445013
I0818 21:30:32.254889 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 21:30:32.254904 22726 solver.cpp:244]     Train net output #1: loss = 0.0445013 (* 1 = 0.0445013 loss)
I0818 21:30:32.338582 22726 sgd_solver.cpp:166] Iteration 12300, lr = 0.3075
I0818 21:32:50.404098 22726 solver.cpp:337] Iteration 12400, Testing net (#0)
I0818 21:34:15.560027 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86032
I0818 21:34:15.560261 22726 solver.cpp:404]     Test net output #1: loss = 0.584553 (* 1 = 0.584553 loss)
I0818 21:34:16.893366 22726 solver.cpp:228] Iteration 12400, loss = 0.0380621
I0818 21:34:16.893409 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 21:34:16.893424 22726 solver.cpp:244]     Train net output #1: loss = 0.038062 (* 1 = 0.038062 loss)
I0818 21:34:16.977377 22726 sgd_solver.cpp:166] Iteration 12400, lr = 0.31
I0818 21:36:34.973660 22726 solver.cpp:337] Iteration 12500, Testing net (#0)
I0818 21:38:00.112280 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86424
I0818 21:38:00.112512 22726 solver.cpp:404]     Test net output #1: loss = 0.574194 (* 1 = 0.574194 loss)
I0818 21:38:01.445418 22726 solver.cpp:228] Iteration 12500, loss = 0.0459679
I0818 21:38:01.445459 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 21:38:01.445474 22726 solver.cpp:244]     Train net output #1: loss = 0.0459679 (* 1 = 0.0459679 loss)
I0818 21:38:01.520400 22726 sgd_solver.cpp:166] Iteration 12500, lr = 0.3125
I0818 21:40:19.428238 22726 solver.cpp:337] Iteration 12600, Testing net (#0)
I0818 21:41:44.586627 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86336
I0818 21:41:44.586850 22726 solver.cpp:404]     Test net output #1: loss = 0.596426 (* 1 = 0.596426 loss)
I0818 21:41:45.919643 22726 solver.cpp:228] Iteration 12600, loss = 0.0723309
I0818 21:41:45.919687 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 21:41:45.919701 22726 solver.cpp:244]     Train net output #1: loss = 0.0723309 (* 1 = 0.0723309 loss)
I0818 21:41:46.003942 22726 sgd_solver.cpp:166] Iteration 12600, lr = 0.315
I0818 21:44:04.048444 22726 solver.cpp:337] Iteration 12700, Testing net (#0)
I0818 21:45:29.206328 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86052
I0818 21:45:29.206636 22726 solver.cpp:404]     Test net output #1: loss = 0.607887 (* 1 = 0.607887 loss)
I0818 21:45:30.540956 22726 solver.cpp:228] Iteration 12700, loss = 0.112363
I0818 21:45:30.540998 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0818 21:45:30.541014 22726 solver.cpp:244]     Train net output #1: loss = 0.112363 (* 1 = 0.112363 loss)
I0818 21:45:30.621538 22726 sgd_solver.cpp:166] Iteration 12700, lr = 0.3175
I0818 21:47:48.619830 22726 solver.cpp:337] Iteration 12800, Testing net (#0)
I0818 21:49:13.856678 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85528
I0818 21:49:13.856976 22726 solver.cpp:404]     Test net output #1: loss = 0.61336 (* 1 = 0.61336 loss)
I0818 21:49:15.191896 22726 solver.cpp:228] Iteration 12800, loss = 0.097828
I0818 21:49:15.191936 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0818 21:49:15.191951 22726 solver.cpp:244]     Train net output #1: loss = 0.0978279 (* 1 = 0.0978279 loss)
I0818 21:49:15.269177 22726 sgd_solver.cpp:166] Iteration 12800, lr = 0.32
I0818 21:51:33.247167 22726 solver.cpp:337] Iteration 12900, Testing net (#0)
I0818 21:52:58.587256 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8618
I0818 21:52:58.587577 22726 solver.cpp:404]     Test net output #1: loss = 0.563554 (* 1 = 0.563554 loss)
I0818 21:52:59.920725 22726 solver.cpp:228] Iteration 12900, loss = 0.0972971
I0818 21:52:59.920768 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 21:52:59.920784 22726 solver.cpp:244]     Train net output #1: loss = 0.097297 (* 1 = 0.097297 loss)
I0818 21:53:00.001044 22726 sgd_solver.cpp:166] Iteration 12900, lr = 0.3225
I0818 21:55:17.944594 22726 solver.cpp:337] Iteration 13000, Testing net (#0)
I0818 21:56:43.319188 22726 solver.cpp:404]     Test net output #0: accuracy = 0.861
I0818 21:56:43.319516 22726 solver.cpp:404]     Test net output #1: loss = 0.585039 (* 1 = 0.585039 loss)
I0818 21:56:44.653517 22726 solver.cpp:228] Iteration 13000, loss = 0.0948445
I0818 21:56:44.653558 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 21:56:44.653573 22726 solver.cpp:244]     Train net output #1: loss = 0.0948444 (* 1 = 0.0948444 loss)
I0818 21:56:44.728464 22726 sgd_solver.cpp:166] Iteration 13000, lr = 0.325
I0818 21:59:02.722539 22726 solver.cpp:337] Iteration 13100, Testing net (#0)
I0818 22:00:28.099803 22726 solver.cpp:404]     Test net output #0: accuracy = 0.85808
I0818 22:00:28.100111 22726 solver.cpp:404]     Test net output #1: loss = 0.578811 (* 1 = 0.578811 loss)
I0818 22:00:29.433341 22726 solver.cpp:228] Iteration 13100, loss = 0.0583398
I0818 22:00:29.433379 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 22:00:29.433395 22726 solver.cpp:244]     Train net output #1: loss = 0.0583397 (* 1 = 0.0583397 loss)
I0818 22:00:29.509918 22726 sgd_solver.cpp:166] Iteration 13100, lr = 0.3275
I0818 22:02:47.626504 22726 solver.cpp:337] Iteration 13200, Testing net (#0)
I0818 22:04:13.007009 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87272
I0818 22:04:13.007333 22726 solver.cpp:404]     Test net output #1: loss = 0.536016 (* 1 = 0.536016 loss)
I0818 22:04:14.340690 22726 solver.cpp:228] Iteration 13200, loss = 0.0427131
I0818 22:04:14.340730 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 22:04:14.340746 22726 solver.cpp:244]     Train net output #1: loss = 0.042713 (* 1 = 0.042713 loss)
I0818 22:04:14.417172 22726 sgd_solver.cpp:166] Iteration 13200, lr = 0.33
I0818 22:06:32.405973 22726 solver.cpp:337] Iteration 13300, Testing net (#0)
I0818 22:07:57.733341 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86496
I0818 22:07:57.733661 22726 solver.cpp:404]     Test net output #1: loss = 0.577857 (* 1 = 0.577857 loss)
I0818 22:07:59.068184 22726 solver.cpp:228] Iteration 13300, loss = 0.0619659
I0818 22:07:59.068233 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 22:07:59.068249 22726 solver.cpp:244]     Train net output #1: loss = 0.0619658 (* 1 = 0.0619658 loss)
I0818 22:07:59.149515 22726 sgd_solver.cpp:166] Iteration 13300, lr = 0.3325
I0818 22:10:17.330637 22726 solver.cpp:337] Iteration 13400, Testing net (#0)
I0818 22:11:42.680147 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86912
I0818 22:11:42.680480 22726 solver.cpp:404]     Test net output #1: loss = 0.556845 (* 1 = 0.556845 loss)
I0818 22:11:44.013687 22726 solver.cpp:228] Iteration 13400, loss = 0.0612258
I0818 22:11:44.013726 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 22:11:44.013742 22726 solver.cpp:244]     Train net output #1: loss = 0.0612257 (* 1 = 0.0612257 loss)
I0818 22:11:44.094700 22726 sgd_solver.cpp:166] Iteration 13400, lr = 0.335
I0818 22:14:02.228660 22726 solver.cpp:337] Iteration 13500, Testing net (#0)
I0818 22:15:27.524184 22726 solver.cpp:404]     Test net output #0: accuracy = 0.861
I0818 22:15:27.524489 22726 solver.cpp:404]     Test net output #1: loss = 0.58558 (* 1 = 0.58558 loss)
I0818 22:15:28.859158 22726 solver.cpp:228] Iteration 13500, loss = 0.109838
I0818 22:15:28.859200 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0818 22:15:28.859215 22726 solver.cpp:244]     Train net output #1: loss = 0.109838 (* 1 = 0.109838 loss)
I0818 22:15:28.936559 22726 sgd_solver.cpp:166] Iteration 13500, lr = 0.3375
I0818 22:17:46.975121 22726 solver.cpp:337] Iteration 13600, Testing net (#0)
I0818 22:19:12.209321 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86472
I0818 22:19:12.209645 22726 solver.cpp:404]     Test net output #1: loss = 0.565424 (* 1 = 0.565424 loss)
I0818 22:19:13.544739 22726 solver.cpp:228] Iteration 13600, loss = 0.0456946
I0818 22:19:13.544778 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 22:19:13.544793 22726 solver.cpp:244]     Train net output #1: loss = 0.0456945 (* 1 = 0.0456945 loss)
I0818 22:19:13.625166 22726 sgd_solver.cpp:166] Iteration 13600, lr = 0.34
I0818 22:21:31.666604 22726 solver.cpp:337] Iteration 13700, Testing net (#0)
I0818 22:22:57.066439 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8652
I0818 22:22:57.066737 22726 solver.cpp:404]     Test net output #1: loss = 0.567982 (* 1 = 0.567982 loss)
I0818 22:22:58.400347 22726 solver.cpp:228] Iteration 13700, loss = 0.066685
I0818 22:22:58.400389 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 22:22:58.400413 22726 solver.cpp:244]     Train net output #1: loss = 0.0666848 (* 1 = 0.0666848 loss)
I0818 22:22:58.480311 22726 sgd_solver.cpp:166] Iteration 13700, lr = 0.3425
I0818 22:25:16.573817 22726 solver.cpp:337] Iteration 13800, Testing net (#0)
I0818 22:26:41.833546 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8576
I0818 22:26:41.833875 22726 solver.cpp:404]     Test net output #1: loss = 0.592569 (* 1 = 0.592569 loss)
I0818 22:26:43.168470 22726 solver.cpp:228] Iteration 13800, loss = 0.137755
I0818 22:26:43.168514 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0818 22:26:43.168535 22726 solver.cpp:244]     Train net output #1: loss = 0.137755 (* 1 = 0.137755 loss)
I0818 22:26:43.247022 22726 sgd_solver.cpp:166] Iteration 13800, lr = 0.345
I0818 22:29:01.289880 22726 solver.cpp:337] Iteration 13900, Testing net (#0)
I0818 22:30:26.536327 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86552
I0818 22:30:26.536638 22726 solver.cpp:404]     Test net output #1: loss = 0.572654 (* 1 = 0.572654 loss)
I0818 22:30:27.871275 22726 solver.cpp:228] Iteration 13900, loss = 0.110724
I0818 22:30:27.871316 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0818 22:30:27.871340 22726 solver.cpp:244]     Train net output #1: loss = 0.110724 (* 1 = 0.110724 loss)
I0818 22:30:27.955162 22726 sgd_solver.cpp:166] Iteration 13900, lr = 0.3475
I0818 22:32:46.198329 22726 solver.cpp:337] Iteration 14000, Testing net (#0)
I0818 22:34:11.448262 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86748
I0818 22:34:11.448597 22726 solver.cpp:404]     Test net output #1: loss = 0.55649 (* 1 = 0.55649 loss)
I0818 22:34:12.783031 22726 solver.cpp:228] Iteration 14000, loss = 0.0349211
I0818 22:34:12.783072 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 22:34:12.783095 22726 solver.cpp:244]     Train net output #1: loss = 0.034921 (* 1 = 0.034921 loss)
I0818 22:34:12.862308 22726 sgd_solver.cpp:166] Iteration 14000, lr = 0.35
I0818 22:36:30.946352 22726 solver.cpp:337] Iteration 14100, Testing net (#0)
I0818 22:37:56.186966 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8662
I0818 22:37:56.187294 22726 solver.cpp:404]     Test net output #1: loss = 0.552344 (* 1 = 0.552344 loss)
I0818 22:37:57.521602 22726 solver.cpp:228] Iteration 14100, loss = 0.0675692
I0818 22:37:57.521644 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 22:37:57.521667 22726 solver.cpp:244]     Train net output #1: loss = 0.0675691 (* 1 = 0.0675691 loss)
I0818 22:37:57.596423 22726 sgd_solver.cpp:166] Iteration 14100, lr = 0.3525
I0818 22:40:15.625530 22726 solver.cpp:337] Iteration 14200, Testing net (#0)
I0818 22:41:40.860647 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8678
I0818 22:41:40.860966 22726 solver.cpp:404]     Test net output #1: loss = 0.560255 (* 1 = 0.560255 loss)
I0818 22:41:42.195677 22726 solver.cpp:228] Iteration 14200, loss = 0.0596975
I0818 22:41:42.195720 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 22:41:42.195735 22726 solver.cpp:244]     Train net output #1: loss = 0.0596974 (* 1 = 0.0596974 loss)
I0818 22:41:42.277523 22726 sgd_solver.cpp:166] Iteration 14200, lr = 0.355
I0818 22:44:00.446722 22726 solver.cpp:337] Iteration 14300, Testing net (#0)
I0818 22:45:25.732324 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86444
I0818 22:45:25.732628 22726 solver.cpp:404]     Test net output #1: loss = 0.572741 (* 1 = 0.572741 loss)
I0818 22:45:27.065784 22726 solver.cpp:228] Iteration 14300, loss = 0.061841
I0818 22:45:27.065826 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 22:45:27.065850 22726 solver.cpp:244]     Train net output #1: loss = 0.0618409 (* 1 = 0.0618409 loss)
I0818 22:45:27.143729 22726 sgd_solver.cpp:166] Iteration 14300, lr = 0.3575
I0818 22:47:45.158377 22726 solver.cpp:337] Iteration 14400, Testing net (#0)
I0818 22:49:10.396535 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8612
I0818 22:49:10.396836 22726 solver.cpp:404]     Test net output #1: loss = 0.590298 (* 1 = 0.590298 loss)
I0818 22:49:11.730559 22726 solver.cpp:228] Iteration 14400, loss = 0.0536143
I0818 22:49:11.730603 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 22:49:11.730626 22726 solver.cpp:244]     Train net output #1: loss = 0.0536141 (* 1 = 0.0536141 loss)
I0818 22:49:11.812271 22726 sgd_solver.cpp:166] Iteration 14400, lr = 0.36
I0818 22:51:29.947104 22726 solver.cpp:337] Iteration 14500, Testing net (#0)
I0818 22:52:55.194689 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86388
I0818 22:52:55.195011 22726 solver.cpp:404]     Test net output #1: loss = 0.580256 (* 1 = 0.580256 loss)
I0818 22:52:56.527987 22726 solver.cpp:228] Iteration 14500, loss = 0.136246
I0818 22:52:56.528034 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0818 22:52:56.528055 22726 solver.cpp:244]     Train net output #1: loss = 0.136246 (* 1 = 0.136246 loss)
I0818 22:52:56.609251 22726 sgd_solver.cpp:166] Iteration 14500, lr = 0.3625
I0818 22:55:14.571894 22726 solver.cpp:337] Iteration 14600, Testing net (#0)
I0818 22:56:39.835914 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86696
I0818 22:56:39.836221 22726 solver.cpp:404]     Test net output #1: loss = 0.567143 (* 1 = 0.567143 loss)
I0818 22:56:41.169643 22726 solver.cpp:228] Iteration 14600, loss = 0.0770639
I0818 22:56:41.169688 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 22:56:41.169710 22726 solver.cpp:244]     Train net output #1: loss = 0.0770638 (* 1 = 0.0770638 loss)
I0818 22:56:41.246868 22726 sgd_solver.cpp:166] Iteration 14600, lr = 0.365
I0818 22:58:59.222813 22726 solver.cpp:337] Iteration 14700, Testing net (#0)
I0818 23:00:24.459857 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86884
I0818 23:00:24.460175 22726 solver.cpp:404]     Test net output #1: loss = 0.583211 (* 1 = 0.583211 loss)
I0818 23:00:25.794715 22726 solver.cpp:228] Iteration 14700, loss = 0.173235
I0818 23:00:25.794757 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0818 23:00:25.794773 22726 solver.cpp:244]     Train net output #1: loss = 0.173235 (* 1 = 0.173235 loss)
I0818 23:00:25.871482 22726 sgd_solver.cpp:166] Iteration 14700, lr = 0.3675
I0818 23:02:44.051566 22726 solver.cpp:337] Iteration 14800, Testing net (#0)
I0818 23:04:09.275841 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86724
I0818 23:04:09.276142 22726 solver.cpp:404]     Test net output #1: loss = 0.569177 (* 1 = 0.569177 loss)
I0818 23:04:10.610803 22726 solver.cpp:228] Iteration 14800, loss = 0.0169321
I0818 23:04:10.610846 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0818 23:04:10.610862 22726 solver.cpp:244]     Train net output #1: loss = 0.016932 (* 1 = 0.016932 loss)
I0818 23:04:10.693040 22726 sgd_solver.cpp:166] Iteration 14800, lr = 0.37
I0818 23:06:28.826529 22726 solver.cpp:337] Iteration 14900, Testing net (#0)
I0818 23:07:54.057749 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86568
I0818 23:07:54.058073 22726 solver.cpp:404]     Test net output #1: loss = 0.571647 (* 1 = 0.571647 loss)
I0818 23:07:55.392112 22726 solver.cpp:228] Iteration 14900, loss = 0.0684817
I0818 23:07:55.392154 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 23:07:55.392169 22726 solver.cpp:244]     Train net output #1: loss = 0.0684816 (* 1 = 0.0684816 loss)
I0818 23:07:55.474949 22726 sgd_solver.cpp:166] Iteration 14900, lr = 0.3725
I0818 23:10:13.675551 22726 solver.cpp:337] Iteration 15000, Testing net (#0)
I0818 23:11:38.911798 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86644
I0818 23:11:38.912122 22726 solver.cpp:404]     Test net output #1: loss = 0.555311 (* 1 = 0.555311 loss)
I0818 23:11:40.246737 22726 solver.cpp:228] Iteration 15000, loss = 0.0764202
I0818 23:11:40.246781 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 23:11:40.246796 22726 solver.cpp:244]     Train net output #1: loss = 0.0764201 (* 1 = 0.0764201 loss)
I0818 23:11:40.322506 22726 sgd_solver.cpp:166] Iteration 15000, lr = 0.375
I0818 23:13:58.415006 22726 solver.cpp:337] Iteration 15100, Testing net (#0)
I0818 23:15:23.667662 22726 solver.cpp:404]     Test net output #0: accuracy = 0.865
I0818 23:15:23.667996 22726 solver.cpp:404]     Test net output #1: loss = 0.554583 (* 1 = 0.554583 loss)
I0818 23:15:25.002699 22726 solver.cpp:228] Iteration 15100, loss = 0.0615335
I0818 23:15:25.002746 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 23:15:25.002768 22726 solver.cpp:244]     Train net output #1: loss = 0.0615334 (* 1 = 0.0615334 loss)
I0818 23:15:25.078439 22726 sgd_solver.cpp:166] Iteration 15100, lr = 0.3775
I0818 23:17:43.109906 22726 solver.cpp:337] Iteration 15200, Testing net (#0)
I0818 23:19:08.336264 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8706
I0818 23:19:08.336583 22726 solver.cpp:404]     Test net output #1: loss = 0.540544 (* 1 = 0.540544 loss)
I0818 23:19:09.670424 22726 solver.cpp:228] Iteration 15200, loss = 0.0622453
I0818 23:19:09.670466 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 23:19:09.670480 22726 solver.cpp:244]     Train net output #1: loss = 0.0622452 (* 1 = 0.0622452 loss)
I0818 23:19:09.745434 22726 sgd_solver.cpp:166] Iteration 15200, lr = 0.38
I0818 23:21:27.835223 22726 solver.cpp:337] Iteration 15300, Testing net (#0)
I0818 23:22:53.065965 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86664
I0818 23:22:53.066263 22726 solver.cpp:404]     Test net output #1: loss = 0.542276 (* 1 = 0.542276 loss)
I0818 23:22:54.400833 22726 solver.cpp:228] Iteration 15300, loss = 0.0608777
I0818 23:22:54.400876 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 23:22:54.400892 22726 solver.cpp:244]     Train net output #1: loss = 0.0608776 (* 1 = 0.0608776 loss)
I0818 23:22:54.478827 22726 sgd_solver.cpp:166] Iteration 15300, lr = 0.3825
I0818 23:25:12.758831 22726 solver.cpp:337] Iteration 15400, Testing net (#0)
I0818 23:26:37.978888 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87312
I0818 23:26:37.979223 22726 solver.cpp:404]     Test net output #1: loss = 0.552346 (* 1 = 0.552346 loss)
I0818 23:26:39.312127 22726 solver.cpp:228] Iteration 15400, loss = 0.0465014
I0818 23:26:39.312170 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 23:26:39.312186 22726 solver.cpp:244]     Train net output #1: loss = 0.0465013 (* 1 = 0.0465013 loss)
I0818 23:26:39.392899 22726 sgd_solver.cpp:166] Iteration 15400, lr = 0.385
I0818 23:28:57.623509 22726 solver.cpp:337] Iteration 15500, Testing net (#0)
I0818 23:30:22.873992 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86804
I0818 23:30:22.874305 22726 solver.cpp:404]     Test net output #1: loss = 0.574414 (* 1 = 0.574414 loss)
I0818 23:30:24.208307 22726 solver.cpp:228] Iteration 15500, loss = 0.0674272
I0818 23:30:24.208353 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0818 23:30:24.208377 22726 solver.cpp:244]     Train net output #1: loss = 0.0674271 (* 1 = 0.0674271 loss)
I0818 23:30:24.289921 22726 sgd_solver.cpp:166] Iteration 15500, lr = 0.3875
I0818 23:32:42.452720 22726 solver.cpp:337] Iteration 15600, Testing net (#0)
I0818 23:34:07.697598 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86796
I0818 23:34:07.697942 22726 solver.cpp:404]     Test net output #1: loss = 0.540221 (* 1 = 0.540221 loss)
I0818 23:34:09.031029 22726 solver.cpp:228] Iteration 15600, loss = 0.0308636
I0818 23:34:09.031077 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 23:34:09.031100 22726 solver.cpp:244]     Train net output #1: loss = 0.0308635 (* 1 = 0.0308635 loss)
I0818 23:34:09.109746 22726 sgd_solver.cpp:166] Iteration 15600, lr = 0.39
I0818 23:36:27.260068 22726 solver.cpp:337] Iteration 15700, Testing net (#0)
I0818 23:37:52.507362 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86164
I0818 23:37:52.507688 22726 solver.cpp:404]     Test net output #1: loss = 0.564676 (* 1 = 0.564676 loss)
I0818 23:37:53.841089 22726 solver.cpp:228] Iteration 15700, loss = 0.148182
I0818 23:37:53.841133 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0818 23:37:53.841156 22726 solver.cpp:244]     Train net output #1: loss = 0.148182 (* 1 = 0.148182 loss)
I0818 23:37:53.925487 22726 sgd_solver.cpp:166] Iteration 15700, lr = 0.3925
I0818 23:40:11.960384 22726 solver.cpp:337] Iteration 15800, Testing net (#0)
I0818 23:41:37.205848 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87244
I0818 23:41:37.206185 22726 solver.cpp:404]     Test net output #1: loss = 0.560471 (* 1 = 0.560471 loss)
I0818 23:41:38.541216 22726 solver.cpp:228] Iteration 15800, loss = 0.0463755
I0818 23:41:38.541306 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0818 23:41:38.541333 22726 solver.cpp:244]     Train net output #1: loss = 0.0463754 (* 1 = 0.0463754 loss)
I0818 23:41:38.617995 22726 sgd_solver.cpp:166] Iteration 15800, lr = 0.395
I0818 23:43:56.672590 22726 solver.cpp:337] Iteration 15900, Testing net (#0)
I0818 23:45:21.918645 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86556
I0818 23:45:21.918972 22726 solver.cpp:404]     Test net output #1: loss = 0.527176 (* 1 = 0.527176 loss)
I0818 23:45:23.253695 22726 solver.cpp:228] Iteration 15900, loss = 0.0647182
I0818 23:45:23.253741 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 23:45:23.253763 22726 solver.cpp:244]     Train net output #1: loss = 0.0647181 (* 1 = 0.0647181 loss)
I0818 23:45:23.332995 22726 sgd_solver.cpp:166] Iteration 15900, lr = 0.3975
I0818 23:47:41.338796 22726 solver.cpp:337] Iteration 16000, Testing net (#0)
I0818 23:49:06.603596 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87168
I0818 23:49:06.603929 22726 solver.cpp:404]     Test net output #1: loss = 0.529721 (* 1 = 0.529721 loss)
I0818 23:49:07.938426 22726 solver.cpp:228] Iteration 16000, loss = 0.0438052
I0818 23:49:07.938473 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0818 23:49:07.938498 22726 solver.cpp:244]     Train net output #1: loss = 0.0438051 (* 1 = 0.0438051 loss)
I0818 23:49:08.019857 22726 sgd_solver.cpp:166] Iteration 16000, lr = 0.4
I0818 23:51:26.029757 22726 solver.cpp:337] Iteration 16100, Testing net (#0)
I0818 23:52:51.338263 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8732
I0818 23:52:51.338578 22726 solver.cpp:404]     Test net output #1: loss = 0.526531 (* 1 = 0.526531 loss)
I0818 23:52:52.675644 22726 solver.cpp:228] Iteration 16100, loss = 0.0427424
I0818 23:52:52.675689 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0818 23:52:52.675714 22726 solver.cpp:244]     Train net output #1: loss = 0.0427423 (* 1 = 0.0427423 loss)
I0818 23:52:52.752454 22726 sgd_solver.cpp:166] Iteration 16100, lr = 0.4025
I0818 23:55:10.780356 22726 solver.cpp:337] Iteration 16200, Testing net (#0)
I0818 23:56:36.129739 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87012
I0818 23:56:36.130050 22726 solver.cpp:404]     Test net output #1: loss = 0.534155 (* 1 = 0.534155 loss)
I0818 23:56:37.464180 22726 solver.cpp:228] Iteration 16200, loss = 0.111396
I0818 23:56:37.464229 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0818 23:56:37.464252 22726 solver.cpp:244]     Train net output #1: loss = 0.111396 (* 1 = 0.111396 loss)
I0818 23:56:37.542078 22726 sgd_solver.cpp:166] Iteration 16200, lr = 0.405
I0818 23:58:55.568892 22726 solver.cpp:337] Iteration 16300, Testing net (#0)
I0819 00:00:20.895087 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87424
I0819 00:00:20.895391 22726 solver.cpp:404]     Test net output #1: loss = 0.528594 (* 1 = 0.528594 loss)
I0819 00:00:22.228996 22726 solver.cpp:228] Iteration 16300, loss = 0.0668828
I0819 00:00:22.229043 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 00:00:22.229065 22726 solver.cpp:244]     Train net output #1: loss = 0.0668827 (* 1 = 0.0668827 loss)
I0819 00:00:22.303839 22726 sgd_solver.cpp:166] Iteration 16300, lr = 0.4075
I0819 00:02:40.417605 22726 solver.cpp:337] Iteration 16400, Testing net (#0)
I0819 00:04:05.689630 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86572
I0819 00:04:05.689939 22726 solver.cpp:404]     Test net output #1: loss = 0.538659 (* 1 = 0.538659 loss)
I0819 00:04:07.024346 22726 solver.cpp:228] Iteration 16400, loss = 0.0376049
I0819 00:04:07.024386 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 00:04:07.024410 22726 solver.cpp:244]     Train net output #1: loss = 0.0376047 (* 1 = 0.0376047 loss)
I0819 00:04:07.106669 22726 sgd_solver.cpp:166] Iteration 16400, lr = 0.41
I0819 00:06:25.253717 22726 solver.cpp:337] Iteration 16500, Testing net (#0)
I0819 00:07:50.638005 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87036
I0819 00:07:50.638334 22726 solver.cpp:404]     Test net output #1: loss = 0.526264 (* 1 = 0.526264 loss)
I0819 00:07:51.972807 22726 solver.cpp:228] Iteration 16500, loss = 0.0372676
I0819 00:07:51.972851 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 00:07:51.972875 22726 solver.cpp:244]     Train net output #1: loss = 0.0372675 (* 1 = 0.0372675 loss)
I0819 00:07:52.049441 22726 sgd_solver.cpp:166] Iteration 16500, lr = 0.4125
I0819 00:10:10.162780 22726 solver.cpp:337] Iteration 16600, Testing net (#0)
I0819 00:11:35.530057 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87104
I0819 00:11:35.530369 22726 solver.cpp:404]     Test net output #1: loss = 0.543883 (* 1 = 0.543883 loss)
I0819 00:11:36.864744 22726 solver.cpp:228] Iteration 16600, loss = 0.0770823
I0819 00:11:36.864789 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 00:11:36.864812 22726 solver.cpp:244]     Train net output #1: loss = 0.0770821 (* 1 = 0.0770821 loss)
I0819 00:11:36.948230 22726 sgd_solver.cpp:166] Iteration 16600, lr = 0.415
I0819 00:13:55.037751 22726 solver.cpp:337] Iteration 16700, Testing net (#0)
I0819 00:15:20.433540 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87252
I0819 00:15:20.433867 22726 solver.cpp:404]     Test net output #1: loss = 0.541139 (* 1 = 0.541139 loss)
I0819 00:15:21.767208 22726 solver.cpp:228] Iteration 16700, loss = 0.0212722
I0819 00:15:21.767251 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 00:15:21.767273 22726 solver.cpp:244]     Train net output #1: loss = 0.021272 (* 1 = 0.021272 loss)
I0819 00:15:21.852367 22726 sgd_solver.cpp:166] Iteration 16700, lr = 0.4175
I0819 00:17:40.117399 22726 solver.cpp:337] Iteration 16800, Testing net (#0)
I0819 00:19:05.437789 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87488
I0819 00:19:05.438117 22726 solver.cpp:404]     Test net output #1: loss = 0.530789 (* 1 = 0.530789 loss)
I0819 00:19:06.772869 22726 solver.cpp:228] Iteration 16800, loss = 0.0763497
I0819 00:19:06.772913 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 00:19:06.772936 22726 solver.cpp:244]     Train net output #1: loss = 0.0763495 (* 1 = 0.0763495 loss)
I0819 00:19:06.849580 22726 sgd_solver.cpp:166] Iteration 16800, lr = 0.42
I0819 00:21:24.851709 22726 solver.cpp:337] Iteration 16900, Testing net (#0)
I0819 00:22:50.193464 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86912
I0819 00:22:50.193787 22726 solver.cpp:404]     Test net output #1: loss = 0.553615 (* 1 = 0.553615 loss)
I0819 00:22:51.527360 22726 solver.cpp:228] Iteration 16900, loss = 0.0629713
I0819 00:22:51.527403 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 00:22:51.527426 22726 solver.cpp:244]     Train net output #1: loss = 0.0629711 (* 1 = 0.0629711 loss)
I0819 00:22:51.605396 22726 sgd_solver.cpp:166] Iteration 16900, lr = 0.4225
I0819 00:25:09.588943 22726 solver.cpp:337] Iteration 17000, Testing net (#0)
I0819 00:26:34.960525 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87184
I0819 00:26:34.960836 22726 solver.cpp:404]     Test net output #1: loss = 0.552544 (* 1 = 0.552544 loss)
I0819 00:26:36.294112 22726 solver.cpp:228] Iteration 17000, loss = 0.0693857
I0819 00:26:36.294154 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 00:26:36.294178 22726 solver.cpp:244]     Train net output #1: loss = 0.0693855 (* 1 = 0.0693855 loss)
I0819 00:26:36.374146 22726 sgd_solver.cpp:166] Iteration 17000, lr = 0.425
I0819 00:28:54.470779 22726 solver.cpp:337] Iteration 17100, Testing net (#0)
I0819 00:30:19.807116 22726 solver.cpp:404]     Test net output #0: accuracy = 0.872801
I0819 00:30:19.807440 22726 solver.cpp:404]     Test net output #1: loss = 0.52155 (* 1 = 0.52155 loss)
I0819 00:30:21.142591 22726 solver.cpp:228] Iteration 17100, loss = 0.0229798
I0819 00:30:21.142634 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 00:30:21.142658 22726 solver.cpp:244]     Train net output #1: loss = 0.0229797 (* 1 = 0.0229797 loss)
I0819 00:30:21.224059 22726 sgd_solver.cpp:166] Iteration 17100, lr = 0.4275
I0819 00:32:39.254106 22726 solver.cpp:337] Iteration 17200, Testing net (#0)
I0819 00:34:04.592799 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87324
I0819 00:34:04.593128 22726 solver.cpp:404]     Test net output #1: loss = 0.524724 (* 1 = 0.524724 loss)
I0819 00:34:05.927609 22726 solver.cpp:228] Iteration 17200, loss = 0.0463251
I0819 00:34:05.927652 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 00:34:05.927676 22726 solver.cpp:244]     Train net output #1: loss = 0.046325 (* 1 = 0.046325 loss)
I0819 00:34:06.012763 22726 sgd_solver.cpp:166] Iteration 17200, lr = 0.43
I0819 00:36:24.361562 22726 solver.cpp:337] Iteration 17300, Testing net (#0)
I0819 00:37:49.586535 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86652
I0819 00:37:49.586859 22726 solver.cpp:404]     Test net output #1: loss = 0.536998 (* 1 = 0.536998 loss)
I0819 00:37:50.919245 22726 solver.cpp:228] Iteration 17300, loss = 0.0412119
I0819 00:37:50.919287 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 00:37:50.919302 22726 solver.cpp:244]     Train net output #1: loss = 0.0412118 (* 1 = 0.0412118 loss)
I0819 00:37:51.003481 22726 sgd_solver.cpp:166] Iteration 17300, lr = 0.4325
I0819 00:40:09.008711 22726 solver.cpp:337] Iteration 17400, Testing net (#0)
I0819 00:41:34.238845 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86976
I0819 00:41:34.239172 22726 solver.cpp:404]     Test net output #1: loss = 0.544659 (* 1 = 0.544659 loss)
I0819 00:41:35.573940 22726 solver.cpp:228] Iteration 17400, loss = 0.106916
I0819 00:41:35.573982 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 00:41:35.574002 22726 solver.cpp:244]     Train net output #1: loss = 0.106916 (* 1 = 0.106916 loss)
I0819 00:41:35.651319 22726 sgd_solver.cpp:166] Iteration 17400, lr = 0.435
I0819 00:43:53.647388 22726 solver.cpp:337] Iteration 17500, Testing net (#0)
I0819 00:45:18.381832 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87344
I0819 00:45:18.382114 22726 solver.cpp:404]     Test net output #1: loss = 0.540694 (* 1 = 0.540694 loss)
I0819 00:45:19.715991 22726 solver.cpp:228] Iteration 17500, loss = 0.107782
I0819 00:45:19.716034 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 00:45:19.716049 22726 solver.cpp:244]     Train net output #1: loss = 0.107782 (* 1 = 0.107782 loss)
I0819 00:45:19.790122 22726 sgd_solver.cpp:166] Iteration 17500, lr = 0.4375
I0819 00:47:37.694692 22726 solver.cpp:337] Iteration 17600, Testing net (#0)
I0819 00:49:02.562525 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8736
I0819 00:49:02.562799 22726 solver.cpp:404]     Test net output #1: loss = 0.515557 (* 1 = 0.515557 loss)
I0819 00:49:03.896220 22726 solver.cpp:228] Iteration 17600, loss = 0.0913487
I0819 00:49:03.896261 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 00:49:03.896277 22726 solver.cpp:244]     Train net output #1: loss = 0.0913486 (* 1 = 0.0913486 loss)
I0819 00:49:03.977382 22726 sgd_solver.cpp:166] Iteration 17600, lr = 0.44
I0819 00:51:21.840839 22726 solver.cpp:337] Iteration 17700, Testing net (#0)
I0819 00:52:46.651932 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87528
I0819 00:52:46.652249 22726 solver.cpp:404]     Test net output #1: loss = 0.506216 (* 1 = 0.506216 loss)
I0819 00:52:47.986050 22726 solver.cpp:228] Iteration 17700, loss = 0.0636979
I0819 00:52:47.986093 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 00:52:47.986109 22726 solver.cpp:244]     Train net output #1: loss = 0.0636977 (* 1 = 0.0636977 loss)
I0819 00:52:48.068655 22726 sgd_solver.cpp:166] Iteration 17700, lr = 0.4425
I0819 00:55:05.844619 22726 solver.cpp:337] Iteration 17800, Testing net (#0)
I0819 00:56:31.063536 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87168
I0819 00:56:31.063864 22726 solver.cpp:404]     Test net output #1: loss = 0.518447 (* 1 = 0.518447 loss)
I0819 00:56:32.397557 22726 solver.cpp:228] Iteration 17800, loss = 0.0866379
I0819 00:56:32.397599 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 00:56:32.397615 22726 solver.cpp:244]     Train net output #1: loss = 0.0866377 (* 1 = 0.0866377 loss)
I0819 00:56:32.470722 22726 sgd_solver.cpp:166] Iteration 17800, lr = 0.445
I0819 00:58:50.299213 22726 solver.cpp:337] Iteration 17900, Testing net (#0)
I0819 01:00:15.529379 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87444
I0819 01:00:15.529681 22726 solver.cpp:404]     Test net output #1: loss = 0.505941 (* 1 = 0.505941 loss)
I0819 01:00:16.863185 22726 solver.cpp:228] Iteration 17900, loss = 0.0843636
I0819 01:00:16.863231 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 01:00:16.863247 22726 solver.cpp:244]     Train net output #1: loss = 0.0843634 (* 1 = 0.0843634 loss)
I0819 01:00:16.944409 22726 sgd_solver.cpp:166] Iteration 17900, lr = 0.4475
I0819 01:02:34.735071 22726 solver.cpp:337] Iteration 18000, Testing net (#0)
I0819 01:03:59.960772 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8742
I0819 01:03:59.961102 22726 solver.cpp:404]     Test net output #1: loss = 0.517494 (* 1 = 0.517494 loss)
I0819 01:04:01.293771 22726 solver.cpp:228] Iteration 18000, loss = 0.0401598
I0819 01:04:01.293823 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 01:04:01.293839 22726 solver.cpp:244]     Train net output #1: loss = 0.0401596 (* 1 = 0.0401596 loss)
I0819 01:04:01.376766 22726 sgd_solver.cpp:166] Iteration 18000, lr = 0.45
I0819 01:06:19.163204 22726 solver.cpp:337] Iteration 18100, Testing net (#0)
I0819 01:07:44.385768 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8752
I0819 01:07:44.386096 22726 solver.cpp:404]     Test net output #1: loss = 0.535202 (* 1 = 0.535202 loss)
I0819 01:07:45.719570 22726 solver.cpp:228] Iteration 18100, loss = 0.0605398
I0819 01:07:45.719612 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 01:07:45.719626 22726 solver.cpp:244]     Train net output #1: loss = 0.0605397 (* 1 = 0.0605397 loss)
I0819 01:07:45.803050 22726 sgd_solver.cpp:166] Iteration 18100, lr = 0.4525
I0819 01:10:03.568186 22726 solver.cpp:337] Iteration 18200, Testing net (#0)
I0819 01:11:28.800058 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87012
I0819 01:11:28.800390 22726 solver.cpp:404]     Test net output #1: loss = 0.514867 (* 1 = 0.514867 loss)
I0819 01:11:30.133755 22726 solver.cpp:228] Iteration 18200, loss = 0.12456
I0819 01:11:30.133797 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 01:11:30.133812 22726 solver.cpp:244]     Train net output #1: loss = 0.124559 (* 1 = 0.124559 loss)
I0819 01:11:30.216416 22726 sgd_solver.cpp:166] Iteration 18200, lr = 0.455
I0819 01:13:48.031249 22726 solver.cpp:337] Iteration 18300, Testing net (#0)
I0819 01:15:13.259488 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87304
I0819 01:15:13.259815 22726 solver.cpp:404]     Test net output #1: loss = 0.532911 (* 1 = 0.532911 loss)
I0819 01:15:14.592876 22726 solver.cpp:228] Iteration 18300, loss = 0.0380372
I0819 01:15:14.592919 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 01:15:14.592936 22726 solver.cpp:244]     Train net output #1: loss = 0.0380371 (* 1 = 0.0380371 loss)
I0819 01:15:14.673274 22726 sgd_solver.cpp:166] Iteration 18300, lr = 0.4575
I0819 01:17:32.457651 22726 solver.cpp:337] Iteration 18400, Testing net (#0)
I0819 01:18:57.693025 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87096
I0819 01:18:57.693334 22726 solver.cpp:404]     Test net output #1: loss = 0.527416 (* 1 = 0.527416 loss)
I0819 01:18:59.026448 22726 solver.cpp:228] Iteration 18400, loss = 0.127637
I0819 01:18:59.026489 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 01:18:59.026505 22726 solver.cpp:244]     Train net output #1: loss = 0.127637 (* 1 = 0.127637 loss)
I0819 01:18:59.105778 22726 sgd_solver.cpp:166] Iteration 18400, lr = 0.46
I0819 01:21:16.870829 22726 solver.cpp:337] Iteration 18500, Testing net (#0)
I0819 01:22:42.112920 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86808
I0819 01:22:42.113222 22726 solver.cpp:404]     Test net output #1: loss = 0.535686 (* 1 = 0.535686 loss)
I0819 01:22:43.446601 22726 solver.cpp:228] Iteration 18500, loss = 0.163259
I0819 01:22:43.446645 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 01:22:43.446660 22726 solver.cpp:244]     Train net output #1: loss = 0.163259 (* 1 = 0.163259 loss)
I0819 01:22:43.526571 22726 sgd_solver.cpp:166] Iteration 18500, lr = 0.4625
I0819 01:25:01.342877 22726 solver.cpp:337] Iteration 18600, Testing net (#0)
I0819 01:26:26.573303 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86732
I0819 01:26:26.573631 22726 solver.cpp:404]     Test net output #1: loss = 0.540047 (* 1 = 0.540047 loss)
I0819 01:26:27.906862 22726 solver.cpp:228] Iteration 18600, loss = 0.105797
I0819 01:26:27.906915 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 01:26:27.906932 22726 solver.cpp:244]     Train net output #1: loss = 0.105797 (* 1 = 0.105797 loss)
I0819 01:26:27.986066 22726 sgd_solver.cpp:166] Iteration 18600, lr = 0.465
I0819 01:28:45.954368 22726 solver.cpp:337] Iteration 18700, Testing net (#0)
I0819 01:30:11.175287 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87364
I0819 01:30:11.175604 22726 solver.cpp:404]     Test net output #1: loss = 0.507061 (* 1 = 0.507061 loss)
I0819 01:30:12.509639 22726 solver.cpp:228] Iteration 18700, loss = 0.141576
I0819 01:30:12.509693 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 01:30:12.509709 22726 solver.cpp:244]     Train net output #1: loss = 0.141576 (* 1 = 0.141576 loss)
I0819 01:30:12.586285 22726 sgd_solver.cpp:166] Iteration 18700, lr = 0.4675
I0819 01:32:30.480911 22726 solver.cpp:337] Iteration 18800, Testing net (#0)
I0819 01:33:55.720623 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87652
I0819 01:33:55.720958 22726 solver.cpp:404]     Test net output #1: loss = 0.517211 (* 1 = 0.517211 loss)
I0819 01:33:57.054752 22726 solver.cpp:228] Iteration 18800, loss = 0.0488095
I0819 01:33:57.054795 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 01:33:57.054811 22726 solver.cpp:244]     Train net output #1: loss = 0.0488094 (* 1 = 0.0488094 loss)
I0819 01:33:57.134076 22726 sgd_solver.cpp:166] Iteration 18800, lr = 0.47
I0819 01:36:15.080008 22726 solver.cpp:337] Iteration 18900, Testing net (#0)
I0819 01:37:40.321279 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87248
I0819 01:37:40.321604 22726 solver.cpp:404]     Test net output #1: loss = 0.516113 (* 1 = 0.516113 loss)
I0819 01:37:41.655452 22726 solver.cpp:228] Iteration 18900, loss = 0.0496628
I0819 01:37:41.655494 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 01:37:41.655509 22726 solver.cpp:244]     Train net output #1: loss = 0.0496627 (* 1 = 0.0496627 loss)
I0819 01:37:41.735008 22726 sgd_solver.cpp:166] Iteration 18900, lr = 0.4725
I0819 01:39:59.640651 22726 solver.cpp:337] Iteration 19000, Testing net (#0)
I0819 01:41:24.876821 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88036
I0819 01:41:24.877140 22726 solver.cpp:404]     Test net output #1: loss = 0.490196 (* 1 = 0.490196 loss)
I0819 01:41:26.211565 22726 solver.cpp:228] Iteration 19000, loss = 0.0551938
I0819 01:41:26.211607 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 01:41:26.211623 22726 solver.cpp:244]     Train net output #1: loss = 0.0551936 (* 1 = 0.0551936 loss)
I0819 01:41:26.283578 22726 sgd_solver.cpp:166] Iteration 19000, lr = 0.475
I0819 01:43:44.147994 22726 solver.cpp:337] Iteration 19100, Testing net (#0)
I0819 01:45:09.377501 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87648
I0819 01:45:09.377862 22726 solver.cpp:404]     Test net output #1: loss = 0.49377 (* 1 = 0.49377 loss)
I0819 01:45:10.711907 22726 solver.cpp:228] Iteration 19100, loss = 0.077916
I0819 01:45:10.711948 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 01:45:10.711964 22726 solver.cpp:244]     Train net output #1: loss = 0.0779159 (* 1 = 0.0779159 loss)
I0819 01:45:10.790292 22726 sgd_solver.cpp:166] Iteration 19100, lr = 0.4775
I0819 01:47:28.632269 22726 solver.cpp:337] Iteration 19200, Testing net (#0)
I0819 01:48:53.867233 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87644
I0819 01:48:53.867539 22726 solver.cpp:404]     Test net output #1: loss = 0.506874 (* 1 = 0.506874 loss)
I0819 01:48:55.201995 22726 solver.cpp:228] Iteration 19200, loss = 0.0988541
I0819 01:48:55.202046 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 01:48:55.202064 22726 solver.cpp:244]     Train net output #1: loss = 0.0988539 (* 1 = 0.0988539 loss)
I0819 01:48:55.281186 22726 sgd_solver.cpp:166] Iteration 19200, lr = 0.48
I0819 01:51:13.134865 22726 solver.cpp:337] Iteration 19300, Testing net (#0)
I0819 01:52:38.365485 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87404
I0819 01:52:38.365814 22726 solver.cpp:404]     Test net output #1: loss = 0.508267 (* 1 = 0.508267 loss)
I0819 01:52:39.699239 22726 solver.cpp:228] Iteration 19300, loss = 0.0490904
I0819 01:52:39.699280 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 01:52:39.699295 22726 solver.cpp:244]     Train net output #1: loss = 0.0490902 (* 1 = 0.0490902 loss)
I0819 01:52:39.780247 22726 sgd_solver.cpp:166] Iteration 19300, lr = 0.4825
I0819 01:54:57.624042 22726 solver.cpp:337] Iteration 19400, Testing net (#0)
I0819 01:56:22.861095 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86316
I0819 01:56:22.861405 22726 solver.cpp:404]     Test net output #1: loss = 0.556116 (* 1 = 0.556116 loss)
I0819 01:56:24.193930 22726 solver.cpp:228] Iteration 19400, loss = 0.0989479
I0819 01:56:24.193972 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 01:56:24.193989 22726 solver.cpp:244]     Train net output #1: loss = 0.0989477 (* 1 = 0.0989477 loss)
I0819 01:56:24.272742 22726 sgd_solver.cpp:166] Iteration 19400, lr = 0.485
I0819 01:58:42.227022 22726 solver.cpp:337] Iteration 19500, Testing net (#0)
I0819 02:00:07.466215 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87804
I0819 02:00:07.466516 22726 solver.cpp:404]     Test net output #1: loss = 0.495772 (* 1 = 0.495772 loss)
I0819 02:00:08.799418 22726 solver.cpp:228] Iteration 19500, loss = 0.0524038
I0819 02:00:08.799469 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 02:00:08.799486 22726 solver.cpp:244]     Train net output #1: loss = 0.0524035 (* 1 = 0.0524035 loss)
I0819 02:00:08.883577 22726 sgd_solver.cpp:166] Iteration 19500, lr = 0.4875
I0819 02:02:26.753214 22726 solver.cpp:337] Iteration 19600, Testing net (#0)
I0819 02:03:51.999603 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87604
I0819 02:03:51.999917 22726 solver.cpp:404]     Test net output #1: loss = 0.50052 (* 1 = 0.50052 loss)
I0819 02:03:53.333499 22726 solver.cpp:228] Iteration 19600, loss = 0.0975625
I0819 02:03:53.333550 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 02:03:53.333567 22726 solver.cpp:244]     Train net output #1: loss = 0.0975623 (* 1 = 0.0975623 loss)
I0819 02:03:53.422945 22726 sgd_solver.cpp:166] Iteration 19600, lr = 0.49
I0819 02:06:11.304603 22726 solver.cpp:337] Iteration 19700, Testing net (#0)
I0819 02:07:36.666684 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8688
I0819 02:07:36.667016 22726 solver.cpp:404]     Test net output #1: loss = 0.525009 (* 1 = 0.525009 loss)
I0819 02:07:38.001457 22726 solver.cpp:228] Iteration 19700, loss = 0.0894855
I0819 02:07:38.001500 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 02:07:38.001516 22726 solver.cpp:244]     Train net output #1: loss = 0.0894853 (* 1 = 0.0894853 loss)
I0819 02:07:38.080081 22726 sgd_solver.cpp:166] Iteration 19700, lr = 0.4925
I0819 02:09:56.025076 22726 solver.cpp:337] Iteration 19800, Testing net (#0)
I0819 02:11:21.322038 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87428
I0819 02:11:21.322332 22726 solver.cpp:404]     Test net output #1: loss = 0.502514 (* 1 = 0.502514 loss)
I0819 02:11:22.655833 22726 solver.cpp:228] Iteration 19800, loss = 0.133147
I0819 02:11:22.655884 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 02:11:22.655901 22726 solver.cpp:244]     Train net output #1: loss = 0.133147 (* 1 = 0.133147 loss)
I0819 02:11:22.730820 22726 sgd_solver.cpp:166] Iteration 19800, lr = 0.495
I0819 02:13:40.644140 22726 solver.cpp:337] Iteration 19900, Testing net (#0)
I0819 02:15:05.952098 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88164
I0819 02:15:05.952440 22726 solver.cpp:404]     Test net output #1: loss = 0.493729 (* 1 = 0.493729 loss)
I0819 02:15:07.286521 22726 solver.cpp:228] Iteration 19900, loss = 0.0339891
I0819 02:15:07.286573 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 02:15:07.286590 22726 solver.cpp:244]     Train net output #1: loss = 0.0339889 (* 1 = 0.0339889 loss)
I0819 02:15:07.358465 22726 sgd_solver.cpp:166] Iteration 19900, lr = 0.4975
I0819 02:17:25.256984 22726 solver.cpp:337] Iteration 20000, Testing net (#0)
I0819 02:18:50.591428 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87324
I0819 02:18:50.591734 22726 solver.cpp:404]     Test net output #1: loss = 0.503316 (* 1 = 0.503316 loss)
I0819 02:18:51.925905 22726 solver.cpp:228] Iteration 20000, loss = 0.0965864
I0819 02:18:51.925956 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 02:18:51.925973 22726 solver.cpp:244]     Train net output #1: loss = 0.0965861 (* 1 = 0.0965861 loss)
I0819 02:18:52.011157 22726 sgd_solver.cpp:166] Iteration 20000, lr = 0.5
I0819 02:21:09.869519 22726 solver.cpp:337] Iteration 20100, Testing net (#0)
I0819 02:22:35.198736 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87692
I0819 02:22:35.199033 22726 solver.cpp:404]     Test net output #1: loss = 0.502021 (* 1 = 0.502021 loss)
I0819 02:22:36.533740 22726 solver.cpp:228] Iteration 20100, loss = 0.072269
I0819 02:22:36.533784 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 02:22:36.533800 22726 solver.cpp:244]     Train net output #1: loss = 0.0722687 (* 1 = 0.0722687 loss)
I0819 02:22:36.611357 22726 sgd_solver.cpp:166] Iteration 20100, lr = 0.5025
I0819 02:24:54.547176 22726 solver.cpp:337] Iteration 20200, Testing net (#0)
I0819 02:26:19.866402 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87364
I0819 02:26:19.866705 22726 solver.cpp:404]     Test net output #1: loss = 0.516902 (* 1 = 0.516902 loss)
I0819 02:26:21.200122 22726 solver.cpp:228] Iteration 20200, loss = 0.0893676
I0819 02:26:21.200165 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 02:26:21.200181 22726 solver.cpp:244]     Train net output #1: loss = 0.0893674 (* 1 = 0.0893674 loss)
I0819 02:26:21.275579 22726 sgd_solver.cpp:166] Iteration 20200, lr = 0.505
I0819 02:28:39.137975 22726 solver.cpp:337] Iteration 20300, Testing net (#0)
I0819 02:30:04.471264 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88116
I0819 02:30:04.471577 22726 solver.cpp:404]     Test net output #1: loss = 0.485514 (* 1 = 0.485514 loss)
I0819 02:30:05.805331 22726 solver.cpp:228] Iteration 20300, loss = 0.0930716
I0819 02:30:05.805375 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 02:30:05.805392 22726 solver.cpp:244]     Train net output #1: loss = 0.0930713 (* 1 = 0.0930713 loss)
I0819 02:30:05.880168 22726 sgd_solver.cpp:166] Iteration 20300, lr = 0.5075
I0819 02:32:23.706722 22726 solver.cpp:337] Iteration 20400, Testing net (#0)
I0819 02:33:48.993764 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87336
I0819 02:33:48.994092 22726 solver.cpp:404]     Test net output #1: loss = 0.50526 (* 1 = 0.50526 loss)
I0819 02:33:50.326771 22726 solver.cpp:228] Iteration 20400, loss = 0.0796948
I0819 02:33:50.326824 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 02:33:50.326843 22726 solver.cpp:244]     Train net output #1: loss = 0.0796946 (* 1 = 0.0796946 loss)
I0819 02:33:50.414252 22726 sgd_solver.cpp:166] Iteration 20400, lr = 0.51
I0819 02:36:08.312935 22726 solver.cpp:337] Iteration 20500, Testing net (#0)
I0819 02:37:33.677733 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8804
I0819 02:37:33.678045 22726 solver.cpp:404]     Test net output #1: loss = 0.479403 (* 1 = 0.479403 loss)
I0819 02:37:35.011575 22726 solver.cpp:228] Iteration 20500, loss = 0.0537436
I0819 02:37:35.011618 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 02:37:35.011633 22726 solver.cpp:244]     Train net output #1: loss = 0.0537434 (* 1 = 0.0537434 loss)
I0819 02:37:35.087092 22726 sgd_solver.cpp:166] Iteration 20500, lr = 0.5125
I0819 02:39:53.001257 22726 solver.cpp:337] Iteration 20600, Testing net (#0)
I0819 02:41:18.248814 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87652
I0819 02:41:18.249135 22726 solver.cpp:404]     Test net output #1: loss = 0.468499 (* 1 = 0.468499 loss)
I0819 02:41:19.582084 22726 solver.cpp:228] Iteration 20600, loss = 0.116045
I0819 02:41:19.582139 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 02:41:19.582155 22726 solver.cpp:244]     Train net output #1: loss = 0.116045 (* 1 = 0.116045 loss)
I0819 02:41:19.659340 22726 sgd_solver.cpp:166] Iteration 20600, lr = 0.515
I0819 02:43:37.596971 22726 solver.cpp:337] Iteration 20700, Testing net (#0)
I0819 02:45:02.814716 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87308
I0819 02:45:02.815059 22726 solver.cpp:404]     Test net output #1: loss = 0.497075 (* 1 = 0.497075 loss)
I0819 02:45:04.151818 22726 solver.cpp:228] Iteration 20700, loss = 0.0250711
I0819 02:45:04.151865 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 02:45:04.151881 22726 solver.cpp:244]     Train net output #1: loss = 0.0250709 (* 1 = 0.0250709 loss)
I0819 02:45:04.227923 22726 sgd_solver.cpp:166] Iteration 20700, lr = 0.5175
I0819 02:47:22.092224 22726 solver.cpp:337] Iteration 20800, Testing net (#0)
I0819 02:48:47.360133 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87736
I0819 02:48:47.360451 22726 solver.cpp:404]     Test net output #1: loss = 0.48452 (* 1 = 0.48452 loss)
I0819 02:48:48.693773 22726 solver.cpp:228] Iteration 20800, loss = 0.126684
I0819 02:48:48.693845 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 02:48:48.693869 22726 solver.cpp:244]     Train net output #1: loss = 0.126683 (* 1 = 0.126683 loss)
I0819 02:48:48.776998 22726 sgd_solver.cpp:166] Iteration 20800, lr = 0.52
I0819 02:51:06.698441 22726 solver.cpp:337] Iteration 20900, Testing net (#0)
I0819 02:52:31.942275 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87444
I0819 02:52:31.942575 22726 solver.cpp:404]     Test net output #1: loss = 0.502479 (* 1 = 0.502479 loss)
I0819 02:52:33.276602 22726 solver.cpp:228] Iteration 20900, loss = 0.0525957
I0819 02:52:33.276657 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 02:52:33.276681 22726 solver.cpp:244]     Train net output #1: loss = 0.0525955 (* 1 = 0.0525955 loss)
I0819 02:52:33.351095 22726 sgd_solver.cpp:166] Iteration 20900, lr = 0.5225
I0819 02:54:51.265161 22726 solver.cpp:337] Iteration 21000, Testing net (#0)
I0819 02:56:16.509675 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87192
I0819 02:56:16.509994 22726 solver.cpp:404]     Test net output #1: loss = 0.510412 (* 1 = 0.510412 loss)
I0819 02:56:17.843230 22726 solver.cpp:228] Iteration 21000, loss = 0.066767
I0819 02:56:17.843276 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 02:56:17.843299 22726 solver.cpp:244]     Train net output #1: loss = 0.0667668 (* 1 = 0.0667668 loss)
I0819 02:56:17.920708 22726 sgd_solver.cpp:166] Iteration 21000, lr = 0.525
I0819 02:58:35.860901 22726 solver.cpp:337] Iteration 21100, Testing net (#0)
I0819 03:00:01.101698 22726 solver.cpp:404]     Test net output #0: accuracy = 0.874
I0819 03:00:01.102023 22726 solver.cpp:404]     Test net output #1: loss = 0.511913 (* 1 = 0.511913 loss)
I0819 03:00:02.436751 22726 solver.cpp:228] Iteration 21100, loss = 0.0358711
I0819 03:00:02.436794 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 03:00:02.436818 22726 solver.cpp:244]     Train net output #1: loss = 0.0358709 (* 1 = 0.0358709 loss)
I0819 03:00:02.512670 22726 sgd_solver.cpp:166] Iteration 21100, lr = 0.5275
I0819 03:02:20.489434 22726 solver.cpp:337] Iteration 21200, Testing net (#0)
I0819 03:03:45.730284 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87648
I0819 03:03:45.730593 22726 solver.cpp:404]     Test net output #1: loss = 0.498982 (* 1 = 0.498982 loss)
I0819 03:03:47.064054 22726 solver.cpp:228] Iteration 21200, loss = 0.0492556
I0819 03:03:47.064110 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 03:03:47.064133 22726 solver.cpp:244]     Train net output #1: loss = 0.0492554 (* 1 = 0.0492554 loss)
I0819 03:03:47.144064 22726 sgd_solver.cpp:166] Iteration 21200, lr = 0.53
I0819 03:06:05.112794 22726 solver.cpp:337] Iteration 21300, Testing net (#0)
I0819 03:07:30.362995 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87632
I0819 03:07:30.363332 22726 solver.cpp:404]     Test net output #1: loss = 0.487357 (* 1 = 0.487357 loss)
I0819 03:07:31.696745 22726 solver.cpp:228] Iteration 21300, loss = 0.0577075
I0819 03:07:31.696800 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 03:07:31.696823 22726 solver.cpp:244]     Train net output #1: loss = 0.0577074 (* 1 = 0.0577074 loss)
I0819 03:07:31.785964 22726 sgd_solver.cpp:166] Iteration 21300, lr = 0.5325
I0819 03:09:49.699785 22726 solver.cpp:337] Iteration 21400, Testing net (#0)
I0819 03:11:14.927409 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87272
I0819 03:11:14.927727 22726 solver.cpp:404]     Test net output #1: loss = 0.515726 (* 1 = 0.515726 loss)
I0819 03:11:16.262217 22726 solver.cpp:228] Iteration 21400, loss = 0.105709
I0819 03:11:16.262259 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 03:11:16.262274 22726 solver.cpp:244]     Train net output #1: loss = 0.105709 (* 1 = 0.105709 loss)
I0819 03:11:16.341514 22726 sgd_solver.cpp:166] Iteration 21400, lr = 0.535
I0819 03:13:34.240177 22726 solver.cpp:337] Iteration 21500, Testing net (#0)
I0819 03:14:59.477015 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87608
I0819 03:14:59.477324 22726 solver.cpp:404]     Test net output #1: loss = 0.481071 (* 1 = 0.481071 loss)
I0819 03:15:00.811374 22726 solver.cpp:228] Iteration 21500, loss = 0.0672113
I0819 03:15:00.811427 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 03:15:00.811444 22726 solver.cpp:244]     Train net output #1: loss = 0.0672111 (* 1 = 0.0672111 loss)
I0819 03:15:00.890007 22726 sgd_solver.cpp:166] Iteration 21500, lr = 0.5375
I0819 03:17:18.813999 22726 solver.cpp:337] Iteration 21600, Testing net (#0)
I0819 03:18:44.057183 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87828
I0819 03:18:44.057521 22726 solver.cpp:404]     Test net output #1: loss = 0.494672 (* 1 = 0.494672 loss)
I0819 03:18:45.390385 22726 solver.cpp:228] Iteration 21600, loss = 0.0190107
I0819 03:18:45.390439 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 03:18:45.390456 22726 solver.cpp:244]     Train net output #1: loss = 0.0190106 (* 1 = 0.0190106 loss)
I0819 03:18:45.470785 22726 sgd_solver.cpp:166] Iteration 21600, lr = 0.54
I0819 03:21:03.289912 22726 solver.cpp:337] Iteration 21700, Testing net (#0)
I0819 03:22:27.786420 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87684
I0819 03:22:27.786687 22726 solver.cpp:404]     Test net output #1: loss = 0.517388 (* 1 = 0.517388 loss)
I0819 03:22:29.117480 22726 solver.cpp:228] Iteration 21700, loss = 0.211087
I0819 03:22:29.117512 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 03:22:29.117527 22726 solver.cpp:244]     Train net output #1: loss = 0.211087 (* 1 = 0.211087 loss)
I0819 03:22:29.198997 22726 sgd_solver.cpp:166] Iteration 21700, lr = 0.5425
I0819 03:24:46.785449 22726 solver.cpp:337] Iteration 21800, Testing net (#0)
I0819 03:26:11.276574 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88048
I0819 03:26:11.276860 22726 solver.cpp:404]     Test net output #1: loss = 0.467198 (* 1 = 0.467198 loss)
I0819 03:26:12.607847 22726 solver.cpp:228] Iteration 21800, loss = 0.0766026
I0819 03:26:12.607882 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 03:26:12.607900 22726 solver.cpp:244]     Train net output #1: loss = 0.0766025 (* 1 = 0.0766025 loss)
I0819 03:26:12.689786 22726 sgd_solver.cpp:166] Iteration 21800, lr = 0.545
I0819 03:28:30.271353 22726 solver.cpp:337] Iteration 21900, Testing net (#0)
I0819 03:29:54.757392 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88076
I0819 03:29:54.757686 22726 solver.cpp:404]     Test net output #1: loss = 0.48224 (* 1 = 0.48224 loss)
I0819 03:29:56.088912 22726 solver.cpp:228] Iteration 21900, loss = 0.061491
I0819 03:29:56.088945 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 03:29:56.088961 22726 solver.cpp:244]     Train net output #1: loss = 0.0614908 (* 1 = 0.0614908 loss)
I0819 03:29:56.169729 22726 sgd_solver.cpp:166] Iteration 21900, lr = 0.5475
I0819 03:32:13.885553 22726 solver.cpp:337] Iteration 22000, Testing net (#0)
I0819 03:33:38.370774 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87356
I0819 03:33:38.371069 22726 solver.cpp:404]     Test net output #1: loss = 0.482133 (* 1 = 0.482133 loss)
I0819 03:33:39.702414 22726 solver.cpp:228] Iteration 22000, loss = 0.0673411
I0819 03:33:39.702451 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 03:33:39.702467 22726 solver.cpp:244]     Train net output #1: loss = 0.067341 (* 1 = 0.067341 loss)
I0819 03:33:39.780346 22726 sgd_solver.cpp:166] Iteration 22000, lr = 0.55
I0819 03:35:57.399910 22726 solver.cpp:337] Iteration 22100, Testing net (#0)
I0819 03:37:21.893854 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8818
I0819 03:37:21.894137 22726 solver.cpp:404]     Test net output #1: loss = 0.471062 (* 1 = 0.471062 loss)
I0819 03:37:23.225148 22726 solver.cpp:228] Iteration 22100, loss = 0.0529904
I0819 03:37:23.225189 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 03:37:23.225206 22726 solver.cpp:244]     Train net output #1: loss = 0.0529903 (* 1 = 0.0529903 loss)
I0819 03:37:23.306998 22726 sgd_solver.cpp:166] Iteration 22100, lr = 0.5525
I0819 03:39:40.903990 22726 solver.cpp:337] Iteration 22200, Testing net (#0)
I0819 03:41:05.387807 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87864
I0819 03:41:05.388085 22726 solver.cpp:404]     Test net output #1: loss = 0.480618 (* 1 = 0.480618 loss)
I0819 03:41:06.718637 22726 solver.cpp:228] Iteration 22200, loss = 0.0811188
I0819 03:41:06.718677 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 03:41:06.718693 22726 solver.cpp:244]     Train net output #1: loss = 0.0811186 (* 1 = 0.0811186 loss)
I0819 03:41:06.797479 22726 sgd_solver.cpp:166] Iteration 22200, lr = 0.555
I0819 03:43:24.391438 22726 solver.cpp:337] Iteration 22300, Testing net (#0)
I0819 03:44:48.877770 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87356
I0819 03:44:48.878068 22726 solver.cpp:404]     Test net output #1: loss = 0.500219 (* 1 = 0.500219 loss)
I0819 03:44:50.208920 22726 solver.cpp:228] Iteration 22300, loss = 0.0201558
I0819 03:44:50.208959 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 03:44:50.208976 22726 solver.cpp:244]     Train net output #1: loss = 0.0201556 (* 1 = 0.0201556 loss)
I0819 03:44:50.286474 22726 sgd_solver.cpp:166] Iteration 22300, lr = 0.5575
I0819 03:47:07.826063 22726 solver.cpp:337] Iteration 22400, Testing net (#0)
I0819 03:48:32.307469 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87896
I0819 03:48:32.307762 22726 solver.cpp:404]     Test net output #1: loss = 0.477803 (* 1 = 0.477803 loss)
I0819 03:48:33.638900 22726 solver.cpp:228] Iteration 22400, loss = 0.084071
I0819 03:48:33.638943 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 03:48:33.638960 22726 solver.cpp:244]     Train net output #1: loss = 0.0840708 (* 1 = 0.0840708 loss)
I0819 03:48:33.714614 22726 sgd_solver.cpp:166] Iteration 22400, lr = 0.56
I0819 03:50:51.288424 22726 solver.cpp:337] Iteration 22500, Testing net (#0)
I0819 03:52:15.769929 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8814
I0819 03:52:15.770216 22726 solver.cpp:404]     Test net output #1: loss = 0.464964 (* 1 = 0.464964 loss)
I0819 03:52:17.100793 22726 solver.cpp:228] Iteration 22500, loss = 0.050832
I0819 03:52:17.100838 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 03:52:17.100854 22726 solver.cpp:244]     Train net output #1: loss = 0.0508319 (* 1 = 0.0508319 loss)
I0819 03:52:17.190088 22726 sgd_solver.cpp:166] Iteration 22500, lr = 0.5625
I0819 03:54:34.881371 22726 solver.cpp:337] Iteration 22600, Testing net (#0)
I0819 03:55:59.368935 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87708
I0819 03:55:59.369199 22726 solver.cpp:404]     Test net output #1: loss = 0.484669 (* 1 = 0.484669 loss)
I0819 03:56:00.699885 22726 solver.cpp:228] Iteration 22600, loss = 0.0353315
I0819 03:56:00.699930 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 03:56:00.699954 22726 solver.cpp:244]     Train net output #1: loss = 0.0353313 (* 1 = 0.0353313 loss)
I0819 03:56:00.782331 22726 sgd_solver.cpp:166] Iteration 22600, lr = 0.565
I0819 03:58:18.287509 22726 solver.cpp:337] Iteration 22700, Testing net (#0)
I0819 03:59:42.776525 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8798
I0819 03:59:42.776792 22726 solver.cpp:404]     Test net output #1: loss = 0.474579 (* 1 = 0.474579 loss)
I0819 03:59:44.107669 22726 solver.cpp:228] Iteration 22700, loss = 0.0356973
I0819 03:59:44.107712 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 03:59:44.107728 22726 solver.cpp:244]     Train net output #1: loss = 0.0356972 (* 1 = 0.0356972 loss)
I0819 03:59:44.184329 22726 sgd_solver.cpp:166] Iteration 22700, lr = 0.5675
I0819 04:02:01.669769 22726 solver.cpp:337] Iteration 22800, Testing net (#0)
I0819 04:03:26.157282 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88308
I0819 04:03:26.157572 22726 solver.cpp:404]     Test net output #1: loss = 0.468605 (* 1 = 0.468605 loss)
I0819 04:03:27.488450 22726 solver.cpp:228] Iteration 22800, loss = 0.0341361
I0819 04:03:27.488492 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 04:03:27.488509 22726 solver.cpp:244]     Train net output #1: loss = 0.0341359 (* 1 = 0.0341359 loss)
I0819 04:03:27.570318 22726 sgd_solver.cpp:166] Iteration 22800, lr = 0.57
I0819 04:05:45.093235 22726 solver.cpp:337] Iteration 22900, Testing net (#0)
I0819 04:07:09.571548 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87588
I0819 04:07:09.571841 22726 solver.cpp:404]     Test net output #1: loss = 0.4874 (* 1 = 0.4874 loss)
I0819 04:07:10.903285 22726 solver.cpp:228] Iteration 22900, loss = 0.0592216
I0819 04:07:10.903319 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 04:07:10.903334 22726 solver.cpp:244]     Train net output #1: loss = 0.0592215 (* 1 = 0.0592215 loss)
I0819 04:07:10.982668 22726 sgd_solver.cpp:166] Iteration 22900, lr = 0.5725
I0819 04:09:28.573071 22726 solver.cpp:337] Iteration 23000, Testing net (#0)
I0819 04:10:53.050364 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88564
I0819 04:10:53.050653 22726 solver.cpp:404]     Test net output #1: loss = 0.469927 (* 1 = 0.469927 loss)
I0819 04:10:54.381106 22726 solver.cpp:228] Iteration 23000, loss = 0.0871131
I0819 04:10:54.381148 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 04:10:54.381165 22726 solver.cpp:244]     Train net output #1: loss = 0.087113 (* 1 = 0.087113 loss)
I0819 04:10:54.459182 22726 sgd_solver.cpp:166] Iteration 23000, lr = 0.575
I0819 04:13:12.028575 22726 solver.cpp:337] Iteration 23100, Testing net (#0)
I0819 04:14:36.512460 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87376
I0819 04:14:36.512749 22726 solver.cpp:404]     Test net output #1: loss = 0.487162 (* 1 = 0.487162 loss)
I0819 04:14:37.843852 22726 solver.cpp:228] Iteration 23100, loss = 0.236982
I0819 04:14:37.843899 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 04:14:37.843915 22726 solver.cpp:244]     Train net output #1: loss = 0.236982 (* 1 = 0.236982 loss)
I0819 04:14:37.925348 22726 sgd_solver.cpp:166] Iteration 23100, lr = 0.5775
I0819 04:16:55.429299 22726 solver.cpp:337] Iteration 23200, Testing net (#0)
I0819 04:18:19.914960 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87876
I0819 04:18:19.915256 22726 solver.cpp:404]     Test net output #1: loss = 0.492639 (* 1 = 0.492639 loss)
I0819 04:18:21.245857 22726 solver.cpp:228] Iteration 23200, loss = 0.0440318
I0819 04:18:21.245901 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 04:18:21.245918 22726 solver.cpp:244]     Train net output #1: loss = 0.0440317 (* 1 = 0.0440317 loss)
I0819 04:18:21.325213 22726 sgd_solver.cpp:166] Iteration 23200, lr = 0.58
I0819 04:20:38.933439 22726 solver.cpp:337] Iteration 23300, Testing net (#0)
I0819 04:22:03.390478 22726 solver.cpp:404]     Test net output #0: accuracy = 0.882
I0819 04:22:03.390745 22726 solver.cpp:404]     Test net output #1: loss = 0.461311 (* 1 = 0.461311 loss)
I0819 04:22:04.721233 22726 solver.cpp:228] Iteration 23300, loss = 0.0257344
I0819 04:22:04.721273 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 04:22:04.721289 22726 solver.cpp:244]     Train net output #1: loss = 0.0257342 (* 1 = 0.0257342 loss)
I0819 04:22:04.798672 22726 sgd_solver.cpp:166] Iteration 23300, lr = 0.5825
I0819 04:24:22.435708 22726 solver.cpp:337] Iteration 23400, Testing net (#0)
I0819 04:25:46.892371 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87828
I0819 04:25:46.892665 22726 solver.cpp:404]     Test net output #1: loss = 0.489395 (* 1 = 0.489395 loss)
I0819 04:25:48.224138 22726 solver.cpp:228] Iteration 23400, loss = 0.0714437
I0819 04:25:48.224179 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 04:25:48.224195 22726 solver.cpp:244]     Train net output #1: loss = 0.0714436 (* 1 = 0.0714436 loss)
I0819 04:25:48.303414 22726 sgd_solver.cpp:166] Iteration 23400, lr = 0.585
I0819 04:28:05.857091 22726 solver.cpp:337] Iteration 23500, Testing net (#0)
I0819 04:29:30.312263 22726 solver.cpp:404]     Test net output #0: accuracy = 0.883
I0819 04:29:30.312556 22726 solver.cpp:404]     Test net output #1: loss = 0.45823 (* 1 = 0.45823 loss)
I0819 04:29:31.642931 22726 solver.cpp:228] Iteration 23500, loss = 0.0363407
I0819 04:29:31.642971 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 04:29:31.642987 22726 solver.cpp:244]     Train net output #1: loss = 0.0363406 (* 1 = 0.0363406 loss)
I0819 04:29:31.723845 22726 sgd_solver.cpp:166] Iteration 23500, lr = 0.5875
I0819 04:31:49.322610 22726 solver.cpp:337] Iteration 23600, Testing net (#0)
I0819 04:33:13.777420 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88212
I0819 04:33:13.777707 22726 solver.cpp:404]     Test net output #1: loss = 0.463813 (* 1 = 0.463813 loss)
I0819 04:33:15.108806 22726 solver.cpp:228] Iteration 23600, loss = 0.0599348
I0819 04:33:15.108844 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 04:33:15.108860 22726 solver.cpp:244]     Train net output #1: loss = 0.0599346 (* 1 = 0.0599346 loss)
I0819 04:33:15.189540 22726 sgd_solver.cpp:166] Iteration 23600, lr = 0.59
I0819 04:35:32.780957 22726 solver.cpp:337] Iteration 23700, Testing net (#0)
I0819 04:36:57.248723 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88116
I0819 04:36:57.248992 22726 solver.cpp:404]     Test net output #1: loss = 0.4589 (* 1 = 0.4589 loss)
I0819 04:36:58.579576 22726 solver.cpp:228] Iteration 23700, loss = 0.0778266
I0819 04:36:58.579617 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 04:36:58.579633 22726 solver.cpp:244]     Train net output #1: loss = 0.0778265 (* 1 = 0.0778265 loss)
I0819 04:36:58.657552 22726 sgd_solver.cpp:166] Iteration 23700, lr = 0.5925
I0819 04:39:16.246486 22726 solver.cpp:337] Iteration 23800, Testing net (#0)
I0819 04:40:40.705482 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88076
I0819 04:40:40.705775 22726 solver.cpp:404]     Test net output #1: loss = 0.459125 (* 1 = 0.459125 loss)
I0819 04:40:42.036780 22726 solver.cpp:228] Iteration 23800, loss = 0.0749915
I0819 04:40:42.036823 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 04:40:42.036840 22726 solver.cpp:244]     Train net output #1: loss = 0.0749913 (* 1 = 0.0749913 loss)
I0819 04:40:42.114086 22726 sgd_solver.cpp:166] Iteration 23800, lr = 0.595
I0819 04:42:59.732697 22726 solver.cpp:337] Iteration 23900, Testing net (#0)
I0819 04:44:24.194689 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87848
I0819 04:44:24.194980 22726 solver.cpp:404]     Test net output #1: loss = 0.493283 (* 1 = 0.493283 loss)
I0819 04:44:25.526355 22726 solver.cpp:228] Iteration 23900, loss = 0.0936261
I0819 04:44:25.526398 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 04:44:25.526414 22726 solver.cpp:244]     Train net output #1: loss = 0.0936259 (* 1 = 0.0936259 loss)
I0819 04:44:25.610347 22726 sgd_solver.cpp:166] Iteration 23900, lr = 0.5975
I0819 04:46:43.259791 22726 solver.cpp:337] Iteration 24000, Testing net (#0)
I0819 04:48:07.716704 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87708
I0819 04:48:07.716996 22726 solver.cpp:404]     Test net output #1: loss = 0.477583 (* 1 = 0.477583 loss)
I0819 04:48:09.047652 22726 solver.cpp:228] Iteration 24000, loss = 0.02903
I0819 04:48:09.047696 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 04:48:09.047713 22726 solver.cpp:244]     Train net output #1: loss = 0.0290299 (* 1 = 0.0290299 loss)
I0819 04:48:09.130548 22726 sgd_solver.cpp:166] Iteration 24000, lr = 0.6
I0819 04:50:26.689924 22726 solver.cpp:337] Iteration 24100, Testing net (#0)
I0819 04:51:51.146947 22726 solver.cpp:404]     Test net output #0: accuracy = 0.877
I0819 04:51:51.147238 22726 solver.cpp:404]     Test net output #1: loss = 0.488176 (* 1 = 0.488176 loss)
I0819 04:51:52.477867 22726 solver.cpp:228] Iteration 24100, loss = 0.0615974
I0819 04:51:52.477916 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 04:51:52.477932 22726 solver.cpp:244]     Train net output #1: loss = 0.0615973 (* 1 = 0.0615973 loss)
I0819 04:51:52.559157 22726 sgd_solver.cpp:166] Iteration 24100, lr = 0.6025
I0819 04:54:10.214411 22726 solver.cpp:337] Iteration 24200, Testing net (#0)
I0819 04:55:34.687310 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8744
I0819 04:55:34.687607 22726 solver.cpp:404]     Test net output #1: loss = 0.485464 (* 1 = 0.485464 loss)
I0819 04:55:36.018260 22726 solver.cpp:228] Iteration 24200, loss = 0.0321902
I0819 04:55:36.018306 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 04:55:36.018321 22726 solver.cpp:244]     Train net output #1: loss = 0.0321901 (* 1 = 0.0321901 loss)
I0819 04:55:36.102149 22726 sgd_solver.cpp:166] Iteration 24200, lr = 0.605
I0819 04:57:53.586674 22726 solver.cpp:337] Iteration 24300, Testing net (#0)
I0819 04:59:18.073104 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88084
I0819 04:59:18.073405 22726 solver.cpp:404]     Test net output #1: loss = 0.474353 (* 1 = 0.474353 loss)
I0819 04:59:19.404537 22726 solver.cpp:228] Iteration 24300, loss = 0.0832481
I0819 04:59:19.404579 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 04:59:19.404595 22726 solver.cpp:244]     Train net output #1: loss = 0.083248 (* 1 = 0.083248 loss)
I0819 04:59:19.479970 22726 sgd_solver.cpp:166] Iteration 24300, lr = 0.6075
I0819 05:01:37.027858 22726 solver.cpp:337] Iteration 24400, Testing net (#0)
I0819 05:03:01.516618 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87952
I0819 05:03:01.516916 22726 solver.cpp:404]     Test net output #1: loss = 0.463567 (* 1 = 0.463567 loss)
I0819 05:03:02.847942 22726 solver.cpp:228] Iteration 24400, loss = 0.0514444
I0819 05:03:02.847983 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 05:03:02.848000 22726 solver.cpp:244]     Train net output #1: loss = 0.0514442 (* 1 = 0.0514442 loss)
I0819 05:03:02.924166 22726 sgd_solver.cpp:166] Iteration 24400, lr = 0.61
I0819 05:05:20.586771 22726 solver.cpp:337] Iteration 24500, Testing net (#0)
I0819 05:06:45.067095 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8752
I0819 05:06:45.067385 22726 solver.cpp:404]     Test net output #1: loss = 0.479359 (* 1 = 0.479359 loss)
I0819 05:06:46.397573 22726 solver.cpp:228] Iteration 24500, loss = 0.0662786
I0819 05:06:46.397614 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 05:06:46.397630 22726 solver.cpp:244]     Train net output #1: loss = 0.0662785 (* 1 = 0.0662785 loss)
I0819 05:06:46.476166 22726 sgd_solver.cpp:166] Iteration 24500, lr = 0.6125
I0819 05:09:04.052575 22726 solver.cpp:337] Iteration 24600, Testing net (#0)
I0819 05:10:28.537678 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8824
I0819 05:10:28.537981 22726 solver.cpp:404]     Test net output #1: loss = 0.457576 (* 1 = 0.457576 loss)
I0819 05:10:29.869333 22726 solver.cpp:228] Iteration 24600, loss = 0.0652849
I0819 05:10:29.869374 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 05:10:29.869390 22726 solver.cpp:244]     Train net output #1: loss = 0.0652847 (* 1 = 0.0652847 loss)
I0819 05:10:29.950007 22726 sgd_solver.cpp:166] Iteration 24600, lr = 0.615
I0819 05:12:47.552130 22726 solver.cpp:337] Iteration 24700, Testing net (#0)
I0819 05:14:12.038257 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8812
I0819 05:14:12.038545 22726 solver.cpp:404]     Test net output #1: loss = 0.495876 (* 1 = 0.495876 loss)
I0819 05:14:13.369097 22726 solver.cpp:228] Iteration 24700, loss = 0.0468816
I0819 05:14:13.369138 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 05:14:13.369153 22726 solver.cpp:244]     Train net output #1: loss = 0.0468815 (* 1 = 0.0468815 loss)
I0819 05:14:13.448947 22726 sgd_solver.cpp:166] Iteration 24700, lr = 0.6175
I0819 05:16:31.023110 22726 solver.cpp:337] Iteration 24800, Testing net (#0)
I0819 05:17:55.518759 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8794
I0819 05:17:55.519048 22726 solver.cpp:404]     Test net output #1: loss = 0.491293 (* 1 = 0.491293 loss)
I0819 05:17:56.850028 22726 solver.cpp:228] Iteration 24800, loss = 0.0799649
I0819 05:17:56.850067 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 05:17:56.850082 22726 solver.cpp:244]     Train net output #1: loss = 0.0799647 (* 1 = 0.0799647 loss)
I0819 05:17:56.926234 22726 sgd_solver.cpp:166] Iteration 24800, lr = 0.62
I0819 05:20:14.481108 22726 solver.cpp:337] Iteration 24900, Testing net (#0)
I0819 05:21:38.969002 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88016
I0819 05:21:38.969280 22726 solver.cpp:404]     Test net output #1: loss = 0.468315 (* 1 = 0.468315 loss)
I0819 05:21:40.299995 22726 solver.cpp:228] Iteration 24900, loss = 0.047255
I0819 05:21:40.300035 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 05:21:40.300051 22726 solver.cpp:244]     Train net output #1: loss = 0.0472548 (* 1 = 0.0472548 loss)
I0819 05:21:40.375252 22726 sgd_solver.cpp:166] Iteration 24900, lr = 0.6225
I0819 05:23:57.917480 22726 solver.cpp:337] Iteration 25000, Testing net (#0)
I0819 05:25:22.399060 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8824
I0819 05:25:22.399361 22726 solver.cpp:404]     Test net output #1: loss = 0.454587 (* 1 = 0.454587 loss)
I0819 05:25:23.729856 22726 solver.cpp:228] Iteration 25000, loss = 0.138741
I0819 05:25:23.729900 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 05:25:23.729917 22726 solver.cpp:244]     Train net output #1: loss = 0.138741 (* 1 = 0.138741 loss)
I0819 05:25:23.808523 22726 sgd_solver.cpp:166] Iteration 25000, lr = 0.625
I0819 05:27:41.322656 22726 solver.cpp:337] Iteration 25100, Testing net (#0)
I0819 05:29:05.808116 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87844
I0819 05:29:05.808405 22726 solver.cpp:404]     Test net output #1: loss = 0.464759 (* 1 = 0.464759 loss)
I0819 05:29:07.138952 22726 solver.cpp:228] Iteration 25100, loss = 0.0737811
I0819 05:29:07.138993 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 05:29:07.139008 22726 solver.cpp:244]     Train net output #1: loss = 0.0737809 (* 1 = 0.0737809 loss)
I0819 05:29:07.215884 22726 sgd_solver.cpp:166] Iteration 25100, lr = 0.6275
I0819 05:31:24.780077 22726 solver.cpp:337] Iteration 25200, Testing net (#0)
I0819 05:32:49.269105 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88192
I0819 05:32:49.269376 22726 solver.cpp:404]     Test net output #1: loss = 0.442422 (* 1 = 0.442422 loss)
I0819 05:32:50.600419 22726 solver.cpp:228] Iteration 25200, loss = 0.0710785
I0819 05:32:50.600458 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 05:32:50.600474 22726 solver.cpp:244]     Train net output #1: loss = 0.0710783 (* 1 = 0.0710783 loss)
I0819 05:32:50.684945 22726 sgd_solver.cpp:166] Iteration 25200, lr = 0.63
I0819 05:35:08.285670 22726 solver.cpp:337] Iteration 25300, Testing net (#0)
I0819 05:36:32.773685 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88112
I0819 05:36:32.773980 22726 solver.cpp:404]     Test net output #1: loss = 0.462586 (* 1 = 0.462586 loss)
I0819 05:36:34.104174 22726 solver.cpp:228] Iteration 25300, loss = 0.093051
I0819 05:36:34.104215 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 05:36:34.104231 22726 solver.cpp:244]     Train net output #1: loss = 0.0930508 (* 1 = 0.0930508 loss)
I0819 05:36:34.184005 22726 sgd_solver.cpp:166] Iteration 25300, lr = 0.6325
I0819 05:38:51.757361 22726 solver.cpp:337] Iteration 25400, Testing net (#0)
I0819 05:40:16.239111 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87704
I0819 05:40:16.239404 22726 solver.cpp:404]     Test net output #1: loss = 0.486293 (* 1 = 0.486293 loss)
I0819 05:40:17.570716 22726 solver.cpp:228] Iteration 25400, loss = 0.0809407
I0819 05:40:17.570757 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 05:40:17.570773 22726 solver.cpp:244]     Train net output #1: loss = 0.0809406 (* 1 = 0.0809406 loss)
I0819 05:40:17.647682 22726 sgd_solver.cpp:166] Iteration 25400, lr = 0.635
I0819 05:42:35.139672 22726 solver.cpp:337] Iteration 25500, Testing net (#0)
I0819 05:43:59.625900 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8758
I0819 05:43:59.626185 22726 solver.cpp:404]     Test net output #1: loss = 0.478881 (* 1 = 0.478881 loss)
I0819 05:44:00.956594 22726 solver.cpp:228] Iteration 25500, loss = 0.0951998
I0819 05:44:00.956634 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 05:44:00.956650 22726 solver.cpp:244]     Train net output #1: loss = 0.0951996 (* 1 = 0.0951996 loss)
I0819 05:44:01.036783 22726 sgd_solver.cpp:166] Iteration 25500, lr = 0.6375
I0819 05:46:18.649487 22726 solver.cpp:337] Iteration 25600, Testing net (#0)
I0819 05:47:43.127486 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88296
I0819 05:47:43.127780 22726 solver.cpp:404]     Test net output #1: loss = 0.441769 (* 1 = 0.441769 loss)
I0819 05:47:44.458873 22726 solver.cpp:228] Iteration 25600, loss = 0.0295325
I0819 05:47:44.458919 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 05:47:44.458935 22726 solver.cpp:244]     Train net output #1: loss = 0.0295323 (* 1 = 0.0295323 loss)
I0819 05:47:44.545380 22726 sgd_solver.cpp:166] Iteration 25600, lr = 0.64
I0819 05:50:02.233638 22726 solver.cpp:337] Iteration 25700, Testing net (#0)
I0819 05:51:26.723971 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88592
I0819 05:51:26.724261 22726 solver.cpp:404]     Test net output #1: loss = 0.447057 (* 1 = 0.447057 loss)
I0819 05:51:28.055510 22726 solver.cpp:228] Iteration 25700, loss = 0.0502407
I0819 05:51:28.055549 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 05:51:28.055564 22726 solver.cpp:244]     Train net output #1: loss = 0.0502405 (* 1 = 0.0502405 loss)
I0819 05:51:28.139192 22726 sgd_solver.cpp:166] Iteration 25700, lr = 0.6425
I0819 05:53:45.726301 22726 solver.cpp:337] Iteration 25800, Testing net (#0)
I0819 05:55:10.215291 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87864
I0819 05:55:10.215560 22726 solver.cpp:404]     Test net output #1: loss = 0.468352 (* 1 = 0.468352 loss)
I0819 05:55:11.545909 22726 solver.cpp:228] Iteration 25800, loss = 0.0867184
I0819 05:55:11.545951 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 05:55:11.545967 22726 solver.cpp:244]     Train net output #1: loss = 0.0867182 (* 1 = 0.0867182 loss)
I0819 05:55:11.627460 22726 sgd_solver.cpp:166] Iteration 25800, lr = 0.645
I0819 05:57:29.180927 22726 solver.cpp:337] Iteration 25900, Testing net (#0)
I0819 05:58:53.668370 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88208
I0819 05:58:53.668653 22726 solver.cpp:404]     Test net output #1: loss = 0.458939 (* 1 = 0.458939 loss)
I0819 05:58:54.999531 22726 solver.cpp:228] Iteration 25900, loss = 0.0352016
I0819 05:58:54.999573 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 05:58:54.999588 22726 solver.cpp:244]     Train net output #1: loss = 0.0352015 (* 1 = 0.0352015 loss)
I0819 05:58:55.080618 22726 sgd_solver.cpp:166] Iteration 25900, lr = 0.6475
I0819 06:01:12.673604 22726 solver.cpp:337] Iteration 26000, Testing net (#0)
I0819 06:02:37.162083 22726 solver.cpp:404]     Test net output #0: accuracy = 0.881
I0819 06:02:37.162384 22726 solver.cpp:404]     Test net output #1: loss = 0.451584 (* 1 = 0.451584 loss)
I0819 06:02:38.492838 22726 solver.cpp:228] Iteration 26000, loss = 0.0492581
I0819 06:02:38.492880 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 06:02:38.492902 22726 solver.cpp:244]     Train net output #1: loss = 0.0492579 (* 1 = 0.0492579 loss)
I0819 06:02:38.568439 22726 sgd_solver.cpp:166] Iteration 26000, lr = 0.65
I0819 06:04:56.127777 22726 solver.cpp:337] Iteration 26100, Testing net (#0)
I0819 06:06:20.607095 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88412
I0819 06:06:20.607375 22726 solver.cpp:404]     Test net output #1: loss = 0.44984 (* 1 = 0.44984 loss)
I0819 06:06:21.938021 22726 solver.cpp:228] Iteration 26100, loss = 0.119083
I0819 06:06:21.938064 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 06:06:21.938081 22726 solver.cpp:244]     Train net output #1: loss = 0.119083 (* 1 = 0.119083 loss)
I0819 06:06:22.022622 22726 sgd_solver.cpp:166] Iteration 26100, lr = 0.6525
I0819 06:08:39.573710 22726 solver.cpp:337] Iteration 26200, Testing net (#0)
I0819 06:10:04.064144 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88504
I0819 06:10:04.064414 22726 solver.cpp:404]     Test net output #1: loss = 0.453514 (* 1 = 0.453514 loss)
I0819 06:10:05.395072 22726 solver.cpp:228] Iteration 26200, loss = 0.0823812
I0819 06:10:05.395114 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 06:10:05.395130 22726 solver.cpp:244]     Train net output #1: loss = 0.082381 (* 1 = 0.082381 loss)
I0819 06:10:05.478298 22726 sgd_solver.cpp:166] Iteration 26200, lr = 0.655
I0819 06:12:22.968006 22726 solver.cpp:337] Iteration 26300, Testing net (#0)
I0819 06:13:47.456609 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87752
I0819 06:13:47.456884 22726 solver.cpp:404]     Test net output #1: loss = 0.467114 (* 1 = 0.467114 loss)
I0819 06:13:48.787492 22726 solver.cpp:228] Iteration 26300, loss = 0.120645
I0819 06:13:48.787533 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 06:13:48.787547 22726 solver.cpp:244]     Train net output #1: loss = 0.120645 (* 1 = 0.120645 loss)
I0819 06:13:48.877843 22726 sgd_solver.cpp:166] Iteration 26300, lr = 0.6575
I0819 06:16:06.456817 22726 solver.cpp:337] Iteration 26400, Testing net (#0)
I0819 06:17:30.942454 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87648
I0819 06:17:30.942745 22726 solver.cpp:404]     Test net output #1: loss = 0.469825 (* 1 = 0.469825 loss)
I0819 06:17:32.273207 22726 solver.cpp:228] Iteration 26400, loss = 0.0574865
I0819 06:17:32.273248 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 06:17:32.273263 22726 solver.cpp:244]     Train net output #1: loss = 0.0574863 (* 1 = 0.0574863 loss)
I0819 06:17:32.355197 22726 sgd_solver.cpp:166] Iteration 26400, lr = 0.66
I0819 06:19:49.918382 22726 solver.cpp:337] Iteration 26500, Testing net (#0)
I0819 06:21:14.405526 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88456
I0819 06:21:14.405827 22726 solver.cpp:404]     Test net output #1: loss = 0.459103 (* 1 = 0.459103 loss)
I0819 06:21:15.736326 22726 solver.cpp:228] Iteration 26500, loss = 0.132251
I0819 06:21:15.736368 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 06:21:15.736383 22726 solver.cpp:244]     Train net output #1: loss = 0.132251 (* 1 = 0.132251 loss)
I0819 06:21:15.817337 22726 sgd_solver.cpp:166] Iteration 26500, lr = 0.6625
I0819 06:23:33.358072 22726 solver.cpp:337] Iteration 26600, Testing net (#0)
I0819 06:24:57.848551 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88068
I0819 06:24:57.848847 22726 solver.cpp:404]     Test net output #1: loss = 0.445853 (* 1 = 0.445853 loss)
I0819 06:24:59.179903 22726 solver.cpp:228] Iteration 26600, loss = 0.113274
I0819 06:24:59.179944 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 06:24:59.179960 22726 solver.cpp:244]     Train net output #1: loss = 0.113274 (* 1 = 0.113274 loss)
I0819 06:24:59.260092 22726 sgd_solver.cpp:166] Iteration 26600, lr = 0.665
I0819 06:27:16.864543 22726 solver.cpp:337] Iteration 26700, Testing net (#0)
I0819 06:28:41.349993 22726 solver.cpp:404]     Test net output #0: accuracy = 0.882001
I0819 06:28:41.350288 22726 solver.cpp:404]     Test net output #1: loss = 0.450391 (* 1 = 0.450391 loss)
I0819 06:28:42.681252 22726 solver.cpp:228] Iteration 26700, loss = 0.0408975
I0819 06:28:42.681296 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 06:28:42.681313 22726 solver.cpp:244]     Train net output #1: loss = 0.0408974 (* 1 = 0.0408974 loss)
I0819 06:28:42.756858 22726 sgd_solver.cpp:166] Iteration 26700, lr = 0.6675
I0819 06:31:00.289816 22726 solver.cpp:337] Iteration 26800, Testing net (#0)
I0819 06:32:24.776046 22726 solver.cpp:404]     Test net output #0: accuracy = 0.879
I0819 06:32:24.776357 22726 solver.cpp:404]     Test net output #1: loss = 0.466892 (* 1 = 0.466892 loss)
I0819 06:32:26.107376 22726 solver.cpp:228] Iteration 26800, loss = 0.0690098
I0819 06:32:26.107419 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 06:32:26.107435 22726 solver.cpp:244]     Train net output #1: loss = 0.0690097 (* 1 = 0.0690097 loss)
I0819 06:32:26.186947 22726 sgd_solver.cpp:166] Iteration 26800, lr = 0.67
I0819 06:34:43.661782 22726 solver.cpp:337] Iteration 26900, Testing net (#0)
I0819 06:36:08.149242 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88264
I0819 06:36:08.149536 22726 solver.cpp:404]     Test net output #1: loss = 0.458961 (* 1 = 0.458961 loss)
I0819 06:36:09.479650 22726 solver.cpp:228] Iteration 26900, loss = 0.0871134
I0819 06:36:09.479691 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 06:36:09.479707 22726 solver.cpp:244]     Train net output #1: loss = 0.0871133 (* 1 = 0.0871133 loss)
I0819 06:36:09.559552 22726 sgd_solver.cpp:166] Iteration 26900, lr = 0.6725
I0819 06:38:27.113730 22726 solver.cpp:337] Iteration 27000, Testing net (#0)
I0819 06:39:51.573583 22726 solver.cpp:404]     Test net output #0: accuracy = 0.879
I0819 06:39:51.573880 22726 solver.cpp:404]     Test net output #1: loss = 0.474752 (* 1 = 0.474752 loss)
I0819 06:39:52.905042 22726 solver.cpp:228] Iteration 27000, loss = 0.0598202
I0819 06:39:52.905084 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 06:39:52.905100 22726 solver.cpp:244]     Train net output #1: loss = 0.0598201 (* 1 = 0.0598201 loss)
I0819 06:39:52.984563 22726 sgd_solver.cpp:166] Iteration 27000, lr = 0.675
I0819 06:42:10.485963 22726 solver.cpp:337] Iteration 27100, Testing net (#0)
I0819 06:43:34.928470 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88272
I0819 06:43:34.928766 22726 solver.cpp:404]     Test net output #1: loss = 0.463085 (* 1 = 0.463085 loss)
I0819 06:43:36.259395 22726 solver.cpp:228] Iteration 27100, loss = 0.112513
I0819 06:43:36.259436 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 06:43:36.259451 22726 solver.cpp:244]     Train net output #1: loss = 0.112513 (* 1 = 0.112513 loss)
I0819 06:43:36.345286 22726 sgd_solver.cpp:166] Iteration 27100, lr = 0.6775
I0819 06:45:53.951169 22726 solver.cpp:337] Iteration 27200, Testing net (#0)
I0819 06:47:18.385004 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8838
I0819 06:47:18.385298 22726 solver.cpp:404]     Test net output #1: loss = 0.453018 (* 1 = 0.453018 loss)
I0819 06:47:19.715742 22726 solver.cpp:228] Iteration 27200, loss = 0.0802916
I0819 06:47:19.715782 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 06:47:19.715798 22726 solver.cpp:244]     Train net output #1: loss = 0.0802915 (* 1 = 0.0802915 loss)
I0819 06:47:19.800151 22726 sgd_solver.cpp:166] Iteration 27200, lr = 0.68
I0819 06:49:37.255568 22726 solver.cpp:337] Iteration 27300, Testing net (#0)
I0819 06:51:01.682680 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87596
I0819 06:51:01.682981 22726 solver.cpp:404]     Test net output #1: loss = 0.473708 (* 1 = 0.473708 loss)
I0819 06:51:03.013392 22726 solver.cpp:228] Iteration 27300, loss = 0.142912
I0819 06:51:03.013432 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 06:51:03.013447 22726 solver.cpp:244]     Train net output #1: loss = 0.142912 (* 1 = 0.142912 loss)
I0819 06:51:03.098876 22726 sgd_solver.cpp:166] Iteration 27300, lr = 0.6825
I0819 06:53:20.636397 22726 solver.cpp:337] Iteration 27400, Testing net (#0)
I0819 06:54:45.065546 22726 solver.cpp:404]     Test net output #0: accuracy = 0.883001
I0819 06:54:45.065845 22726 solver.cpp:404]     Test net output #1: loss = 0.459462 (* 1 = 0.459462 loss)
I0819 06:54:46.396705 22726 solver.cpp:228] Iteration 27400, loss = 0.0770613
I0819 06:54:46.396739 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 06:54:46.396754 22726 solver.cpp:244]     Train net output #1: loss = 0.0770612 (* 1 = 0.0770612 loss)
I0819 06:54:46.481763 22726 sgd_solver.cpp:166] Iteration 27400, lr = 0.685
I0819 06:57:03.994168 22726 solver.cpp:337] Iteration 27500, Testing net (#0)
I0819 06:58:28.412155 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8834
I0819 06:58:28.412451 22726 solver.cpp:404]     Test net output #1: loss = 0.448715 (* 1 = 0.448715 loss)
I0819 06:58:29.742729 22726 solver.cpp:228] Iteration 27500, loss = 0.156186
I0819 06:58:29.742774 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 06:58:29.742790 22726 solver.cpp:244]     Train net output #1: loss = 0.156186 (* 1 = 0.156186 loss)
I0819 06:58:29.830536 22726 sgd_solver.cpp:166] Iteration 27500, lr = 0.6875
I0819 07:00:47.338673 22726 solver.cpp:337] Iteration 27600, Testing net (#0)
I0819 07:02:11.755456 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87548
I0819 07:02:11.755756 22726 solver.cpp:404]     Test net output #1: loss = 0.486752 (* 1 = 0.486752 loss)
I0819 07:02:13.086973 22726 solver.cpp:228] Iteration 27600, loss = 0.11594
I0819 07:02:13.087018 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 07:02:13.087033 22726 solver.cpp:244]     Train net output #1: loss = 0.11594 (* 1 = 0.11594 loss)
I0819 07:02:13.169059 22726 sgd_solver.cpp:166] Iteration 27600, lr = 0.69
I0819 07:04:30.670137 22726 solver.cpp:337] Iteration 27700, Testing net (#0)
I0819 07:05:55.092340 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87272
I0819 07:05:55.092638 22726 solver.cpp:404]     Test net output #1: loss = 0.494312 (* 1 = 0.494312 loss)
I0819 07:05:56.424507 22726 solver.cpp:228] Iteration 27700, loss = 0.0198901
I0819 07:05:56.424554 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 07:05:56.424571 22726 solver.cpp:244]     Train net output #1: loss = 0.01989 (* 1 = 0.01989 loss)
I0819 07:05:56.500816 22726 sgd_solver.cpp:166] Iteration 27700, lr = 0.6925
I0819 07:08:14.008148 22726 solver.cpp:337] Iteration 27800, Testing net (#0)
I0819 07:09:38.437664 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87752
I0819 07:09:38.437961 22726 solver.cpp:404]     Test net output #1: loss = 0.476626 (* 1 = 0.476626 loss)
I0819 07:09:39.768388 22726 solver.cpp:228] Iteration 27800, loss = 0.107985
I0819 07:09:39.768432 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 07:09:39.768448 22726 solver.cpp:244]     Train net output #1: loss = 0.107985 (* 1 = 0.107985 loss)
I0819 07:09:39.856386 22726 sgd_solver.cpp:166] Iteration 27800, lr = 0.695
I0819 07:11:57.340117 22726 solver.cpp:337] Iteration 27900, Testing net (#0)
I0819 07:13:21.791393 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86732
I0819 07:13:21.791700 22726 solver.cpp:404]     Test net output #1: loss = 0.518662 (* 1 = 0.518662 loss)
I0819 07:13:23.122964 22726 solver.cpp:228] Iteration 27900, loss = 0.102919
I0819 07:13:23.123008 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 07:13:23.123023 22726 solver.cpp:244]     Train net output #1: loss = 0.102919 (* 1 = 0.102919 loss)
I0819 07:13:23.199403 22726 sgd_solver.cpp:166] Iteration 27900, lr = 0.6975
I0819 07:15:40.717337 22726 solver.cpp:337] Iteration 28000, Testing net (#0)
I0819 07:17:05.166455 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87844
I0819 07:17:05.166731 22726 solver.cpp:404]     Test net output #1: loss = 0.465273 (* 1 = 0.465273 loss)
I0819 07:17:06.497808 22726 solver.cpp:228] Iteration 28000, loss = 0.0495978
I0819 07:17:06.497853 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 07:17:06.497870 22726 solver.cpp:244]     Train net output #1: loss = 0.0495977 (* 1 = 0.0495977 loss)
I0819 07:17:06.580052 22726 sgd_solver.cpp:166] Iteration 28000, lr = 0.7
I0819 07:19:24.065837 22726 solver.cpp:337] Iteration 28100, Testing net (#0)
I0819 07:20:48.537274 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8832
I0819 07:20:48.537576 22726 solver.cpp:404]     Test net output #1: loss = 0.464446 (* 1 = 0.464446 loss)
I0819 07:20:49.868727 22726 solver.cpp:228] Iteration 28100, loss = 0.0177448
I0819 07:20:49.868772 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 07:20:49.868788 22726 solver.cpp:244]     Train net output #1: loss = 0.0177447 (* 1 = 0.0177447 loss)
I0819 07:20:49.945477 22726 sgd_solver.cpp:166] Iteration 28100, lr = 0.7025
I0819 07:23:07.427564 22726 solver.cpp:337] Iteration 28200, Testing net (#0)
I0819 07:24:31.886791 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88204
I0819 07:24:31.887102 22726 solver.cpp:404]     Test net output #1: loss = 0.439488 (* 1 = 0.439488 loss)
I0819 07:24:33.218436 22726 solver.cpp:228] Iteration 28200, loss = 0.0941644
I0819 07:24:33.218482 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 07:24:33.218497 22726 solver.cpp:244]     Train net output #1: loss = 0.0941643 (* 1 = 0.0941643 loss)
I0819 07:24:33.300583 22726 sgd_solver.cpp:166] Iteration 28200, lr = 0.705
I0819 07:26:50.816999 22726 solver.cpp:337] Iteration 28300, Testing net (#0)
I0819 07:28:15.281016 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87928
I0819 07:28:15.281321 22726 solver.cpp:404]     Test net output #1: loss = 0.458815 (* 1 = 0.458815 loss)
I0819 07:28:16.612169 22726 solver.cpp:228] Iteration 28300, loss = 0.0681918
I0819 07:28:16.612215 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 07:28:16.612231 22726 solver.cpp:244]     Train net output #1: loss = 0.0681917 (* 1 = 0.0681917 loss)
I0819 07:28:16.686738 22726 sgd_solver.cpp:166] Iteration 28300, lr = 0.7075
I0819 07:30:34.193379 22726 solver.cpp:337] Iteration 28400, Testing net (#0)
I0819 07:31:58.662559 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88208
I0819 07:31:58.662863 22726 solver.cpp:404]     Test net output #1: loss = 0.438144 (* 1 = 0.438144 loss)
I0819 07:31:59.994540 22726 solver.cpp:228] Iteration 28400, loss = 0.0600953
I0819 07:31:59.994585 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 07:31:59.994601 22726 solver.cpp:244]     Train net output #1: loss = 0.0600953 (* 1 = 0.0600953 loss)
I0819 07:32:00.074731 22726 sgd_solver.cpp:166] Iteration 28400, lr = 0.71
I0819 07:34:17.655331 22726 solver.cpp:337] Iteration 28500, Testing net (#0)
I0819 07:35:42.176884 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88276
I0819 07:35:42.177194 22726 solver.cpp:404]     Test net output #1: loss = 0.451774 (* 1 = 0.451774 loss)
I0819 07:35:43.508854 22726 solver.cpp:228] Iteration 28500, loss = 0.103162
I0819 07:35:43.508893 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 07:35:43.508916 22726 solver.cpp:244]     Train net output #1: loss = 0.103162 (* 1 = 0.103162 loss)
I0819 07:35:43.588739 22726 sgd_solver.cpp:166] Iteration 28500, lr = 0.7125
I0819 07:38:01.152281 22726 solver.cpp:337] Iteration 28600, Testing net (#0)
I0819 07:39:25.750975 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88148
I0819 07:39:25.751288 22726 solver.cpp:404]     Test net output #1: loss = 0.448099 (* 1 = 0.448099 loss)
I0819 07:39:27.082736 22726 solver.cpp:228] Iteration 28600, loss = 0.0450188
I0819 07:39:27.082772 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 07:39:27.082797 22726 solver.cpp:244]     Train net output #1: loss = 0.0450186 (* 1 = 0.0450186 loss)
I0819 07:39:27.155804 22726 sgd_solver.cpp:166] Iteration 28600, lr = 0.715
I0819 07:41:44.651414 22726 solver.cpp:337] Iteration 28700, Testing net (#0)
I0819 07:43:09.150485 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86812
I0819 07:43:09.150789 22726 solver.cpp:404]     Test net output #1: loss = 0.505146 (* 1 = 0.505146 loss)
I0819 07:43:10.481431 22726 solver.cpp:228] Iteration 28700, loss = 0.156289
I0819 07:43:10.481465 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 07:43:10.481480 22726 solver.cpp:244]     Train net output #1: loss = 0.156289 (* 1 = 0.156289 loss)
I0819 07:43:10.565367 22726 sgd_solver.cpp:166] Iteration 28700, lr = 0.7175
I0819 07:45:28.029793 22726 solver.cpp:337] Iteration 28800, Testing net (#0)
I0819 07:46:52.498466 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88284
I0819 07:46:52.498760 22726 solver.cpp:404]     Test net output #1: loss = 0.45542 (* 1 = 0.45542 loss)
I0819 07:46:53.829105 22726 solver.cpp:228] Iteration 28800, loss = 0.105531
I0819 07:46:53.829140 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 07:46:53.829155 22726 solver.cpp:244]     Train net output #1: loss = 0.105531 (* 1 = 0.105531 loss)
I0819 07:46:53.911573 22726 sgd_solver.cpp:166] Iteration 28800, lr = 0.72
I0819 07:49:11.426317 22726 solver.cpp:337] Iteration 28900, Testing net (#0)
I0819 07:50:35.892714 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88232
I0819 07:50:35.893023 22726 solver.cpp:404]     Test net output #1: loss = 0.440219 (* 1 = 0.440219 loss)
I0819 07:50:37.224474 22726 solver.cpp:228] Iteration 28900, loss = 0.0447241
I0819 07:50:37.224508 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 07:50:37.224522 22726 solver.cpp:244]     Train net output #1: loss = 0.0447239 (* 1 = 0.0447239 loss)
I0819 07:50:37.308351 22726 sgd_solver.cpp:166] Iteration 28900, lr = 0.7225
I0819 07:52:54.776530 22726 solver.cpp:337] Iteration 29000, Testing net (#0)
I0819 07:54:19.289494 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87692
I0819 07:54:19.289767 22726 solver.cpp:404]     Test net output #1: loss = 0.471826 (* 1 = 0.471826 loss)
I0819 07:54:20.621137 22726 solver.cpp:228] Iteration 29000, loss = 0.109903
I0819 07:54:20.621171 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 07:54:20.621187 22726 solver.cpp:244]     Train net output #1: loss = 0.109902 (* 1 = 0.109902 loss)
I0819 07:54:20.695471 22726 sgd_solver.cpp:166] Iteration 29000, lr = 0.725
I0819 07:56:38.248457 22726 solver.cpp:337] Iteration 29100, Testing net (#0)
I0819 07:58:02.702216 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88332
I0819 07:58:02.702515 22726 solver.cpp:404]     Test net output #1: loss = 0.457141 (* 1 = 0.457141 loss)
I0819 07:58:04.034198 22726 solver.cpp:228] Iteration 29100, loss = 0.0524762
I0819 07:58:04.034234 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 07:58:04.034248 22726 solver.cpp:244]     Train net output #1: loss = 0.0524761 (* 1 = 0.0524761 loss)
I0819 07:58:04.109503 22726 sgd_solver.cpp:166] Iteration 29100, lr = 0.7275
I0819 08:00:21.610076 22726 solver.cpp:337] Iteration 29200, Testing net (#0)
I0819 08:01:46.060887 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87976
I0819 08:01:46.061363 22726 solver.cpp:404]     Test net output #1: loss = 0.461656 (* 1 = 0.461656 loss)
I0819 08:01:47.391974 22726 solver.cpp:228] Iteration 29200, loss = 0.0488679
I0819 08:01:47.392009 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 08:01:47.392024 22726 solver.cpp:244]     Train net output #1: loss = 0.0488678 (* 1 = 0.0488678 loss)
I0819 08:01:47.473618 22726 sgd_solver.cpp:166] Iteration 29200, lr = 0.73
I0819 08:04:04.987969 22726 solver.cpp:337] Iteration 29300, Testing net (#0)
I0819 08:05:29.462198 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88128
I0819 08:05:29.462502 22726 solver.cpp:404]     Test net output #1: loss = 0.45795 (* 1 = 0.45795 loss)
I0819 08:05:30.793684 22726 solver.cpp:228] Iteration 29300, loss = 0.0480825
I0819 08:05:30.793720 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 08:05:30.793735 22726 solver.cpp:244]     Train net output #1: loss = 0.0480824 (* 1 = 0.0480824 loss)
I0819 08:05:30.875633 22726 sgd_solver.cpp:166] Iteration 29300, lr = 0.7325
I0819 08:07:48.326345 22726 solver.cpp:337] Iteration 29400, Testing net (#0)
I0819 08:09:12.775975 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88212
I0819 08:09:12.776284 22726 solver.cpp:404]     Test net output #1: loss = 0.431411 (* 1 = 0.431411 loss)
I0819 08:09:14.107455 22726 solver.cpp:228] Iteration 29400, loss = 0.0547697
I0819 08:09:14.107489 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 08:09:14.107504 22726 solver.cpp:244]     Train net output #1: loss = 0.0547696 (* 1 = 0.0547696 loss)
I0819 08:09:14.187139 22726 sgd_solver.cpp:166] Iteration 29400, lr = 0.735
I0819 08:11:31.795578 22726 solver.cpp:337] Iteration 29500, Testing net (#0)
I0819 08:12:56.252795 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88472
I0819 08:12:56.253113 22726 solver.cpp:404]     Test net output #1: loss = 0.441078 (* 1 = 0.441078 loss)
I0819 08:12:57.584944 22726 solver.cpp:228] Iteration 29500, loss = 0.0624006
I0819 08:12:57.584978 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 08:12:57.584993 22726 solver.cpp:244]     Train net output #1: loss = 0.0624005 (* 1 = 0.0624005 loss)
I0819 08:12:57.658684 22726 sgd_solver.cpp:166] Iteration 29500, lr = 0.7375
I0819 08:15:15.175357 22726 solver.cpp:337] Iteration 29600, Testing net (#0)
I0819 08:16:39.620723 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88012
I0819 08:16:39.621037 22726 solver.cpp:404]     Test net output #1: loss = 0.449989 (* 1 = 0.449989 loss)
I0819 08:16:40.952549 22726 solver.cpp:228] Iteration 29600, loss = 0.0501943
I0819 08:16:40.952601 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 08:16:40.952618 22726 solver.cpp:244]     Train net output #1: loss = 0.0501942 (* 1 = 0.0501942 loss)
I0819 08:16:41.031301 22726 sgd_solver.cpp:166] Iteration 29600, lr = 0.74
I0819 08:18:58.692787 22726 solver.cpp:337] Iteration 29700, Testing net (#0)
I0819 08:20:23.130172 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87604
I0819 08:20:23.130475 22726 solver.cpp:404]     Test net output #1: loss = 0.46689 (* 1 = 0.46689 loss)
I0819 08:20:24.461685 22726 solver.cpp:228] Iteration 29700, loss = 0.116709
I0819 08:20:24.461720 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 08:20:24.461736 22726 solver.cpp:244]     Train net output #1: loss = 0.116709 (* 1 = 0.116709 loss)
I0819 08:20:24.544579 22726 sgd_solver.cpp:166] Iteration 29700, lr = 0.7425
I0819 08:22:42.038801 22726 solver.cpp:337] Iteration 29800, Testing net (#0)
I0819 08:24:06.479215 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88648
I0819 08:24:06.479514 22726 solver.cpp:404]     Test net output #1: loss = 0.446691 (* 1 = 0.446691 loss)
I0819 08:24:07.810636 22726 solver.cpp:228] Iteration 29800, loss = 0.115177
I0819 08:24:07.810672 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 08:24:07.810686 22726 solver.cpp:244]     Train net output #1: loss = 0.115177 (* 1 = 0.115177 loss)
I0819 08:24:07.890632 22726 sgd_solver.cpp:166] Iteration 29800, lr = 0.745
I0819 08:26:25.461063 22726 solver.cpp:337] Iteration 29900, Testing net (#0)
I0819 08:27:49.906792 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88492
I0819 08:27:49.907100 22726 solver.cpp:404]     Test net output #1: loss = 0.435137 (* 1 = 0.435137 loss)
I0819 08:27:51.237764 22726 solver.cpp:228] Iteration 29900, loss = 0.0910353
I0819 08:27:51.237799 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 08:27:51.237814 22726 solver.cpp:244]     Train net output #1: loss = 0.0910352 (* 1 = 0.0910352 loss)
I0819 08:27:51.318048 22726 sgd_solver.cpp:166] Iteration 29900, lr = 0.7475
I0819 08:30:08.912600 22726 solver.cpp:337] Iteration 30000, Testing net (#0)
I0819 08:31:33.342260 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8874
I0819 08:31:33.342536 22726 solver.cpp:404]     Test net output #1: loss = 0.413032 (* 1 = 0.413032 loss)
I0819 08:31:34.673228 22726 solver.cpp:228] Iteration 30000, loss = 0.0702202
I0819 08:31:34.673264 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 08:31:34.673279 22726 solver.cpp:244]     Train net output #1: loss = 0.0702201 (* 1 = 0.0702201 loss)
I0819 08:31:34.754127 22726 sgd_solver.cpp:166] Iteration 30000, lr = 0.75
I0819 08:33:52.545085 22726 solver.cpp:337] Iteration 30100, Testing net (#0)
I0819 08:35:16.976094 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87968
I0819 08:35:16.976385 22726 solver.cpp:404]     Test net output #1: loss = 0.448139 (* 1 = 0.448139 loss)
I0819 08:35:18.306871 22726 solver.cpp:228] Iteration 30100, loss = 0.139183
I0819 08:35:18.306912 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 08:35:18.306928 22726 solver.cpp:244]     Train net output #1: loss = 0.139183 (* 1 = 0.139183 loss)
I0819 08:35:18.382403 22726 sgd_solver.cpp:166] Iteration 30100, lr = 0.7525
I0819 08:37:36.017807 22726 solver.cpp:337] Iteration 30200, Testing net (#0)
I0819 08:39:00.447352 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88708
I0819 08:39:00.447650 22726 solver.cpp:404]     Test net output #1: loss = 0.435095 (* 1 = 0.435095 loss)
I0819 08:39:01.778164 22726 solver.cpp:228] Iteration 30200, loss = 0.10561
I0819 08:39:01.778199 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 08:39:01.778215 22726 solver.cpp:244]     Train net output #1: loss = 0.10561 (* 1 = 0.10561 loss)
I0819 08:39:01.855389 22726 sgd_solver.cpp:166] Iteration 30200, lr = 0.755
I0819 08:41:19.466261 22726 solver.cpp:337] Iteration 30300, Testing net (#0)
I0819 08:42:43.920336 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87736
I0819 08:42:43.920637 22726 solver.cpp:404]     Test net output #1: loss = 0.471028 (* 1 = 0.471028 loss)
I0819 08:42:45.251106 22726 solver.cpp:228] Iteration 30300, loss = 0.106829
I0819 08:42:45.251142 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 08:42:45.251157 22726 solver.cpp:244]     Train net output #1: loss = 0.106829 (* 1 = 0.106829 loss)
I0819 08:42:45.335074 22726 sgd_solver.cpp:166] Iteration 30300, lr = 0.7575
I0819 08:45:02.900081 22726 solver.cpp:337] Iteration 30400, Testing net (#0)
I0819 08:46:27.346904 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87972
I0819 08:46:27.347183 22726 solver.cpp:404]     Test net output #1: loss = 0.444016 (* 1 = 0.444016 loss)
I0819 08:46:28.678191 22726 solver.cpp:228] Iteration 30400, loss = 0.0793023
I0819 08:46:28.678228 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 08:46:28.678242 22726 solver.cpp:244]     Train net output #1: loss = 0.0793022 (* 1 = 0.0793022 loss)
I0819 08:46:28.755342 22726 sgd_solver.cpp:166] Iteration 30400, lr = 0.76
I0819 08:48:46.424283 22726 solver.cpp:337] Iteration 30500, Testing net (#0)
I0819 08:50:10.851583 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86392
I0819 08:50:10.851867 22726 solver.cpp:404]     Test net output #1: loss = 0.522773 (* 1 = 0.522773 loss)
I0819 08:50:12.182643 22726 solver.cpp:228] Iteration 30500, loss = 0.202588
I0819 08:50:12.182679 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0819 08:50:12.182693 22726 solver.cpp:244]     Train net output #1: loss = 0.202588 (* 1 = 0.202588 loss)
I0819 08:50:12.265075 22726 sgd_solver.cpp:166] Iteration 30500, lr = 0.7625
I0819 08:52:30.024327 22726 solver.cpp:337] Iteration 30600, Testing net (#0)
I0819 08:53:54.454108 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88392
I0819 08:53:54.454411 22726 solver.cpp:404]     Test net output #1: loss = 0.447723 (* 1 = 0.447723 loss)
I0819 08:53:55.785562 22726 solver.cpp:228] Iteration 30600, loss = 0.067538
I0819 08:53:55.785596 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 08:53:55.785612 22726 solver.cpp:244]     Train net output #1: loss = 0.0675379 (* 1 = 0.0675379 loss)
I0819 08:53:55.867256 22726 sgd_solver.cpp:166] Iteration 30600, lr = 0.765
I0819 08:56:13.516572 22726 solver.cpp:337] Iteration 30700, Testing net (#0)
I0819 08:57:37.901700 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88136
I0819 08:57:37.901995 22726 solver.cpp:404]     Test net output #1: loss = 0.440899 (* 1 = 0.440899 loss)
I0819 08:57:39.232271 22726 solver.cpp:228] Iteration 30700, loss = 0.187685
I0819 08:57:39.232306 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 08:57:39.232321 22726 solver.cpp:244]     Train net output #1: loss = 0.187685 (* 1 = 0.187685 loss)
I0819 08:57:39.309661 22726 sgd_solver.cpp:166] Iteration 30700, lr = 0.7675
I0819 08:59:57.043928 22726 solver.cpp:337] Iteration 30800, Testing net (#0)
I0819 09:01:21.435783 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88564
I0819 09:01:21.436096 22726 solver.cpp:404]     Test net output #1: loss = 0.422293 (* 1 = 0.422293 loss)
I0819 09:01:22.766752 22726 solver.cpp:228] Iteration 30800, loss = 0.0701362
I0819 09:01:22.766788 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 09:01:22.766803 22726 solver.cpp:244]     Train net output #1: loss = 0.0701361 (* 1 = 0.0701361 loss)
I0819 09:01:22.849817 22726 sgd_solver.cpp:166] Iteration 30800, lr = 0.77
I0819 09:03:40.414904 22726 solver.cpp:337] Iteration 30900, Testing net (#0)
I0819 09:05:04.810963 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88688
I0819 09:05:04.811254 22726 solver.cpp:404]     Test net output #1: loss = 0.437515 (* 1 = 0.437515 loss)
I0819 09:05:06.140928 22726 solver.cpp:228] Iteration 30900, loss = 0.0682294
I0819 09:05:06.140964 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 09:05:06.140980 22726 solver.cpp:244]     Train net output #1: loss = 0.0682293 (* 1 = 0.0682293 loss)
I0819 09:05:06.221652 22726 sgd_solver.cpp:166] Iteration 30900, lr = 0.7725
I0819 09:07:23.712203 22726 solver.cpp:337] Iteration 31000, Testing net (#0)
I0819 09:08:48.110756 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88164
I0819 09:08:48.111068 22726 solver.cpp:404]     Test net output #1: loss = 0.438578 (* 1 = 0.438578 loss)
I0819 09:08:49.441674 22726 solver.cpp:228] Iteration 31000, loss = 0.122047
I0819 09:08:49.441709 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 09:08:49.441725 22726 solver.cpp:244]     Train net output #1: loss = 0.122047 (* 1 = 0.122047 loss)
I0819 09:08:49.518422 22726 sgd_solver.cpp:166] Iteration 31000, lr = 0.775
I0819 09:11:07.025246 22726 solver.cpp:337] Iteration 31100, Testing net (#0)
I0819 09:12:31.425832 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88224
I0819 09:12:31.426143 22726 solver.cpp:404]     Test net output #1: loss = 0.428616 (* 1 = 0.428616 loss)
I0819 09:12:32.757129 22726 solver.cpp:228] Iteration 31100, loss = 0.0618621
I0819 09:12:32.757164 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 09:12:32.757179 22726 solver.cpp:244]     Train net output #1: loss = 0.0618621 (* 1 = 0.0618621 loss)
I0819 09:12:32.841480 22726 sgd_solver.cpp:166] Iteration 31100, lr = 0.7775
I0819 09:14:50.374440 22726 solver.cpp:337] Iteration 31200, Testing net (#0)
I0819 09:16:14.774495 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88444
I0819 09:16:14.774791 22726 solver.cpp:404]     Test net output #1: loss = 0.430021 (* 1 = 0.430021 loss)
I0819 09:16:16.105670 22726 solver.cpp:228] Iteration 31200, loss = 0.0794078
I0819 09:16:16.105705 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 09:16:16.105720 22726 solver.cpp:244]     Train net output #1: loss = 0.0794078 (* 1 = 0.0794078 loss)
I0819 09:16:16.184119 22726 sgd_solver.cpp:166] Iteration 31200, lr = 0.78
I0819 09:18:33.788861 22726 solver.cpp:337] Iteration 31300, Testing net (#0)
I0819 09:19:58.188262 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88312
I0819 09:19:58.188544 22726 solver.cpp:404]     Test net output #1: loss = 0.442896 (* 1 = 0.442896 loss)
I0819 09:19:59.519289 22726 solver.cpp:228] Iteration 31300, loss = 0.0593549
I0819 09:19:59.519326 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 09:19:59.519341 22726 solver.cpp:244]     Train net output #1: loss = 0.0593549 (* 1 = 0.0593549 loss)
I0819 09:19:59.598203 22726 sgd_solver.cpp:166] Iteration 31300, lr = 0.7825
I0819 09:22:17.202491 22726 solver.cpp:337] Iteration 31400, Testing net (#0)
I0819 09:23:41.595706 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87672
I0819 09:23:41.596035 22726 solver.cpp:404]     Test net output #1: loss = 0.458991 (* 1 = 0.458991 loss)
I0819 09:23:42.926709 22726 solver.cpp:228] Iteration 31400, loss = 0.176648
I0819 09:23:42.926743 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 09:23:42.926759 22726 solver.cpp:244]     Train net output #1: loss = 0.176648 (* 1 = 0.176648 loss)
I0819 09:23:43.007608 22726 sgd_solver.cpp:166] Iteration 31400, lr = 0.785
I0819 09:26:00.629330 22726 solver.cpp:337] Iteration 31500, Testing net (#0)
I0819 09:27:25.022791 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8732
I0819 09:27:25.023102 22726 solver.cpp:404]     Test net output #1: loss = 0.468902 (* 1 = 0.468902 loss)
I0819 09:27:26.353657 22726 solver.cpp:228] Iteration 31500, loss = 0.0581237
I0819 09:27:26.353691 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 09:27:26.353708 22726 solver.cpp:244]     Train net output #1: loss = 0.0581237 (* 1 = 0.0581237 loss)
I0819 09:27:26.434201 22726 sgd_solver.cpp:166] Iteration 31500, lr = 0.7875
I0819 09:29:44.031363 22726 solver.cpp:337] Iteration 31600, Testing net (#0)
I0819 09:31:08.459061 22726 solver.cpp:404]     Test net output #0: accuracy = 0.881681
I0819 09:31:08.459358 22726 solver.cpp:404]     Test net output #1: loss = 0.444472 (* 1 = 0.444472 loss)
I0819 09:31:09.790043 22726 solver.cpp:228] Iteration 31600, loss = 0.122762
I0819 09:31:09.790077 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 09:31:09.790092 22726 solver.cpp:244]     Train net output #1: loss = 0.122762 (* 1 = 0.122762 loss)
I0819 09:31:09.870307 22726 sgd_solver.cpp:166] Iteration 31600, lr = 0.79
I0819 09:33:27.480787 22726 solver.cpp:337] Iteration 31700, Testing net (#0)
I0819 09:34:51.908298 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88444
I0819 09:34:51.908598 22726 solver.cpp:404]     Test net output #1: loss = 0.423642 (* 1 = 0.423642 loss)
I0819 09:34:53.239573 22726 solver.cpp:228] Iteration 31700, loss = 0.0663246
I0819 09:34:53.239608 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 09:34:53.239622 22726 solver.cpp:244]     Train net output #1: loss = 0.0663246 (* 1 = 0.0663246 loss)
I0819 09:34:53.314913 22726 sgd_solver.cpp:166] Iteration 31700, lr = 0.7925
I0819 09:37:10.890817 22726 solver.cpp:337] Iteration 31800, Testing net (#0)
I0819 09:38:35.317184 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87556
I0819 09:38:35.317486 22726 solver.cpp:404]     Test net output #1: loss = 0.448354 (* 1 = 0.448354 loss)
I0819 09:38:36.648483 22726 solver.cpp:228] Iteration 31800, loss = 0.0679408
I0819 09:38:36.648519 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 09:38:36.648535 22726 solver.cpp:244]     Train net output #1: loss = 0.0679407 (* 1 = 0.0679407 loss)
I0819 09:38:36.727701 22726 sgd_solver.cpp:166] Iteration 31800, lr = 0.795
I0819 09:40:54.302242 22726 solver.cpp:337] Iteration 31900, Testing net (#0)
I0819 09:42:18.730010 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87972
I0819 09:42:18.730314 22726 solver.cpp:404]     Test net output #1: loss = 0.431533 (* 1 = 0.431533 loss)
I0819 09:42:20.061266 22726 solver.cpp:228] Iteration 31900, loss = 0.0841815
I0819 09:42:20.061302 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 09:42:20.061318 22726 solver.cpp:244]     Train net output #1: loss = 0.0841814 (* 1 = 0.0841814 loss)
I0819 09:42:20.141485 22726 sgd_solver.cpp:166] Iteration 31900, lr = 0.7975
I0819 09:44:37.698171 22726 solver.cpp:337] Iteration 32000, Testing net (#0)
I0819 09:46:02.120311 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8806
I0819 09:46:02.120604 22726 solver.cpp:404]     Test net output #1: loss = 0.453481 (* 1 = 0.453481 loss)
I0819 09:46:03.451647 22726 solver.cpp:228] Iteration 32000, loss = 0.174344
I0819 09:46:03.451683 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 09:46:03.451699 22726 solver.cpp:244]     Train net output #1: loss = 0.174344 (* 1 = 0.174344 loss)
I0819 09:46:03.533208 22726 sgd_solver.cpp:166] Iteration 32000, lr = 0.8
I0819 09:48:21.116336 22726 solver.cpp:337] Iteration 32100, Testing net (#0)
I0819 09:49:45.532085 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88036
I0819 09:49:45.532388 22726 solver.cpp:404]     Test net output #1: loss = 0.456768 (* 1 = 0.456768 loss)
I0819 09:49:46.862479 22726 solver.cpp:228] Iteration 32100, loss = 0.0786766
I0819 09:49:46.862514 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 09:49:46.862529 22726 solver.cpp:244]     Train net output #1: loss = 0.0786765 (* 1 = 0.0786765 loss)
I0819 09:49:46.945642 22726 sgd_solver.cpp:166] Iteration 32100, lr = 0.8025
I0819 09:52:04.558830 22726 solver.cpp:337] Iteration 32200, Testing net (#0)
I0819 09:53:28.977447 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87716
I0819 09:53:28.977751 22726 solver.cpp:404]     Test net output #1: loss = 0.469742 (* 1 = 0.469742 loss)
I0819 09:53:30.308924 22726 solver.cpp:228] Iteration 32200, loss = 0.0861462
I0819 09:53:30.308959 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 09:53:30.308975 22726 solver.cpp:244]     Train net output #1: loss = 0.0861461 (* 1 = 0.0861461 loss)
I0819 09:53:30.391372 22726 sgd_solver.cpp:166] Iteration 32200, lr = 0.805
I0819 09:55:48.034144 22726 solver.cpp:337] Iteration 32300, Testing net (#0)
I0819 09:57:12.453557 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88712
I0819 09:57:12.453857 22726 solver.cpp:404]     Test net output #1: loss = 0.41867 (* 1 = 0.41867 loss)
I0819 09:57:13.785284 22726 solver.cpp:228] Iteration 32300, loss = 0.0508906
I0819 09:57:13.785317 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 09:57:13.785333 22726 solver.cpp:244]     Train net output #1: loss = 0.0508904 (* 1 = 0.0508904 loss)
I0819 09:57:13.864079 22726 sgd_solver.cpp:166] Iteration 32300, lr = 0.8075
I0819 09:59:31.485033 22726 solver.cpp:337] Iteration 32400, Testing net (#0)
I0819 10:00:55.958323 22726 solver.cpp:404]     Test net output #0: accuracy = 0.886
I0819 10:00:55.958626 22726 solver.cpp:404]     Test net output #1: loss = 0.425182 (* 1 = 0.425182 loss)
I0819 10:00:57.290150 22726 solver.cpp:228] Iteration 32400, loss = 0.127637
I0819 10:00:57.290189 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 10:00:57.290211 22726 solver.cpp:244]     Train net output #1: loss = 0.127637 (* 1 = 0.127637 loss)
I0819 10:00:57.372195 22726 sgd_solver.cpp:166] Iteration 32400, lr = 0.81
I0819 10:03:14.964088 22726 solver.cpp:337] Iteration 32500, Testing net (#0)
I0819 10:04:39.472631 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87736
I0819 10:04:39.472915 22726 solver.cpp:404]     Test net output #1: loss = 0.458994 (* 1 = 0.458994 loss)
I0819 10:04:40.804404 22726 solver.cpp:228] Iteration 32500, loss = 0.131199
I0819 10:04:40.804443 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 10:04:40.804466 22726 solver.cpp:244]     Train net output #1: loss = 0.131199 (* 1 = 0.131199 loss)
I0819 10:04:40.880033 22726 sgd_solver.cpp:166] Iteration 32500, lr = 0.8125
I0819 10:06:58.487534 22726 solver.cpp:337] Iteration 32600, Testing net (#0)
I0819 10:08:22.993618 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87876
I0819 10:08:22.993911 22726 solver.cpp:404]     Test net output #1: loss = 0.447293 (* 1 = 0.447293 loss)
I0819 10:08:24.325448 22726 solver.cpp:228] Iteration 32600, loss = 0.0982114
I0819 10:08:24.325487 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 10:08:24.325511 22726 solver.cpp:244]     Train net output #1: loss = 0.0982113 (* 1 = 0.0982113 loss)
I0819 10:08:24.409907 22726 sgd_solver.cpp:166] Iteration 32600, lr = 0.815
I0819 10:10:41.915285 22726 solver.cpp:337] Iteration 32700, Testing net (#0)
I0819 10:12:06.466159 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87712
I0819 10:12:06.466460 22726 solver.cpp:404]     Test net output #1: loss = 0.471629 (* 1 = 0.471629 loss)
I0819 10:12:07.798305 22726 solver.cpp:228] Iteration 32700, loss = 0.0407355
I0819 10:12:07.798343 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 10:12:07.798367 22726 solver.cpp:244]     Train net output #1: loss = 0.0407355 (* 1 = 0.0407355 loss)
I0819 10:12:07.876168 22726 sgd_solver.cpp:166] Iteration 32700, lr = 0.8175
I0819 10:14:25.482998 22726 solver.cpp:337] Iteration 32800, Testing net (#0)
I0819 10:15:49.986681 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87844
I0819 10:15:49.986981 22726 solver.cpp:404]     Test net output #1: loss = 0.447842 (* 1 = 0.447842 loss)
I0819 10:15:51.318658 22726 solver.cpp:228] Iteration 32800, loss = 0.0934006
I0819 10:15:51.318696 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 10:15:51.318718 22726 solver.cpp:244]     Train net output #1: loss = 0.0934005 (* 1 = 0.0934005 loss)
I0819 10:15:51.396833 22726 sgd_solver.cpp:166] Iteration 32800, lr = 0.82
I0819 10:18:08.914808 22726 solver.cpp:337] Iteration 32900, Testing net (#0)
I0819 10:19:33.351028 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8816
I0819 10:19:33.351346 22726 solver.cpp:404]     Test net output #1: loss = 0.441188 (* 1 = 0.441188 loss)
I0819 10:19:34.682919 22726 solver.cpp:228] Iteration 32900, loss = 0.127571
I0819 10:19:34.682955 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 10:19:34.682978 22726 solver.cpp:244]     Train net output #1: loss = 0.127571 (* 1 = 0.127571 loss)
I0819 10:19:34.763181 22726 sgd_solver.cpp:166] Iteration 32900, lr = 0.8225
I0819 10:21:52.254976 22726 solver.cpp:337] Iteration 33000, Testing net (#0)
I0819 10:23:16.744729 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88116
I0819 10:23:16.745039 22726 solver.cpp:404]     Test net output #1: loss = 0.451015 (* 1 = 0.451015 loss)
I0819 10:23:18.075876 22726 solver.cpp:228] Iteration 33000, loss = 0.0399886
I0819 10:23:18.075911 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 10:23:18.075935 22726 solver.cpp:244]     Train net output #1: loss = 0.0399885 (* 1 = 0.0399885 loss)
I0819 10:23:18.158650 22726 sgd_solver.cpp:166] Iteration 33000, lr = 0.825
I0819 10:25:35.756805 22726 solver.cpp:337] Iteration 33100, Testing net (#0)
I0819 10:27:00.227275 22726 solver.cpp:404]     Test net output #0: accuracy = 0.880321
I0819 10:27:00.227584 22726 solver.cpp:404]     Test net output #1: loss = 0.439966 (* 1 = 0.439966 loss)
I0819 10:27:01.559412 22726 solver.cpp:228] Iteration 33100, loss = 0.129761
I0819 10:27:01.559449 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 10:27:01.559471 22726 solver.cpp:244]     Train net output #1: loss = 0.129761 (* 1 = 0.129761 loss)
I0819 10:27:01.634296 22726 sgd_solver.cpp:166] Iteration 33100, lr = 0.8275
I0819 10:29:19.259829 22726 solver.cpp:337] Iteration 33200, Testing net (#0)
I0819 10:30:43.741117 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88532
I0819 10:30:43.741430 22726 solver.cpp:404]     Test net output #1: loss = 0.421979 (* 1 = 0.421979 loss)
I0819 10:30:45.072633 22726 solver.cpp:228] Iteration 33200, loss = 0.0850488
I0819 10:30:45.072669 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 10:30:45.072691 22726 solver.cpp:244]     Train net output #1: loss = 0.0850487 (* 1 = 0.0850487 loss)
I0819 10:30:45.157466 22726 sgd_solver.cpp:166] Iteration 33200, lr = 0.83
I0819 10:33:02.810366 22726 solver.cpp:337] Iteration 33300, Testing net (#0)
I0819 10:34:27.304579 22726 solver.cpp:404]     Test net output #0: accuracy = 0.879
I0819 10:34:27.304890 22726 solver.cpp:404]     Test net output #1: loss = 0.442261 (* 1 = 0.442261 loss)
I0819 10:34:28.636648 22726 solver.cpp:228] Iteration 33300, loss = 0.0933326
I0819 10:34:28.636685 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 10:34:28.636708 22726 solver.cpp:244]     Train net output #1: loss = 0.0933325 (* 1 = 0.0933325 loss)
I0819 10:34:28.711511 22726 sgd_solver.cpp:166] Iteration 33300, lr = 0.8325
I0819 10:36:46.197405 22726 solver.cpp:337] Iteration 33400, Testing net (#0)
I0819 10:38:10.655236 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88232
I0819 10:38:10.655541 22726 solver.cpp:404]     Test net output #1: loss = 0.439922 (* 1 = 0.439922 loss)
I0819 10:38:11.987263 22726 solver.cpp:228] Iteration 33400, loss = 0.205085
I0819 10:38:11.987300 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 10:38:11.987323 22726 solver.cpp:244]     Train net output #1: loss = 0.205085 (* 1 = 0.205085 loss)
I0819 10:38:12.066967 22726 sgd_solver.cpp:166] Iteration 33400, lr = 0.835
I0819 10:40:29.606003 22726 solver.cpp:337] Iteration 33500, Testing net (#0)
I0819 10:41:54.063793 22726 solver.cpp:404]     Test net output #0: accuracy = 0.886361
I0819 10:41:54.064116 22726 solver.cpp:404]     Test net output #1: loss = 0.421667 (* 1 = 0.421667 loss)
I0819 10:41:55.395411 22726 solver.cpp:228] Iteration 33500, loss = 0.104513
I0819 10:41:55.395448 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 10:41:55.395472 22726 solver.cpp:244]     Train net output #1: loss = 0.104513 (* 1 = 0.104513 loss)
I0819 10:41:55.477923 22726 sgd_solver.cpp:166] Iteration 33500, lr = 0.8375
I0819 10:44:13.010120 22726 solver.cpp:337] Iteration 33600, Testing net (#0)
I0819 10:45:37.508426 22726 solver.cpp:404]     Test net output #0: accuracy = 0.882601
I0819 10:45:37.508740 22726 solver.cpp:404]     Test net output #1: loss = 0.427444 (* 1 = 0.427444 loss)
I0819 10:45:38.835454 22726 solver.cpp:228] Iteration 33600, loss = 0.107491
I0819 10:45:38.835491 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 10:45:38.835513 22726 solver.cpp:244]     Train net output #1: loss = 0.107491 (* 1 = 0.107491 loss)
I0819 10:45:38.918422 22726 sgd_solver.cpp:166] Iteration 33600, lr = 0.84
I0819 10:47:56.233397 22726 solver.cpp:337] Iteration 33700, Testing net (#0)
I0819 10:49:20.739059 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87804
I0819 10:49:20.739372 22726 solver.cpp:404]     Test net output #1: loss = 0.456359 (* 1 = 0.456359 loss)
I0819 10:49:22.067198 22726 solver.cpp:228] Iteration 33700, loss = 0.121948
I0819 10:49:22.067234 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 10:49:22.067258 22726 solver.cpp:244]     Train net output #1: loss = 0.121948 (* 1 = 0.121948 loss)
I0819 10:49:22.152750 22726 sgd_solver.cpp:166] Iteration 33700, lr = 0.8425
I0819 10:51:39.323415 22726 solver.cpp:337] Iteration 33800, Testing net (#0)
I0819 10:53:03.844954 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88008
I0819 10:53:03.845259 22726 solver.cpp:404]     Test net output #1: loss = 0.44264 (* 1 = 0.44264 loss)
I0819 10:53:05.172906 22726 solver.cpp:228] Iteration 33800, loss = 0.141986
I0819 10:53:05.172951 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 10:53:05.172976 22726 solver.cpp:244]     Train net output #1: loss = 0.141986 (* 1 = 0.141986 loss)
I0819 10:53:05.299018 22726 sgd_solver.cpp:166] Iteration 33800, lr = 0.845
I0819 10:55:22.473892 22726 solver.cpp:337] Iteration 33900, Testing net (#0)
I0819 10:56:46.935714 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88136
I0819 10:56:46.936020 22726 solver.cpp:404]     Test net output #1: loss = 0.432113 (* 1 = 0.432113 loss)
I0819 10:56:48.264398 22726 solver.cpp:228] Iteration 33900, loss = 0.145024
I0819 10:56:48.264434 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 10:56:48.264457 22726 solver.cpp:244]     Train net output #1: loss = 0.145024 (* 1 = 0.145024 loss)
I0819 10:56:48.344640 22726 sgd_solver.cpp:166] Iteration 33900, lr = 0.8475
I0819 10:59:05.669057 22726 solver.cpp:337] Iteration 34000, Testing net (#0)
I0819 11:00:30.181305 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88052
I0819 11:00:30.181612 22726 solver.cpp:404]     Test net output #1: loss = 0.434911 (* 1 = 0.434911 loss)
I0819 11:00:31.508622 22726 solver.cpp:228] Iteration 34000, loss = 0.0850736
I0819 11:00:31.508668 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 11:00:31.508692 22726 solver.cpp:244]     Train net output #1: loss = 0.0850735 (* 1 = 0.0850735 loss)
I0819 11:00:31.591910 22726 sgd_solver.cpp:166] Iteration 34000, lr = 0.85
I0819 11:02:48.879951 22726 solver.cpp:337] Iteration 34100, Testing net (#0)
I0819 11:04:13.375015 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88372
I0819 11:04:13.375313 22726 solver.cpp:404]     Test net output #1: loss = 0.43781 (* 1 = 0.43781 loss)
I0819 11:04:14.702394 22726 solver.cpp:228] Iteration 34100, loss = 0.0988423
I0819 11:04:14.702430 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 11:04:14.702452 22726 solver.cpp:244]     Train net output #1: loss = 0.0988422 (* 1 = 0.0988422 loss)
I0819 11:04:14.782506 22726 sgd_solver.cpp:166] Iteration 34100, lr = 0.8525
I0819 11:06:31.999769 22726 solver.cpp:337] Iteration 34200, Testing net (#0)
I0819 11:07:56.555734 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88128
I0819 11:07:56.556030 22726 solver.cpp:404]     Test net output #1: loss = 0.445191 (* 1 = 0.445191 loss)
I0819 11:07:57.883322 22726 solver.cpp:228] Iteration 34200, loss = 0.139664
I0819 11:07:57.883359 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 11:07:57.883383 22726 solver.cpp:244]     Train net output #1: loss = 0.139664 (* 1 = 0.139664 loss)
I0819 11:07:57.965914 22726 sgd_solver.cpp:166] Iteration 34200, lr = 0.855
I0819 11:10:15.176045 22726 solver.cpp:337] Iteration 34300, Testing net (#0)
I0819 11:11:39.687098 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87476
I0819 11:11:39.687408 22726 solver.cpp:404]     Test net output #1: loss = 0.483347 (* 1 = 0.483347 loss)
I0819 11:11:41.014329 22726 solver.cpp:228] Iteration 34300, loss = 0.0730371
I0819 11:11:41.014366 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 11:11:41.014389 22726 solver.cpp:244]     Train net output #1: loss = 0.073037 (* 1 = 0.073037 loss)
I0819 11:11:41.090283 22726 sgd_solver.cpp:166] Iteration 34300, lr = 0.8575
I0819 11:13:58.274837 22726 solver.cpp:337] Iteration 34400, Testing net (#0)
I0819 11:15:22.742943 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88268
I0819 11:15:22.743219 22726 solver.cpp:404]     Test net output #1: loss = 0.446385 (* 1 = 0.446385 loss)
I0819 11:15:24.071008 22726 solver.cpp:228] Iteration 34400, loss = 0.0893001
I0819 11:15:24.071045 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 11:15:24.071069 22726 solver.cpp:244]     Train net output #1: loss = 0.0893 (* 1 = 0.0893 loss)
I0819 11:15:24.155546 22726 sgd_solver.cpp:166] Iteration 34400, lr = 0.86
I0819 11:17:41.341876 22726 solver.cpp:337] Iteration 34500, Testing net (#0)
I0819 11:19:05.791903 22726 solver.cpp:404]     Test net output #0: accuracy = 0.89036
I0819 11:19:05.792214 22726 solver.cpp:404]     Test net output #1: loss = 0.40551 (* 1 = 0.40551 loss)
I0819 11:19:07.119941 22726 solver.cpp:228] Iteration 34500, loss = 0.0656912
I0819 11:19:07.119978 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 11:19:07.120003 22726 solver.cpp:244]     Train net output #1: loss = 0.0656911 (* 1 = 0.0656911 loss)
I0819 11:19:07.202391 22726 sgd_solver.cpp:166] Iteration 34500, lr = 0.8625
I0819 11:21:24.450196 22726 solver.cpp:337] Iteration 34600, Testing net (#0)
I0819 11:22:48.946360 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86956
I0819 11:22:48.946671 22726 solver.cpp:404]     Test net output #1: loss = 0.485561 (* 1 = 0.485561 loss)
I0819 11:22:50.273499 22726 solver.cpp:228] Iteration 34600, loss = 0.216599
I0819 11:22:50.273533 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 11:22:50.273556 22726 solver.cpp:244]     Train net output #1: loss = 0.216599 (* 1 = 0.216599 loss)
I0819 11:22:50.353615 22726 sgd_solver.cpp:166] Iteration 34600, lr = 0.865
I0819 11:25:07.613142 22726 solver.cpp:337] Iteration 34700, Testing net (#0)
I0819 11:26:32.084223 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87908
I0819 11:26:32.084534 22726 solver.cpp:404]     Test net output #1: loss = 0.47289 (* 1 = 0.47289 loss)
I0819 11:26:33.411763 22726 solver.cpp:228] Iteration 34700, loss = 0.130743
I0819 11:26:33.411810 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 11:26:33.411836 22726 solver.cpp:244]     Train net output #1: loss = 0.130743 (* 1 = 0.130743 loss)
I0819 11:26:33.488091 22726 sgd_solver.cpp:166] Iteration 34700, lr = 0.8675
I0819 11:28:50.681360 22726 solver.cpp:337] Iteration 34800, Testing net (#0)
I0819 11:30:15.180500 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88192
I0819 11:30:15.180811 22726 solver.cpp:404]     Test net output #1: loss = 0.429555 (* 1 = 0.429555 loss)
I0819 11:30:16.508359 22726 solver.cpp:228] Iteration 34800, loss = 0.0583815
I0819 11:30:16.508407 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 11:30:16.508433 22726 solver.cpp:244]     Train net output #1: loss = 0.0583814 (* 1 = 0.0583814 loss)
I0819 11:30:16.585562 22726 sgd_solver.cpp:166] Iteration 34800, lr = 0.87
I0819 11:32:33.761363 22726 solver.cpp:337] Iteration 34900, Testing net (#0)
I0819 11:33:58.218909 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88252
I0819 11:33:58.219230 22726 solver.cpp:404]     Test net output #1: loss = 0.449507 (* 1 = 0.449507 loss)
I0819 11:33:59.547206 22726 solver.cpp:228] Iteration 34900, loss = 0.0590279
I0819 11:33:59.547243 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 11:33:59.547266 22726 solver.cpp:244]     Train net output #1: loss = 0.0590278 (* 1 = 0.0590278 loss)
I0819 11:33:59.625488 22726 sgd_solver.cpp:166] Iteration 34900, lr = 0.8725
I0819 11:36:17.291206 22726 solver.cpp:337] Iteration 35000, Testing net (#0)
I0819 11:37:42.448400 22726 solver.cpp:404]     Test net output #0: accuracy = 0.877281
I0819 11:37:42.448668 22726 solver.cpp:404]     Test net output #1: loss = 0.454246 (* 1 = 0.454246 loss)
I0819 11:37:43.779388 22726 solver.cpp:228] Iteration 35000, loss = 0.130402
I0819 11:37:43.779433 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 11:37:43.779448 22726 solver.cpp:244]     Train net output #1: loss = 0.130402 (* 1 = 0.130402 loss)
I0819 11:37:43.859644 22726 sgd_solver.cpp:166] Iteration 35000, lr = 0.875
I0819 11:40:01.514215 22726 solver.cpp:337] Iteration 35100, Testing net (#0)
I0819 11:41:26.671556 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88368
I0819 11:41:26.671866 22726 solver.cpp:404]     Test net output #1: loss = 0.433497 (* 1 = 0.433497 loss)
I0819 11:41:28.003280 22726 solver.cpp:228] Iteration 35100, loss = 0.12095
I0819 11:41:28.003325 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 11:41:28.003341 22726 solver.cpp:244]     Train net output #1: loss = 0.12095 (* 1 = 0.12095 loss)
I0819 11:41:28.084744 22726 sgd_solver.cpp:166] Iteration 35100, lr = 0.8775
I0819 11:43:45.731544 22726 solver.cpp:337] Iteration 35200, Testing net (#0)
I0819 11:45:10.893591 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87936
I0819 11:45:10.893878 22726 solver.cpp:404]     Test net output #1: loss = 0.470291 (* 1 = 0.470291 loss)
I0819 11:45:12.224889 22726 solver.cpp:228] Iteration 35200, loss = 0.0761982
I0819 11:45:12.224933 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 11:45:12.224949 22726 solver.cpp:244]     Train net output #1: loss = 0.0761982 (* 1 = 0.0761982 loss)
I0819 11:45:12.298589 22726 sgd_solver.cpp:166] Iteration 35200, lr = 0.88
I0819 11:47:30.052994 22726 solver.cpp:337] Iteration 35300, Testing net (#0)
I0819 11:48:55.127668 22726 solver.cpp:404]     Test net output #0: accuracy = 0.881121
I0819 11:48:55.127952 22726 solver.cpp:404]     Test net output #1: loss = 0.429046 (* 1 = 0.429046 loss)
I0819 11:48:56.458364 22726 solver.cpp:228] Iteration 35300, loss = 0.062588
I0819 11:48:56.458410 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 11:48:56.458425 22726 solver.cpp:244]     Train net output #1: loss = 0.0625879 (* 1 = 0.0625879 loss)
I0819 11:48:56.537005 22726 sgd_solver.cpp:166] Iteration 35300, lr = 0.8825
I0819 11:51:14.365465 22726 solver.cpp:337] Iteration 35400, Testing net (#0)
I0819 11:52:39.479009 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8838
I0819 11:52:39.479338 22726 solver.cpp:404]     Test net output #1: loss = 0.430366 (* 1 = 0.430366 loss)
I0819 11:52:40.809991 22726 solver.cpp:228] Iteration 35400, loss = 0.0182442
I0819 11:52:40.810039 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 11:52:40.810053 22726 solver.cpp:244]     Train net output #1: loss = 0.0182441 (* 1 = 0.0182441 loss)
I0819 11:52:40.893828 22726 sgd_solver.cpp:166] Iteration 35400, lr = 0.885
I0819 11:54:58.834329 22726 solver.cpp:337] Iteration 35500, Testing net (#0)
I0819 11:56:23.907274 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88132
I0819 11:56:23.907507 22726 solver.cpp:404]     Test net output #1: loss = 0.436344 (* 1 = 0.436344 loss)
I0819 11:56:25.237797 22726 solver.cpp:228] Iteration 35500, loss = 0.0943684
I0819 11:56:25.237841 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 11:56:25.237859 22726 solver.cpp:244]     Train net output #1: loss = 0.0943683 (* 1 = 0.0943683 loss)
I0819 11:56:25.321229 22726 sgd_solver.cpp:166] Iteration 35500, lr = 0.8875
I0819 11:58:43.124017 22726 solver.cpp:337] Iteration 35600, Testing net (#0)
I0819 12:00:07.552664 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88544
I0819 12:00:07.552970 22726 solver.cpp:404]     Test net output #1: loss = 0.421935 (* 1 = 0.421935 loss)
I0819 12:00:08.883034 22726 solver.cpp:228] Iteration 35600, loss = 0.0581537
I0819 12:00:08.883074 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 12:00:08.883090 22726 solver.cpp:244]     Train net output #1: loss = 0.0581537 (* 1 = 0.0581537 loss)
I0819 12:00:08.961565 22726 sgd_solver.cpp:166] Iteration 35600, lr = 0.89
I0819 12:02:26.765532 22726 solver.cpp:337] Iteration 35700, Testing net (#0)
I0819 12:03:51.200417 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87804
I0819 12:03:51.200721 22726 solver.cpp:404]     Test net output #1: loss = 0.467893 (* 1 = 0.467893 loss)
I0819 12:03:52.531395 22726 solver.cpp:228] Iteration 35700, loss = 0.143833
I0819 12:03:52.531430 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 12:03:52.531443 22726 solver.cpp:244]     Train net output #1: loss = 0.143833 (* 1 = 0.143833 loss)
I0819 12:03:52.610018 22726 sgd_solver.cpp:166] Iteration 35700, lr = 0.8925
I0819 12:06:10.221515 22726 solver.cpp:337] Iteration 35800, Testing net (#0)
I0819 12:07:34.653018 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88916
I0819 12:07:34.653313 22726 solver.cpp:404]     Test net output #1: loss = 0.410016 (* 1 = 0.410016 loss)
I0819 12:07:35.983741 22726 solver.cpp:228] Iteration 35800, loss = 0.098717
I0819 12:07:35.983774 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 12:07:35.983789 22726 solver.cpp:244]     Train net output #1: loss = 0.0987169 (* 1 = 0.0987169 loss)
I0819 12:07:36.069310 22726 sgd_solver.cpp:166] Iteration 35800, lr = 0.895
I0819 12:09:53.644330 22726 solver.cpp:337] Iteration 35900, Testing net (#0)
I0819 12:11:18.075587 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88056
I0819 12:11:18.075893 22726 solver.cpp:404]     Test net output #1: loss = 0.439031 (* 1 = 0.439031 loss)
I0819 12:11:19.406144 22726 solver.cpp:228] Iteration 35900, loss = 0.0531521
I0819 12:11:19.406178 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 12:11:19.406193 22726 solver.cpp:244]     Train net output #1: loss = 0.053152 (* 1 = 0.053152 loss)
I0819 12:11:19.491276 22726 sgd_solver.cpp:166] Iteration 35900, lr = 0.8975
I0819 12:13:37.127110 22726 solver.cpp:337] Iteration 36000, Testing net (#0)
I0819 12:15:01.618541 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87892
I0819 12:15:01.618858 22726 solver.cpp:404]     Test net output #1: loss = 0.444767 (* 1 = 0.444767 loss)
I0819 12:15:02.949357 22726 solver.cpp:228] Iteration 36000, loss = 0.075498
I0819 12:15:02.949393 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 12:15:02.949417 22726 solver.cpp:244]     Train net output #1: loss = 0.0754979 (* 1 = 0.0754979 loss)
I0819 12:15:03.027142 22726 sgd_solver.cpp:166] Iteration 36000, lr = 0.9
I0819 12:17:20.839973 22726 solver.cpp:337] Iteration 36100, Testing net (#0)
I0819 12:18:45.353132 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88072
I0819 12:18:45.353446 22726 solver.cpp:404]     Test net output #1: loss = 0.432587 (* 1 = 0.432587 loss)
I0819 12:18:46.684080 22726 solver.cpp:228] Iteration 36100, loss = 0.100446
I0819 12:18:46.684118 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 12:18:46.684140 22726 solver.cpp:244]     Train net output #1: loss = 0.100446 (* 1 = 0.100446 loss)
I0819 12:18:46.766888 22726 sgd_solver.cpp:166] Iteration 36100, lr = 0.9025
I0819 12:21:04.400185 22726 solver.cpp:337] Iteration 36200, Testing net (#0)
I0819 12:22:28.881675 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88092
I0819 12:22:28.881992 22726 solver.cpp:404]     Test net output #1: loss = 0.416939 (* 1 = 0.416939 loss)
I0819 12:22:30.213584 22726 solver.cpp:228] Iteration 36200, loss = 0.0873027
I0819 12:22:30.213620 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 12:22:30.213644 22726 solver.cpp:244]     Train net output #1: loss = 0.0873027 (* 1 = 0.0873027 loss)
I0819 12:22:30.296900 22726 sgd_solver.cpp:166] Iteration 36200, lr = 0.905
I0819 12:24:47.873881 22726 solver.cpp:337] Iteration 36300, Testing net (#0)
I0819 12:26:12.366545 22726 solver.cpp:404]     Test net output #0: accuracy = 0.879801
I0819 12:26:12.366858 22726 solver.cpp:404]     Test net output #1: loss = 0.438993 (* 1 = 0.438993 loss)
I0819 12:26:13.699185 22726 solver.cpp:228] Iteration 36300, loss = 0.120873
I0819 12:26:13.699223 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 12:26:13.699245 22726 solver.cpp:244]     Train net output #1: loss = 0.120873 (* 1 = 0.120873 loss)
I0819 12:26:13.778205 22726 sgd_solver.cpp:166] Iteration 36300, lr = 0.9075
I0819 12:28:31.381353 22726 solver.cpp:337] Iteration 36400, Testing net (#0)
I0819 12:29:55.821614 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88124
I0819 12:29:55.821933 22726 solver.cpp:404]     Test net output #1: loss = 0.434625 (* 1 = 0.434625 loss)
I0819 12:29:57.152890 22726 solver.cpp:228] Iteration 36400, loss = 0.100242
I0819 12:29:57.152927 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 12:29:57.152951 22726 solver.cpp:244]     Train net output #1: loss = 0.100242 (* 1 = 0.100242 loss)
I0819 12:29:57.232836 22726 sgd_solver.cpp:166] Iteration 36400, lr = 0.91
I0819 12:32:14.883358 22726 solver.cpp:337] Iteration 36500, Testing net (#0)
I0819 12:33:39.367341 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88576
I0819 12:33:39.367661 22726 solver.cpp:404]     Test net output #1: loss = 0.419955 (* 1 = 0.419955 loss)
I0819 12:33:40.699833 22726 solver.cpp:228] Iteration 36500, loss = 0.0504498
I0819 12:33:40.699869 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 12:33:40.699892 22726 solver.cpp:244]     Train net output #1: loss = 0.0504497 (* 1 = 0.0504497 loss)
I0819 12:33:40.781899 22726 sgd_solver.cpp:166] Iteration 36500, lr = 0.9125
I0819 12:35:58.491993 22726 solver.cpp:337] Iteration 36600, Testing net (#0)
I0819 12:37:22.962570 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88612
I0819 12:37:22.962893 22726 solver.cpp:404]     Test net output #1: loss = 0.430964 (* 1 = 0.430964 loss)
I0819 12:37:24.294356 22726 solver.cpp:228] Iteration 36600, loss = 0.119535
I0819 12:37:24.294394 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 12:37:24.294416 22726 solver.cpp:244]     Train net output #1: loss = 0.119535 (* 1 = 0.119535 loss)
I0819 12:37:24.377463 22726 sgd_solver.cpp:166] Iteration 36600, lr = 0.915
I0819 12:39:41.953155 22726 solver.cpp:337] Iteration 36700, Testing net (#0)
I0819 12:41:06.476681 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88312
I0819 12:41:06.476984 22726 solver.cpp:404]     Test net output #1: loss = 0.434615 (* 1 = 0.434615 loss)
I0819 12:41:07.808193 22726 solver.cpp:228] Iteration 36700, loss = 0.14272
I0819 12:41:07.808231 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 12:41:07.808254 22726 solver.cpp:244]     Train net output #1: loss = 0.14272 (* 1 = 0.14272 loss)
I0819 12:41:07.884529 22726 sgd_solver.cpp:166] Iteration 36700, lr = 0.9175
I0819 12:43:25.533535 22726 solver.cpp:337] Iteration 36800, Testing net (#0)
I0819 12:44:50.033421 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87988
I0819 12:44:50.033740 22726 solver.cpp:404]     Test net output #1: loss = 0.440452 (* 1 = 0.440452 loss)
I0819 12:44:51.365067 22726 solver.cpp:228] Iteration 36800, loss = 0.156665
I0819 12:44:51.365104 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 12:44:51.365126 22726 solver.cpp:244]     Train net output #1: loss = 0.156665 (* 1 = 0.156665 loss)
I0819 12:44:51.443770 22726 sgd_solver.cpp:166] Iteration 36800, lr = 0.92
I0819 12:47:09.152087 22726 solver.cpp:337] Iteration 36900, Testing net (#0)
I0819 12:48:33.729378 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88324
I0819 12:48:33.729743 22726 solver.cpp:404]     Test net output #1: loss = 0.419324 (* 1 = 0.419324 loss)
I0819 12:48:35.061101 22726 solver.cpp:228] Iteration 36900, loss = 0.100001
I0819 12:48:35.061138 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 12:48:35.061161 22726 solver.cpp:244]     Train net output #1: loss = 0.100001 (* 1 = 0.100001 loss)
I0819 12:48:35.142506 22726 sgd_solver.cpp:166] Iteration 36900, lr = 0.9225
I0819 12:50:52.821064 22726 solver.cpp:337] Iteration 37000, Testing net (#0)
I0819 12:52:17.361459 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88688
I0819 12:52:17.361774 22726 solver.cpp:404]     Test net output #1: loss = 0.410122 (* 1 = 0.410122 loss)
I0819 12:52:18.693009 22726 solver.cpp:228] Iteration 37000, loss = 0.105938
I0819 12:52:18.693048 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 12:52:18.693076 22726 solver.cpp:244]     Train net output #1: loss = 0.105938 (* 1 = 0.105938 loss)
I0819 12:52:18.775583 22726 sgd_solver.cpp:166] Iteration 37000, lr = 0.925
I0819 12:54:36.325585 22726 solver.cpp:337] Iteration 37100, Testing net (#0)
I0819 12:56:00.893069 22726 solver.cpp:404]     Test net output #0: accuracy = 0.888281
I0819 12:56:00.893401 22726 solver.cpp:404]     Test net output #1: loss = 0.403588 (* 1 = 0.403588 loss)
I0819 12:56:02.225137 22726 solver.cpp:228] Iteration 37100, loss = 0.175607
I0819 12:56:02.225173 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 12:56:02.225198 22726 solver.cpp:244]     Train net output #1: loss = 0.175607 (* 1 = 0.175607 loss)
I0819 12:56:02.300684 22726 sgd_solver.cpp:166] Iteration 37100, lr = 0.9275
I0819 12:58:19.814576 22726 solver.cpp:337] Iteration 37200, Testing net (#0)
I0819 12:59:44.343343 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88472
I0819 12:59:44.343662 22726 solver.cpp:404]     Test net output #1: loss = 0.442411 (* 1 = 0.442411 loss)
I0819 12:59:45.675154 22726 solver.cpp:228] Iteration 37200, loss = 0.165006
I0819 12:59:45.675194 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 12:59:45.675215 22726 solver.cpp:244]     Train net output #1: loss = 0.165006 (* 1 = 0.165006 loss)
I0819 12:59:45.759537 22726 sgd_solver.cpp:166] Iteration 37200, lr = 0.93
I0819 13:02:03.323073 22726 solver.cpp:337] Iteration 37300, Testing net (#0)
I0819 13:03:27.854696 22726 solver.cpp:404]     Test net output #0: accuracy = 0.89048
I0819 13:03:27.855013 22726 solver.cpp:404]     Test net output #1: loss = 0.417886 (* 1 = 0.417886 loss)
I0819 13:03:29.186610 22726 solver.cpp:228] Iteration 37300, loss = 0.170814
I0819 13:03:29.186650 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 13:03:29.186673 22726 solver.cpp:244]     Train net output #1: loss = 0.170814 (* 1 = 0.170814 loss)
I0819 13:03:29.266129 22726 sgd_solver.cpp:166] Iteration 37300, lr = 0.9325
I0819 13:05:46.775317 22726 solver.cpp:337] Iteration 37400, Testing net (#0)
I0819 13:07:11.267493 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8872
I0819 13:07:11.267802 22726 solver.cpp:404]     Test net output #1: loss = 0.419553 (* 1 = 0.419553 loss)
I0819 13:07:12.599593 22726 solver.cpp:228] Iteration 37400, loss = 0.0850908
I0819 13:07:12.599632 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 13:07:12.599655 22726 solver.cpp:244]     Train net output #1: loss = 0.0850907 (* 1 = 0.0850907 loss)
I0819 13:07:12.678598 22726 sgd_solver.cpp:166] Iteration 37400, lr = 0.935
I0819 13:09:30.189268 22726 solver.cpp:337] Iteration 37500, Testing net (#0)
I0819 13:10:54.731304 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88612
I0819 13:10:54.731621 22726 solver.cpp:404]     Test net output #1: loss = 0.420505 (* 1 = 0.420505 loss)
I0819 13:10:56.063413 22726 solver.cpp:228] Iteration 37500, loss = 0.0546935
I0819 13:10:56.063452 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 13:10:56.063477 22726 solver.cpp:244]     Train net output #1: loss = 0.0546934 (* 1 = 0.0546934 loss)
I0819 13:10:56.141050 22726 sgd_solver.cpp:166] Iteration 37500, lr = 0.9375
I0819 13:13:13.761420 22726 solver.cpp:337] Iteration 37600, Testing net (#0)
I0819 13:14:38.259623 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8802
I0819 13:14:38.259912 22726 solver.cpp:404]     Test net output #1: loss = 0.435853 (* 1 = 0.435853 loss)
I0819 13:14:39.591626 22726 solver.cpp:228] Iteration 37600, loss = 0.151125
I0819 13:14:39.591665 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 13:14:39.591687 22726 solver.cpp:244]     Train net output #1: loss = 0.151124 (* 1 = 0.151124 loss)
I0819 13:14:39.673707 22726 sgd_solver.cpp:166] Iteration 37600, lr = 0.94
I0819 13:16:57.316779 22726 solver.cpp:337] Iteration 37700, Testing net (#0)
I0819 13:18:21.834892 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87704
I0819 13:18:21.835209 22726 solver.cpp:404]     Test net output #1: loss = 0.463197 (* 1 = 0.463197 loss)
I0819 13:18:23.166628 22726 solver.cpp:228] Iteration 37700, loss = 0.208281
I0819 13:18:23.166666 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 13:18:23.166687 22726 solver.cpp:244]     Train net output #1: loss = 0.208281 (* 1 = 0.208281 loss)
I0819 13:18:23.248874 22726 sgd_solver.cpp:166] Iteration 37700, lr = 0.9425
I0819 13:20:40.795665 22726 solver.cpp:337] Iteration 37800, Testing net (#0)
I0819 13:22:05.308291 22726 solver.cpp:404]     Test net output #0: accuracy = 0.888561
I0819 13:22:05.308594 22726 solver.cpp:404]     Test net output #1: loss = 0.402458 (* 1 = 0.402458 loss)
I0819 13:22:06.639374 22726 solver.cpp:228] Iteration 37800, loss = 0.111242
I0819 13:22:06.639412 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 13:22:06.639436 22726 solver.cpp:244]     Train net output #1: loss = 0.111242 (* 1 = 0.111242 loss)
I0819 13:22:06.719475 22726 sgd_solver.cpp:166] Iteration 37800, lr = 0.945
I0819 13:24:24.249256 22726 solver.cpp:337] Iteration 37900, Testing net (#0)
I0819 13:25:48.798945 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8854
I0819 13:25:48.799268 22726 solver.cpp:404]     Test net output #1: loss = 0.401249 (* 1 = 0.401249 loss)
I0819 13:25:50.131351 22726 solver.cpp:228] Iteration 37900, loss = 0.0975174
I0819 13:25:50.131395 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 13:25:50.131420 22726 solver.cpp:244]     Train net output #1: loss = 0.0975172 (* 1 = 0.0975172 loss)
I0819 13:25:50.215255 22726 sgd_solver.cpp:166] Iteration 37900, lr = 0.9475
I0819 13:28:07.722625 22726 solver.cpp:337] Iteration 38000, Testing net (#0)
I0819 13:29:32.197860 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88588
I0819 13:29:32.198179 22726 solver.cpp:404]     Test net output #1: loss = 0.420121 (* 1 = 0.420121 loss)
I0819 13:29:33.529881 22726 solver.cpp:228] Iteration 38000, loss = 0.132587
I0819 13:29:33.529923 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 13:29:33.529947 22726 solver.cpp:244]     Train net output #1: loss = 0.132587 (* 1 = 0.132587 loss)
I0819 13:29:33.605360 22726 sgd_solver.cpp:166] Iteration 38000, lr = 0.95
I0819 13:31:51.104347 22726 solver.cpp:337] Iteration 38100, Testing net (#0)
I0819 13:33:15.566273 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88112
I0819 13:33:15.566586 22726 solver.cpp:404]     Test net output #1: loss = 0.455135 (* 1 = 0.455135 loss)
I0819 13:33:16.894632 22726 solver.cpp:228] Iteration 38100, loss = 0.0721985
I0819 13:33:16.894666 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 13:33:16.894681 22726 solver.cpp:244]     Train net output #1: loss = 0.0721984 (* 1 = 0.0721984 loss)
I0819 13:33:16.977152 22726 sgd_solver.cpp:166] Iteration 38100, lr = 0.9525
I0819 13:35:34.624838 22726 solver.cpp:337] Iteration 38200, Testing net (#0)
I0819 13:36:59.114022 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88168
I0819 13:36:59.114325 22726 solver.cpp:404]     Test net output #1: loss = 0.439902 (* 1 = 0.439902 loss)
I0819 13:37:00.441920 22726 solver.cpp:228] Iteration 38200, loss = 0.0547399
I0819 13:37:00.441962 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 13:37:00.441977 22726 solver.cpp:244]     Train net output #1: loss = 0.0547398 (* 1 = 0.0547398 loss)
I0819 13:37:00.527192 22726 sgd_solver.cpp:166] Iteration 38200, lr = 0.955
I0819 13:39:18.129560 22726 solver.cpp:337] Iteration 38300, Testing net (#0)
I0819 13:40:42.591884 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8826
I0819 13:40:42.592196 22726 solver.cpp:404]     Test net output #1: loss = 0.409734 (* 1 = 0.409734 loss)
I0819 13:40:43.919607 22726 solver.cpp:228] Iteration 38300, loss = 0.1603
I0819 13:40:43.919639 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 13:40:43.919656 22726 solver.cpp:244]     Train net output #1: loss = 0.1603 (* 1 = 0.1603 loss)
I0819 13:40:43.999399 22726 sgd_solver.cpp:166] Iteration 38300, lr = 0.9575
I0819 13:43:01.716248 22726 solver.cpp:337] Iteration 38400, Testing net (#0)
I0819 13:44:26.227180 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87236
I0819 13:44:26.227491 22726 solver.cpp:404]     Test net output #1: loss = 0.45943 (* 1 = 0.45943 loss)
I0819 13:44:27.557904 22726 solver.cpp:228] Iteration 38400, loss = 0.15641
I0819 13:44:27.557947 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 13:44:27.557965 22726 solver.cpp:244]     Train net output #1: loss = 0.15641 (* 1 = 0.15641 loss)
I0819 13:44:27.639276 22726 sgd_solver.cpp:166] Iteration 38400, lr = 0.96
I0819 13:46:45.566419 22726 solver.cpp:337] Iteration 38500, Testing net (#0)
I0819 13:48:10.061520 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88352
I0819 13:48:10.061835 22726 solver.cpp:404]     Test net output #1: loss = 0.417185 (* 1 = 0.417185 loss)
I0819 13:48:11.393560 22726 solver.cpp:228] Iteration 38500, loss = 0.0525465
I0819 13:48:11.393605 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 13:48:11.393622 22726 solver.cpp:244]     Train net output #1: loss = 0.0525463 (* 1 = 0.0525463 loss)
I0819 13:48:11.478149 22726 sgd_solver.cpp:166] Iteration 38500, lr = 0.9625
I0819 13:50:29.231680 22726 solver.cpp:337] Iteration 38600, Testing net (#0)
I0819 13:51:53.717523 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8836
I0819 13:51:53.717835 22726 solver.cpp:404]     Test net output #1: loss = 0.442293 (* 1 = 0.442293 loss)
I0819 13:51:55.049330 22726 solver.cpp:228] Iteration 38600, loss = 0.0968207
I0819 13:51:55.049374 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 13:51:55.049391 22726 solver.cpp:244]     Train net output #1: loss = 0.0968205 (* 1 = 0.0968205 loss)
I0819 13:51:55.128656 22726 sgd_solver.cpp:166] Iteration 38600, lr = 0.965
I0819 13:54:13.072935 22726 solver.cpp:337] Iteration 38700, Testing net (#0)
I0819 13:55:37.527145 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88132
I0819 13:55:37.527458 22726 solver.cpp:404]     Test net output #1: loss = 0.431332 (* 1 = 0.431332 loss)
I0819 13:55:38.858675 22726 solver.cpp:228] Iteration 38700, loss = 0.0436653
I0819 13:55:38.858721 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 13:55:38.858736 22726 solver.cpp:244]     Train net output #1: loss = 0.0436651 (* 1 = 0.0436651 loss)
I0819 13:55:38.937386 22726 sgd_solver.cpp:166] Iteration 38700, lr = 0.9675
I0819 13:57:56.707535 22726 solver.cpp:337] Iteration 38800, Testing net (#0)
I0819 13:59:21.198340 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88452
I0819 13:59:21.198654 22726 solver.cpp:404]     Test net output #1: loss = 0.427073 (* 1 = 0.427073 loss)
I0819 13:59:22.530475 22726 solver.cpp:228] Iteration 38800, loss = 0.131698
I0819 13:59:22.530519 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 13:59:22.530536 22726 solver.cpp:244]     Train net output #1: loss = 0.131698 (* 1 = 0.131698 loss)
I0819 13:59:22.614711 22726 sgd_solver.cpp:166] Iteration 38800, lr = 0.97
I0819 14:01:40.536041 22726 solver.cpp:337] Iteration 38900, Testing net (#0)
I0819 14:03:05.034021 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87824
I0819 14:03:05.034339 22726 solver.cpp:404]     Test net output #1: loss = 0.439457 (* 1 = 0.439457 loss)
I0819 14:03:06.364852 22726 solver.cpp:228] Iteration 38900, loss = 0.127364
I0819 14:03:06.364898 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 14:03:06.364914 22726 solver.cpp:244]     Train net output #1: loss = 0.127364 (* 1 = 0.127364 loss)
I0819 14:03:06.450594 22726 sgd_solver.cpp:166] Iteration 38900, lr = 0.9725
I0819 14:05:24.397042 22726 solver.cpp:337] Iteration 39000, Testing net (#0)
I0819 14:06:48.968999 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87824
I0819 14:06:48.969317 22726 solver.cpp:404]     Test net output #1: loss = 0.448687 (* 1 = 0.448687 loss)
I0819 14:06:50.297240 22726 solver.cpp:228] Iteration 39000, loss = 0.198809
I0819 14:06:50.297276 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0819 14:06:50.297292 22726 solver.cpp:244]     Train net output #1: loss = 0.198809 (* 1 = 0.198809 loss)
I0819 14:06:50.378574 22726 sgd_solver.cpp:166] Iteration 39000, lr = 0.975
I0819 14:09:07.949425 22726 solver.cpp:337] Iteration 39100, Testing net (#0)
I0819 14:10:32.469285 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88248
I0819 14:10:32.469591 22726 solver.cpp:404]     Test net output #1: loss = 0.430042 (* 1 = 0.430042 loss)
I0819 14:10:33.797693 22726 solver.cpp:228] Iteration 39100, loss = 0.101155
I0819 14:10:33.797737 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 14:10:33.797754 22726 solver.cpp:244]     Train net output #1: loss = 0.101155 (* 1 = 0.101155 loss)
I0819 14:10:33.880633 22726 sgd_solver.cpp:166] Iteration 39100, lr = 0.9775
I0819 14:12:51.525198 22726 solver.cpp:337] Iteration 39200, Testing net (#0)
I0819 14:14:16.065369 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8778
I0819 14:14:16.065680 22726 solver.cpp:404]     Test net output #1: loss = 0.431454 (* 1 = 0.431454 loss)
I0819 14:14:17.393935 22726 solver.cpp:228] Iteration 39200, loss = 0.108407
I0819 14:14:17.393980 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 14:14:17.393996 22726 solver.cpp:244]     Train net output #1: loss = 0.108407 (* 1 = 0.108407 loss)
I0819 14:14:17.479441 22726 sgd_solver.cpp:166] Iteration 39200, lr = 0.98
I0819 14:16:35.196808 22726 solver.cpp:337] Iteration 39300, Testing net (#0)
I0819 14:17:59.726341 22726 solver.cpp:404]     Test net output #0: accuracy = 0.879
I0819 14:17:59.726652 22726 solver.cpp:404]     Test net output #1: loss = 0.432377 (* 1 = 0.432377 loss)
I0819 14:18:01.053627 22726 solver.cpp:228] Iteration 39300, loss = 0.113894
I0819 14:18:01.053673 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 14:18:01.053689 22726 solver.cpp:244]     Train net output #1: loss = 0.113893 (* 1 = 0.113893 loss)
I0819 14:18:01.140277 22726 sgd_solver.cpp:166] Iteration 39300, lr = 0.9825
I0819 14:20:18.658411 22726 solver.cpp:337] Iteration 39400, Testing net (#0)
I0819 14:21:43.107398 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88452
I0819 14:21:43.107712 22726 solver.cpp:404]     Test net output #1: loss = 0.433075 (* 1 = 0.433075 loss)
I0819 14:21:44.435233 22726 solver.cpp:228] Iteration 39400, loss = 0.0729276
I0819 14:21:44.435278 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 14:21:44.435295 22726 solver.cpp:244]     Train net output #1: loss = 0.0729274 (* 1 = 0.0729274 loss)
I0819 14:21:44.519707 22726 sgd_solver.cpp:166] Iteration 39400, lr = 0.985
I0819 14:24:02.162986 22726 solver.cpp:337] Iteration 39500, Testing net (#0)
I0819 14:25:26.594759 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87968
I0819 14:25:26.595077 22726 solver.cpp:404]     Test net output #1: loss = 0.426412 (* 1 = 0.426412 loss)
I0819 14:25:27.922189 22726 solver.cpp:228] Iteration 39500, loss = 0.171442
I0819 14:25:27.922225 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 14:25:27.922240 22726 solver.cpp:244]     Train net output #1: loss = 0.171442 (* 1 = 0.171442 loss)
I0819 14:25:28.006824 22726 sgd_solver.cpp:166] Iteration 39500, lr = 0.9875
I0819 14:27:45.696240 22726 solver.cpp:337] Iteration 39600, Testing net (#0)
I0819 14:29:10.124325 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88192
I0819 14:29:10.124637 22726 solver.cpp:404]     Test net output #1: loss = 0.445656 (* 1 = 0.445656 loss)
I0819 14:29:11.451611 22726 solver.cpp:228] Iteration 39600, loss = 0.0759904
I0819 14:29:11.451656 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 14:29:11.451673 22726 solver.cpp:244]     Train net output #1: loss = 0.0759902 (* 1 = 0.0759902 loss)
I0819 14:29:11.536144 22726 sgd_solver.cpp:166] Iteration 39600, lr = 0.99
I0819 14:31:29.150033 22726 solver.cpp:337] Iteration 39700, Testing net (#0)
I0819 14:32:53.576704 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88668
I0819 14:32:53.577020 22726 solver.cpp:404]     Test net output #1: loss = 0.412761 (* 1 = 0.412761 loss)
I0819 14:32:54.903630 22726 solver.cpp:228] Iteration 39700, loss = 0.128591
I0819 14:32:54.903676 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 14:32:54.903692 22726 solver.cpp:244]     Train net output #1: loss = 0.12859 (* 1 = 0.12859 loss)
I0819 14:32:54.987207 22726 sgd_solver.cpp:166] Iteration 39700, lr = 0.9925
I0819 14:35:12.634361 22726 solver.cpp:337] Iteration 39800, Testing net (#0)
I0819 14:36:37.069723 22726 solver.cpp:404]     Test net output #0: accuracy = 0.883
I0819 14:36:37.070044 22726 solver.cpp:404]     Test net output #1: loss = 0.409333 (* 1 = 0.409333 loss)
I0819 14:36:38.396669 22726 solver.cpp:228] Iteration 39800, loss = 0.0716699
I0819 14:36:38.396705 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 14:36:38.396720 22726 solver.cpp:244]     Train net output #1: loss = 0.0716697 (* 1 = 0.0716697 loss)
I0819 14:36:38.475947 22726 sgd_solver.cpp:166] Iteration 39800, lr = 0.995
I0819 14:38:56.095620 22726 solver.cpp:337] Iteration 39900, Testing net (#0)
I0819 14:40:20.514803 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87888
I0819 14:40:20.515123 22726 solver.cpp:404]     Test net output #1: loss = 0.426669 (* 1 = 0.426669 loss)
I0819 14:40:21.842047 22726 solver.cpp:228] Iteration 39900, loss = 0.105062
I0819 14:40:21.842082 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 14:40:21.842098 22726 solver.cpp:244]     Train net output #1: loss = 0.105062 (* 1 = 0.105062 loss)
I0819 14:40:21.921788 22726 sgd_solver.cpp:166] Iteration 39900, lr = 0.9975
I0819 14:42:39.524056 22726 solver.cpp:337] Iteration 40000, Testing net (#0)
I0819 14:44:04.471660 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88252
I0819 14:44:04.471922 22726 solver.cpp:404]     Test net output #1: loss = 0.427824 (* 1 = 0.427824 loss)
I0819 14:44:05.801090 22726 solver.cpp:228] Iteration 40000, loss = 0.112772
I0819 14:44:05.801136 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 14:44:05.801152 22726 solver.cpp:244]     Train net output #1: loss = 0.112772 (* 1 = 0.112772 loss)
I0819 14:44:05.886127 22726 sgd_solver.cpp:166] Iteration 40000, lr = 1
I0819 14:46:23.661007 22726 solver.cpp:337] Iteration 40100, Testing net (#0)
I0819 14:47:48.558416 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88204
I0819 14:47:48.558668 22726 solver.cpp:404]     Test net output #1: loss = 0.420009 (* 1 = 0.420009 loss)
I0819 14:47:49.888573 22726 solver.cpp:228] Iteration 40100, loss = 0.0756406
I0819 14:47:49.888619 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 14:47:49.888634 22726 solver.cpp:244]     Train net output #1: loss = 0.0756404 (* 1 = 0.0756404 loss)
I0819 14:47:49.975463 22726 sgd_solver.cpp:166] Iteration 40100, lr = 1.0025
I0819 14:50:07.776142 22726 solver.cpp:337] Iteration 40200, Testing net (#0)
I0819 14:51:32.882784 22726 solver.cpp:404]     Test net output #0: accuracy = 0.880521
I0819 14:51:32.883112 22726 solver.cpp:404]     Test net output #1: loss = 0.437502 (* 1 = 0.437502 loss)
I0819 14:51:34.212599 22726 solver.cpp:228] Iteration 40200, loss = 0.0715516
I0819 14:51:34.212644 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 14:51:34.212661 22726 solver.cpp:244]     Train net output #1: loss = 0.0715514 (* 1 = 0.0715514 loss)
I0819 14:51:34.293429 22726 sgd_solver.cpp:166] Iteration 40200, lr = 1.005
I0819 14:53:52.091289 22726 solver.cpp:337] Iteration 40300, Testing net (#0)
I0819 14:55:16.834141 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8836
I0819 14:55:16.834383 22726 solver.cpp:404]     Test net output #1: loss = 0.441575 (* 1 = 0.441575 loss)
I0819 14:55:18.164894 22726 solver.cpp:228] Iteration 40300, loss = 0.0520737
I0819 14:55:18.164937 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 14:55:18.164958 22726 solver.cpp:244]     Train net output #1: loss = 0.0520735 (* 1 = 0.0520735 loss)
I0819 14:55:18.243198 22726 sgd_solver.cpp:166] Iteration 40300, lr = 1.0075
I0819 14:57:36.054780 22726 solver.cpp:337] Iteration 40400, Testing net (#0)
I0819 14:59:01.100524 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87852
I0819 14:59:01.100780 22726 solver.cpp:404]     Test net output #1: loss = 0.470168 (* 1 = 0.470168 loss)
I0819 14:59:02.431170 22726 solver.cpp:228] Iteration 40400, loss = 0.0846796
I0819 14:59:02.431213 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 14:59:02.431229 22726 solver.cpp:244]     Train net output #1: loss = 0.0846794 (* 1 = 0.0846794 loss)
I0819 14:59:02.511971 22726 sgd_solver.cpp:166] Iteration 40400, lr = 1.01
I0819 15:01:20.250792 22726 solver.cpp:337] Iteration 40500, Testing net (#0)
I0819 15:02:45.397644 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88244
I0819 15:02:45.397979 22726 solver.cpp:404]     Test net output #1: loss = 0.43428 (* 1 = 0.43428 loss)
I0819 15:02:46.727648 22726 solver.cpp:228] Iteration 40500, loss = 0.0974222
I0819 15:02:46.727691 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 15:02:46.727708 22726 solver.cpp:244]     Train net output #1: loss = 0.0974221 (* 1 = 0.0974221 loss)
I0819 15:02:46.807709 22726 sgd_solver.cpp:166] Iteration 40500, lr = 1.0125
I0819 15:05:04.466759 22726 solver.cpp:337] Iteration 40600, Testing net (#0)
I0819 15:06:29.510972 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8878
I0819 15:06:29.511252 22726 solver.cpp:404]     Test net output #1: loss = 0.411102 (* 1 = 0.411102 loss)
I0819 15:06:30.840848 22726 solver.cpp:228] Iteration 40600, loss = 0.0907582
I0819 15:06:30.840893 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 15:06:30.840910 22726 solver.cpp:244]     Train net output #1: loss = 0.0907581 (* 1 = 0.0907581 loss)
I0819 15:06:30.921100 22726 sgd_solver.cpp:166] Iteration 40600, lr = 1.015
I0819 15:08:48.672329 22726 solver.cpp:337] Iteration 40700, Testing net (#0)
I0819 15:10:13.782232 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88304
I0819 15:10:13.782505 22726 solver.cpp:404]     Test net output #1: loss = 0.424374 (* 1 = 0.424374 loss)
I0819 15:10:15.113586 22726 solver.cpp:228] Iteration 40700, loss = 0.0722541
I0819 15:10:15.113631 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 15:10:15.113647 22726 solver.cpp:244]     Train net output #1: loss = 0.0722539 (* 1 = 0.0722539 loss)
I0819 15:10:15.192525 22726 sgd_solver.cpp:166] Iteration 40700, lr = 1.0175
I0819 15:12:33.022027 22726 solver.cpp:337] Iteration 40800, Testing net (#0)
I0819 15:13:58.176062 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88452
I0819 15:13:58.176359 22726 solver.cpp:404]     Test net output #1: loss = 0.419228 (* 1 = 0.419228 loss)
I0819 15:13:59.506028 22726 solver.cpp:228] Iteration 40800, loss = 0.0843472
I0819 15:13:59.506074 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 15:13:59.506091 22726 solver.cpp:244]     Train net output #1: loss = 0.084347 (* 1 = 0.084347 loss)
I0819 15:13:59.586179 22726 sgd_solver.cpp:166] Iteration 40800, lr = 1.02
I0819 15:16:17.248021 22726 solver.cpp:337] Iteration 40900, Testing net (#0)
I0819 15:17:42.400990 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87876
I0819 15:17:42.401268 22726 solver.cpp:404]     Test net output #1: loss = 0.455578 (* 1 = 0.455578 loss)
I0819 15:17:43.730931 22726 solver.cpp:228] Iteration 40900, loss = 0.0974859
I0819 15:17:43.730980 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 15:17:43.730999 22726 solver.cpp:244]     Train net output #1: loss = 0.0974857 (* 1 = 0.0974857 loss)
I0819 15:17:43.813105 22726 sgd_solver.cpp:166] Iteration 40900, lr = 1.0225
I0819 15:20:01.592986 22726 solver.cpp:337] Iteration 41000, Testing net (#0)
I0819 15:21:26.739270 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87768
I0819 15:21:26.739572 22726 solver.cpp:404]     Test net output #1: loss = 0.438502 (* 1 = 0.438502 loss)
I0819 15:21:28.070978 22726 solver.cpp:228] Iteration 41000, loss = 0.0699136
I0819 15:21:28.071022 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 15:21:28.071038 22726 solver.cpp:244]     Train net output #1: loss = 0.0699134 (* 1 = 0.0699134 loss)
I0819 15:21:28.147475 22726 sgd_solver.cpp:166] Iteration 41000, lr = 1.025
I0819 15:23:45.919183 22726 solver.cpp:337] Iteration 41100, Testing net (#0)
I0819 15:25:11.035980 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88088
I0819 15:25:11.036259 22726 solver.cpp:404]     Test net output #1: loss = 0.459575 (* 1 = 0.459575 loss)
I0819 15:25:12.367382 22726 solver.cpp:228] Iteration 41100, loss = 0.185923
I0819 15:25:12.367425 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 15:25:12.367442 22726 solver.cpp:244]     Train net output #1: loss = 0.185923 (* 1 = 0.185923 loss)
I0819 15:25:12.451439 22726 sgd_solver.cpp:166] Iteration 41100, lr = 1.0275
I0819 15:27:30.217934 22726 solver.cpp:337] Iteration 41200, Testing net (#0)
I0819 15:28:55.348373 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87996
I0819 15:28:55.348659 22726 solver.cpp:404]     Test net output #1: loss = 0.424589 (* 1 = 0.424589 loss)
I0819 15:28:56.678125 22726 solver.cpp:228] Iteration 41200, loss = 0.0909304
I0819 15:28:56.678169 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 15:28:56.678186 22726 solver.cpp:244]     Train net output #1: loss = 0.0909302 (* 1 = 0.0909302 loss)
I0819 15:28:56.761217 22726 sgd_solver.cpp:166] Iteration 41200, lr = 1.03
I0819 15:31:14.463173 22726 solver.cpp:337] Iteration 41300, Testing net (#0)
I0819 15:32:39.575937 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87916
I0819 15:32:39.576236 22726 solver.cpp:404]     Test net output #1: loss = 0.441303 (* 1 = 0.441303 loss)
I0819 15:32:40.905644 22726 solver.cpp:228] Iteration 41300, loss = 0.10088
I0819 15:32:40.905689 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 15:32:40.905705 22726 solver.cpp:244]     Train net output #1: loss = 0.10088 (* 1 = 0.10088 loss)
I0819 15:32:40.991164 22726 sgd_solver.cpp:166] Iteration 41300, lr = 1.0325
I0819 15:34:58.705114 22726 solver.cpp:337] Iteration 41400, Testing net (#0)
I0819 15:36:23.828917 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8842
I0819 15:36:23.829211 22726 solver.cpp:404]     Test net output #1: loss = 0.425179 (* 1 = 0.425179 loss)
I0819 15:36:25.160259 22726 solver.cpp:228] Iteration 41400, loss = 0.107576
I0819 15:36:25.160303 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 15:36:25.160318 22726 solver.cpp:244]     Train net output #1: loss = 0.107576 (* 1 = 0.107576 loss)
I0819 15:36:25.243655 22726 sgd_solver.cpp:166] Iteration 41400, lr = 1.035
I0819 15:38:42.929360 22726 solver.cpp:337] Iteration 41500, Testing net (#0)
I0819 15:40:08.055935 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88404
I0819 15:40:08.056210 22726 solver.cpp:404]     Test net output #1: loss = 0.431507 (* 1 = 0.431507 loss)
I0819 15:40:09.386792 22726 solver.cpp:228] Iteration 41500, loss = 0.147465
I0819 15:40:09.386837 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 15:40:09.386852 22726 solver.cpp:244]     Train net output #1: loss = 0.147465 (* 1 = 0.147465 loss)
I0819 15:40:09.463538 22726 sgd_solver.cpp:166] Iteration 41500, lr = 1.0375
I0819 15:42:27.178031 22726 solver.cpp:337] Iteration 41600, Testing net (#0)
I0819 15:43:52.220455 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87248
I0819 15:43:52.220784 22726 solver.cpp:404]     Test net output #1: loss = 0.459651 (* 1 = 0.459651 loss)
I0819 15:43:53.551825 22726 solver.cpp:228] Iteration 41600, loss = 0.0988391
I0819 15:43:53.551869 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 15:43:53.551885 22726 solver.cpp:244]     Train net output #1: loss = 0.0988389 (* 1 = 0.0988389 loss)
I0819 15:43:53.635951 22726 sgd_solver.cpp:166] Iteration 41600, lr = 1.04
I0819 15:46:11.357810 22726 solver.cpp:337] Iteration 41700, Testing net (#0)
I0819 15:47:36.266216 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87776
I0819 15:47:36.266505 22726 solver.cpp:404]     Test net output #1: loss = 0.432032 (* 1 = 0.432032 loss)
I0819 15:47:37.595846 22726 solver.cpp:228] Iteration 41700, loss = 0.0970362
I0819 15:47:37.595890 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 15:47:37.595906 22726 solver.cpp:244]     Train net output #1: loss = 0.0970361 (* 1 = 0.0970361 loss)
I0819 15:47:37.668362 22726 sgd_solver.cpp:166] Iteration 41700, lr = 1.0425
I0819 15:49:55.152839 22726 solver.cpp:337] Iteration 41800, Testing net (#0)
I0819 15:51:19.975368 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87748
I0819 15:51:19.975631 22726 solver.cpp:404]     Test net output #1: loss = 0.44826 (* 1 = 0.44826 loss)
I0819 15:51:21.305503 22726 solver.cpp:228] Iteration 41800, loss = 0.079757
I0819 15:51:21.305546 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 15:51:21.305562 22726 solver.cpp:244]     Train net output #1: loss = 0.0797569 (* 1 = 0.0797569 loss)
I0819 15:51:21.381971 22726 sgd_solver.cpp:166] Iteration 41800, lr = 1.045
I0819 15:53:38.962419 22726 solver.cpp:337] Iteration 41900, Testing net (#0)
I0819 15:55:03.800855 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88516
I0819 15:55:03.801156 22726 solver.cpp:404]     Test net output #1: loss = 0.408636 (* 1 = 0.408636 loss)
I0819 15:55:05.132336 22726 solver.cpp:228] Iteration 41900, loss = 0.0784445
I0819 15:55:05.132378 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 15:55:05.132395 22726 solver.cpp:244]     Train net output #1: loss = 0.0784444 (* 1 = 0.0784444 loss)
I0819 15:55:05.207399 22726 sgd_solver.cpp:166] Iteration 41900, lr = 1.0475
I0819 15:57:22.693509 22726 solver.cpp:337] Iteration 42000, Testing net (#0)
I0819 15:58:47.788733 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8776
I0819 15:58:47.789026 22726 solver.cpp:404]     Test net output #1: loss = 0.449468 (* 1 = 0.449468 loss)
I0819 15:58:49.118413 22726 solver.cpp:228] Iteration 42000, loss = 0.146537
I0819 15:58:49.118455 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 15:58:49.118470 22726 solver.cpp:244]     Train net output #1: loss = 0.146537 (* 1 = 0.146537 loss)
I0819 15:58:49.199465 22726 sgd_solver.cpp:166] Iteration 42000, lr = 1.05
I0819 16:01:06.728054 22726 solver.cpp:337] Iteration 42100, Testing net (#0)
I0819 16:02:31.812613 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87364
I0819 16:02:31.812896 22726 solver.cpp:404]     Test net output #1: loss = 0.446916 (* 1 = 0.446916 loss)
I0819 16:02:33.143167 22726 solver.cpp:228] Iteration 42100, loss = 0.200835
I0819 16:02:33.143208 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 16:02:33.143224 22726 solver.cpp:244]     Train net output #1: loss = 0.200835 (* 1 = 0.200835 loss)
I0819 16:02:33.221462 22726 sgd_solver.cpp:166] Iteration 42100, lr = 1.0525
I0819 16:04:50.668620 22726 solver.cpp:337] Iteration 42200, Testing net (#0)
I0819 16:06:15.653465 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8834
I0819 16:06:15.653753 22726 solver.cpp:404]     Test net output #1: loss = 0.416616 (* 1 = 0.416616 loss)
I0819 16:06:16.983779 22726 solver.cpp:228] Iteration 42200, loss = 0.0525403
I0819 16:06:16.983821 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 16:06:16.983837 22726 solver.cpp:244]     Train net output #1: loss = 0.0525402 (* 1 = 0.0525402 loss)
I0819 16:06:17.065155 22726 sgd_solver.cpp:166] Iteration 42200, lr = 1.055
I0819 16:08:34.553774 22726 solver.cpp:337] Iteration 42300, Testing net (#0)
I0819 16:09:59.522421 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8802
I0819 16:09:59.522708 22726 solver.cpp:404]     Test net output #1: loss = 0.435527 (* 1 = 0.435527 loss)
I0819 16:10:00.853998 22726 solver.cpp:228] Iteration 42300, loss = 0.0940859
I0819 16:10:00.854041 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 16:10:00.854058 22726 solver.cpp:244]     Train net output #1: loss = 0.0940858 (* 1 = 0.0940858 loss)
I0819 16:10:00.931179 22726 sgd_solver.cpp:166] Iteration 42300, lr = 1.0575
I0819 16:12:18.523306 22726 solver.cpp:337] Iteration 42400, Testing net (#0)
I0819 16:13:43.401370 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88504
I0819 16:13:43.401659 22726 solver.cpp:404]     Test net output #1: loss = 0.420347 (* 1 = 0.420347 loss)
I0819 16:13:44.733059 22726 solver.cpp:228] Iteration 42400, loss = 0.119676
I0819 16:13:44.733101 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 16:13:44.733117 22726 solver.cpp:244]     Train net output #1: loss = 0.119676 (* 1 = 0.119676 loss)
I0819 16:13:44.811556 22726 sgd_solver.cpp:166] Iteration 42400, lr = 1.06
I0819 16:16:02.335233 22726 solver.cpp:337] Iteration 42500, Testing net (#0)
I0819 16:17:27.135213 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88356
I0819 16:17:27.135545 22726 solver.cpp:404]     Test net output #1: loss = 0.431356 (* 1 = 0.431356 loss)
I0819 16:17:28.465512 22726 solver.cpp:228] Iteration 42500, loss = 0.0821538
I0819 16:17:28.465556 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 16:17:28.465572 22726 solver.cpp:244]     Train net output #1: loss = 0.0821536 (* 1 = 0.0821536 loss)
I0819 16:17:28.548283 22726 sgd_solver.cpp:166] Iteration 42500, lr = 1.0625
I0819 16:19:46.126786 22726 solver.cpp:337] Iteration 42600, Testing net (#0)
I0819 16:21:10.997858 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8834
I0819 16:21:10.998160 22726 solver.cpp:404]     Test net output #1: loss = 0.416378 (* 1 = 0.416378 loss)
I0819 16:21:12.329241 22726 solver.cpp:228] Iteration 42600, loss = 0.15107
I0819 16:21:12.329285 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 16:21:12.329301 22726 solver.cpp:244]     Train net output #1: loss = 0.15107 (* 1 = 0.15107 loss)
I0819 16:21:12.408110 22726 sgd_solver.cpp:166] Iteration 42600, lr = 1.065
I0819 16:23:29.849527 22726 solver.cpp:337] Iteration 42700, Testing net (#0)
I0819 16:24:54.701652 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88504
I0819 16:24:54.701896 22726 solver.cpp:404]     Test net output #1: loss = 0.41011 (* 1 = 0.41011 loss)
I0819 16:24:56.031538 22726 solver.cpp:228] Iteration 42700, loss = 0.0919337
I0819 16:24:56.031579 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 16:24:56.031594 22726 solver.cpp:244]     Train net output #1: loss = 0.0919334 (* 1 = 0.0919334 loss)
I0819 16:24:56.110299 22726 sgd_solver.cpp:166] Iteration 42700, lr = 1.0675
I0819 16:27:13.549742 22726 solver.cpp:337] Iteration 42800, Testing net (#0)
I0819 16:28:38.346746 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88188
I0819 16:28:38.347000 22726 solver.cpp:404]     Test net output #1: loss = 0.424547 (* 1 = 0.424547 loss)
I0819 16:28:39.676911 22726 solver.cpp:228] Iteration 42800, loss = 0.0951257
I0819 16:28:39.676954 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 16:28:39.676970 22726 solver.cpp:244]     Train net output #1: loss = 0.0951255 (* 1 = 0.0951255 loss)
I0819 16:28:39.754849 22726 sgd_solver.cpp:166] Iteration 42800, lr = 1.07
I0819 16:30:57.260035 22726 solver.cpp:337] Iteration 42900, Testing net (#0)
I0819 16:32:22.191169 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8774
I0819 16:32:22.191488 22726 solver.cpp:404]     Test net output #1: loss = 0.425607 (* 1 = 0.425607 loss)
I0819 16:32:23.521741 22726 solver.cpp:228] Iteration 42900, loss = 0.110396
I0819 16:32:23.521783 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 16:32:23.521800 22726 solver.cpp:244]     Train net output #1: loss = 0.110396 (* 1 = 0.110396 loss)
I0819 16:32:23.596628 22726 sgd_solver.cpp:166] Iteration 42900, lr = 1.0725
I0819 16:34:41.049579 22726 solver.cpp:337] Iteration 43000, Testing net (#0)
I0819 16:36:06.119321 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87936
I0819 16:36:06.119618 22726 solver.cpp:404]     Test net output #1: loss = 0.424524 (* 1 = 0.424524 loss)
I0819 16:36:07.449546 22726 solver.cpp:228] Iteration 43000, loss = 0.0878933
I0819 16:36:07.449584 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 16:36:07.449599 22726 solver.cpp:244]     Train net output #1: loss = 0.0878931 (* 1 = 0.0878931 loss)
I0819 16:36:07.525980 22726 sgd_solver.cpp:166] Iteration 43000, lr = 1.075
I0819 16:38:24.929280 22726 solver.cpp:337] Iteration 43100, Testing net (#0)
I0819 16:39:50.036535 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87988
I0819 16:39:50.036826 22726 solver.cpp:404]     Test net output #1: loss = 0.439756 (* 1 = 0.439756 loss)
I0819 16:39:51.366554 22726 solver.cpp:228] Iteration 43100, loss = 0.104938
I0819 16:39:51.366593 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 16:39:51.366610 22726 solver.cpp:244]     Train net output #1: loss = 0.104938 (* 1 = 0.104938 loss)
I0819 16:39:51.444577 22726 sgd_solver.cpp:166] Iteration 43100, lr = 1.0775
I0819 16:42:08.863945 22726 solver.cpp:337] Iteration 43200, Testing net (#0)
I0819 16:43:33.996430 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8776
I0819 16:43:33.996695 22726 solver.cpp:404]     Test net output #1: loss = 0.447823 (* 1 = 0.447823 loss)
I0819 16:43:35.326504 22726 solver.cpp:228] Iteration 43200, loss = 0.184124
I0819 16:43:35.326547 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0819 16:43:35.326562 22726 solver.cpp:244]     Train net output #1: loss = 0.184124 (* 1 = 0.184124 loss)
I0819 16:43:35.402746 22726 sgd_solver.cpp:166] Iteration 43200, lr = 1.08
I0819 16:45:52.883839 22726 solver.cpp:337] Iteration 43300, Testing net (#0)
I0819 16:47:17.995203 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86888
I0819 16:47:17.995465 22726 solver.cpp:404]     Test net output #1: loss = 0.501064 (* 1 = 0.501064 loss)
I0819 16:47:19.325191 22726 solver.cpp:228] Iteration 43300, loss = 0.19333
I0819 16:47:19.325232 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 16:47:19.325248 22726 solver.cpp:244]     Train net output #1: loss = 0.193329 (* 1 = 0.193329 loss)
I0819 16:47:19.406035 22726 sgd_solver.cpp:166] Iteration 43300, lr = 1.0825
I0819 16:49:36.849910 22726 solver.cpp:337] Iteration 43400, Testing net (#0)
I0819 16:51:01.967381 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88652
I0819 16:51:01.967679 22726 solver.cpp:404]     Test net output #1: loss = 0.404461 (* 1 = 0.404461 loss)
I0819 16:51:03.296964 22726 solver.cpp:228] Iteration 43400, loss = 0.204437
I0819 16:51:03.297009 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 16:51:03.297024 22726 solver.cpp:244]     Train net output #1: loss = 0.204437 (* 1 = 0.204437 loss)
I0819 16:51:03.379329 22726 sgd_solver.cpp:166] Iteration 43400, lr = 1.085
I0819 16:53:20.862982 22726 solver.cpp:337] Iteration 43500, Testing net (#0)
I0819 16:54:46.001421 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87724
I0819 16:54:46.001680 22726 solver.cpp:404]     Test net output #1: loss = 0.441079 (* 1 = 0.441079 loss)
I0819 16:54:47.331423 22726 solver.cpp:228] Iteration 43500, loss = 0.146761
I0819 16:54:47.331465 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 16:54:47.331481 22726 solver.cpp:244]     Train net output #1: loss = 0.146761 (* 1 = 0.146761 loss)
I0819 16:54:47.406639 22726 sgd_solver.cpp:166] Iteration 43500, lr = 1.0875
I0819 16:57:04.878435 22726 solver.cpp:337] Iteration 43600, Testing net (#0)
I0819 16:58:29.916144 22726 solver.cpp:404]     Test net output #0: accuracy = 0.886
I0819 16:58:29.916399 22726 solver.cpp:404]     Test net output #1: loss = 0.417883 (* 1 = 0.417883 loss)
I0819 16:58:31.246407 22726 solver.cpp:228] Iteration 43600, loss = 0.130605
I0819 16:58:31.246449 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 16:58:31.246465 22726 solver.cpp:244]     Train net output #1: loss = 0.130605 (* 1 = 0.130605 loss)
I0819 16:58:31.326779 22726 sgd_solver.cpp:166] Iteration 43600, lr = 1.09
I0819 17:00:48.825153 22726 solver.cpp:337] Iteration 43700, Testing net (#0)
I0819 17:02:13.801988 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88736
I0819 17:02:13.802320 22726 solver.cpp:404]     Test net output #1: loss = 0.423079 (* 1 = 0.423079 loss)
I0819 17:02:15.131331 22726 solver.cpp:228] Iteration 43700, loss = 0.182598
I0819 17:02:15.131374 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 17:02:15.131391 22726 solver.cpp:244]     Train net output #1: loss = 0.182598 (* 1 = 0.182598 loss)
I0819 17:02:15.209754 22726 sgd_solver.cpp:166] Iteration 43700, lr = 1.0925
I0819 17:04:32.679133 22726 solver.cpp:337] Iteration 43800, Testing net (#0)
I0819 17:05:57.790673 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87844
I0819 17:05:57.790935 22726 solver.cpp:404]     Test net output #1: loss = 0.428662 (* 1 = 0.428662 loss)
I0819 17:05:59.120579 22726 solver.cpp:228] Iteration 43800, loss = 0.0918641
I0819 17:05:59.120623 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 17:05:59.120640 22726 solver.cpp:244]     Train net output #1: loss = 0.0918639 (* 1 = 0.0918639 loss)
I0819 17:05:59.196118 22726 sgd_solver.cpp:166] Iteration 43800, lr = 1.095
I0819 17:08:16.654353 22726 solver.cpp:337] Iteration 43900, Testing net (#0)
I0819 17:09:41.488696 22726 solver.cpp:404]     Test net output #0: accuracy = 0.89
I0819 17:09:41.488965 22726 solver.cpp:404]     Test net output #1: loss = 0.393206 (* 1 = 0.393206 loss)
I0819 17:09:42.818874 22726 solver.cpp:228] Iteration 43900, loss = 0.120798
I0819 17:09:42.818917 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 17:09:42.818933 22726 solver.cpp:244]     Train net output #1: loss = 0.120797 (* 1 = 0.120797 loss)
I0819 17:09:42.898593 22726 sgd_solver.cpp:166] Iteration 43900, lr = 1.0975
I0819 17:12:00.394758 22726 solver.cpp:337] Iteration 44000, Testing net (#0)
I0819 17:13:25.163998 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88708
I0819 17:13:25.164276 22726 solver.cpp:404]     Test net output #1: loss = 0.419186 (* 1 = 0.419186 loss)
I0819 17:13:26.493723 22726 solver.cpp:228] Iteration 44000, loss = 0.102897
I0819 17:13:26.493767 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 17:13:26.493784 22726 solver.cpp:244]     Train net output #1: loss = 0.102897 (* 1 = 0.102897 loss)
I0819 17:13:26.574417 22726 sgd_solver.cpp:166] Iteration 44000, lr = 1.1
I0819 17:15:44.149307 22726 solver.cpp:337] Iteration 44100, Testing net (#0)
I0819 17:17:09.129048 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8866
I0819 17:17:09.129318 22726 solver.cpp:404]     Test net output #1: loss = 0.405243 (* 1 = 0.405243 loss)
I0819 17:17:10.459347 22726 solver.cpp:228] Iteration 44100, loss = 0.227105
I0819 17:17:10.459389 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0819 17:17:10.459405 22726 solver.cpp:244]     Train net output #1: loss = 0.227104 (* 1 = 0.227104 loss)
I0819 17:17:10.535346 22726 sgd_solver.cpp:166] Iteration 44100, lr = 1.1025
I0819 17:19:28.015758 22726 solver.cpp:337] Iteration 44200, Testing net (#0)
I0819 17:20:52.810108 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88544
I0819 17:20:52.810403 22726 solver.cpp:404]     Test net output #1: loss = 0.420298 (* 1 = 0.420298 loss)
I0819 17:20:54.140688 22726 solver.cpp:228] Iteration 44200, loss = 0.0370334
I0819 17:20:54.140730 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 17:20:54.140748 22726 solver.cpp:244]     Train net output #1: loss = 0.0370333 (* 1 = 0.0370333 loss)
I0819 17:20:54.221444 22726 sgd_solver.cpp:166] Iteration 44200, lr = 1.105
I0819 17:23:11.725849 22726 solver.cpp:337] Iteration 44300, Testing net (#0)
I0819 17:24:36.538452 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87516
I0819 17:24:36.538689 22726 solver.cpp:404]     Test net output #1: loss = 0.445707 (* 1 = 0.445707 loss)
I0819 17:24:37.867678 22726 solver.cpp:228] Iteration 44300, loss = 0.081498
I0819 17:24:37.867720 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 17:24:37.867735 22726 solver.cpp:244]     Train net output #1: loss = 0.0814978 (* 1 = 0.0814978 loss)
I0819 17:24:37.945550 22726 sgd_solver.cpp:166] Iteration 44300, lr = 1.1075
I0819 17:26:55.424620 22726 solver.cpp:337] Iteration 44400, Testing net (#0)
I0819 17:28:20.211244 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88032
I0819 17:28:20.211486 22726 solver.cpp:404]     Test net output #1: loss = 0.429527 (* 1 = 0.429527 loss)
I0819 17:28:21.541242 22726 solver.cpp:228] Iteration 44400, loss = 0.11621
I0819 17:28:21.541285 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 17:28:21.541301 22726 solver.cpp:244]     Train net output #1: loss = 0.116209 (* 1 = 0.116209 loss)
I0819 17:28:21.621300 22726 sgd_solver.cpp:166] Iteration 44400, lr = 1.11
I0819 17:30:39.106544 22726 solver.cpp:337] Iteration 44500, Testing net (#0)
I0819 17:32:03.896246 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8862
I0819 17:32:03.896570 22726 solver.cpp:404]     Test net output #1: loss = 0.427583 (* 1 = 0.427583 loss)
I0819 17:32:05.226454 22726 solver.cpp:228] Iteration 44500, loss = 0.0404185
I0819 17:32:05.226496 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 17:32:05.226511 22726 solver.cpp:244]     Train net output #1: loss = 0.0404183 (* 1 = 0.0404183 loss)
I0819 17:32:05.301136 22726 sgd_solver.cpp:166] Iteration 44500, lr = 1.1125
I0819 17:34:22.792170 22726 solver.cpp:337] Iteration 44600, Testing net (#0)
I0819 17:35:47.842387 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87996
I0819 17:35:47.842634 22726 solver.cpp:404]     Test net output #1: loss = 0.433381 (* 1 = 0.433381 loss)
I0819 17:35:49.171835 22726 solver.cpp:228] Iteration 44600, loss = 0.15142
I0819 17:35:49.171878 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 17:35:49.171892 22726 solver.cpp:244]     Train net output #1: loss = 0.15142 (* 1 = 0.15142 loss)
I0819 17:35:49.246340 22726 sgd_solver.cpp:166] Iteration 44600, lr = 1.115
I0819 17:38:06.934823 22726 solver.cpp:337] Iteration 44700, Testing net (#0)
I0819 17:39:31.784144 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88368
I0819 17:39:31.784409 22726 solver.cpp:404]     Test net output #1: loss = 0.425267 (* 1 = 0.425267 loss)
I0819 17:39:33.114380 22726 solver.cpp:228] Iteration 44700, loss = 0.132285
I0819 17:39:33.114428 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 17:39:33.114450 22726 solver.cpp:244]     Train net output #1: loss = 0.132285 (* 1 = 0.132285 loss)
I0819 17:39:33.192706 22726 sgd_solver.cpp:166] Iteration 44700, lr = 1.1175
I0819 17:41:51.021797 22726 solver.cpp:337] Iteration 44800, Testing net (#0)
I0819 17:43:16.164727 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88436
I0819 17:43:16.165060 22726 solver.cpp:404]     Test net output #1: loss = 0.41835 (* 1 = 0.41835 loss)
I0819 17:43:17.496475 22726 solver.cpp:228] Iteration 44800, loss = 0.145433
I0819 17:43:17.496521 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 17:43:17.496543 22726 solver.cpp:244]     Train net output #1: loss = 0.145433 (* 1 = 0.145433 loss)
I0819 17:43:17.576355 22726 sgd_solver.cpp:166] Iteration 44800, lr = 1.12
I0819 17:45:35.325043 22726 solver.cpp:337] Iteration 44900, Testing net (#0)
I0819 17:47:00.485183 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88264
I0819 17:47:00.485451 22726 solver.cpp:404]     Test net output #1: loss = 0.432994 (* 1 = 0.432994 loss)
I0819 17:47:01.815129 22726 solver.cpp:228] Iteration 44900, loss = 0.1554
I0819 17:47:01.815176 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 17:47:01.815201 22726 solver.cpp:244]     Train net output #1: loss = 0.155399 (* 1 = 0.155399 loss)
I0819 17:47:01.885095 22726 sgd_solver.cpp:166] Iteration 44900, lr = 1.1225
I0819 17:49:19.559855 22726 solver.cpp:337] Iteration 45000, Testing net (#0)
I0819 17:50:44.715332 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88504
I0819 17:50:44.715585 22726 solver.cpp:404]     Test net output #1: loss = 0.420074 (* 1 = 0.420074 loss)
I0819 17:50:46.045999 22726 solver.cpp:228] Iteration 45000, loss = 0.0719199
I0819 17:50:46.046038 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 17:50:46.046054 22726 solver.cpp:244]     Train net output #1: loss = 0.0719197 (* 1 = 0.0719197 loss)
I0819 17:50:46.125102 22726 sgd_solver.cpp:166] Iteration 45000, lr = 1.125
I0819 17:53:03.673178 22726 solver.cpp:337] Iteration 45100, Testing net (#0)
I0819 17:54:28.102478 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8812
I0819 17:54:28.102774 22726 solver.cpp:404]     Test net output #1: loss = 0.435752 (* 1 = 0.435752 loss)
I0819 17:54:29.430872 22726 solver.cpp:228] Iteration 45100, loss = 0.0476121
I0819 17:54:29.430917 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 17:54:29.430940 22726 solver.cpp:244]     Train net output #1: loss = 0.0476119 (* 1 = 0.0476119 loss)
I0819 17:54:29.513969 22726 sgd_solver.cpp:166] Iteration 45100, lr = 1.1275
I0819 17:56:47.042331 22726 solver.cpp:337] Iteration 45200, Testing net (#0)
I0819 17:58:11.474210 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88008
I0819 17:58:11.474539 22726 solver.cpp:404]     Test net output #1: loss = 0.430082 (* 1 = 0.430082 loss)
I0819 17:58:12.802101 22726 solver.cpp:228] Iteration 45200, loss = 0.124969
I0819 17:58:12.802150 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 17:58:12.802173 22726 solver.cpp:244]     Train net output #1: loss = 0.124969 (* 1 = 0.124969 loss)
I0819 17:58:12.888739 22726 sgd_solver.cpp:166] Iteration 45200, lr = 1.13
I0819 18:00:30.418285 22726 solver.cpp:337] Iteration 45300, Testing net (#0)
I0819 18:01:54.813693 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87852
I0819 18:01:54.814028 22726 solver.cpp:404]     Test net output #1: loss = 0.44426 (* 1 = 0.44426 loss)
I0819 18:01:56.141800 22726 solver.cpp:228] Iteration 45300, loss = 0.185026
I0819 18:01:56.141844 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 18:01:56.141867 22726 solver.cpp:244]     Train net output #1: loss = 0.185025 (* 1 = 0.185025 loss)
I0819 18:01:56.225647 22726 sgd_solver.cpp:166] Iteration 45300, lr = 1.1325
I0819 18:04:13.819963 22726 solver.cpp:337] Iteration 45400, Testing net (#0)
I0819 18:05:38.212400 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87856
I0819 18:05:38.212725 22726 solver.cpp:404]     Test net output #1: loss = 0.431743 (* 1 = 0.431743 loss)
I0819 18:05:39.540576 22726 solver.cpp:228] Iteration 45400, loss = 0.0966843
I0819 18:05:39.540624 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 18:05:39.540648 22726 solver.cpp:244]     Train net output #1: loss = 0.0966841 (* 1 = 0.0966841 loss)
I0819 18:05:39.624575 22726 sgd_solver.cpp:166] Iteration 45400, lr = 1.135
I0819 18:07:57.154387 22726 solver.cpp:337] Iteration 45500, Testing net (#0)
I0819 18:09:21.550453 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88076
I0819 18:09:21.550789 22726 solver.cpp:404]     Test net output #1: loss = 0.420523 (* 1 = 0.420523 loss)
I0819 18:09:22.878618 22726 solver.cpp:228] Iteration 45500, loss = 0.111069
I0819 18:09:22.878665 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 18:09:22.878690 22726 solver.cpp:244]     Train net output #1: loss = 0.111069 (* 1 = 0.111069 loss)
I0819 18:09:22.960634 22726 sgd_solver.cpp:166] Iteration 45500, lr = 1.1375
I0819 18:11:40.590859 22726 solver.cpp:337] Iteration 45600, Testing net (#0)
I0819 18:13:04.982164 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87828
I0819 18:13:04.982491 22726 solver.cpp:404]     Test net output #1: loss = 0.438675 (* 1 = 0.438675 loss)
I0819 18:13:06.310500 22726 solver.cpp:228] Iteration 45600, loss = 0.0880177
I0819 18:13:06.310549 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 18:13:06.310572 22726 solver.cpp:244]     Train net output #1: loss = 0.0880174 (* 1 = 0.0880174 loss)
I0819 18:13:06.390768 22726 sgd_solver.cpp:166] Iteration 45600, lr = 1.14
I0819 18:15:24.136515 22726 solver.cpp:337] Iteration 45700, Testing net (#0)
I0819 18:16:48.525220 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87384
I0819 18:16:48.525547 22726 solver.cpp:404]     Test net output #1: loss = 0.444564 (* 1 = 0.444564 loss)
I0819 18:16:49.853263 22726 solver.cpp:228] Iteration 45700, loss = 0.12727
I0819 18:16:49.853301 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 18:16:49.853322 22726 solver.cpp:244]     Train net output #1: loss = 0.12727 (* 1 = 0.12727 loss)
I0819 18:16:49.935395 22726 sgd_solver.cpp:166] Iteration 45700, lr = 1.1425
I0819 18:19:07.624141 22726 solver.cpp:337] Iteration 45800, Testing net (#0)
I0819 18:20:32.016074 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8866
I0819 18:20:32.016417 22726 solver.cpp:404]     Test net output #1: loss = 0.408267 (* 1 = 0.408267 loss)
I0819 18:20:33.342885 22726 solver.cpp:228] Iteration 45800, loss = 0.0703556
I0819 18:20:33.342933 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 18:20:33.342957 22726 solver.cpp:244]     Train net output #1: loss = 0.0703554 (* 1 = 0.0703554 loss)
I0819 18:20:33.429291 22726 sgd_solver.cpp:166] Iteration 45800, lr = 1.145
I0819 18:22:50.967988 22726 solver.cpp:337] Iteration 45900, Testing net (#0)
I0819 18:24:15.381077 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8888
I0819 18:24:15.381400 22726 solver.cpp:404]     Test net output #1: loss = 0.397893 (* 1 = 0.397893 loss)
I0819 18:24:16.708601 22726 solver.cpp:228] Iteration 45900, loss = 0.136161
I0819 18:24:16.708640 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 18:24:16.708662 22726 solver.cpp:244]     Train net output #1: loss = 0.13616 (* 1 = 0.13616 loss)
I0819 18:24:16.789161 22726 sgd_solver.cpp:166] Iteration 45900, lr = 1.1475
I0819 18:26:34.413347 22726 solver.cpp:337] Iteration 46000, Testing net (#0)
I0819 18:27:58.867154 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88656
I0819 18:27:58.867465 22726 solver.cpp:404]     Test net output #1: loss = 0.421817 (* 1 = 0.421817 loss)
I0819 18:28:00.194694 22726 solver.cpp:228] Iteration 46000, loss = 0.0533006
I0819 18:28:00.194738 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0819 18:28:00.194756 22726 solver.cpp:244]     Train net output #1: loss = 0.0533004 (* 1 = 0.0533004 loss)
I0819 18:28:00.282202 22726 sgd_solver.cpp:166] Iteration 46000, lr = 1.15
I0819 18:30:17.887912 22726 solver.cpp:337] Iteration 46100, Testing net (#0)
I0819 18:31:42.295480 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88784
I0819 18:31:42.295801 22726 solver.cpp:404]     Test net output #1: loss = 0.403742 (* 1 = 0.403742 loss)
I0819 18:31:43.624711 22726 solver.cpp:228] Iteration 46100, loss = 0.121245
I0819 18:31:43.624756 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 18:31:43.624773 22726 solver.cpp:244]     Train net output #1: loss = 0.121245 (* 1 = 0.121245 loss)
I0819 18:31:43.710935 22726 sgd_solver.cpp:166] Iteration 46100, lr = 1.1525
I0819 18:34:01.343050 22726 solver.cpp:337] Iteration 46200, Testing net (#0)
I0819 18:35:25.785075 22726 solver.cpp:404]     Test net output #0: accuracy = 0.881601
I0819 18:35:25.785406 22726 solver.cpp:404]     Test net output #1: loss = 0.421497 (* 1 = 0.421497 loss)
I0819 18:35:27.113411 22726 solver.cpp:228] Iteration 46200, loss = 0.093508
I0819 18:35:27.113457 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 18:35:27.113481 22726 solver.cpp:244]     Train net output #1: loss = 0.0935078 (* 1 = 0.0935078 loss)
I0819 18:35:27.197077 22726 sgd_solver.cpp:166] Iteration 46200, lr = 1.155
I0819 18:37:44.852674 22726 solver.cpp:337] Iteration 46300, Testing net (#0)
I0819 18:39:09.303418 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88488
I0819 18:39:09.303750 22726 solver.cpp:404]     Test net output #1: loss = 0.399207 (* 1 = 0.399207 loss)
I0819 18:39:10.631417 22726 solver.cpp:228] Iteration 46300, loss = 0.0822586
I0819 18:39:10.631459 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 18:39:10.631484 22726 solver.cpp:244]     Train net output #1: loss = 0.0822584 (* 1 = 0.0822584 loss)
I0819 18:39:10.710960 22726 sgd_solver.cpp:166] Iteration 46300, lr = 1.1575
I0819 18:41:28.426810 22726 solver.cpp:337] Iteration 46400, Testing net (#0)
I0819 18:42:52.856968 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88
I0819 18:42:52.857292 22726 solver.cpp:404]     Test net output #1: loss = 0.438245 (* 1 = 0.438245 loss)
I0819 18:42:54.184001 22726 solver.cpp:228] Iteration 46400, loss = 0.152211
I0819 18:42:54.184034 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 18:42:54.184049 22726 solver.cpp:244]     Train net output #1: loss = 0.152211 (* 1 = 0.152211 loss)
I0819 18:42:54.266265 22726 sgd_solver.cpp:166] Iteration 46400, lr = 1.16
I0819 18:45:11.850544 22726 solver.cpp:337] Iteration 46500, Testing net (#0)
I0819 18:46:36.281000 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88536
I0819 18:46:36.281324 22726 solver.cpp:404]     Test net output #1: loss = 0.39519 (* 1 = 0.39519 loss)
I0819 18:46:37.608018 22726 solver.cpp:228] Iteration 46500, loss = 0.0745814
I0819 18:46:37.608055 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 18:46:37.608070 22726 solver.cpp:244]     Train net output #1: loss = 0.0745812 (* 1 = 0.0745812 loss)
I0819 18:46:37.689085 22726 sgd_solver.cpp:166] Iteration 46500, lr = 1.1625
I0819 18:48:55.183740 22726 solver.cpp:337] Iteration 46600, Testing net (#0)
I0819 18:50:19.615010 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88708
I0819 18:50:19.615320 22726 solver.cpp:404]     Test net output #1: loss = 0.404372 (* 1 = 0.404372 loss)
I0819 18:50:20.942342 22726 solver.cpp:228] Iteration 46600, loss = 0.0939489
I0819 18:50:20.942379 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 18:50:20.942395 22726 solver.cpp:244]     Train net output #1: loss = 0.0939487 (* 1 = 0.0939487 loss)
I0819 18:50:21.021126 22726 sgd_solver.cpp:166] Iteration 46600, lr = 1.165
I0819 18:52:38.539577 22726 solver.cpp:337] Iteration 46700, Testing net (#0)
I0819 18:54:02.968257 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87888
I0819 18:54:02.968571 22726 solver.cpp:404]     Test net output #1: loss = 0.41529 (* 1 = 0.41529 loss)
I0819 18:54:04.295377 22726 solver.cpp:228] Iteration 46700, loss = 0.0895156
I0819 18:54:04.295415 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 18:54:04.295431 22726 solver.cpp:244]     Train net output #1: loss = 0.0895154 (* 1 = 0.0895154 loss)
I0819 18:54:04.379843 22726 sgd_solver.cpp:166] Iteration 46700, lr = 1.1675
I0819 18:56:21.920337 22726 solver.cpp:337] Iteration 46800, Testing net (#0)
I0819 18:57:46.353533 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88184
I0819 18:57:46.353849 22726 solver.cpp:404]     Test net output #1: loss = 0.443431 (* 1 = 0.443431 loss)
I0819 18:57:47.681288 22726 solver.cpp:228] Iteration 46800, loss = 0.223196
I0819 18:57:47.681330 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 18:57:47.681346 22726 solver.cpp:244]     Train net output #1: loss = 0.223196 (* 1 = 0.223196 loss)
I0819 18:57:47.765404 22726 sgd_solver.cpp:166] Iteration 46800, lr = 1.17
I0819 19:00:05.252040 22726 solver.cpp:337] Iteration 46900, Testing net (#0)
I0819 19:01:29.689455 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86996
I0819 19:01:29.689779 22726 solver.cpp:404]     Test net output #1: loss = 0.4753 (* 1 = 0.4753 loss)
I0819 19:01:31.016886 22726 solver.cpp:228] Iteration 46900, loss = 0.223155
I0819 19:01:31.016923 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0819 19:01:31.016938 22726 solver.cpp:244]     Train net output #1: loss = 0.223155 (* 1 = 0.223155 loss)
I0819 19:01:31.096772 22726 sgd_solver.cpp:166] Iteration 46900, lr = 1.1725
I0819 19:03:48.602079 22726 solver.cpp:337] Iteration 47000, Testing net (#0)
I0819 19:05:13.038480 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8826
I0819 19:05:13.038808 22726 solver.cpp:404]     Test net output #1: loss = 0.417122 (* 1 = 0.417122 loss)
I0819 19:05:14.366179 22726 solver.cpp:228] Iteration 47000, loss = 0.0679621
I0819 19:05:14.366221 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 19:05:14.366237 22726 solver.cpp:244]     Train net output #1: loss = 0.0679619 (* 1 = 0.0679619 loss)
I0819 19:05:14.451835 22726 sgd_solver.cpp:166] Iteration 47000, lr = 1.175
I0819 19:07:31.962970 22726 solver.cpp:337] Iteration 47100, Testing net (#0)
I0819 19:08:56.398727 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88096
I0819 19:08:56.399044 22726 solver.cpp:404]     Test net output #1: loss = 0.428933 (* 1 = 0.428933 loss)
I0819 19:08:57.725436 22726 solver.cpp:228] Iteration 47100, loss = 0.146672
I0819 19:08:57.725476 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 19:08:57.725492 22726 solver.cpp:244]     Train net output #1: loss = 0.146672 (* 1 = 0.146672 loss)
I0819 19:08:57.806758 22726 sgd_solver.cpp:166] Iteration 47100, lr = 1.1775
I0819 19:11:15.294486 22726 solver.cpp:337] Iteration 47200, Testing net (#0)
I0819 19:12:39.729275 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87496
I0819 19:12:39.729604 22726 solver.cpp:404]     Test net output #1: loss = 0.448276 (* 1 = 0.448276 loss)
I0819 19:12:41.056627 22726 solver.cpp:228] Iteration 47200, loss = 0.153864
I0819 19:12:41.056668 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 19:12:41.056684 22726 solver.cpp:244]     Train net output #1: loss = 0.153864 (* 1 = 0.153864 loss)
I0819 19:12:41.143465 22726 sgd_solver.cpp:166] Iteration 47200, lr = 1.18
I0819 19:14:58.732410 22726 solver.cpp:337] Iteration 47300, Testing net (#0)
I0819 19:16:23.171239 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87556
I0819 19:16:23.171563 22726 solver.cpp:404]     Test net output #1: loss = 0.443823 (* 1 = 0.443823 loss)
I0819 19:16:24.502106 22726 solver.cpp:228] Iteration 47300, loss = 0.0900085
I0819 19:16:24.502147 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 19:16:24.502162 22726 solver.cpp:244]     Train net output #1: loss = 0.0900083 (* 1 = 0.0900083 loss)
I0819 19:16:24.586990 22726 sgd_solver.cpp:166] Iteration 47300, lr = 1.1825
I0819 19:18:42.091874 22726 solver.cpp:337] Iteration 47400, Testing net (#0)
I0819 19:20:06.519081 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87548
I0819 19:20:06.519405 22726 solver.cpp:404]     Test net output #1: loss = 0.433187 (* 1 = 0.433187 loss)
I0819 19:20:07.850252 22726 solver.cpp:228] Iteration 47400, loss = 0.133181
I0819 19:20:07.850293 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 19:20:07.850309 22726 solver.cpp:244]     Train net output #1: loss = 0.13318 (* 1 = 0.13318 loss)
I0819 19:20:07.929139 22726 sgd_solver.cpp:166] Iteration 47400, lr = 1.185
I0819 19:22:25.540318 22726 solver.cpp:337] Iteration 47500, Testing net (#0)
I0819 19:23:50.020970 22726 solver.cpp:404]     Test net output #0: accuracy = 0.880681
I0819 19:23:50.021303 22726 solver.cpp:404]     Test net output #1: loss = 0.420161 (* 1 = 0.420161 loss)
I0819 19:23:51.352929 22726 solver.cpp:228] Iteration 47500, loss = 0.0891745
I0819 19:23:51.352972 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 19:23:51.352988 22726 solver.cpp:244]     Train net output #1: loss = 0.0891742 (* 1 = 0.0891742 loss)
I0819 19:23:51.441884 22726 sgd_solver.cpp:166] Iteration 47500, lr = 1.1875
I0819 19:26:09.007803 22726 solver.cpp:337] Iteration 47600, Testing net (#0)
I0819 19:27:33.458338 22726 solver.cpp:404]     Test net output #0: accuracy = 0.881561
I0819 19:27:33.458662 22726 solver.cpp:404]     Test net output #1: loss = 0.440841 (* 1 = 0.440841 loss)
I0819 19:27:34.789350 22726 solver.cpp:228] Iteration 47600, loss = 0.113273
I0819 19:27:34.789393 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 19:27:34.789410 22726 solver.cpp:244]     Train net output #1: loss = 0.113273 (* 1 = 0.113273 loss)
I0819 19:27:34.873459 22726 sgd_solver.cpp:166] Iteration 47600, lr = 1.19
I0819 19:29:52.774245 22726 solver.cpp:337] Iteration 47700, Testing net (#0)
I0819 19:31:17.250519 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86996
I0819 19:31:17.250846 22726 solver.cpp:404]     Test net output #1: loss = 0.474175 (* 1 = 0.474175 loss)
I0819 19:31:18.582727 22726 solver.cpp:228] Iteration 47700, loss = 0.205607
I0819 19:31:18.582768 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 19:31:18.582785 22726 solver.cpp:244]     Train net output #1: loss = 0.205607 (* 1 = 0.205607 loss)
I0819 19:31:18.663760 22726 sgd_solver.cpp:166] Iteration 47700, lr = 1.1925
I0819 19:33:36.680502 22726 solver.cpp:337] Iteration 47800, Testing net (#0)
I0819 19:35:01.118135 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87192
I0819 19:35:01.118469 22726 solver.cpp:404]     Test net output #1: loss = 0.456475 (* 1 = 0.456475 loss)
I0819 19:35:02.449463 22726 solver.cpp:228] Iteration 47800, loss = 0.10647
I0819 19:35:02.449503 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 19:35:02.449520 22726 solver.cpp:244]     Train net output #1: loss = 0.10647 (* 1 = 0.10647 loss)
I0819 19:35:02.535939 22726 sgd_solver.cpp:166] Iteration 47800, lr = 1.195
I0819 19:37:20.434294 22726 solver.cpp:337] Iteration 47900, Testing net (#0)
I0819 19:38:44.903687 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88428
I0819 19:38:44.904014 22726 solver.cpp:404]     Test net output #1: loss = 0.437964 (* 1 = 0.437964 loss)
I0819 19:38:46.235801 22726 solver.cpp:228] Iteration 47900, loss = 0.175451
I0819 19:38:46.235843 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 19:38:46.235859 22726 solver.cpp:244]     Train net output #1: loss = 0.175451 (* 1 = 0.175451 loss)
I0819 19:38:46.320001 22726 sgd_solver.cpp:166] Iteration 47900, lr = 1.1975
I0819 19:41:04.160390 22726 solver.cpp:337] Iteration 48000, Testing net (#0)
I0819 19:42:28.652971 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87428
I0819 19:42:28.653270 22726 solver.cpp:404]     Test net output #1: loss = 0.455786 (* 1 = 0.455786 loss)
I0819 19:42:29.984650 22726 solver.cpp:228] Iteration 48000, loss = 0.178625
I0819 19:42:29.984691 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 19:42:29.984707 22726 solver.cpp:244]     Train net output #1: loss = 0.178625 (* 1 = 0.178625 loss)
I0819 19:42:30.068169 22726 sgd_solver.cpp:166] Iteration 48000, lr = 1.2
I0819 19:44:47.896508 22726 solver.cpp:337] Iteration 48100, Testing net (#0)
I0819 19:46:12.321913 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87676
I0819 19:46:12.322239 22726 solver.cpp:404]     Test net output #1: loss = 0.441683 (* 1 = 0.441683 loss)
I0819 19:46:13.653045 22726 solver.cpp:228] Iteration 48100, loss = 0.103727
I0819 19:46:13.653087 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 19:46:13.653108 22726 solver.cpp:244]     Train net output #1: loss = 0.103727 (* 1 = 0.103727 loss)
I0819 19:46:13.738014 22726 sgd_solver.cpp:166] Iteration 48100, lr = 1.2025
I0819 19:48:31.573359 22726 solver.cpp:337] Iteration 48200, Testing net (#0)
I0819 19:49:56.002048 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87808
I0819 19:49:56.002363 22726 solver.cpp:404]     Test net output #1: loss = 0.441844 (* 1 = 0.441844 loss)
I0819 19:49:57.332878 22726 solver.cpp:228] Iteration 48200, loss = 0.163493
I0819 19:49:57.332921 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 19:49:57.332937 22726 solver.cpp:244]     Train net output #1: loss = 0.163493 (* 1 = 0.163493 loss)
I0819 19:49:57.412881 22726 sgd_solver.cpp:166] Iteration 48200, lr = 1.205
I0819 19:52:15.210454 22726 solver.cpp:337] Iteration 48300, Testing net (#0)
I0819 19:53:39.649838 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87492
I0819 19:53:39.650148 22726 solver.cpp:404]     Test net output #1: loss = 0.431437 (* 1 = 0.431437 loss)
I0819 19:53:40.981871 22726 solver.cpp:228] Iteration 48300, loss = 0.161566
I0819 19:53:40.981914 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 19:53:40.981931 22726 solver.cpp:244]     Train net output #1: loss = 0.161566 (* 1 = 0.161566 loss)
I0819 19:53:41.061910 22726 sgd_solver.cpp:166] Iteration 48300, lr = 1.2075
I0819 19:55:58.928257 22726 solver.cpp:337] Iteration 48400, Testing net (#0)
I0819 19:57:23.366858 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87824
I0819 19:57:23.367182 22726 solver.cpp:404]     Test net output #1: loss = 0.4376 (* 1 = 0.4376 loss)
I0819 19:57:24.699179 22726 solver.cpp:228] Iteration 48400, loss = 0.174262
I0819 19:57:24.699223 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0819 19:57:24.699239 22726 solver.cpp:244]     Train net output #1: loss = 0.174262 (* 1 = 0.174262 loss)
I0819 19:57:24.782042 22726 sgd_solver.cpp:166] Iteration 48400, lr = 1.21
I0819 19:59:42.777451 22726 solver.cpp:337] Iteration 48500, Testing net (#0)
I0819 20:01:07.215898 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8864
I0819 20:01:07.216202 22726 solver.cpp:404]     Test net output #1: loss = 0.42246 (* 1 = 0.42246 loss)
I0819 20:01:08.546607 22726 solver.cpp:228] Iteration 48500, loss = 0.129582
I0819 20:01:08.546651 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 20:01:08.546675 22726 solver.cpp:244]     Train net output #1: loss = 0.129582 (* 1 = 0.129582 loss)
I0819 20:01:08.630240 22726 sgd_solver.cpp:166] Iteration 48500, lr = 1.2125
I0819 20:03:26.531553 22726 solver.cpp:337] Iteration 48600, Testing net (#0)
I0819 20:04:50.963956 22726 solver.cpp:404]     Test net output #0: accuracy = 0.884
I0819 20:04:50.964289 22726 solver.cpp:404]     Test net output #1: loss = 0.411601 (* 1 = 0.411601 loss)
I0819 20:04:52.299947 22726 solver.cpp:228] Iteration 48600, loss = 0.196507
I0819 20:04:52.299994 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 20:04:52.300019 22726 solver.cpp:244]     Train net output #1: loss = 0.196506 (* 1 = 0.196506 loss)
I0819 20:04:52.371129 22726 sgd_solver.cpp:166] Iteration 48600, lr = 1.215
I0819 20:07:10.177073 22726 solver.cpp:337] Iteration 48700, Testing net (#0)
I0819 20:08:34.622931 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88328
I0819 20:08:34.623242 22726 solver.cpp:404]     Test net output #1: loss = 0.399775 (* 1 = 0.399775 loss)
I0819 20:08:35.955066 22726 solver.cpp:228] Iteration 48700, loss = 0.162707
I0819 20:08:35.955108 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 20:08:35.955124 22726 solver.cpp:244]     Train net output #1: loss = 0.162707 (* 1 = 0.162707 loss)
I0819 20:08:36.039623 22726 sgd_solver.cpp:166] Iteration 48700, lr = 1.2175
I0819 20:10:53.862969 22726 solver.cpp:337] Iteration 48800, Testing net (#0)
I0819 20:12:18.310567 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8842
I0819 20:12:18.310890 22726 solver.cpp:404]     Test net output #1: loss = 0.421054 (* 1 = 0.421054 loss)
I0819 20:12:19.642060 22726 solver.cpp:228] Iteration 48800, loss = 0.167148
I0819 20:12:19.642101 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 20:12:19.642117 22726 solver.cpp:244]     Train net output #1: loss = 0.167148 (* 1 = 0.167148 loss)
I0819 20:12:19.717730 22726 sgd_solver.cpp:166] Iteration 48800, lr = 1.22
I0819 20:14:37.641825 22726 solver.cpp:337] Iteration 48900, Testing net (#0)
I0819 20:16:02.754685 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88632
I0819 20:16:02.754968 22726 solver.cpp:404]     Test net output #1: loss = 0.40987 (* 1 = 0.40987 loss)
I0819 20:16:04.087846 22726 solver.cpp:228] Iteration 48900, loss = 0.131116
I0819 20:16:04.087888 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 20:16:04.087904 22726 solver.cpp:244]     Train net output #1: loss = 0.131116 (* 1 = 0.131116 loss)
I0819 20:16:04.166968 22726 sgd_solver.cpp:166] Iteration 48900, lr = 1.2225
I0819 20:18:22.306344 22726 solver.cpp:337] Iteration 49000, Testing net (#0)
I0819 20:19:47.409186 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88168
I0819 20:19:47.409471 22726 solver.cpp:404]     Test net output #1: loss = 0.418979 (* 1 = 0.418979 loss)
I0819 20:19:48.743564 22726 solver.cpp:228] Iteration 49000, loss = 0.096998
I0819 20:19:48.743607 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 20:19:48.743623 22726 solver.cpp:244]     Train net output #1: loss = 0.0969979 (* 1 = 0.0969979 loss)
I0819 20:19:48.818657 22726 sgd_solver.cpp:166] Iteration 49000, lr = 1.225
I0819 20:22:06.961220 22726 solver.cpp:337] Iteration 49100, Testing net (#0)
I0819 20:23:32.092149 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88
I0819 20:23:32.092416 22726 solver.cpp:404]     Test net output #1: loss = 0.415454 (* 1 = 0.415454 loss)
I0819 20:23:33.424110 22726 solver.cpp:228] Iteration 49100, loss = 0.127898
I0819 20:23:33.424154 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 20:23:33.424170 22726 solver.cpp:244]     Train net output #1: loss = 0.127898 (* 1 = 0.127898 loss)
I0819 20:23:33.508035 22726 sgd_solver.cpp:166] Iteration 49100, lr = 1.2275
I0819 20:25:51.772017 22726 solver.cpp:337] Iteration 49200, Testing net (#0)
I0819 20:27:16.895689 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88212
I0819 20:27:16.895987 22726 solver.cpp:404]     Test net output #1: loss = 0.414193 (* 1 = 0.414193 loss)
I0819 20:27:18.229848 22726 solver.cpp:228] Iteration 49200, loss = 0.203477
I0819 20:27:18.229895 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0819 20:27:18.229918 22726 solver.cpp:244]     Train net output #1: loss = 0.203477 (* 1 = 0.203477 loss)
I0819 20:27:18.308815 22726 sgd_solver.cpp:166] Iteration 49200, lr = 1.23
I0819 20:29:36.437278 22726 solver.cpp:337] Iteration 49300, Testing net (#0)
I0819 20:31:01.565196 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88248
I0819 20:31:01.565505 22726 solver.cpp:404]     Test net output #1: loss = 0.424422 (* 1 = 0.424422 loss)
I0819 20:31:02.899507 22726 solver.cpp:228] Iteration 49300, loss = 0.207418
I0819 20:31:02.899551 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 20:31:02.899566 22726 solver.cpp:244]     Train net output #1: loss = 0.207418 (* 1 = 0.207418 loss)
I0819 20:31:02.986004 22726 sgd_solver.cpp:166] Iteration 49300, lr = 1.2325
I0819 20:33:21.334888 22726 solver.cpp:337] Iteration 49400, Testing net (#0)
I0819 20:34:46.452715 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8838
I0819 20:34:46.452983 22726 solver.cpp:404]     Test net output #1: loss = 0.395484 (* 1 = 0.395484 loss)
I0819 20:34:47.785890 22726 solver.cpp:228] Iteration 49400, loss = 0.0689618
I0819 20:34:47.785935 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 20:34:47.785949 22726 solver.cpp:244]     Train net output #1: loss = 0.0689618 (* 1 = 0.0689618 loss)
I0819 20:34:47.864177 22726 sgd_solver.cpp:166] Iteration 49400, lr = 1.235
I0819 20:37:06.084041 22726 solver.cpp:337] Iteration 49500, Testing net (#0)
I0819 20:38:31.181381 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87188
I0819 20:38:31.181684 22726 solver.cpp:404]     Test net output #1: loss = 0.45326 (* 1 = 0.45326 loss)
I0819 20:38:32.515261 22726 solver.cpp:228] Iteration 49500, loss = 0.142651
I0819 20:38:32.515302 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 20:38:32.515317 22726 solver.cpp:244]     Train net output #1: loss = 0.142651 (* 1 = 0.142651 loss)
I0819 20:38:32.594017 22726 sgd_solver.cpp:166] Iteration 49500, lr = 1.2375
I0819 20:40:50.639158 22726 solver.cpp:337] Iteration 49600, Testing net (#0)
I0819 20:42:15.738489 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87776
I0819 20:42:15.738811 22726 solver.cpp:404]     Test net output #1: loss = 0.430537 (* 1 = 0.430537 loss)
I0819 20:42:17.071035 22726 solver.cpp:228] Iteration 49600, loss = 0.0593288
I0819 20:42:17.071087 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 20:42:17.071105 22726 solver.cpp:244]     Train net output #1: loss = 0.0593288 (* 1 = 0.0593288 loss)
I0819 20:42:17.152737 22726 sgd_solver.cpp:166] Iteration 49600, lr = 1.24
I0819 20:44:35.243459 22726 solver.cpp:337] Iteration 49700, Testing net (#0)
I0819 20:46:00.335269 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8846
I0819 20:46:00.335546 22726 solver.cpp:404]     Test net output #1: loss = 0.415641 (* 1 = 0.415641 loss)
I0819 20:46:01.668349 22726 solver.cpp:228] Iteration 49700, loss = 0.133266
I0819 20:46:01.668395 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 20:46:01.668411 22726 solver.cpp:244]     Train net output #1: loss = 0.133266 (* 1 = 0.133266 loss)
I0819 20:46:01.750471 22726 sgd_solver.cpp:166] Iteration 49700, lr = 1.2425
I0819 20:48:19.897670 22726 solver.cpp:337] Iteration 49800, Testing net (#0)
I0819 20:49:44.989873 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87652
I0819 20:49:44.990172 22726 solver.cpp:404]     Test net output #1: loss = 0.446702 (* 1 = 0.446702 loss)
I0819 20:49:46.323245 22726 solver.cpp:228] Iteration 49800, loss = 0.152697
I0819 20:49:46.323287 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 20:49:46.323302 22726 solver.cpp:244]     Train net output #1: loss = 0.152696 (* 1 = 0.152696 loss)
I0819 20:49:46.400475 22726 sgd_solver.cpp:166] Iteration 49800, lr = 1.245
I0819 20:52:04.450191 22726 solver.cpp:337] Iteration 49900, Testing net (#0)
I0819 20:53:29.539875 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88112
I0819 20:53:29.540165 22726 solver.cpp:404]     Test net output #1: loss = 0.413625 (* 1 = 0.413625 loss)
I0819 20:53:30.872936 22726 solver.cpp:228] Iteration 49900, loss = 0.156976
I0819 20:53:30.872985 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 20:53:30.873001 22726 solver.cpp:244]     Train net output #1: loss = 0.156976 (* 1 = 0.156976 loss)
I0819 20:53:30.955485 22726 sgd_solver.cpp:166] Iteration 49900, lr = 1.2475
I0819 20:55:49.138612 22726 solver.cpp:337] Iteration 50000, Testing net (#0)
I0819 20:57:14.214371 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88252
I0819 20:57:14.214649 22726 solver.cpp:404]     Test net output #1: loss = 0.416618 (* 1 = 0.416618 loss)
I0819 20:57:15.547247 22726 solver.cpp:228] Iteration 50000, loss = 0.118758
I0819 20:57:15.547287 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 20:57:15.547302 22726 solver.cpp:244]     Train net output #1: loss = 0.118758 (* 1 = 0.118758 loss)
I0819 20:57:15.626237 22726 sgd_solver.cpp:166] Iteration 50000, lr = 1.25
I0819 20:59:33.917567 22726 solver.cpp:337] Iteration 50100, Testing net (#0)
I0819 21:00:59.023599 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88352
I0819 21:00:59.023910 22726 solver.cpp:404]     Test net output #1: loss = 0.418233 (* 1 = 0.418233 loss)
I0819 21:01:00.356801 22726 solver.cpp:228] Iteration 50100, loss = 0.114394
I0819 21:01:00.356842 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 21:01:00.356858 22726 solver.cpp:244]     Train net output #1: loss = 0.114394 (* 1 = 0.114394 loss)
I0819 21:01:00.433372 22726 sgd_solver.cpp:166] Iteration 50100, lr = 1.2525
I0819 21:03:18.556344 22726 solver.cpp:337] Iteration 50200, Testing net (#0)
I0819 21:04:43.676113 22726 solver.cpp:404]     Test net output #0: accuracy = 0.89396
I0819 21:04:43.676398 22726 solver.cpp:404]     Test net output #1: loss = 0.380496 (* 1 = 0.380496 loss)
I0819 21:04:45.008858 22726 solver.cpp:228] Iteration 50200, loss = 0.0702409
I0819 21:04:45.008901 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 21:04:45.008918 22726 solver.cpp:244]     Train net output #1: loss = 0.0702408 (* 1 = 0.0702408 loss)
I0819 21:04:45.089318 22726 sgd_solver.cpp:166] Iteration 50200, lr = 1.255
I0819 21:07:03.179484 22726 solver.cpp:337] Iteration 50300, Testing net (#0)
I0819 21:08:28.310145 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88808
I0819 21:08:28.310420 22726 solver.cpp:404]     Test net output #1: loss = 0.392652 (* 1 = 0.392652 loss)
I0819 21:08:29.643362 22726 solver.cpp:228] Iteration 50300, loss = 0.161919
I0819 21:08:29.643402 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 21:08:29.643417 22726 solver.cpp:244]     Train net output #1: loss = 0.161918 (* 1 = 0.161918 loss)
I0819 21:08:29.726411 22726 sgd_solver.cpp:166] Iteration 50300, lr = 1.2575
I0819 21:10:47.799088 22726 solver.cpp:337] Iteration 50400, Testing net (#0)
I0819 21:12:12.914829 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88452
I0819 21:12:12.915159 22726 solver.cpp:404]     Test net output #1: loss = 0.402642 (* 1 = 0.402642 loss)
I0819 21:12:14.248044 22726 solver.cpp:228] Iteration 50400, loss = 0.185151
I0819 21:12:14.248086 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 21:12:14.248102 22726 solver.cpp:244]     Train net output #1: loss = 0.185151 (* 1 = 0.185151 loss)
I0819 21:12:14.331853 22726 sgd_solver.cpp:166] Iteration 50400, lr = 1.26
I0819 21:14:32.519317 22726 solver.cpp:337] Iteration 50500, Testing net (#0)
I0819 21:15:57.648898 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88432
I0819 21:15:57.649230 22726 solver.cpp:404]     Test net output #1: loss = 0.412018 (* 1 = 0.412018 loss)
I0819 21:15:58.981806 22726 solver.cpp:228] Iteration 50500, loss = 0.167868
I0819 21:15:58.981847 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 21:15:58.981863 22726 solver.cpp:244]     Train net output #1: loss = 0.167868 (* 1 = 0.167868 loss)
I0819 21:15:59.060168 22726 sgd_solver.cpp:166] Iteration 50500, lr = 1.2625
I0819 21:18:17.197489 22726 solver.cpp:337] Iteration 50600, Testing net (#0)
I0819 21:19:42.324971 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88996
I0819 21:19:42.325251 22726 solver.cpp:404]     Test net output #1: loss = 0.385878 (* 1 = 0.385878 loss)
I0819 21:19:43.658663 22726 solver.cpp:228] Iteration 50600, loss = 0.085132
I0819 21:19:43.658704 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 21:19:43.658720 22726 solver.cpp:244]     Train net output #1: loss = 0.085132 (* 1 = 0.085132 loss)
I0819 21:19:43.739131 22726 sgd_solver.cpp:166] Iteration 50600, lr = 1.265
I0819 21:22:01.842651 22726 solver.cpp:337] Iteration 50700, Testing net (#0)
I0819 21:23:26.972934 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88664
I0819 21:23:26.973240 22726 solver.cpp:404]     Test net output #1: loss = 0.406265 (* 1 = 0.406265 loss)
I0819 21:23:28.305153 22726 solver.cpp:228] Iteration 50700, loss = 0.124242
I0819 21:23:28.305203 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 21:23:28.305218 22726 solver.cpp:244]     Train net output #1: loss = 0.124242 (* 1 = 0.124242 loss)
I0819 21:23:28.385051 22726 sgd_solver.cpp:166] Iteration 50700, lr = 1.2675
I0819 21:25:46.498540 22726 solver.cpp:337] Iteration 50800, Testing net (#0)
I0819 21:27:11.624275 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8738
I0819 21:27:11.624569 22726 solver.cpp:404]     Test net output #1: loss = 0.444212 (* 1 = 0.444212 loss)
I0819 21:27:12.957166 22726 solver.cpp:228] Iteration 50800, loss = 0.230476
I0819 21:27:12.957209 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 21:27:12.957226 22726 solver.cpp:244]     Train net output #1: loss = 0.230476 (* 1 = 0.230476 loss)
I0819 21:27:13.041231 22726 sgd_solver.cpp:166] Iteration 50800, lr = 1.27
I0819 21:29:31.170440 22726 solver.cpp:337] Iteration 50900, Testing net (#0)
I0819 21:30:56.300035 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88484
I0819 21:30:56.300333 22726 solver.cpp:404]     Test net output #1: loss = 0.405759 (* 1 = 0.405759 loss)
I0819 21:30:57.633144 22726 solver.cpp:228] Iteration 50900, loss = 0.186587
I0819 21:30:57.633186 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0819 21:30:57.633201 22726 solver.cpp:244]     Train net output #1: loss = 0.186587 (* 1 = 0.186587 loss)
I0819 21:30:57.718538 22726 sgd_solver.cpp:166] Iteration 50900, lr = 1.2725
I0819 21:33:15.819537 22726 solver.cpp:337] Iteration 51000, Testing net (#0)
I0819 21:34:40.936086 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8804
I0819 21:34:40.936354 22726 solver.cpp:404]     Test net output #1: loss = 0.416316 (* 1 = 0.416316 loss)
I0819 21:34:42.268899 22726 solver.cpp:228] Iteration 51000, loss = 0.132697
I0819 21:34:42.268954 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 21:34:42.268970 22726 solver.cpp:244]     Train net output #1: loss = 0.132697 (* 1 = 0.132697 loss)
I0819 21:34:42.348762 22726 sgd_solver.cpp:166] Iteration 51000, lr = 1.275
I0819 21:37:00.548239 22726 solver.cpp:337] Iteration 51100, Testing net (#0)
I0819 21:38:25.666718 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88404
I0819 21:38:25.667006 22726 solver.cpp:404]     Test net output #1: loss = 0.409756 (* 1 = 0.409756 loss)
I0819 21:38:26.999675 22726 solver.cpp:228] Iteration 51100, loss = 0.131553
I0819 21:38:26.999719 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 21:38:26.999734 22726 solver.cpp:244]     Train net output #1: loss = 0.131553 (* 1 = 0.131553 loss)
I0819 21:38:27.080760 22726 sgd_solver.cpp:166] Iteration 51100, lr = 1.2775
I0819 21:40:45.194444 22726 solver.cpp:337] Iteration 51200, Testing net (#0)
I0819 21:42:10.286746 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88588
I0819 21:42:10.287057 22726 solver.cpp:404]     Test net output #1: loss = 0.407526 (* 1 = 0.407526 loss)
I0819 21:42:11.619490 22726 solver.cpp:228] Iteration 51200, loss = 0.16876
I0819 21:42:11.619534 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 21:42:11.619549 22726 solver.cpp:244]     Train net output #1: loss = 0.16876 (* 1 = 0.16876 loss)
I0819 21:42:11.699069 22726 sgd_solver.cpp:166] Iteration 51200, lr = 1.28
I0819 21:44:29.825374 22726 solver.cpp:337] Iteration 51300, Testing net (#0)
I0819 21:45:54.730296 22726 solver.cpp:404]     Test net output #0: accuracy = 0.89112
I0819 21:45:54.730567 22726 solver.cpp:404]     Test net output #1: loss = 0.384559 (* 1 = 0.384559 loss)
I0819 21:45:56.063484 22726 solver.cpp:228] Iteration 51300, loss = 0.161379
I0819 21:45:56.063525 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 21:45:56.063541 22726 solver.cpp:244]     Train net output #1: loss = 0.161379 (* 1 = 0.161379 loss)
I0819 21:45:56.145583 22726 sgd_solver.cpp:166] Iteration 51300, lr = 1.2825
I0819 21:48:14.270977 22726 solver.cpp:337] Iteration 51400, Testing net (#0)
I0819 21:49:39.208710 22726 solver.cpp:404]     Test net output #0: accuracy = 0.886521
I0819 21:49:39.208983 22726 solver.cpp:404]     Test net output #1: loss = 0.391145 (* 1 = 0.391145 loss)
I0819 21:49:40.541909 22726 solver.cpp:228] Iteration 51400, loss = 0.139674
I0819 21:49:40.541954 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 21:49:40.541968 22726 solver.cpp:244]     Train net output #1: loss = 0.139674 (* 1 = 0.139674 loss)
I0819 21:49:40.620153 22726 sgd_solver.cpp:166] Iteration 51400, lr = 1.285
I0819 21:51:58.651643 22726 solver.cpp:337] Iteration 51500, Testing net (#0)
I0819 21:53:23.706290 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88256
I0819 21:53:23.706599 22726 solver.cpp:404]     Test net output #1: loss = 0.408804 (* 1 = 0.408804 loss)
I0819 21:53:25.039358 22726 solver.cpp:228] Iteration 51500, loss = 0.12237
I0819 21:53:25.039408 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 21:53:25.039425 22726 solver.cpp:244]     Train net output #1: loss = 0.12237 (* 1 = 0.12237 loss)
I0819 21:53:25.124732 22726 sgd_solver.cpp:166] Iteration 51500, lr = 1.2875
I0819 21:55:43.165110 22726 solver.cpp:337] Iteration 51600, Testing net (#0)
I0819 21:57:08.232604 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87692
I0819 21:57:08.232905 22726 solver.cpp:404]     Test net output #1: loss = 0.430086 (* 1 = 0.430086 loss)
I0819 21:57:09.565583 22726 solver.cpp:228] Iteration 51600, loss = 0.135303
I0819 21:57:09.565625 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 21:57:09.565640 22726 solver.cpp:244]     Train net output #1: loss = 0.135302 (* 1 = 0.135302 loss)
I0819 21:57:09.646227 22726 sgd_solver.cpp:166] Iteration 51600, lr = 1.29
I0819 21:59:27.739984 22726 solver.cpp:337] Iteration 51700, Testing net (#0)
I0819 22:00:52.792207 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8886
I0819 22:00:52.792500 22726 solver.cpp:404]     Test net output #1: loss = 0.400972 (* 1 = 0.400972 loss)
I0819 22:00:54.124827 22726 solver.cpp:228] Iteration 51700, loss = 0.0307401
I0819 22:00:54.124878 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 22:00:54.124894 22726 solver.cpp:244]     Train net output #1: loss = 0.03074 (* 1 = 0.03074 loss)
I0819 22:00:54.208847 22726 sgd_solver.cpp:166] Iteration 51700, lr = 1.2925
I0819 22:03:12.261983 22726 solver.cpp:337] Iteration 51800, Testing net (#0)
I0819 22:04:37.324385 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88812
I0819 22:04:37.324686 22726 solver.cpp:404]     Test net output #1: loss = 0.391522 (* 1 = 0.391522 loss)
I0819 22:04:38.657241 22726 solver.cpp:228] Iteration 51800, loss = 0.0890575
I0819 22:04:38.657281 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 22:04:38.657296 22726 solver.cpp:244]     Train net output #1: loss = 0.0890574 (* 1 = 0.0890574 loss)
I0819 22:04:38.735883 22726 sgd_solver.cpp:166] Iteration 51800, lr = 1.295
I0819 22:06:56.848686 22726 solver.cpp:337] Iteration 51900, Testing net (#0)
I0819 22:08:21.735610 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8892
I0819 22:08:21.735875 22726 solver.cpp:404]     Test net output #1: loss = 0.372186 (* 1 = 0.372186 loss)
I0819 22:08:23.068583 22726 solver.cpp:228] Iteration 51900, loss = 0.118487
I0819 22:08:23.068625 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 22:08:23.068641 22726 solver.cpp:244]     Train net output #1: loss = 0.118486 (* 1 = 0.118486 loss)
I0819 22:08:23.146569 22726 sgd_solver.cpp:166] Iteration 51900, lr = 1.2975
I0819 22:10:41.221645 22726 solver.cpp:337] Iteration 52000, Testing net (#0)
I0819 22:12:06.365970 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87808
I0819 22:12:06.366315 22726 solver.cpp:404]     Test net output #1: loss = 0.44509 (* 1 = 0.44509 loss)
I0819 22:12:07.698482 22726 solver.cpp:228] Iteration 52000, loss = 0.195879
I0819 22:12:07.698520 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0819 22:12:07.698536 22726 solver.cpp:244]     Train net output #1: loss = 0.195879 (* 1 = 0.195879 loss)
I0819 22:12:07.774377 22726 sgd_solver.cpp:166] Iteration 52000, lr = 1.3
I0819 22:14:25.764848 22726 solver.cpp:337] Iteration 52100, Testing net (#0)
I0819 22:15:50.628180 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88032
I0819 22:15:50.628458 22726 solver.cpp:404]     Test net output #1: loss = 0.403391 (* 1 = 0.403391 loss)
I0819 22:15:51.961659 22726 solver.cpp:228] Iteration 52100, loss = 0.100027
I0819 22:15:51.961699 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 22:15:51.961715 22726 solver.cpp:244]     Train net output #1: loss = 0.100026 (* 1 = 0.100026 loss)
I0819 22:15:52.039520 22726 sgd_solver.cpp:166] Iteration 52100, lr = 1.3025
I0819 22:18:10.101287 22726 solver.cpp:337] Iteration 52200, Testing net (#0)
I0819 22:19:34.934378 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88048
I0819 22:19:34.934660 22726 solver.cpp:404]     Test net output #1: loss = 0.431455 (* 1 = 0.431455 loss)
I0819 22:19:36.267103 22726 solver.cpp:228] Iteration 52200, loss = 0.302011
I0819 22:19:36.267146 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 22:19:36.267163 22726 solver.cpp:244]     Train net output #1: loss = 0.302011 (* 1 = 0.302011 loss)
I0819 22:19:36.350970 22726 sgd_solver.cpp:166] Iteration 52200, lr = 1.305
I0819 22:21:54.403620 22726 solver.cpp:337] Iteration 52300, Testing net (#0)
I0819 22:23:19.245056 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88704
I0819 22:23:19.245363 22726 solver.cpp:404]     Test net output #1: loss = 0.396455 (* 1 = 0.396455 loss)
I0819 22:23:20.578383 22726 solver.cpp:228] Iteration 52300, loss = 0.13975
I0819 22:23:20.578425 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 22:23:20.578440 22726 solver.cpp:244]     Train net output #1: loss = 0.13975 (* 1 = 0.13975 loss)
I0819 22:23:20.660912 22726 sgd_solver.cpp:166] Iteration 52300, lr = 1.3075
I0819 22:25:38.990757 22726 solver.cpp:337] Iteration 52400, Testing net (#0)
I0819 22:27:03.797897 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88304
I0819 22:27:03.798166 22726 solver.cpp:404]     Test net output #1: loss = 0.401215 (* 1 = 0.401215 loss)
I0819 22:27:05.130683 22726 solver.cpp:228] Iteration 52400, loss = 0.178766
I0819 22:27:05.130724 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 22:27:05.130740 22726 solver.cpp:244]     Train net output #1: loss = 0.178766 (* 1 = 0.178766 loss)
I0819 22:27:05.215258 22726 sgd_solver.cpp:166] Iteration 52400, lr = 1.31
I0819 22:29:23.456898 22726 solver.cpp:337] Iteration 52500, Testing net (#0)
I0819 22:30:48.373311 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88064
I0819 22:30:48.373651 22726 solver.cpp:404]     Test net output #1: loss = 0.418013 (* 1 = 0.418013 loss)
I0819 22:30:49.706701 22726 solver.cpp:228] Iteration 52500, loss = 0.0949333
I0819 22:30:49.706744 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 22:30:49.706760 22726 solver.cpp:244]     Train net output #1: loss = 0.0949332 (* 1 = 0.0949332 loss)
I0819 22:30:49.790977 22726 sgd_solver.cpp:166] Iteration 52500, lr = 1.3125
I0819 22:33:07.914942 22726 solver.cpp:337] Iteration 52600, Testing net (#0)
I0819 22:34:32.769816 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88396
I0819 22:34:32.770081 22726 solver.cpp:404]     Test net output #1: loss = 0.406995 (* 1 = 0.406995 loss)
I0819 22:34:34.101974 22726 solver.cpp:228] Iteration 52600, loss = 0.0499557
I0819 22:34:34.102031 22726 solver.cpp:244]     Train net output #0: accuracy = 1
I0819 22:34:34.102048 22726 solver.cpp:244]     Train net output #1: loss = 0.0499556 (* 1 = 0.0499556 loss)
I0819 22:34:34.179811 22726 sgd_solver.cpp:166] Iteration 52600, lr = 1.315
I0819 22:36:52.328084 22726 solver.cpp:337] Iteration 52700, Testing net (#0)
I0819 22:38:17.082365 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88072
I0819 22:38:17.082650 22726 solver.cpp:404]     Test net output #1: loss = 0.404664 (* 1 = 0.404664 loss)
I0819 22:38:18.415204 22726 solver.cpp:228] Iteration 52700, loss = 0.200416
I0819 22:38:18.415249 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 22:38:18.415266 22726 solver.cpp:244]     Train net output #1: loss = 0.200415 (* 1 = 0.200415 loss)
I0819 22:38:18.497457 22726 sgd_solver.cpp:166] Iteration 52700, lr = 1.3175
I0819 22:40:36.593426 22726 solver.cpp:337] Iteration 52800, Testing net (#0)
I0819 22:42:01.373078 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88932
I0819 22:42:01.373343 22726 solver.cpp:404]     Test net output #1: loss = 0.395613 (* 1 = 0.395613 loss)
I0819 22:42:02.707105 22726 solver.cpp:228] Iteration 52800, loss = 0.152618
I0819 22:42:02.707145 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0819 22:42:02.707160 22726 solver.cpp:244]     Train net output #1: loss = 0.152618 (* 1 = 0.152618 loss)
I0819 22:42:02.790611 22726 sgd_solver.cpp:166] Iteration 52800, lr = 1.32
I0819 22:44:20.840029 22726 solver.cpp:337] Iteration 52900, Testing net (#0)
I0819 22:45:45.612697 22726 solver.cpp:404]     Test net output #0: accuracy = 0.886921
I0819 22:45:45.612987 22726 solver.cpp:404]     Test net output #1: loss = 0.391603 (* 1 = 0.391603 loss)
I0819 22:45:46.946805 22726 solver.cpp:228] Iteration 52900, loss = 0.0989175
I0819 22:45:46.946848 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 22:45:46.946863 22726 solver.cpp:244]     Train net output #1: loss = 0.0989174 (* 1 = 0.0989174 loss)
I0819 22:45:47.022672 22726 sgd_solver.cpp:166] Iteration 52900, lr = 1.3225
I0819 22:48:05.151257 22726 solver.cpp:337] Iteration 53000, Testing net (#0)
I0819 22:49:29.947284 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88472
I0819 22:49:29.947559 22726 solver.cpp:404]     Test net output #1: loss = 0.408584 (* 1 = 0.408584 loss)
I0819 22:49:31.280560 22726 solver.cpp:228] Iteration 53000, loss = 0.150853
I0819 22:49:31.280611 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 22:49:31.280627 22726 solver.cpp:244]     Train net output #1: loss = 0.150853 (* 1 = 0.150853 loss)
I0819 22:49:31.363003 22726 sgd_solver.cpp:166] Iteration 53000, lr = 1.325
I0819 22:51:49.458710 22726 solver.cpp:337] Iteration 53100, Testing net (#0)
I0819 22:53:14.200407 22726 solver.cpp:404]     Test net output #0: accuracy = 0.888
I0819 22:53:14.200712 22726 solver.cpp:404]     Test net output #1: loss = 0.393014 (* 1 = 0.393014 loss)
I0819 22:53:15.534165 22726 solver.cpp:228] Iteration 53100, loss = 0.216402
I0819 22:53:15.534207 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 22:53:15.534224 22726 solver.cpp:244]     Train net output #1: loss = 0.216402 (* 1 = 0.216402 loss)
I0819 22:53:15.615756 22726 sgd_solver.cpp:166] Iteration 53100, lr = 1.3275
I0819 22:55:33.600149 22726 solver.cpp:337] Iteration 53200, Testing net (#0)
I0819 22:56:58.457468 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88624
I0819 22:56:58.457720 22726 solver.cpp:404]     Test net output #1: loss = 0.396191 (* 1 = 0.396191 loss)
I0819 22:56:59.791474 22726 solver.cpp:228] Iteration 53200, loss = 0.117953
I0819 22:56:59.791518 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 22:56:59.791534 22726 solver.cpp:244]     Train net output #1: loss = 0.117952 (* 1 = 0.117952 loss)
I0819 22:56:59.872078 22726 sgd_solver.cpp:166] Iteration 53200, lr = 1.33
I0819 22:59:17.954541 22726 solver.cpp:337] Iteration 53300, Testing net (#0)
I0819 23:00:42.776180 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8896
I0819 23:00:42.776474 22726 solver.cpp:404]     Test net output #1: loss = 0.379407 (* 1 = 0.379407 loss)
I0819 23:00:44.110373 22726 solver.cpp:228] Iteration 53300, loss = 0.0947585
I0819 23:00:44.110416 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 23:00:44.110432 22726 solver.cpp:244]     Train net output #1: loss = 0.0947583 (* 1 = 0.0947583 loss)
I0819 23:00:44.189208 22726 sgd_solver.cpp:166] Iteration 53300, lr = 1.3325
I0819 23:03:02.280944 22726 solver.cpp:337] Iteration 53400, Testing net (#0)
I0819 23:04:27.299412 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8776
I0819 23:04:27.299701 22726 solver.cpp:404]     Test net output #1: loss = 0.422914 (* 1 = 0.422914 loss)
I0819 23:04:28.632855 22726 solver.cpp:228] Iteration 53400, loss = 0.120344
I0819 23:04:28.632899 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 23:04:28.632915 22726 solver.cpp:244]     Train net output #1: loss = 0.120344 (* 1 = 0.120344 loss)
I0819 23:04:28.717016 22726 sgd_solver.cpp:166] Iteration 53400, lr = 1.335
I0819 23:06:47.017642 22726 solver.cpp:337] Iteration 53500, Testing net (#0)
I0819 23:08:11.783696 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88152
I0819 23:08:11.784013 22726 solver.cpp:404]     Test net output #1: loss = 0.422802 (* 1 = 0.422802 loss)
I0819 23:08:13.117739 22726 solver.cpp:228] Iteration 53500, loss = 0.0983419
I0819 23:08:13.117781 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 23:08:13.117797 22726 solver.cpp:244]     Train net output #1: loss = 0.0983417 (* 1 = 0.0983417 loss)
I0819 23:08:13.199092 22726 sgd_solver.cpp:166] Iteration 53500, lr = 1.3375
I0819 23:10:31.293215 22726 solver.cpp:337] Iteration 53600, Testing net (#0)
I0819 23:11:56.391242 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8856
I0819 23:11:56.391592 22726 solver.cpp:404]     Test net output #1: loss = 0.389156 (* 1 = 0.389156 loss)
I0819 23:11:57.725888 22726 solver.cpp:228] Iteration 53600, loss = 0.146033
I0819 23:11:57.725929 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0819 23:11:57.725945 22726 solver.cpp:244]     Train net output #1: loss = 0.146033 (* 1 = 0.146033 loss)
I0819 23:11:57.805932 22726 sgd_solver.cpp:166] Iteration 53600, lr = 1.34
I0819 23:14:15.828820 22726 solver.cpp:337] Iteration 53700, Testing net (#0)
I0819 23:15:40.979192 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8778
I0819 23:15:40.979519 22726 solver.cpp:404]     Test net output #1: loss = 0.418274 (* 1 = 0.418274 loss)
I0819 23:15:42.313526 22726 solver.cpp:228] Iteration 53700, loss = 0.254303
I0819 23:15:42.313570 22726 solver.cpp:244]     Train net output #0: accuracy = 0.896
I0819 23:15:42.313585 22726 solver.cpp:244]     Train net output #1: loss = 0.254303 (* 1 = 0.254303 loss)
I0819 23:15:42.401584 22726 sgd_solver.cpp:166] Iteration 53700, lr = 1.3425
I0819 23:18:00.568684 22726 solver.cpp:337] Iteration 53800, Testing net (#0)
I0819 23:19:25.705653 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88436
I0819 23:19:25.706009 22726 solver.cpp:404]     Test net output #1: loss = 0.416462 (* 1 = 0.416462 loss)
I0819 23:19:27.040248 22726 solver.cpp:228] Iteration 53800, loss = 0.20828
I0819 23:19:27.040290 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 23:19:27.040307 22726 solver.cpp:244]     Train net output #1: loss = 0.20828 (* 1 = 0.20828 loss)
I0819 23:19:27.123831 22726 sgd_solver.cpp:166] Iteration 53800, lr = 1.345
I0819 23:21:45.222463 22726 solver.cpp:337] Iteration 53900, Testing net (#0)
I0819 23:23:10.344247 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88756
I0819 23:23:10.344584 22726 solver.cpp:404]     Test net output #1: loss = 0.401891 (* 1 = 0.401891 loss)
I0819 23:23:11.677073 22726 solver.cpp:228] Iteration 53900, loss = 0.0636728
I0819 23:23:11.677119 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0819 23:23:11.677135 22726 solver.cpp:244]     Train net output #1: loss = 0.0636726 (* 1 = 0.0636726 loss)
I0819 23:23:11.759116 22726 sgd_solver.cpp:166] Iteration 53900, lr = 1.3475
I0819 23:25:29.776108 22726 solver.cpp:337] Iteration 54000, Testing net (#0)
I0819 23:26:54.900599 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88296
I0819 23:26:54.900975 22726 solver.cpp:404]     Test net output #1: loss = 0.403791 (* 1 = 0.403791 loss)
I0819 23:26:56.233898 22726 solver.cpp:228] Iteration 54000, loss = 0.127542
I0819 23:26:56.233942 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0819 23:26:56.233958 22726 solver.cpp:244]     Train net output #1: loss = 0.127541 (* 1 = 0.127541 loss)
I0819 23:26:56.317970 22726 sgd_solver.cpp:166] Iteration 54000, lr = 1.35
I0819 23:29:14.446296 22726 solver.cpp:337] Iteration 54100, Testing net (#0)
I0819 23:30:39.574851 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88392
I0819 23:30:39.575206 22726 solver.cpp:404]     Test net output #1: loss = 0.399701 (* 1 = 0.399701 loss)
I0819 23:30:40.908150 22726 solver.cpp:228] Iteration 54100, loss = 0.115005
I0819 23:30:40.908192 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 23:30:40.908208 22726 solver.cpp:244]     Train net output #1: loss = 0.115005 (* 1 = 0.115005 loss)
I0819 23:30:40.988548 22726 sgd_solver.cpp:166] Iteration 54100, lr = 1.3525
I0819 23:32:59.063977 22726 solver.cpp:337] Iteration 54200, Testing net (#0)
I0819 23:34:24.190241 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8858
I0819 23:34:24.190570 22726 solver.cpp:404]     Test net output #1: loss = 0.405211 (* 1 = 0.405211 loss)
I0819 23:34:25.523272 22726 solver.cpp:228] Iteration 54200, loss = 0.204751
I0819 23:34:25.523315 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0819 23:34:25.523330 22726 solver.cpp:244]     Train net output #1: loss = 0.204751 (* 1 = 0.204751 loss)
I0819 23:34:25.603302 22726 sgd_solver.cpp:166] Iteration 54200, lr = 1.355
I0819 23:36:43.821949 22726 solver.cpp:337] Iteration 54300, Testing net (#0)
I0819 23:38:08.973340 22726 solver.cpp:404]     Test net output #0: accuracy = 0.884
I0819 23:38:08.973686 22726 solver.cpp:404]     Test net output #1: loss = 0.405921 (* 1 = 0.405921 loss)
I0819 23:38:10.306170 22726 solver.cpp:228] Iteration 54300, loss = 0.0688179
I0819 23:38:10.306213 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0819 23:38:10.306229 22726 solver.cpp:244]     Train net output #1: loss = 0.0688177 (* 1 = 0.0688177 loss)
I0819 23:38:10.385233 22726 sgd_solver.cpp:166] Iteration 54300, lr = 1.3575
I0819 23:40:28.514470 22726 solver.cpp:337] Iteration 54400, Testing net (#0)
I0819 23:41:53.677891 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88096
I0819 23:41:53.678290 22726 solver.cpp:404]     Test net output #1: loss = 0.397362 (* 1 = 0.397362 loss)
I0819 23:41:55.010781 22726 solver.cpp:228] Iteration 54400, loss = 0.108855
I0819 23:41:55.010833 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 23:41:55.010849 22726 solver.cpp:244]     Train net output #1: loss = 0.108855 (* 1 = 0.108855 loss)
I0819 23:41:55.093431 22726 sgd_solver.cpp:166] Iteration 54400, lr = 1.36
I0819 23:44:13.224627 22726 solver.cpp:337] Iteration 54500, Testing net (#0)
I0819 23:45:38.393736 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8814
I0819 23:45:38.394095 22726 solver.cpp:404]     Test net output #1: loss = 0.408931 (* 1 = 0.408931 loss)
I0819 23:45:39.726800 22726 solver.cpp:228] Iteration 54500, loss = 0.103023
I0819 23:45:39.726841 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 23:45:39.726857 22726 solver.cpp:244]     Train net output #1: loss = 0.103022 (* 1 = 0.103022 loss)
I0819 23:45:39.816511 22726 sgd_solver.cpp:166] Iteration 54500, lr = 1.3625
I0819 23:47:58.117115 22726 solver.cpp:337] Iteration 54600, Testing net (#0)
I0819 23:49:23.268155 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88064
I0819 23:49:23.268532 22726 solver.cpp:404]     Test net output #1: loss = 0.405704 (* 1 = 0.405704 loss)
I0819 23:49:24.600711 22726 solver.cpp:228] Iteration 54600, loss = 0.115076
I0819 23:49:24.600754 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 23:49:24.600769 22726 solver.cpp:244]     Train net output #1: loss = 0.115075 (* 1 = 0.115075 loss)
I0819 23:49:24.680362 22726 sgd_solver.cpp:166] Iteration 54600, lr = 1.365
I0819 23:51:42.876655 22726 solver.cpp:337] Iteration 54700, Testing net (#0)
I0819 23:53:08.033365 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87744
I0819 23:53:08.033717 22726 solver.cpp:404]     Test net output #1: loss = 0.435277 (* 1 = 0.435277 loss)
I0819 23:53:09.366508 22726 solver.cpp:228] Iteration 54700, loss = 0.166086
I0819 23:53:09.366547 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0819 23:53:09.366564 22726 solver.cpp:244]     Train net output #1: loss = 0.166086 (* 1 = 0.166086 loss)
I0819 23:53:09.444557 22726 sgd_solver.cpp:166] Iteration 54700, lr = 1.3675
I0819 23:55:27.550895 22726 solver.cpp:337] Iteration 54800, Testing net (#0)
I0819 23:56:52.705484 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88756
I0819 23:56:52.705865 22726 solver.cpp:404]     Test net output #1: loss = 0.387296 (* 1 = 0.387296 loss)
I0819 23:56:54.038702 22726 solver.cpp:228] Iteration 54800, loss = 0.135508
I0819 23:56:54.038740 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0819 23:56:54.038756 22726 solver.cpp:244]     Train net output #1: loss = 0.135508 (* 1 = 0.135508 loss)
I0819 23:56:54.120592 22726 sgd_solver.cpp:166] Iteration 54800, lr = 1.37
I0819 23:59:12.246912 22726 solver.cpp:337] Iteration 54900, Testing net (#0)
I0820 00:00:37.412770 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87928
I0820 00:00:37.413116 22726 solver.cpp:404]     Test net output #1: loss = 0.437905 (* 1 = 0.437905 loss)
I0820 00:00:38.745707 22726 solver.cpp:228] Iteration 54900, loss = 0.132169
I0820 00:00:38.745750 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 00:00:38.745767 22726 solver.cpp:244]     Train net output #1: loss = 0.132169 (* 1 = 0.132169 loss)
I0820 00:00:38.821498 22726 sgd_solver.cpp:166] Iteration 54900, lr = 1.3725
I0820 00:02:56.929143 22726 solver.cpp:337] Iteration 55000, Testing net (#0)
I0820 00:04:22.075670 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88732
I0820 00:04:22.076028 22726 solver.cpp:404]     Test net output #1: loss = 0.395137 (* 1 = 0.395137 loss)
I0820 00:04:23.409121 22726 solver.cpp:228] Iteration 55000, loss = 0.119832
I0820 00:04:23.409165 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 00:04:23.409180 22726 solver.cpp:244]     Train net output #1: loss = 0.119832 (* 1 = 0.119832 loss)
I0820 00:04:23.491222 22726 sgd_solver.cpp:166] Iteration 55000, lr = 1.375
I0820 00:06:41.482234 22726 solver.cpp:337] Iteration 55100, Testing net (#0)
I0820 00:08:06.653378 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88092
I0820 00:08:06.653740 22726 solver.cpp:404]     Test net output #1: loss = 0.420854 (* 1 = 0.420854 loss)
I0820 00:08:07.986742 22726 solver.cpp:228] Iteration 55100, loss = 0.147623
I0820 00:08:07.986783 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 00:08:07.986799 22726 solver.cpp:244]     Train net output #1: loss = 0.147623 (* 1 = 0.147623 loss)
I0820 00:08:08.070540 22726 sgd_solver.cpp:166] Iteration 55100, lr = 1.3775
I0820 00:10:26.144897 22726 solver.cpp:337] Iteration 55200, Testing net (#0)
I0820 00:11:51.311641 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87748
I0820 00:11:51.311992 22726 solver.cpp:404]     Test net output #1: loss = 0.430871 (* 1 = 0.430871 loss)
I0820 00:11:52.644984 22726 solver.cpp:228] Iteration 55200, loss = 0.0759977
I0820 00:11:52.645033 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 00:11:52.645051 22726 solver.cpp:244]     Train net output #1: loss = 0.0759976 (* 1 = 0.0759976 loss)
I0820 00:11:52.729567 22726 sgd_solver.cpp:166] Iteration 55200, lr = 1.38
I0820 00:14:10.832607 22726 solver.cpp:337] Iteration 55300, Testing net (#0)
I0820 00:15:35.988762 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88148
I0820 00:15:35.989115 22726 solver.cpp:404]     Test net output #1: loss = 0.415274 (* 1 = 0.415274 loss)
I0820 00:15:37.321964 22726 solver.cpp:228] Iteration 55300, loss = 0.096892
I0820 00:15:37.322008 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 00:15:37.322024 22726 solver.cpp:244]     Train net output #1: loss = 0.0968919 (* 1 = 0.0968919 loss)
I0820 00:15:37.398030 22726 sgd_solver.cpp:166] Iteration 55300, lr = 1.3825
I0820 00:17:55.474453 22726 solver.cpp:337] Iteration 55400, Testing net (#0)
I0820 00:19:20.623762 22726 solver.cpp:404]     Test net output #0: accuracy = 0.883
I0820 00:19:20.624140 22726 solver.cpp:404]     Test net output #1: loss = 0.400761 (* 1 = 0.400761 loss)
I0820 00:19:21.956696 22726 solver.cpp:228] Iteration 55400, loss = 0.109219
I0820 00:19:21.956737 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 00:19:21.956753 22726 solver.cpp:244]     Train net output #1: loss = 0.109219 (* 1 = 0.109219 loss)
I0820 00:19:22.042152 22726 sgd_solver.cpp:166] Iteration 55400, lr = 1.385
I0820 00:21:40.244765 22726 solver.cpp:337] Iteration 55500, Testing net (#0)
I0820 00:23:05.406697 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87692
I0820 00:23:05.407042 22726 solver.cpp:404]     Test net output #1: loss = 0.425387 (* 1 = 0.425387 loss)
I0820 00:23:06.739848 22726 solver.cpp:228] Iteration 55500, loss = 0.134287
I0820 00:23:06.739892 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 00:23:06.739907 22726 solver.cpp:244]     Train net output #1: loss = 0.134287 (* 1 = 0.134287 loss)
I0820 00:23:06.832247 22726 sgd_solver.cpp:166] Iteration 55500, lr = 1.3875
I0820 00:25:25.025771 22726 solver.cpp:337] Iteration 55600, Testing net (#0)
I0820 00:26:50.169740 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8762
I0820 00:26:50.170111 22726 solver.cpp:404]     Test net output #1: loss = 0.430643 (* 1 = 0.430643 loss)
I0820 00:26:51.502524 22726 solver.cpp:228] Iteration 55600, loss = 0.206796
I0820 00:26:51.502568 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 00:26:51.502583 22726 solver.cpp:244]     Train net output #1: loss = 0.206796 (* 1 = 0.206796 loss)
I0820 00:26:51.580157 22726 sgd_solver.cpp:166] Iteration 55600, lr = 1.39
I0820 00:29:09.669761 22726 solver.cpp:337] Iteration 55700, Testing net (#0)
I0820 00:30:34.821945 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87804
I0820 00:30:34.822285 22726 solver.cpp:404]     Test net output #1: loss = 0.427016 (* 1 = 0.427016 loss)
I0820 00:30:36.156428 22726 solver.cpp:228] Iteration 55700, loss = 0.202077
I0820 00:30:36.156469 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 00:30:36.156486 22726 solver.cpp:244]     Train net output #1: loss = 0.202077 (* 1 = 0.202077 loss)
I0820 00:30:36.241925 22726 sgd_solver.cpp:166] Iteration 55700, lr = 1.3925
I0820 00:32:54.377068 22726 solver.cpp:337] Iteration 55800, Testing net (#0)
I0820 00:34:19.553402 22726 solver.cpp:404]     Test net output #0: accuracy = 0.879
I0820 00:34:19.553781 22726 solver.cpp:404]     Test net output #1: loss = 0.42059 (* 1 = 0.42059 loss)
I0820 00:34:20.887733 22726 solver.cpp:228] Iteration 55800, loss = 0.194065
I0820 00:34:20.887774 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 00:34:20.887789 22726 solver.cpp:244]     Train net output #1: loss = 0.194065 (* 1 = 0.194065 loss)
I0820 00:34:20.970023 22726 sgd_solver.cpp:166] Iteration 55800, lr = 1.395
I0820 00:36:39.041484 22726 solver.cpp:337] Iteration 55900, Testing net (#0)
I0820 00:38:04.205221 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87972
I0820 00:38:04.205585 22726 solver.cpp:404]     Test net output #1: loss = 0.40393 (* 1 = 0.40393 loss)
I0820 00:38:05.539042 22726 solver.cpp:228] Iteration 55900, loss = 0.138543
I0820 00:38:05.539084 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 00:38:05.539100 22726 solver.cpp:244]     Train net output #1: loss = 0.138543 (* 1 = 0.138543 loss)
I0820 00:38:05.620450 22726 sgd_solver.cpp:166] Iteration 55900, lr = 1.3975
I0820 00:40:23.750311 22726 solver.cpp:337] Iteration 56000, Testing net (#0)
I0820 00:41:48.908486 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88784
I0820 00:41:48.908861 22726 solver.cpp:404]     Test net output #1: loss = 0.396897 (* 1 = 0.396897 loss)
I0820 00:41:50.241729 22726 solver.cpp:228] Iteration 56000, loss = 0.123213
I0820 00:41:50.241780 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 00:41:50.241796 22726 solver.cpp:244]     Train net output #1: loss = 0.123213 (* 1 = 0.123213 loss)
I0820 00:41:50.328322 22726 sgd_solver.cpp:166] Iteration 56000, lr = 1.4
I0820 00:44:08.491070 22726 solver.cpp:337] Iteration 56100, Testing net (#0)
I0820 00:45:33.115901 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88524
I0820 00:45:33.116230 22726 solver.cpp:404]     Test net output #1: loss = 0.402783 (* 1 = 0.402783 loss)
I0820 00:45:34.451206 22726 solver.cpp:228] Iteration 56100, loss = 0.157239
I0820 00:45:34.451253 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 00:45:34.451274 22726 solver.cpp:244]     Train net output #1: loss = 0.157239 (* 1 = 0.157239 loss)
I0820 00:45:34.529840 22726 sgd_solver.cpp:166] Iteration 56100, lr = 1.4025
I0820 00:47:52.649823 22726 solver.cpp:337] Iteration 56200, Testing net (#0)
I0820 00:49:17.080231 22726 solver.cpp:404]     Test net output #0: accuracy = 0.882
I0820 00:49:17.080541 22726 solver.cpp:404]     Test net output #1: loss = 0.41999 (* 1 = 0.41999 loss)
I0820 00:49:18.411967 22726 solver.cpp:228] Iteration 56200, loss = 0.188514
I0820 00:49:18.412014 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 00:49:18.412031 22726 solver.cpp:244]     Train net output #1: loss = 0.188514 (* 1 = 0.188514 loss)
I0820 00:49:18.486570 22726 sgd_solver.cpp:166] Iteration 56200, lr = 1.405
I0820 00:51:36.343444 22726 solver.cpp:337] Iteration 56300, Testing net (#0)
I0820 00:53:00.730490 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8788
I0820 00:53:00.730804 22726 solver.cpp:404]     Test net output #1: loss = 0.430337 (* 1 = 0.430337 loss)
I0820 00:53:02.061573 22726 solver.cpp:228] Iteration 56300, loss = 0.281086
I0820 00:53:02.061620 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 00:53:02.061635 22726 solver.cpp:244]     Train net output #1: loss = 0.281086 (* 1 = 0.281086 loss)
I0820 00:53:02.144862 22726 sgd_solver.cpp:166] Iteration 56300, lr = 1.4075
I0820 00:55:20.106088 22726 solver.cpp:337] Iteration 56400, Testing net (#0)
I0820 00:56:44.498456 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88216
I0820 00:56:44.498762 22726 solver.cpp:404]     Test net output #1: loss = 0.412837 (* 1 = 0.412837 loss)
I0820 00:56:45.829092 22726 solver.cpp:228] Iteration 56400, loss = 0.238263
I0820 00:56:45.829139 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 00:56:45.829157 22726 solver.cpp:244]     Train net output #1: loss = 0.238263 (* 1 = 0.238263 loss)
I0820 00:56:45.915508 22726 sgd_solver.cpp:166] Iteration 56400, lr = 1.41
I0820 00:59:03.811439 22726 solver.cpp:337] Iteration 56500, Testing net (#0)
I0820 01:00:28.200116 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8822
I0820 01:00:28.200403 22726 solver.cpp:404]     Test net output #1: loss = 0.414762 (* 1 = 0.414762 loss)
I0820 01:00:29.531339 22726 solver.cpp:228] Iteration 56500, loss = 0.10269
I0820 01:00:29.531383 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 01:00:29.531399 22726 solver.cpp:244]     Train net output #1: loss = 0.10269 (* 1 = 0.10269 loss)
I0820 01:00:29.609707 22726 sgd_solver.cpp:166] Iteration 56500, lr = 1.4125
I0820 01:02:47.469097 22726 solver.cpp:337] Iteration 56600, Testing net (#0)
I0820 01:04:11.863298 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88056
I0820 01:04:11.863589 22726 solver.cpp:404]     Test net output #1: loss = 0.406355 (* 1 = 0.406355 loss)
I0820 01:04:13.194460 22726 solver.cpp:228] Iteration 56600, loss = 0.111398
I0820 01:04:13.194504 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 01:04:13.194520 22726 solver.cpp:244]     Train net output #1: loss = 0.111398 (* 1 = 0.111398 loss)
I0820 01:04:13.281445 22726 sgd_solver.cpp:166] Iteration 56600, lr = 1.415
I0820 01:06:31.148267 22726 solver.cpp:337] Iteration 56700, Testing net (#0)
I0820 01:07:55.554718 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87864
I0820 01:07:55.555034 22726 solver.cpp:404]     Test net output #1: loss = 0.430556 (* 1 = 0.430556 loss)
I0820 01:07:56.885532 22726 solver.cpp:228] Iteration 56700, loss = 0.191349
I0820 01:07:56.885576 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 01:07:56.885592 22726 solver.cpp:244]     Train net output #1: loss = 0.191349 (* 1 = 0.191349 loss)
I0820 01:07:56.962307 22726 sgd_solver.cpp:166] Iteration 56700, lr = 1.4175
I0820 01:10:14.806521 22726 solver.cpp:337] Iteration 56800, Testing net (#0)
I0820 01:11:39.213104 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88112
I0820 01:11:39.213376 22726 solver.cpp:404]     Test net output #1: loss = 0.430986 (* 1 = 0.430986 loss)
I0820 01:11:40.543998 22726 solver.cpp:228] Iteration 56800, loss = 0.138928
I0820 01:11:40.544042 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 01:11:40.544059 22726 solver.cpp:244]     Train net output #1: loss = 0.138928 (* 1 = 0.138928 loss)
I0820 01:11:40.627980 22726 sgd_solver.cpp:166] Iteration 56800, lr = 1.42
I0820 01:13:58.549304 22726 solver.cpp:337] Iteration 56900, Testing net (#0)
I0820 01:15:22.960681 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87916
I0820 01:15:22.960988 22726 solver.cpp:404]     Test net output #1: loss = 0.418405 (* 1 = 0.418405 loss)
I0820 01:15:24.291368 22726 solver.cpp:228] Iteration 56900, loss = 0.106565
I0820 01:15:24.291412 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 01:15:24.291429 22726 solver.cpp:244]     Train net output #1: loss = 0.106565 (* 1 = 0.106565 loss)
I0820 01:15:24.366693 22726 sgd_solver.cpp:166] Iteration 56900, lr = 1.4225
I0820 01:17:42.359396 22726 solver.cpp:337] Iteration 57000, Testing net (#0)
I0820 01:19:06.756227 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8834
I0820 01:19:06.756500 22726 solver.cpp:404]     Test net output #1: loss = 0.391933 (* 1 = 0.391933 loss)
I0820 01:19:08.087296 22726 solver.cpp:228] Iteration 57000, loss = 0.147339
I0820 01:19:08.087338 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 01:19:08.087353 22726 solver.cpp:244]     Train net output #1: loss = 0.147339 (* 1 = 0.147339 loss)
I0820 01:19:08.165894 22726 sgd_solver.cpp:166] Iteration 57000, lr = 1.425
I0820 01:21:26.218154 22726 solver.cpp:337] Iteration 57100, Testing net (#0)
I0820 01:22:51.054993 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87792
I0820 01:22:51.055369 22726 solver.cpp:404]     Test net output #1: loss = 0.411721 (* 1 = 0.411721 loss)
I0820 01:22:52.387858 22726 solver.cpp:228] Iteration 57100, loss = 0.167703
I0820 01:22:52.387902 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 01:22:52.387917 22726 solver.cpp:244]     Train net output #1: loss = 0.167703 (* 1 = 0.167703 loss)
I0820 01:22:52.474092 22726 sgd_solver.cpp:166] Iteration 57100, lr = 1.4275
I0820 01:25:10.581084 22726 solver.cpp:337] Iteration 57200, Testing net (#0)
I0820 01:26:35.732975 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8722
I0820 01:26:35.733341 22726 solver.cpp:404]     Test net output #1: loss = 0.438892 (* 1 = 0.438892 loss)
I0820 01:26:37.065731 22726 solver.cpp:228] Iteration 57200, loss = 0.161432
I0820 01:26:37.065770 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 01:26:37.065785 22726 solver.cpp:244]     Train net output #1: loss = 0.161432 (* 1 = 0.161432 loss)
I0820 01:26:37.149652 22726 sgd_solver.cpp:166] Iteration 57200, lr = 1.43
I0820 01:28:55.262331 22726 solver.cpp:337] Iteration 57300, Testing net (#0)
I0820 01:30:20.421054 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8814
I0820 01:30:20.421418 22726 solver.cpp:404]     Test net output #1: loss = 0.405242 (* 1 = 0.405242 loss)
I0820 01:30:21.754125 22726 solver.cpp:228] Iteration 57300, loss = 0.13339
I0820 01:30:21.754168 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 01:30:21.754182 22726 solver.cpp:244]     Train net output #1: loss = 0.13339 (* 1 = 0.13339 loss)
I0820 01:30:21.835814 22726 sgd_solver.cpp:166] Iteration 57300, lr = 1.4325
I0820 01:32:40.004021 22726 solver.cpp:337] Iteration 57400, Testing net (#0)
I0820 01:34:05.172925 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8842
I0820 01:34:05.173310 22726 solver.cpp:404]     Test net output #1: loss = 0.407338 (* 1 = 0.407338 loss)
I0820 01:34:06.505540 22726 solver.cpp:228] Iteration 57400, loss = 0.23025
I0820 01:34:06.505581 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 01:34:06.505597 22726 solver.cpp:244]     Train net output #1: loss = 0.23025 (* 1 = 0.23025 loss)
I0820 01:34:06.582432 22726 sgd_solver.cpp:166] Iteration 57400, lr = 1.435
I0820 01:36:24.693143 22726 solver.cpp:337] Iteration 57500, Testing net (#0)
I0820 01:37:49.856120 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88052
I0820 01:37:49.856473 22726 solver.cpp:404]     Test net output #1: loss = 0.404377 (* 1 = 0.404377 loss)
I0820 01:37:51.189327 22726 solver.cpp:228] Iteration 57500, loss = 0.0806574
I0820 01:37:51.189364 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 01:37:51.189379 22726 solver.cpp:244]     Train net output #1: loss = 0.0806573 (* 1 = 0.0806573 loss)
I0820 01:37:51.272186 22726 sgd_solver.cpp:166] Iteration 57500, lr = 1.4375
I0820 01:40:09.314803 22726 solver.cpp:337] Iteration 57600, Testing net (#0)
I0820 01:41:34.470201 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8758
I0820 01:41:34.470587 22726 solver.cpp:404]     Test net output #1: loss = 0.428466 (* 1 = 0.428466 loss)
I0820 01:41:35.803218 22726 solver.cpp:228] Iteration 57600, loss = 0.193506
I0820 01:41:35.803258 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 01:41:35.803274 22726 solver.cpp:244]     Train net output #1: loss = 0.193506 (* 1 = 0.193506 loss)
I0820 01:41:35.884826 22726 sgd_solver.cpp:166] Iteration 57600, lr = 1.44
I0820 01:43:53.990721 22726 solver.cpp:337] Iteration 57700, Testing net (#0)
I0820 01:45:19.154448 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88556
I0820 01:45:19.154806 22726 solver.cpp:404]     Test net output #1: loss = 0.391322 (* 1 = 0.391322 loss)
I0820 01:45:20.487609 22726 solver.cpp:228] Iteration 57700, loss = 0.160041
I0820 01:45:20.487649 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 01:45:20.487664 22726 solver.cpp:244]     Train net output #1: loss = 0.160041 (* 1 = 0.160041 loss)
I0820 01:45:20.565532 22726 sgd_solver.cpp:166] Iteration 57700, lr = 1.4425
I0820 01:47:38.623123 22726 solver.cpp:337] Iteration 57800, Testing net (#0)
I0820 01:49:03.782985 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8772
I0820 01:49:03.783365 22726 solver.cpp:404]     Test net output #1: loss = 0.426862 (* 1 = 0.426862 loss)
I0820 01:49:05.116055 22726 solver.cpp:228] Iteration 57800, loss = 0.152023
I0820 01:49:05.116093 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 01:49:05.116108 22726 solver.cpp:244]     Train net output #1: loss = 0.152023 (* 1 = 0.152023 loss)
I0820 01:49:05.189872 22726 sgd_solver.cpp:166] Iteration 57800, lr = 1.445
I0820 01:51:23.179656 22726 solver.cpp:337] Iteration 57900, Testing net (#0)
I0820 01:52:48.324816 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8846
I0820 01:52:48.325206 22726 solver.cpp:404]     Test net output #1: loss = 0.3917 (* 1 = 0.3917 loss)
I0820 01:52:49.657979 22726 solver.cpp:228] Iteration 57900, loss = 0.0801318
I0820 01:52:49.658025 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 01:52:49.658041 22726 solver.cpp:244]     Train net output #1: loss = 0.0801317 (* 1 = 0.0801317 loss)
I0820 01:52:49.739378 22726 sgd_solver.cpp:166] Iteration 57900, lr = 1.4475
I0820 01:55:07.844988 22726 solver.cpp:337] Iteration 58000, Testing net (#0)
I0820 01:56:32.994050 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88116
I0820 01:56:32.994407 22726 solver.cpp:404]     Test net output #1: loss = 0.418345 (* 1 = 0.418345 loss)
I0820 01:56:34.326817 22726 solver.cpp:228] Iteration 58000, loss = 0.176963
I0820 01:56:34.326858 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 01:56:34.326874 22726 solver.cpp:244]     Train net output #1: loss = 0.176963 (* 1 = 0.176963 loss)
I0820 01:56:34.408998 22726 sgd_solver.cpp:166] Iteration 58000, lr = 1.45
I0820 01:58:52.485013 22726 solver.cpp:337] Iteration 58100, Testing net (#0)
I0820 02:00:17.635596 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8766
I0820 02:00:17.635964 22726 solver.cpp:404]     Test net output #1: loss = 0.425634 (* 1 = 0.425634 loss)
I0820 02:00:18.968744 22726 solver.cpp:228] Iteration 58100, loss = 0.140779
I0820 02:00:18.968783 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 02:00:18.968797 22726 solver.cpp:244]     Train net output #1: loss = 0.140779 (* 1 = 0.140779 loss)
I0820 02:00:19.055297 22726 sgd_solver.cpp:166] Iteration 58100, lr = 1.4525
I0820 02:02:37.347390 22726 solver.cpp:337] Iteration 58200, Testing net (#0)
I0820 02:04:02.513032 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88692
I0820 02:04:02.513383 22726 solver.cpp:404]     Test net output #1: loss = 0.391871 (* 1 = 0.391871 loss)
I0820 02:04:03.846339 22726 solver.cpp:228] Iteration 58200, loss = 0.138006
I0820 02:04:03.846381 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 02:04:03.846396 22726 solver.cpp:244]     Train net output #1: loss = 0.138006 (* 1 = 0.138006 loss)
I0820 02:04:03.925827 22726 sgd_solver.cpp:166] Iteration 58200, lr = 1.455
I0820 02:06:21.983026 22726 solver.cpp:337] Iteration 58300, Testing net (#0)
I0820 02:07:47.143400 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88764
I0820 02:07:47.143754 22726 solver.cpp:404]     Test net output #1: loss = 0.386905 (* 1 = 0.386905 loss)
I0820 02:07:48.476069 22726 solver.cpp:228] Iteration 58300, loss = 0.169811
I0820 02:07:48.476111 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 02:07:48.476126 22726 solver.cpp:244]     Train net output #1: loss = 0.169811 (* 1 = 0.169811 loss)
I0820 02:07:48.555510 22726 sgd_solver.cpp:166] Iteration 58300, lr = 1.4575
I0820 02:10:06.559825 22726 solver.cpp:337] Iteration 58400, Testing net (#0)
I0820 02:11:31.717880 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88456
I0820 02:11:31.718273 22726 solver.cpp:404]     Test net output #1: loss = 0.380616 (* 1 = 0.380616 loss)
I0820 02:11:33.050768 22726 solver.cpp:228] Iteration 58400, loss = 0.137581
I0820 02:11:33.050807 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 02:11:33.050823 22726 solver.cpp:244]     Train net output #1: loss = 0.137581 (* 1 = 0.137581 loss)
I0820 02:11:33.129827 22726 sgd_solver.cpp:166] Iteration 58400, lr = 1.46
I0820 02:13:51.134392 22726 solver.cpp:337] Iteration 58500, Testing net (#0)
I0820 02:15:16.290145 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8766
I0820 02:15:16.290503 22726 solver.cpp:404]     Test net output #1: loss = 0.404754 (* 1 = 0.404754 loss)
I0820 02:15:17.622860 22726 solver.cpp:228] Iteration 58500, loss = 0.138006
I0820 02:15:17.622902 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 02:15:17.622918 22726 solver.cpp:244]     Train net output #1: loss = 0.138005 (* 1 = 0.138005 loss)
I0820 02:15:17.704116 22726 sgd_solver.cpp:166] Iteration 58500, lr = 1.4625
I0820 02:17:35.717067 22726 solver.cpp:337] Iteration 58600, Testing net (#0)
I0820 02:19:00.866569 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88572
I0820 02:19:00.866940 22726 solver.cpp:404]     Test net output #1: loss = 0.406006 (* 1 = 0.406006 loss)
I0820 02:19:02.199038 22726 solver.cpp:228] Iteration 58600, loss = 0.116335
I0820 02:19:02.199080 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 02:19:02.199095 22726 solver.cpp:244]     Train net output #1: loss = 0.116335 (* 1 = 0.116335 loss)
I0820 02:19:02.283836 22726 sgd_solver.cpp:166] Iteration 58600, lr = 1.465
I0820 02:21:20.514932 22726 solver.cpp:337] Iteration 58700, Testing net (#0)
I0820 02:22:45.658890 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88536
I0820 02:22:45.659241 22726 solver.cpp:404]     Test net output #1: loss = 0.389082 (* 1 = 0.389082 loss)
I0820 02:22:46.991183 22726 solver.cpp:228] Iteration 58700, loss = 0.125212
I0820 02:22:46.991221 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 02:22:46.991237 22726 solver.cpp:244]     Train net output #1: loss = 0.125212 (* 1 = 0.125212 loss)
I0820 02:22:47.073644 22726 sgd_solver.cpp:166] Iteration 58700, lr = 1.4675
I0820 02:25:05.039978 22726 solver.cpp:337] Iteration 58800, Testing net (#0)
I0820 02:26:30.196658 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8856
I0820 02:26:30.197024 22726 solver.cpp:404]     Test net output #1: loss = 0.399004 (* 1 = 0.399004 loss)
I0820 02:26:31.530427 22726 solver.cpp:228] Iteration 58800, loss = 0.210868
I0820 02:26:31.530469 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 02:26:31.530485 22726 solver.cpp:244]     Train net output #1: loss = 0.210868 (* 1 = 0.210868 loss)
I0820 02:26:31.612395 22726 sgd_solver.cpp:166] Iteration 58800, lr = 1.47
I0820 02:28:49.520449 22726 solver.cpp:337] Iteration 58900, Testing net (#0)
I0820 02:30:14.689785 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87272
I0820 02:30:14.690129 22726 solver.cpp:404]     Test net output #1: loss = 0.437269 (* 1 = 0.437269 loss)
I0820 02:30:16.023102 22726 solver.cpp:228] Iteration 58900, loss = 0.138162
I0820 02:30:16.023144 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 02:30:16.023159 22726 solver.cpp:244]     Train net output #1: loss = 0.138161 (* 1 = 0.138161 loss)
I0820 02:30:16.102190 22726 sgd_solver.cpp:166] Iteration 58900, lr = 1.4725
I0820 02:32:34.032699 22726 solver.cpp:337] Iteration 59000, Testing net (#0)
I0820 02:33:59.193333 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88128
I0820 02:33:59.193713 22726 solver.cpp:404]     Test net output #1: loss = 0.42072 (* 1 = 0.42072 loss)
I0820 02:34:00.527487 22726 solver.cpp:228] Iteration 59000, loss = 0.109644
I0820 02:34:00.527530 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 02:34:00.527546 22726 solver.cpp:244]     Train net output #1: loss = 0.109644 (* 1 = 0.109644 loss)
I0820 02:34:00.606431 22726 sgd_solver.cpp:166] Iteration 59000, lr = 1.475
I0820 02:36:18.606854 22726 solver.cpp:337] Iteration 59100, Testing net (#0)
I0820 02:37:43.765103 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8874
I0820 02:37:43.765467 22726 solver.cpp:404]     Test net output #1: loss = 0.395035 (* 1 = 0.395035 loss)
I0820 02:37:45.097811 22726 solver.cpp:228] Iteration 59100, loss = 0.0725888
I0820 02:37:45.097852 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 02:37:45.097868 22726 solver.cpp:244]     Train net output #1: loss = 0.0725886 (* 1 = 0.0725886 loss)
I0820 02:37:45.178289 22726 sgd_solver.cpp:166] Iteration 59100, lr = 1.4775
I0820 02:40:03.273576 22726 solver.cpp:337] Iteration 59200, Testing net (#0)
I0820 02:41:28.438509 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88372
I0820 02:41:28.438889 22726 solver.cpp:404]     Test net output #1: loss = 0.396527 (* 1 = 0.396527 loss)
I0820 02:41:29.771425 22726 solver.cpp:228] Iteration 59200, loss = 0.19297
I0820 02:41:29.771467 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 02:41:29.771482 22726 solver.cpp:244]     Train net output #1: loss = 0.19297 (* 1 = 0.19297 loss)
I0820 02:41:29.849756 22726 sgd_solver.cpp:166] Iteration 59200, lr = 1.48
I0820 02:43:47.906123 22726 solver.cpp:337] Iteration 59300, Testing net (#0)
I0820 02:45:13.060501 22726 solver.cpp:404]     Test net output #0: accuracy = 0.871921
I0820 02:45:13.060861 22726 solver.cpp:404]     Test net output #1: loss = 0.434196 (* 1 = 0.434196 loss)
I0820 02:45:14.393659 22726 solver.cpp:228] Iteration 59300, loss = 0.22989
I0820 02:45:14.393699 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 02:45:14.393714 22726 solver.cpp:244]     Train net output #1: loss = 0.229889 (* 1 = 0.229889 loss)
I0820 02:45:14.478476 22726 sgd_solver.cpp:166] Iteration 59300, lr = 1.4825
I0820 02:47:32.529681 22726 solver.cpp:337] Iteration 59400, Testing net (#0)
I0820 02:48:57.687347 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88296
I0820 02:48:57.687700 22726 solver.cpp:404]     Test net output #1: loss = 0.413666 (* 1 = 0.413666 loss)
I0820 02:48:59.020720 22726 solver.cpp:228] Iteration 59400, loss = 0.0367935
I0820 02:48:59.020762 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0820 02:48:59.020777 22726 solver.cpp:244]     Train net output #1: loss = 0.0367933 (* 1 = 0.0367933 loss)
I0820 02:48:59.102706 22726 sgd_solver.cpp:166] Iteration 59400, lr = 1.485
I0820 02:51:17.224998 22726 solver.cpp:337] Iteration 59500, Testing net (#0)
I0820 02:52:42.375972 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8858
I0820 02:52:42.376348 22726 solver.cpp:404]     Test net output #1: loss = 0.398849 (* 1 = 0.398849 loss)
I0820 02:52:43.709484 22726 solver.cpp:228] Iteration 59500, loss = 0.10581
I0820 02:52:43.709525 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 02:52:43.709542 22726 solver.cpp:244]     Train net output #1: loss = 0.105809 (* 1 = 0.105809 loss)
I0820 02:52:43.786854 22726 sgd_solver.cpp:166] Iteration 59500, lr = 1.4875
I0820 02:55:01.903529 22726 solver.cpp:337] Iteration 59600, Testing net (#0)
I0820 02:56:27.062863 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88832
I0820 02:56:27.063226 22726 solver.cpp:404]     Test net output #1: loss = 0.386465 (* 1 = 0.386465 loss)
I0820 02:56:28.396224 22726 solver.cpp:228] Iteration 59600, loss = 0.148858
I0820 02:56:28.396265 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 02:56:28.396280 22726 solver.cpp:244]     Train net output #1: loss = 0.148858 (* 1 = 0.148858 loss)
I0820 02:56:28.478121 22726 sgd_solver.cpp:166] Iteration 59600, lr = 1.49
I0820 02:58:46.664554 22726 solver.cpp:337] Iteration 59700, Testing net (#0)
I0820 03:00:11.821959 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87676
I0820 03:00:11.822310 22726 solver.cpp:404]     Test net output #1: loss = 0.402279 (* 1 = 0.402279 loss)
I0820 03:00:13.154952 22726 solver.cpp:228] Iteration 59700, loss = 0.116229
I0820 03:00:13.154994 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 03:00:13.155009 22726 solver.cpp:244]     Train net output #1: loss = 0.116229 (* 1 = 0.116229 loss)
I0820 03:00:13.236588 22726 sgd_solver.cpp:166] Iteration 59700, lr = 1.4925
I0820 03:02:31.377920 22726 solver.cpp:337] Iteration 59800, Testing net (#0)
I0820 03:03:56.539620 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88616
I0820 03:03:56.540024 22726 solver.cpp:404]     Test net output #1: loss = 0.39667 (* 1 = 0.39667 loss)
I0820 03:03:57.872508 22726 solver.cpp:228] Iteration 59800, loss = 0.0637384
I0820 03:03:57.872547 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0820 03:03:57.872563 22726 solver.cpp:244]     Train net output #1: loss = 0.0637381 (* 1 = 0.0637381 loss)
I0820 03:03:57.951575 22726 sgd_solver.cpp:166] Iteration 59800, lr = 1.495
I0820 03:06:16.166294 22726 solver.cpp:337] Iteration 59900, Testing net (#0)
I0820 03:07:41.338675 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88264
I0820 03:07:41.339072 22726 solver.cpp:404]     Test net output #1: loss = 0.400645 (* 1 = 0.400645 loss)
I0820 03:07:42.672068 22726 solver.cpp:228] Iteration 59900, loss = 0.0938828
I0820 03:07:42.672106 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 03:07:42.672122 22726 solver.cpp:244]     Train net output #1: loss = 0.0938826 (* 1 = 0.0938826 loss)
I0820 03:07:42.758509 22726 sgd_solver.cpp:166] Iteration 59900, lr = 1.4975
I0820 03:10:00.886862 22726 solver.cpp:337] Iteration 60000, Testing net (#0)
I0820 03:11:26.066251 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88504
I0820 03:11:26.066597 22726 solver.cpp:404]     Test net output #1: loss = 0.394165 (* 1 = 0.394165 loss)
I0820 03:11:27.399399 22726 solver.cpp:228] Iteration 60000, loss = 0.1337
I0820 03:11:27.399438 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 03:11:27.399454 22726 solver.cpp:244]     Train net output #1: loss = 0.133699 (* 1 = 0.133699 loss)
I0820 03:11:27.478382 22726 sgd_solver.cpp:166] Iteration 60000, lr = 1.5
I0820 03:13:45.744779 22726 solver.cpp:337] Iteration 60100, Testing net (#0)
I0820 03:15:10.898082 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88596
I0820 03:15:10.898427 22726 solver.cpp:404]     Test net output #1: loss = 0.402531 (* 1 = 0.402531 loss)
I0820 03:15:12.231014 22726 solver.cpp:228] Iteration 60100, loss = 0.13332
I0820 03:15:12.231061 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 03:15:12.231077 22726 solver.cpp:244]     Train net output #1: loss = 0.13332 (* 1 = 0.13332 loss)
I0820 03:15:12.315474 22726 sgd_solver.cpp:166] Iteration 60100, lr = 1.5025
I0820 03:17:30.481981 22726 solver.cpp:337] Iteration 60200, Testing net (#0)
I0820 03:18:55.642320 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8808
I0820 03:18:55.642662 22726 solver.cpp:404]     Test net output #1: loss = 0.399655 (* 1 = 0.399655 loss)
I0820 03:18:56.975263 22726 solver.cpp:228] Iteration 60200, loss = 0.0631312
I0820 03:18:56.975304 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0820 03:18:56.975319 22726 solver.cpp:244]     Train net output #1: loss = 0.063131 (* 1 = 0.063131 loss)
I0820 03:18:57.058598 22726 sgd_solver.cpp:166] Iteration 60200, lr = 1.505
I0820 03:21:15.176882 22726 solver.cpp:337] Iteration 60300, Testing net (#0)
I0820 03:22:40.319994 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8788
I0820 03:22:40.320371 22726 solver.cpp:404]     Test net output #1: loss = 0.417477 (* 1 = 0.417477 loss)
I0820 03:22:41.652940 22726 solver.cpp:228] Iteration 60300, loss = 0.141535
I0820 03:22:41.652982 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 03:22:41.652997 22726 solver.cpp:244]     Train net output #1: loss = 0.141534 (* 1 = 0.141534 loss)
I0820 03:22:41.731518 22726 sgd_solver.cpp:166] Iteration 60300, lr = 1.5075
I0820 03:24:59.776047 22726 solver.cpp:337] Iteration 60400, Testing net (#0)
I0820 03:26:24.937944 22726 solver.cpp:404]     Test net output #0: accuracy = 0.875
I0820 03:26:24.938313 22726 solver.cpp:404]     Test net output #1: loss = 0.432127 (* 1 = 0.432127 loss)
I0820 03:26:26.270627 22726 solver.cpp:228] Iteration 60400, loss = 0.13639
I0820 03:26:26.270669 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 03:26:26.270684 22726 solver.cpp:244]     Train net output #1: loss = 0.13639 (* 1 = 0.13639 loss)
I0820 03:26:26.347101 22726 sgd_solver.cpp:166] Iteration 60400, lr = 1.51
I0820 03:28:44.290637 22726 solver.cpp:337] Iteration 60500, Testing net (#0)
I0820 03:30:09.467911 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87868
I0820 03:30:09.468260 22726 solver.cpp:404]     Test net output #1: loss = 0.426144 (* 1 = 0.426144 loss)
I0820 03:30:10.800688 22726 solver.cpp:228] Iteration 60500, loss = 0.164964
I0820 03:30:10.800729 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 03:30:10.800745 22726 solver.cpp:244]     Train net output #1: loss = 0.164963 (* 1 = 0.164963 loss)
I0820 03:30:10.882297 22726 sgd_solver.cpp:166] Iteration 60500, lr = 1.5125
I0820 03:32:28.857517 22726 solver.cpp:337] Iteration 60600, Testing net (#0)
I0820 03:33:54.035127 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88088
I0820 03:33:54.035519 22726 solver.cpp:404]     Test net output #1: loss = 0.40723 (* 1 = 0.40723 loss)
I0820 03:33:55.367810 22726 solver.cpp:228] Iteration 60600, loss = 0.176044
I0820 03:33:55.367853 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 03:33:55.367869 22726 solver.cpp:244]     Train net output #1: loss = 0.176043 (* 1 = 0.176043 loss)
I0820 03:33:55.449483 22726 sgd_solver.cpp:166] Iteration 60600, lr = 1.515
I0820 03:36:13.548254 22726 solver.cpp:337] Iteration 60700, Testing net (#0)
I0820 03:37:38.721864 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8838
I0820 03:37:38.722263 22726 solver.cpp:404]     Test net output #1: loss = 0.398261 (* 1 = 0.398261 loss)
I0820 03:37:40.054975 22726 solver.cpp:228] Iteration 60700, loss = 0.12888
I0820 03:37:40.055022 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 03:37:40.055037 22726 solver.cpp:244]     Train net output #1: loss = 0.12888 (* 1 = 0.12888 loss)
I0820 03:37:40.131762 22726 sgd_solver.cpp:166] Iteration 60700, lr = 1.5175
I0820 03:39:58.114142 22726 solver.cpp:337] Iteration 60800, Testing net (#0)
I0820 03:41:23.269593 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8884
I0820 03:41:23.269960 22726 solver.cpp:404]     Test net output #1: loss = 0.396044 (* 1 = 0.396044 loss)
I0820 03:41:24.602964 22726 solver.cpp:228] Iteration 60800, loss = 0.13525
I0820 03:41:24.603004 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 03:41:24.603024 22726 solver.cpp:244]     Train net output #1: loss = 0.13525 (* 1 = 0.13525 loss)
I0820 03:41:24.682914 22726 sgd_solver.cpp:166] Iteration 60800, lr = 1.52
I0820 03:43:42.704174 22726 solver.cpp:337] Iteration 60900, Testing net (#0)
I0820 03:45:07.863301 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88444
I0820 03:45:07.863656 22726 solver.cpp:404]     Test net output #1: loss = 0.391748 (* 1 = 0.391748 loss)
I0820 03:45:09.196235 22726 solver.cpp:228] Iteration 60900, loss = 0.128603
I0820 03:45:09.196277 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 03:45:09.196293 22726 solver.cpp:244]     Train net output #1: loss = 0.128603 (* 1 = 0.128603 loss)
I0820 03:45:09.276861 22726 sgd_solver.cpp:166] Iteration 60900, lr = 1.5225
I0820 03:47:27.286680 22726 solver.cpp:337] Iteration 61000, Testing net (#0)
I0820 03:48:52.441184 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87572
I0820 03:48:52.441567 22726 solver.cpp:404]     Test net output #1: loss = 0.437781 (* 1 = 0.437781 loss)
I0820 03:48:53.773840 22726 solver.cpp:228] Iteration 61000, loss = 0.0966251
I0820 03:48:53.773882 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 03:48:53.773897 22726 solver.cpp:244]     Train net output #1: loss = 0.0966249 (* 1 = 0.0966249 loss)
I0820 03:48:53.854050 22726 sgd_solver.cpp:166] Iteration 61000, lr = 1.525
I0820 03:51:11.898658 22726 solver.cpp:337] Iteration 61100, Testing net (#0)
I0820 03:52:37.044821 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87512
I0820 03:52:37.045207 22726 solver.cpp:404]     Test net output #1: loss = 0.420797 (* 1 = 0.420797 loss)
I0820 03:52:38.377898 22726 solver.cpp:228] Iteration 61100, loss = 0.120016
I0820 03:52:38.377939 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 03:52:38.377955 22726 solver.cpp:244]     Train net output #1: loss = 0.120016 (* 1 = 0.120016 loss)
I0820 03:52:38.459136 22726 sgd_solver.cpp:166] Iteration 61100, lr = 1.5275
I0820 03:54:56.427196 22726 solver.cpp:337] Iteration 61200, Testing net (#0)
I0820 03:56:21.633625 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87596
I0820 03:56:21.634021 22726 solver.cpp:404]     Test net output #1: loss = 0.419878 (* 1 = 0.419878 loss)
I0820 03:56:22.966497 22726 solver.cpp:228] Iteration 61200, loss = 0.142731
I0820 03:56:22.966542 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 03:56:22.966557 22726 solver.cpp:244]     Train net output #1: loss = 0.142731 (* 1 = 0.142731 loss)
I0820 03:56:23.056573 22726 sgd_solver.cpp:166] Iteration 61200, lr = 1.53
I0820 03:58:41.008723 22726 solver.cpp:337] Iteration 61300, Testing net (#0)
I0820 04:00:06.163970 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8836
I0820 04:00:06.164353 22726 solver.cpp:404]     Test net output #1: loss = 0.406493 (* 1 = 0.406493 loss)
I0820 04:00:07.497972 22726 solver.cpp:228] Iteration 61300, loss = 0.228537
I0820 04:00:07.498020 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 04:00:07.498034 22726 solver.cpp:244]     Train net output #1: loss = 0.228537 (* 1 = 0.228537 loss)
I0820 04:00:07.577292 22726 sgd_solver.cpp:166] Iteration 61300, lr = 1.5325
I0820 04:02:25.590622 22726 solver.cpp:337] Iteration 61400, Testing net (#0)
I0820 04:03:50.742385 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8886
I0820 04:03:50.742929 22726 solver.cpp:404]     Test net output #1: loss = 0.394783 (* 1 = 0.394783 loss)
I0820 04:03:52.076628 22726 solver.cpp:228] Iteration 61400, loss = 0.0761213
I0820 04:03:52.076670 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0820 04:03:52.076686 22726 solver.cpp:244]     Train net output #1: loss = 0.0761211 (* 1 = 0.0761211 loss)
I0820 04:03:52.152261 22726 sgd_solver.cpp:166] Iteration 61400, lr = 1.535
I0820 04:06:10.162024 22726 solver.cpp:337] Iteration 61500, Testing net (#0)
I0820 04:07:35.326133 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87628
I0820 04:07:35.326516 22726 solver.cpp:404]     Test net output #1: loss = 0.415467 (* 1 = 0.415467 loss)
I0820 04:07:36.659884 22726 solver.cpp:228] Iteration 61500, loss = 0.234714
I0820 04:07:36.659927 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 04:07:36.659942 22726 solver.cpp:244]     Train net output #1: loss = 0.234714 (* 1 = 0.234714 loss)
I0820 04:07:36.742605 22726 sgd_solver.cpp:166] Iteration 61500, lr = 1.5375
I0820 04:09:54.763947 22726 solver.cpp:337] Iteration 61600, Testing net (#0)
I0820 04:11:19.939563 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88552
I0820 04:11:19.939939 22726 solver.cpp:404]     Test net output #1: loss = 0.387178 (* 1 = 0.387178 loss)
I0820 04:11:21.273928 22726 solver.cpp:228] Iteration 61600, loss = 0.0903065
I0820 04:11:21.273972 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 04:11:21.273991 22726 solver.cpp:244]     Train net output #1: loss = 0.0903062 (* 1 = 0.0903062 loss)
I0820 04:11:21.354589 22726 sgd_solver.cpp:166] Iteration 61600, lr = 1.54
I0820 04:13:39.538854 22726 solver.cpp:337] Iteration 61700, Testing net (#0)
I0820 04:15:04.702901 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88364
I0820 04:15:04.703290 22726 solver.cpp:404]     Test net output #1: loss = 0.409348 (* 1 = 0.409348 loss)
I0820 04:15:06.041566 22726 solver.cpp:228] Iteration 61700, loss = 0.0599699
I0820 04:15:06.041610 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0820 04:15:06.041635 22726 solver.cpp:244]     Train net output #1: loss = 0.0599696 (* 1 = 0.0599696 loss)
I0820 04:15:06.115365 22726 sgd_solver.cpp:166] Iteration 61700, lr = 1.5425
I0820 04:17:24.117496 22726 solver.cpp:337] Iteration 61800, Testing net (#0)
I0820 04:18:49.318608 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87848
I0820 04:18:49.319000 22726 solver.cpp:404]     Test net output #1: loss = 0.412733 (* 1 = 0.412733 loss)
I0820 04:18:50.651935 22726 solver.cpp:228] Iteration 61800, loss = 0.193261
I0820 04:18:50.651978 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 04:18:50.651994 22726 solver.cpp:244]     Train net output #1: loss = 0.193261 (* 1 = 0.193261 loss)
I0820 04:18:50.732553 22726 sgd_solver.cpp:166] Iteration 61800, lr = 1.545
I0820 04:21:08.661928 22726 solver.cpp:337] Iteration 61900, Testing net (#0)
I0820 04:22:33.849246 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87892
I0820 04:22:33.849627 22726 solver.cpp:404]     Test net output #1: loss = 0.408584 (* 1 = 0.408584 loss)
I0820 04:22:35.183991 22726 solver.cpp:228] Iteration 61900, loss = 0.203259
I0820 04:22:35.184033 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 04:22:35.184056 22726 solver.cpp:244]     Train net output #1: loss = 0.203259 (* 1 = 0.203259 loss)
I0820 04:22:35.263749 22726 sgd_solver.cpp:166] Iteration 61900, lr = 1.5475
I0820 04:24:53.123004 22726 solver.cpp:337] Iteration 62000, Testing net (#0)
I0820 04:26:18.300070 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87796
I0820 04:26:18.300439 22726 solver.cpp:404]     Test net output #1: loss = 0.426934 (* 1 = 0.426934 loss)
I0820 04:26:19.633167 22726 solver.cpp:228] Iteration 62000, loss = 0.1338
I0820 04:26:19.633213 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 04:26:19.633237 22726 solver.cpp:244]     Train net output #1: loss = 0.1338 (* 1 = 0.1338 loss)
I0820 04:26:19.713553 22726 sgd_solver.cpp:166] Iteration 62000, lr = 1.55
I0820 04:28:37.524843 22726 solver.cpp:337] Iteration 62100, Testing net (#0)
I0820 04:30:02.784996 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88672
I0820 04:30:02.785359 22726 solver.cpp:404]     Test net output #1: loss = 0.390586 (* 1 = 0.390586 loss)
I0820 04:30:04.118343 22726 solver.cpp:228] Iteration 62100, loss = 0.165376
I0820 04:30:04.118391 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 04:30:04.118414 22726 solver.cpp:244]     Train net output #1: loss = 0.165376 (* 1 = 0.165376 loss)
I0820 04:30:04.197000 22726 sgd_solver.cpp:166] Iteration 62100, lr = 1.5525
I0820 04:32:22.052711 22726 solver.cpp:337] Iteration 62200, Testing net (#0)
I0820 04:33:47.318702 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8796
I0820 04:33:47.319075 22726 solver.cpp:404]     Test net output #1: loss = 0.412631 (* 1 = 0.412631 loss)
I0820 04:33:48.653524 22726 solver.cpp:228] Iteration 62200, loss = 0.183733
I0820 04:33:48.653570 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 04:33:48.653594 22726 solver.cpp:244]     Train net output #1: loss = 0.183733 (* 1 = 0.183733 loss)
I0820 04:33:48.733916 22726 sgd_solver.cpp:166] Iteration 62200, lr = 1.555
I0820 04:36:06.588551 22726 solver.cpp:337] Iteration 62300, Testing net (#0)
I0820 04:37:31.858028 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88292
I0820 04:37:31.858422 22726 solver.cpp:404]     Test net output #1: loss = 0.404147 (* 1 = 0.404147 loss)
I0820 04:37:33.191009 22726 solver.cpp:228] Iteration 62300, loss = 0.173183
I0820 04:37:33.191064 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 04:37:33.191089 22726 solver.cpp:244]     Train net output #1: loss = 0.173183 (* 1 = 0.173183 loss)
I0820 04:37:33.269871 22726 sgd_solver.cpp:166] Iteration 62300, lr = 1.5575
I0820 04:39:51.097128 22726 solver.cpp:337] Iteration 62400, Testing net (#0)
I0820 04:41:16.384189 22726 solver.cpp:404]     Test net output #0: accuracy = 0.881041
I0820 04:41:16.384572 22726 solver.cpp:404]     Test net output #1: loss = 0.406968 (* 1 = 0.406968 loss)
I0820 04:41:17.718972 22726 solver.cpp:228] Iteration 62400, loss = 0.1319
I0820 04:41:17.719018 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 04:41:17.719040 22726 solver.cpp:244]     Train net output #1: loss = 0.131899 (* 1 = 0.131899 loss)
I0820 04:41:17.799274 22726 sgd_solver.cpp:166] Iteration 62400, lr = 1.56
I0820 04:43:35.605612 22726 solver.cpp:337] Iteration 62500, Testing net (#0)
I0820 04:45:00.857882 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88716
I0820 04:45:00.858285 22726 solver.cpp:404]     Test net output #1: loss = 0.381664 (* 1 = 0.381664 loss)
I0820 04:45:02.190680 22726 solver.cpp:228] Iteration 62500, loss = 0.0613996
I0820 04:45:02.190717 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 04:45:02.190742 22726 solver.cpp:244]     Train net output #1: loss = 0.0613993 (* 1 = 0.0613993 loss)
I0820 04:45:02.269320 22726 sgd_solver.cpp:166] Iteration 62500, lr = 1.5625
I0820 04:47:20.095067 22726 solver.cpp:337] Iteration 62600, Testing net (#0)
I0820 04:48:45.395287 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87844
I0820 04:48:45.395674 22726 solver.cpp:404]     Test net output #1: loss = 0.427667 (* 1 = 0.427667 loss)
I0820 04:48:46.728121 22726 solver.cpp:228] Iteration 62600, loss = 0.159749
I0820 04:48:46.728162 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 04:48:46.728184 22726 solver.cpp:244]     Train net output #1: loss = 0.159748 (* 1 = 0.159748 loss)
I0820 04:48:46.807621 22726 sgd_solver.cpp:166] Iteration 62600, lr = 1.565
I0820 04:51:04.664527 22726 solver.cpp:337] Iteration 62700, Testing net (#0)
I0820 04:52:29.922837 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87832
I0820 04:52:29.923220 22726 solver.cpp:404]     Test net output #1: loss = 0.402875 (* 1 = 0.402875 loss)
I0820 04:52:31.255646 22726 solver.cpp:228] Iteration 62700, loss = 0.151584
I0820 04:52:31.255702 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 04:52:31.255725 22726 solver.cpp:244]     Train net output #1: loss = 0.151584 (* 1 = 0.151584 loss)
I0820 04:52:31.333374 22726 sgd_solver.cpp:166] Iteration 62700, lr = 1.5675
I0820 04:54:49.154880 22726 solver.cpp:337] Iteration 62800, Testing net (#0)
I0820 04:56:14.326081 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8806
I0820 04:56:14.326483 22726 solver.cpp:404]     Test net output #1: loss = 0.409366 (* 1 = 0.409366 loss)
I0820 04:56:15.657701 22726 solver.cpp:228] Iteration 62800, loss = 0.181961
I0820 04:56:15.657758 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 04:56:15.657783 22726 solver.cpp:244]     Train net output #1: loss = 0.181961 (* 1 = 0.181961 loss)
I0820 04:56:15.737934 22726 sgd_solver.cpp:166] Iteration 62800, lr = 1.57
I0820 04:58:33.585772 22726 solver.cpp:337] Iteration 62900, Testing net (#0)
I0820 04:59:58.793105 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88208
I0820 04:59:58.793504 22726 solver.cpp:404]     Test net output #1: loss = 0.40094 (* 1 = 0.40094 loss)
I0820 05:00:00.123435 22726 solver.cpp:228] Iteration 62900, loss = 0.132862
I0820 05:00:00.123489 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 05:00:00.123514 22726 solver.cpp:244]     Train net output #1: loss = 0.132861 (* 1 = 0.132861 loss)
I0820 05:00:00.202306 22726 sgd_solver.cpp:166] Iteration 62900, lr = 1.5725
I0820 05:02:18.017191 22726 solver.cpp:337] Iteration 63000, Testing net (#0)
I0820 05:03:43.230201 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87088
I0820 05:03:43.230607 22726 solver.cpp:404]     Test net output #1: loss = 0.45242 (* 1 = 0.45242 loss)
I0820 05:03:44.560967 22726 solver.cpp:228] Iteration 63000, loss = 0.155582
I0820 05:03:44.561023 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 05:03:44.561048 22726 solver.cpp:244]     Train net output #1: loss = 0.155582 (* 1 = 0.155582 loss)
I0820 05:03:44.643579 22726 sgd_solver.cpp:166] Iteration 63000, lr = 1.575
I0820 05:06:02.523557 22726 solver.cpp:337] Iteration 63100, Testing net (#0)
I0820 05:07:27.729682 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87976
I0820 05:07:27.730047 22726 solver.cpp:404]     Test net output #1: loss = 0.417509 (* 1 = 0.417509 loss)
I0820 05:07:29.059741 22726 solver.cpp:228] Iteration 63100, loss = 0.141484
I0820 05:07:29.059797 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 05:07:29.059819 22726 solver.cpp:244]     Train net output #1: loss = 0.141484 (* 1 = 0.141484 loss)
I0820 05:07:29.141091 22726 sgd_solver.cpp:166] Iteration 63100, lr = 1.5775
I0820 05:09:46.791815 22726 solver.cpp:337] Iteration 63200, Testing net (#0)
I0820 05:11:12.053961 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87796
I0820 05:11:12.054337 22726 solver.cpp:404]     Test net output #1: loss = 0.428545 (* 1 = 0.428545 loss)
I0820 05:11:13.384816 22726 solver.cpp:228] Iteration 63200, loss = 0.125459
I0820 05:11:13.384866 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 05:11:13.384891 22726 solver.cpp:244]     Train net output #1: loss = 0.125459 (* 1 = 0.125459 loss)
I0820 05:11:13.466110 22726 sgd_solver.cpp:166] Iteration 63200, lr = 1.58
I0820 05:13:31.159294 22726 solver.cpp:337] Iteration 63300, Testing net (#0)
I0820 05:14:56.380903 22726 solver.cpp:404]     Test net output #0: accuracy = 0.875
I0820 05:14:56.381295 22726 solver.cpp:404]     Test net output #1: loss = 0.42414 (* 1 = 0.42414 loss)
I0820 05:14:57.711300 22726 solver.cpp:228] Iteration 63300, loss = 0.192408
I0820 05:14:57.711350 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 05:14:57.711376 22726 solver.cpp:244]     Train net output #1: loss = 0.192408 (* 1 = 0.192408 loss)
I0820 05:14:57.790307 22726 sgd_solver.cpp:166] Iteration 63300, lr = 1.5825
I0820 05:17:15.485517 22726 solver.cpp:337] Iteration 63400, Testing net (#0)
I0820 05:18:40.751394 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87904
I0820 05:18:40.751793 22726 solver.cpp:404]     Test net output #1: loss = 0.42716 (* 1 = 0.42716 loss)
I0820 05:18:42.082968 22726 solver.cpp:228] Iteration 63400, loss = 0.0684592
I0820 05:18:42.083016 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 05:18:42.083039 22726 solver.cpp:244]     Train net output #1: loss = 0.068459 (* 1 = 0.068459 loss)
I0820 05:18:42.163925 22726 sgd_solver.cpp:166] Iteration 63400, lr = 1.585
I0820 05:20:59.830183 22726 solver.cpp:337] Iteration 63500, Testing net (#0)
I0820 05:22:25.084954 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8774
I0820 05:22:25.085335 22726 solver.cpp:404]     Test net output #1: loss = 0.404726 (* 1 = 0.404726 loss)
I0820 05:22:26.414651 22726 solver.cpp:228] Iteration 63500, loss = 0.122809
I0820 05:22:26.414700 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 05:22:26.414722 22726 solver.cpp:244]     Train net output #1: loss = 0.122809 (* 1 = 0.122809 loss)
I0820 05:22:26.493147 22726 sgd_solver.cpp:166] Iteration 63500, lr = 1.5875
I0820 05:24:44.204813 22726 solver.cpp:337] Iteration 63600, Testing net (#0)
I0820 05:26:09.519579 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87628
I0820 05:26:09.519968 22726 solver.cpp:404]     Test net output #1: loss = 0.420014 (* 1 = 0.420014 loss)
I0820 05:26:10.851236 22726 solver.cpp:228] Iteration 63600, loss = 0.255481
I0820 05:26:10.851289 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 05:26:10.851312 22726 solver.cpp:244]     Train net output #1: loss = 0.255481 (* 1 = 0.255481 loss)
I0820 05:26:10.926952 22726 sgd_solver.cpp:166] Iteration 63600, lr = 1.59
I0820 05:28:28.611040 22726 solver.cpp:337] Iteration 63700, Testing net (#0)
I0820 05:29:53.899813 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8784
I0820 05:29:53.900180 22726 solver.cpp:404]     Test net output #1: loss = 0.417407 (* 1 = 0.417407 loss)
I0820 05:29:55.232194 22726 solver.cpp:228] Iteration 63700, loss = 0.253416
I0820 05:29:55.232252 22726 solver.cpp:244]     Train net output #0: accuracy = 0.896
I0820 05:29:55.232276 22726 solver.cpp:244]     Train net output #1: loss = 0.253416 (* 1 = 0.253416 loss)
I0820 05:29:55.310853 22726 sgd_solver.cpp:166] Iteration 63700, lr = 1.5925
I0820 05:32:13.075711 22726 solver.cpp:337] Iteration 63800, Testing net (#0)
I0820 05:33:38.400383 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8832
I0820 05:33:38.400773 22726 solver.cpp:404]     Test net output #1: loss = 0.424146 (* 1 = 0.424146 loss)
I0820 05:33:39.732096 22726 solver.cpp:228] Iteration 63800, loss = 0.0929459
I0820 05:33:39.732146 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 05:33:39.732162 22726 solver.cpp:244]     Train net output #1: loss = 0.0929456 (* 1 = 0.0929456 loss)
I0820 05:33:39.811252 22726 sgd_solver.cpp:166] Iteration 63800, lr = 1.595
I0820 05:35:57.590256 22726 solver.cpp:337] Iteration 63900, Testing net (#0)
I0820 05:37:22.762150 22726 solver.cpp:404]     Test net output #0: accuracy = 0.89036
I0820 05:37:22.762512 22726 solver.cpp:404]     Test net output #1: loss = 0.377229 (* 1 = 0.377229 loss)
I0820 05:37:24.093082 22726 solver.cpp:228] Iteration 63900, loss = 0.0711785
I0820 05:37:24.093132 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 05:37:24.093149 22726 solver.cpp:244]     Train net output #1: loss = 0.0711782 (* 1 = 0.0711782 loss)
I0820 05:37:24.179925 22726 sgd_solver.cpp:166] Iteration 63900, lr = 1.5975
I0820 05:39:41.935101 22726 solver.cpp:337] Iteration 64000, Testing net (#0)
I0820 05:41:07.103060 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87636
I0820 05:41:07.103386 22726 solver.cpp:404]     Test net output #1: loss = 0.420412 (* 1 = 0.420412 loss)
I0820 05:41:08.434054 22726 solver.cpp:228] Iteration 64000, loss = 0.133204
I0820 05:41:08.434105 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 05:41:08.434121 22726 solver.cpp:244]     Train net output #1: loss = 0.133204 (* 1 = 0.133204 loss)
I0820 05:41:08.514098 22726 sgd_solver.cpp:166] Iteration 64000, lr = 1.6
I0820 05:43:26.259279 22726 solver.cpp:337] Iteration 64100, Testing net (#0)
I0820 05:44:51.430068 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87704
I0820 05:44:51.430459 22726 solver.cpp:404]     Test net output #1: loss = 0.425465 (* 1 = 0.425465 loss)
I0820 05:44:52.761036 22726 solver.cpp:228] Iteration 64100, loss = 0.153454
I0820 05:44:52.761086 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 05:44:52.761102 22726 solver.cpp:244]     Train net output #1: loss = 0.153454 (* 1 = 0.153454 loss)
I0820 05:44:52.839087 22726 sgd_solver.cpp:166] Iteration 64100, lr = 1.6025
I0820 05:47:10.673375 22726 solver.cpp:337] Iteration 64200, Testing net (#0)
I0820 05:48:35.856688 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88388
I0820 05:48:35.857074 22726 solver.cpp:404]     Test net output #1: loss = 0.390683 (* 1 = 0.390683 loss)
I0820 05:48:37.188225 22726 solver.cpp:228] Iteration 64200, loss = 0.146805
I0820 05:48:37.188277 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 05:48:37.188293 22726 solver.cpp:244]     Train net output #1: loss = 0.146805 (* 1 = 0.146805 loss)
I0820 05:48:37.266007 22726 sgd_solver.cpp:166] Iteration 64200, lr = 1.605
I0820 05:50:55.094462 22726 solver.cpp:337] Iteration 64300, Testing net (#0)
I0820 05:52:20.266275 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8792
I0820 05:52:20.266625 22726 solver.cpp:404]     Test net output #1: loss = 0.395541 (* 1 = 0.395541 loss)
I0820 05:52:21.597481 22726 solver.cpp:228] Iteration 64300, loss = 0.114525
I0820 05:52:21.597532 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 05:52:21.597548 22726 solver.cpp:244]     Train net output #1: loss = 0.114524 (* 1 = 0.114524 loss)
I0820 05:52:21.676666 22726 sgd_solver.cpp:166] Iteration 64300, lr = 1.6075
I0820 05:54:39.468322 22726 solver.cpp:337] Iteration 64400, Testing net (#0)
I0820 05:56:04.640415 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88824
I0820 05:56:04.640816 22726 solver.cpp:404]     Test net output #1: loss = 0.388502 (* 1 = 0.388502 loss)
I0820 05:56:05.971297 22726 solver.cpp:228] Iteration 64400, loss = 0.234167
I0820 05:56:05.971348 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 05:56:05.971364 22726 solver.cpp:244]     Train net output #1: loss = 0.234167 (* 1 = 0.234167 loss)
I0820 05:56:06.052433 22726 sgd_solver.cpp:166] Iteration 64400, lr = 1.61
I0820 05:58:23.887275 22726 solver.cpp:337] Iteration 64500, Testing net (#0)
I0820 05:59:49.060870 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88708
I0820 05:59:49.061239 22726 solver.cpp:404]     Test net output #1: loss = 0.382594 (* 1 = 0.382594 loss)
I0820 05:59:50.390802 22726 solver.cpp:228] Iteration 64500, loss = 0.0923844
I0820 05:59:50.390854 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 05:59:50.390872 22726 solver.cpp:244]     Train net output #1: loss = 0.0923841 (* 1 = 0.0923841 loss)
I0820 05:59:50.468816 22726 sgd_solver.cpp:166] Iteration 64500, lr = 1.6125
I0820 06:02:08.220481 22726 solver.cpp:337] Iteration 64600, Testing net (#0)
I0820 06:03:33.398494 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87464
I0820 06:03:33.398859 22726 solver.cpp:404]     Test net output #1: loss = 0.428333 (* 1 = 0.428333 loss)
I0820 06:03:34.728873 22726 solver.cpp:228] Iteration 64600, loss = 0.247256
I0820 06:03:34.728924 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 06:03:34.728940 22726 solver.cpp:244]     Train net output #1: loss = 0.247255 (* 1 = 0.247255 loss)
I0820 06:03:34.807265 22726 sgd_solver.cpp:166] Iteration 64600, lr = 1.615
I0820 06:05:52.614117 22726 solver.cpp:337] Iteration 64700, Testing net (#0)
I0820 06:07:17.787418 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88592
I0820 06:07:17.787791 22726 solver.cpp:404]     Test net output #1: loss = 0.385586 (* 1 = 0.385586 loss)
I0820 06:07:19.119303 22726 solver.cpp:228] Iteration 64700, loss = 0.0802152
I0820 06:07:19.119354 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 06:07:19.119369 22726 solver.cpp:244]     Train net output #1: loss = 0.0802148 (* 1 = 0.0802148 loss)
I0820 06:07:19.199789 22726 sgd_solver.cpp:166] Iteration 64700, lr = 1.6175
I0820 06:09:36.995437 22726 solver.cpp:337] Iteration 64800, Testing net (#0)
I0820 06:11:02.217394 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88656
I0820 06:11:02.217761 22726 solver.cpp:404]     Test net output #1: loss = 0.375032 (* 1 = 0.375032 loss)
I0820 06:11:03.549409 22726 solver.cpp:228] Iteration 64800, loss = 0.190994
I0820 06:11:03.549463 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 06:11:03.549480 22726 solver.cpp:244]     Train net output #1: loss = 0.190994 (* 1 = 0.190994 loss)
I0820 06:11:03.628926 22726 sgd_solver.cpp:166] Iteration 64800, lr = 1.62
I0820 06:13:21.350530 22726 solver.cpp:337] Iteration 64900, Testing net (#0)
I0820 06:14:46.592311 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8838
I0820 06:14:46.592701 22726 solver.cpp:404]     Test net output #1: loss = 0.383257 (* 1 = 0.383257 loss)
I0820 06:14:47.923341 22726 solver.cpp:228] Iteration 64900, loss = 0.111141
I0820 06:14:47.923393 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 06:14:47.923409 22726 solver.cpp:244]     Train net output #1: loss = 0.111141 (* 1 = 0.111141 loss)
I0820 06:14:48.007994 22726 sgd_solver.cpp:166] Iteration 64900, lr = 1.6225
I0820 06:17:05.785172 22726 solver.cpp:337] Iteration 65000, Testing net (#0)
I0820 06:18:31.045127 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88128
I0820 06:18:31.045500 22726 solver.cpp:404]     Test net output #1: loss = 0.404345 (* 1 = 0.404345 loss)
I0820 06:18:32.376827 22726 solver.cpp:228] Iteration 65000, loss = 0.116409
I0820 06:18:32.376875 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 06:18:32.376893 22726 solver.cpp:244]     Train net output #1: loss = 0.116408 (* 1 = 0.116408 loss)
I0820 06:18:32.464107 22726 sgd_solver.cpp:166] Iteration 65000, lr = 1.625
I0820 06:20:50.245543 22726 solver.cpp:337] Iteration 65100, Testing net (#0)
I0820 06:22:15.434896 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88136
I0820 06:22:15.435276 22726 solver.cpp:404]     Test net output #1: loss = 0.415409 (* 1 = 0.415409 loss)
I0820 06:22:16.765992 22726 solver.cpp:228] Iteration 65100, loss = 0.134615
I0820 06:22:16.766043 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 06:22:16.766059 22726 solver.cpp:244]     Train net output #1: loss = 0.134615 (* 1 = 0.134615 loss)
I0820 06:22:16.842548 22726 sgd_solver.cpp:166] Iteration 65100, lr = 1.6275
I0820 06:24:34.649077 22726 solver.cpp:337] Iteration 65200, Testing net (#0)
I0820 06:25:59.835182 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88148
I0820 06:25:59.835574 22726 solver.cpp:404]     Test net output #1: loss = 0.401332 (* 1 = 0.401332 loss)
I0820 06:26:01.165333 22726 solver.cpp:228] Iteration 65200, loss = 0.151369
I0820 06:26:01.165380 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 06:26:01.165396 22726 solver.cpp:244]     Train net output #1: loss = 0.151369 (* 1 = 0.151369 loss)
I0820 06:26:01.243796 22726 sgd_solver.cpp:166] Iteration 65200, lr = 1.63
I0820 06:28:18.895864 22726 solver.cpp:337] Iteration 65300, Testing net (#0)
I0820 06:29:44.122079 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88496
I0820 06:29:44.122449 22726 solver.cpp:404]     Test net output #1: loss = 0.393083 (* 1 = 0.393083 loss)
I0820 06:29:45.453315 22726 solver.cpp:228] Iteration 65300, loss = 0.0923935
I0820 06:29:45.453361 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 06:29:45.453377 22726 solver.cpp:244]     Train net output #1: loss = 0.0923931 (* 1 = 0.0923931 loss)
I0820 06:29:45.528563 22726 sgd_solver.cpp:166] Iteration 65300, lr = 1.6325
I0820 06:32:03.351717 22726 solver.cpp:337] Iteration 65400, Testing net (#0)
I0820 06:33:28.564025 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87788
I0820 06:33:28.564386 22726 solver.cpp:404]     Test net output #1: loss = 0.409564 (* 1 = 0.409564 loss)
I0820 06:33:29.896004 22726 solver.cpp:228] Iteration 65400, loss = 0.134018
I0820 06:33:29.896057 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 06:33:29.896073 22726 solver.cpp:244]     Train net output #1: loss = 0.134017 (* 1 = 0.134017 loss)
I0820 06:33:29.971123 22726 sgd_solver.cpp:166] Iteration 65400, lr = 1.635
I0820 06:35:47.906263 22726 solver.cpp:337] Iteration 65500, Testing net (#0)
I0820 06:37:13.108499 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8804
I0820 06:37:13.108865 22726 solver.cpp:404]     Test net output #1: loss = 0.413356 (* 1 = 0.413356 loss)
I0820 06:37:14.440484 22726 solver.cpp:228] Iteration 65500, loss = 0.223986
I0820 06:37:14.440536 22726 solver.cpp:244]     Train net output #0: accuracy = 0.904
I0820 06:37:14.440552 22726 solver.cpp:244]     Train net output #1: loss = 0.223986 (* 1 = 0.223986 loss)
I0820 06:37:14.513988 22726 sgd_solver.cpp:166] Iteration 65500, lr = 1.6375
I0820 06:39:32.276314 22726 solver.cpp:337] Iteration 65600, Testing net (#0)
I0820 06:40:57.521688 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8836
I0820 06:40:57.522040 22726 solver.cpp:404]     Test net output #1: loss = 0.412083 (* 1 = 0.412083 loss)
I0820 06:40:58.852943 22726 solver.cpp:228] Iteration 65600, loss = 0.105468
I0820 06:40:58.853000 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 06:40:58.853026 22726 solver.cpp:244]     Train net output #1: loss = 0.105467 (* 1 = 0.105467 loss)
I0820 06:40:58.929328 22726 sgd_solver.cpp:166] Iteration 65600, lr = 1.64
I0820 06:43:16.739189 22726 solver.cpp:337] Iteration 65700, Testing net (#0)
I0820 06:44:42.028314 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88172
I0820 06:44:42.028714 22726 solver.cpp:404]     Test net output #1: loss = 0.414843 (* 1 = 0.414843 loss)
I0820 06:44:43.359930 22726 solver.cpp:228] Iteration 65700, loss = 0.121999
I0820 06:44:43.359987 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 06:44:43.360011 22726 solver.cpp:244]     Train net output #1: loss = 0.121998 (* 1 = 0.121998 loss)
I0820 06:44:43.436810 22726 sgd_solver.cpp:166] Iteration 65700, lr = 1.6425
I0820 06:47:01.219977 22726 solver.cpp:337] Iteration 65800, Testing net (#0)
I0820 06:48:26.515615 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88248
I0820 06:48:26.516031 22726 solver.cpp:404]     Test net output #1: loss = 0.406113 (* 1 = 0.406113 loss)
I0820 06:48:27.848069 22726 solver.cpp:228] Iteration 65800, loss = 0.0959242
I0820 06:48:27.848125 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0820 06:48:27.848150 22726 solver.cpp:244]     Train net output #1: loss = 0.0959238 (* 1 = 0.0959238 loss)
I0820 06:48:27.929467 22726 sgd_solver.cpp:166] Iteration 65800, lr = 1.645
I0820 06:50:45.741678 22726 solver.cpp:337] Iteration 65900, Testing net (#0)
I0820 06:52:10.951226 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88328
I0820 06:52:10.951581 22726 solver.cpp:404]     Test net output #1: loss = 0.403101 (* 1 = 0.403101 loss)
I0820 06:52:12.282516 22726 solver.cpp:228] Iteration 65900, loss = 0.206521
I0820 06:52:12.282570 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 06:52:12.282595 22726 solver.cpp:244]     Train net output #1: loss = 0.206521 (* 1 = 0.206521 loss)
I0820 06:52:12.364261 22726 sgd_solver.cpp:166] Iteration 65900, lr = 1.6475
I0820 06:54:30.130081 22726 solver.cpp:337] Iteration 66000, Testing net (#0)
I0820 06:55:55.308034 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87716
I0820 06:55:55.308444 22726 solver.cpp:404]     Test net output #1: loss = 0.419091 (* 1 = 0.419091 loss)
I0820 06:55:56.637928 22726 solver.cpp:228] Iteration 66000, loss = 0.112439
I0820 06:55:56.637984 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 06:55:56.638010 22726 solver.cpp:244]     Train net output #1: loss = 0.112439 (* 1 = 0.112439 loss)
I0820 06:55:56.714946 22726 sgd_solver.cpp:166] Iteration 66000, lr = 1.65
I0820 06:58:14.699018 22726 solver.cpp:337] Iteration 66100, Testing net (#0)
I0820 06:59:39.898793 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87744
I0820 06:59:39.899168 22726 solver.cpp:404]     Test net output #1: loss = 0.418493 (* 1 = 0.418493 loss)
I0820 06:59:41.229249 22726 solver.cpp:228] Iteration 66100, loss = 0.107077
I0820 06:59:41.229307 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 06:59:41.229332 22726 solver.cpp:244]     Train net output #1: loss = 0.107077 (* 1 = 0.107077 loss)
I0820 06:59:41.308190 22726 sgd_solver.cpp:166] Iteration 66100, lr = 1.6525
I0820 07:01:59.239166 22726 solver.cpp:337] Iteration 66200, Testing net (#0)
I0820 07:03:24.500972 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88216
I0820 07:03:24.501363 22726 solver.cpp:404]     Test net output #1: loss = 0.402851 (* 1 = 0.402851 loss)
I0820 07:03:25.832522 22726 solver.cpp:228] Iteration 66200, loss = 0.0817614
I0820 07:03:25.832782 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 07:03:25.832814 22726 solver.cpp:244]     Train net output #1: loss = 0.081761 (* 1 = 0.081761 loss)
I0820 07:03:25.910876 22726 sgd_solver.cpp:166] Iteration 66200, lr = 1.655
I0820 07:05:43.854183 22726 solver.cpp:337] Iteration 66300, Testing net (#0)
I0820 07:07:09.053045 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87964
I0820 07:07:09.053418 22726 solver.cpp:404]     Test net output #1: loss = 0.414239 (* 1 = 0.414239 loss)
I0820 07:07:10.384670 22726 solver.cpp:228] Iteration 66300, loss = 0.0760087
I0820 07:07:10.384726 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 07:07:10.384749 22726 solver.cpp:244]     Train net output #1: loss = 0.0760083 (* 1 = 0.0760083 loss)
I0820 07:07:10.462851 22726 sgd_solver.cpp:166] Iteration 66300, lr = 1.6575
I0820 07:09:28.333444 22726 solver.cpp:337] Iteration 66400, Testing net (#0)
I0820 07:10:53.509377 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87236
I0820 07:10:53.509757 22726 solver.cpp:404]     Test net output #1: loss = 0.44937 (* 1 = 0.44937 loss)
I0820 07:10:54.841639 22726 solver.cpp:228] Iteration 66400, loss = 0.188691
I0820 07:10:54.841697 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 07:10:54.841722 22726 solver.cpp:244]     Train net output #1: loss = 0.188691 (* 1 = 0.188691 loss)
I0820 07:10:54.918807 22726 sgd_solver.cpp:166] Iteration 66400, lr = 1.66
I0820 07:13:12.645745 22726 solver.cpp:337] Iteration 66500, Testing net (#0)
I0820 07:14:37.538641 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87224
I0820 07:14:37.538921 22726 solver.cpp:404]     Test net output #1: loss = 0.43311 (* 1 = 0.43311 loss)
I0820 07:14:38.868741 22726 solver.cpp:228] Iteration 66500, loss = 0.197613
I0820 07:14:38.868798 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 07:14:38.868822 22726 solver.cpp:244]     Train net output #1: loss = 0.197612 (* 1 = 0.197612 loss)
I0820 07:14:38.951141 22726 sgd_solver.cpp:166] Iteration 66500, lr = 1.6625
I0820 07:16:56.627347 22726 solver.cpp:337] Iteration 66600, Testing net (#0)
I0820 07:18:21.501426 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88244
I0820 07:18:21.501739 22726 solver.cpp:404]     Test net output #1: loss = 0.403549 (* 1 = 0.403549 loss)
I0820 07:18:22.833003 22726 solver.cpp:228] Iteration 66600, loss = 0.11152
I0820 07:18:22.833055 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 07:18:22.833072 22726 solver.cpp:244]     Train net output #1: loss = 0.111519 (* 1 = 0.111519 loss)
I0820 07:18:22.912592 22726 sgd_solver.cpp:166] Iteration 66600, lr = 1.665
I0820 07:20:40.659780 22726 solver.cpp:337] Iteration 66700, Testing net (#0)
I0820 07:22:05.795011 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88144
I0820 07:22:05.795361 22726 solver.cpp:404]     Test net output #1: loss = 0.402512 (* 1 = 0.402512 loss)
I0820 07:22:07.125057 22726 solver.cpp:228] Iteration 66700, loss = 0.0877102
I0820 07:22:07.125108 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 07:22:07.125126 22726 solver.cpp:244]     Train net output #1: loss = 0.0877097 (* 1 = 0.0877097 loss)
I0820 07:22:07.207134 22726 sgd_solver.cpp:166] Iteration 66700, lr = 1.6675
I0820 07:24:24.901929 22726 solver.cpp:337] Iteration 66800, Testing net (#0)
I0820 07:25:49.922233 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8802
I0820 07:25:49.922502 22726 solver.cpp:404]     Test net output #1: loss = 0.416251 (* 1 = 0.416251 loss)
I0820 07:25:51.252353 22726 solver.cpp:228] Iteration 66800, loss = 0.103723
I0820 07:25:51.252408 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 07:25:51.252424 22726 solver.cpp:244]     Train net output #1: loss = 0.103722 (* 1 = 0.103722 loss)
I0820 07:25:51.332437 22726 sgd_solver.cpp:166] Iteration 66800, lr = 1.67
I0820 07:28:09.030735 22726 solver.cpp:337] Iteration 66900, Testing net (#0)
I0820 07:29:33.962698 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87624
I0820 07:29:33.962976 22726 solver.cpp:404]     Test net output #1: loss = 0.428515 (* 1 = 0.428515 loss)
I0820 07:29:35.293856 22726 solver.cpp:228] Iteration 66900, loss = 0.159588
I0820 07:29:35.293910 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 07:29:35.293928 22726 solver.cpp:244]     Train net output #1: loss = 0.159588 (* 1 = 0.159588 loss)
I0820 07:29:35.377259 22726 sgd_solver.cpp:166] Iteration 66900, lr = 1.6725
I0820 07:31:53.039963 22726 solver.cpp:337] Iteration 67000, Testing net (#0)
I0820 07:33:18.040755 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88416
I0820 07:33:18.041072 22726 solver.cpp:404]     Test net output #1: loss = 0.395892 (* 1 = 0.395892 loss)
I0820 07:33:19.372447 22726 solver.cpp:228] Iteration 67000, loss = 0.17295
I0820 07:33:19.372499 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 07:33:19.372516 22726 solver.cpp:244]     Train net output #1: loss = 0.172949 (* 1 = 0.172949 loss)
I0820 07:33:19.455346 22726 sgd_solver.cpp:166] Iteration 67000, lr = 1.675
I0820 07:35:37.148448 22726 solver.cpp:337] Iteration 67100, Testing net (#0)
I0820 07:37:02.269691 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88244
I0820 07:37:02.270112 22726 solver.cpp:404]     Test net output #1: loss = 0.385007 (* 1 = 0.385007 loss)
I0820 07:37:03.600137 22726 solver.cpp:228] Iteration 67100, loss = 0.129882
I0820 07:37:03.600190 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 07:37:03.600211 22726 solver.cpp:244]     Train net output #1: loss = 0.129881 (* 1 = 0.129881 loss)
I0820 07:37:03.676779 22726 sgd_solver.cpp:166] Iteration 67100, lr = 1.6775
I0820 07:39:21.354028 22726 solver.cpp:337] Iteration 67200, Testing net (#0)
I0820 07:40:46.387498 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87056
I0820 07:40:46.387783 22726 solver.cpp:404]     Test net output #1: loss = 0.448648 (* 1 = 0.448648 loss)
I0820 07:40:47.717470 22726 solver.cpp:228] Iteration 67200, loss = 0.164186
I0820 07:40:47.717522 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 07:40:47.717540 22726 solver.cpp:244]     Train net output #1: loss = 0.164186 (* 1 = 0.164186 loss)
I0820 07:40:47.793581 22726 sgd_solver.cpp:166] Iteration 67200, lr = 1.68
I0820 07:43:05.507015 22726 solver.cpp:337] Iteration 67300, Testing net (#0)
I0820 07:44:30.582458 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87936
I0820 07:44:30.582768 22726 solver.cpp:404]     Test net output #1: loss = 0.406339 (* 1 = 0.406339 loss)
I0820 07:44:31.913697 22726 solver.cpp:228] Iteration 67300, loss = 0.099875
I0820 07:44:31.913750 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 07:44:31.913767 22726 solver.cpp:244]     Train net output #1: loss = 0.0998746 (* 1 = 0.0998746 loss)
I0820 07:44:31.995633 22726 sgd_solver.cpp:166] Iteration 67300, lr = 1.6825
I0820 07:46:49.691915 22726 solver.cpp:337] Iteration 67400, Testing net (#0)
I0820 07:48:14.807845 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88376
I0820 07:48:14.808135 22726 solver.cpp:404]     Test net output #1: loss = 0.406158 (* 1 = 0.406158 loss)
I0820 07:48:16.138983 22726 solver.cpp:228] Iteration 67400, loss = 0.160239
I0820 07:48:16.139037 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 07:48:16.139055 22726 solver.cpp:244]     Train net output #1: loss = 0.160238 (* 1 = 0.160238 loss)
I0820 07:48:16.227325 22726 sgd_solver.cpp:166] Iteration 67400, lr = 1.685
I0820 07:50:33.848083 22726 solver.cpp:337] Iteration 67500, Testing net (#0)
I0820 07:51:59.003132 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88128
I0820 07:51:59.003430 22726 solver.cpp:404]     Test net output #1: loss = 0.414947 (* 1 = 0.414947 loss)
I0820 07:52:00.334179 22726 solver.cpp:228] Iteration 67500, loss = 0.204288
I0820 07:52:00.334239 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 07:52:00.334256 22726 solver.cpp:244]     Train net output #1: loss = 0.204288 (* 1 = 0.204288 loss)
I0820 07:52:00.413817 22726 sgd_solver.cpp:166] Iteration 67500, lr = 1.6875
I0820 07:54:18.179085 22726 solver.cpp:337] Iteration 67600, Testing net (#0)
I0820 07:55:43.331312 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87812
I0820 07:55:43.331603 22726 solver.cpp:404]     Test net output #1: loss = 0.443229 (* 1 = 0.443229 loss)
I0820 07:55:44.662410 22726 solver.cpp:228] Iteration 67600, loss = 0.297145
I0820 07:55:44.662464 22726 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0820 07:55:44.662480 22726 solver.cpp:244]     Train net output #1: loss = 0.297145 (* 1 = 0.297145 loss)
I0820 07:55:44.740087 22726 sgd_solver.cpp:166] Iteration 67600, lr = 1.69
I0820 07:58:02.641047 22726 solver.cpp:337] Iteration 67700, Testing net (#0)
I0820 07:59:27.788538 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87632
I0820 07:59:27.788820 22726 solver.cpp:404]     Test net output #1: loss = 0.403606 (* 1 = 0.403606 loss)
I0820 07:59:29.120163 22726 solver.cpp:228] Iteration 67700, loss = 0.164976
I0820 07:59:29.120213 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 07:59:29.120230 22726 solver.cpp:244]     Train net output #1: loss = 0.164976 (* 1 = 0.164976 loss)
I0820 07:59:29.203518 22726 sgd_solver.cpp:166] Iteration 67700, lr = 1.6925
I0820 08:01:46.956578 22726 solver.cpp:337] Iteration 67800, Testing net (#0)
I0820 08:03:11.922063 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88808
I0820 08:03:11.922420 22726 solver.cpp:404]     Test net output #1: loss = 0.373483 (* 1 = 0.373483 loss)
I0820 08:03:13.253073 22726 solver.cpp:228] Iteration 67800, loss = 0.118597
I0820 08:03:13.253125 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 08:03:13.253142 22726 solver.cpp:244]     Train net output #1: loss = 0.118596 (* 1 = 0.118596 loss)
I0820 08:03:13.335177 22726 sgd_solver.cpp:166] Iteration 67800, lr = 1.695
I0820 08:05:31.159860 22726 solver.cpp:337] Iteration 67900, Testing net (#0)
I0820 08:06:56.206822 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88008
I0820 08:06:56.207134 22726 solver.cpp:404]     Test net output #1: loss = 0.411957 (* 1 = 0.411957 loss)
I0820 08:06:57.536715 22726 solver.cpp:228] Iteration 67900, loss = 0.191705
I0820 08:06:57.536765 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 08:06:57.536782 22726 solver.cpp:244]     Train net output #1: loss = 0.191704 (* 1 = 0.191704 loss)
I0820 08:06:57.614730 22726 sgd_solver.cpp:166] Iteration 67900, lr = 1.6975
I0820 08:09:15.452991 22726 solver.cpp:337] Iteration 68000, Testing net (#0)
I0820 08:10:40.363123 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8826
I0820 08:10:40.363421 22726 solver.cpp:404]     Test net output #1: loss = 0.39527 (* 1 = 0.39527 loss)
I0820 08:10:41.693006 22726 solver.cpp:228] Iteration 68000, loss = 0.181889
I0820 08:10:41.693055 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 08:10:41.693071 22726 solver.cpp:244]     Train net output #1: loss = 0.181889 (* 1 = 0.181889 loss)
I0820 08:10:41.770123 22726 sgd_solver.cpp:166] Iteration 68000, lr = 1.7
I0820 08:12:59.499987 22726 solver.cpp:337] Iteration 68100, Testing net (#0)
I0820 08:14:24.592752 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87932
I0820 08:14:24.593029 22726 solver.cpp:404]     Test net output #1: loss = 0.39896 (* 1 = 0.39896 loss)
I0820 08:14:25.922729 22726 solver.cpp:228] Iteration 68100, loss = 0.232084
I0820 08:14:25.922782 22726 solver.cpp:244]     Train net output #0: accuracy = 0.904
I0820 08:14:25.922798 22726 solver.cpp:244]     Train net output #1: loss = 0.232083 (* 1 = 0.232083 loss)
I0820 08:14:26.001631 22726 sgd_solver.cpp:166] Iteration 68100, lr = 1.7025
I0820 08:16:43.799814 22726 solver.cpp:337] Iteration 68200, Testing net (#0)
I0820 08:18:08.912636 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87532
I0820 08:18:08.912947 22726 solver.cpp:404]     Test net output #1: loss = 0.429879 (* 1 = 0.429879 loss)
I0820 08:18:10.244148 22726 solver.cpp:228] Iteration 68200, loss = 0.120031
I0820 08:18:10.244199 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 08:18:10.244220 22726 solver.cpp:244]     Train net output #1: loss = 0.12003 (* 1 = 0.12003 loss)
I0820 08:18:10.327630 22726 sgd_solver.cpp:166] Iteration 68200, lr = 1.705
I0820 08:20:28.089105 22726 solver.cpp:337] Iteration 68300, Testing net (#0)
I0820 08:21:53.192314 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8778
I0820 08:21:53.192608 22726 solver.cpp:404]     Test net output #1: loss = 0.422674 (* 1 = 0.422674 loss)
I0820 08:21:54.523340 22726 solver.cpp:228] Iteration 68300, loss = 0.167193
I0820 08:21:54.523391 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 08:21:54.523406 22726 solver.cpp:244]     Train net output #1: loss = 0.167192 (* 1 = 0.167192 loss)
I0820 08:21:54.608826 22726 sgd_solver.cpp:166] Iteration 68300, lr = 1.7075
I0820 08:24:12.428417 22726 solver.cpp:337] Iteration 68400, Testing net (#0)
I0820 08:25:37.392490 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88524
I0820 08:25:37.392807 22726 solver.cpp:404]     Test net output #1: loss = 0.395023 (* 1 = 0.395023 loss)
I0820 08:25:38.722731 22726 solver.cpp:228] Iteration 68400, loss = 0.187821
I0820 08:25:38.722780 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 08:25:38.722797 22726 solver.cpp:244]     Train net output #1: loss = 0.18782 (* 1 = 0.18782 loss)
I0820 08:25:38.797171 22726 sgd_solver.cpp:166] Iteration 68400, lr = 1.71
I0820 08:27:56.494746 22726 solver.cpp:337] Iteration 68500, Testing net (#0)
I0820 08:29:21.403148 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86764
I0820 08:29:21.403445 22726 solver.cpp:404]     Test net output #1: loss = 0.439284 (* 1 = 0.439284 loss)
I0820 08:29:22.733403 22726 solver.cpp:228] Iteration 68500, loss = 0.197703
I0820 08:29:22.733455 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 08:29:22.733471 22726 solver.cpp:244]     Train net output #1: loss = 0.197703 (* 1 = 0.197703 loss)
I0820 08:29:22.817044 22726 sgd_solver.cpp:166] Iteration 68500, lr = 1.7125
I0820 08:31:40.592149 22726 solver.cpp:337] Iteration 68600, Testing net (#0)
I0820 08:33:05.670486 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88212
I0820 08:33:05.670838 22726 solver.cpp:404]     Test net output #1: loss = 0.398313 (* 1 = 0.398313 loss)
I0820 08:33:07.001083 22726 solver.cpp:228] Iteration 68600, loss = 0.180042
I0820 08:33:07.001133 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 08:33:07.001150 22726 solver.cpp:244]     Train net output #1: loss = 0.180042 (* 1 = 0.180042 loss)
I0820 08:33:07.084805 22726 sgd_solver.cpp:166] Iteration 68600, lr = 1.715
I0820 08:35:25.001157 22726 solver.cpp:337] Iteration 68700, Testing net (#0)
I0820 08:36:49.995676 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8792
I0820 08:36:49.995949 22726 solver.cpp:404]     Test net output #1: loss = 0.428513 (* 1 = 0.428513 loss)
I0820 08:36:51.326367 22726 solver.cpp:228] Iteration 68700, loss = 0.0928761
I0820 08:36:51.326421 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 08:36:51.326444 22726 solver.cpp:244]     Train net output #1: loss = 0.0928755 (* 1 = 0.0928755 loss)
I0820 08:36:51.407194 22726 sgd_solver.cpp:166] Iteration 68700, lr = 1.7175
I0820 08:39:09.191292 22726 solver.cpp:337] Iteration 68800, Testing net (#0)
I0820 08:40:34.297462 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88152
I0820 08:40:34.297791 22726 solver.cpp:404]     Test net output #1: loss = 0.386979 (* 1 = 0.386979 loss)
I0820 08:40:35.628581 22726 solver.cpp:228] Iteration 68800, loss = 0.207389
I0820 08:40:35.628630 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 08:40:35.628646 22726 solver.cpp:244]     Train net output #1: loss = 0.207389 (* 1 = 0.207389 loss)
I0820 08:40:35.707244 22726 sgd_solver.cpp:166] Iteration 68800, lr = 1.72
I0820 08:42:53.440124 22726 solver.cpp:337] Iteration 68900, Testing net (#0)
I0820 08:44:18.461807 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88288
I0820 08:44:18.462100 22726 solver.cpp:404]     Test net output #1: loss = 0.405967 (* 1 = 0.405967 loss)
I0820 08:44:19.793072 22726 solver.cpp:228] Iteration 68900, loss = 0.172987
I0820 08:44:19.793123 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 08:44:19.793138 22726 solver.cpp:244]     Train net output #1: loss = 0.172986 (* 1 = 0.172986 loss)
I0820 08:44:19.876830 22726 sgd_solver.cpp:166] Iteration 68900, lr = 1.7225
I0820 08:46:37.730298 22726 solver.cpp:337] Iteration 69000, Testing net (#0)
I0820 08:48:02.751332 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88412
I0820 08:48:02.751622 22726 solver.cpp:404]     Test net output #1: loss = 0.381692 (* 1 = 0.381692 loss)
I0820 08:48:04.082566 22726 solver.cpp:228] Iteration 69000, loss = 0.10253
I0820 08:48:04.082617 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 08:48:04.082633 22726 solver.cpp:244]     Train net output #1: loss = 0.102529 (* 1 = 0.102529 loss)
I0820 08:48:04.165400 22726 sgd_solver.cpp:166] Iteration 69000, lr = 1.725
I0820 08:50:22.172937 22726 solver.cpp:337] Iteration 69100, Testing net (#0)
I0820 08:51:47.279176 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88216
I0820 08:51:47.279507 22726 solver.cpp:404]     Test net output #1: loss = 0.397706 (* 1 = 0.397706 loss)
I0820 08:51:48.609758 22726 solver.cpp:228] Iteration 69100, loss = 0.168906
I0820 08:51:48.609810 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 08:51:48.609827 22726 solver.cpp:244]     Train net output #1: loss = 0.168906 (* 1 = 0.168906 loss)
I0820 08:51:48.687371 22726 sgd_solver.cpp:166] Iteration 69100, lr = 1.7275
I0820 08:54:06.405287 22726 solver.cpp:337] Iteration 69200, Testing net (#0)
I0820 08:55:31.511903 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88348
I0820 08:55:31.512192 22726 solver.cpp:404]     Test net output #1: loss = 0.395284 (* 1 = 0.395284 loss)
I0820 08:55:32.841307 22726 solver.cpp:228] Iteration 69200, loss = 0.256295
I0820 08:55:32.841357 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 08:55:32.841374 22726 solver.cpp:244]     Train net output #1: loss = 0.256294 (* 1 = 0.256294 loss)
I0820 08:55:32.923704 22726 sgd_solver.cpp:166] Iteration 69200, lr = 1.73
I0820 08:57:50.808670 22726 solver.cpp:337] Iteration 69300, Testing net (#0)
I0820 08:59:15.912317 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87664
I0820 08:59:15.912672 22726 solver.cpp:404]     Test net output #1: loss = 0.416342 (* 1 = 0.416342 loss)
I0820 08:59:17.243608 22726 solver.cpp:228] Iteration 69300, loss = 0.156967
I0820 08:59:17.243656 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 08:59:17.243680 22726 solver.cpp:244]     Train net output #1: loss = 0.156967 (* 1 = 0.156967 loss)
I0820 08:59:17.324177 22726 sgd_solver.cpp:166] Iteration 69300, lr = 1.7325
I0820 09:01:35.074404 22726 solver.cpp:337] Iteration 69400, Testing net (#0)
I0820 09:03:00.250038 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87648
I0820 09:03:00.250444 22726 solver.cpp:404]     Test net output #1: loss = 0.425518 (* 1 = 0.425518 loss)
I0820 09:03:01.580404 22726 solver.cpp:228] Iteration 69400, loss = 0.170231
I0820 09:03:01.580451 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 09:03:01.580474 22726 solver.cpp:244]     Train net output #1: loss = 0.17023 (* 1 = 0.17023 loss)
I0820 09:03:01.661309 22726 sgd_solver.cpp:166] Iteration 69400, lr = 1.735
I0820 09:05:19.460330 22726 solver.cpp:337] Iteration 69500, Testing net (#0)
I0820 09:06:44.586200 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87044
I0820 09:06:44.586571 22726 solver.cpp:404]     Test net output #1: loss = 0.444469 (* 1 = 0.444469 loss)
I0820 09:06:45.916393 22726 solver.cpp:228] Iteration 69500, loss = 0.110374
I0820 09:06:45.916438 22726 solver.cpp:244]     Train net output #0: accuracy = 0.984
I0820 09:06:45.916455 22726 solver.cpp:244]     Train net output #1: loss = 0.110373 (* 1 = 0.110373 loss)
I0820 09:06:45.999830 22726 sgd_solver.cpp:166] Iteration 69500, lr = 1.7375
I0820 09:09:03.784179 22726 solver.cpp:337] Iteration 69600, Testing net (#0)
I0820 09:10:28.233290 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86572
I0820 09:10:28.233640 22726 solver.cpp:404]     Test net output #1: loss = 0.449665 (* 1 = 0.449665 loss)
I0820 09:10:29.561805 22726 solver.cpp:228] Iteration 69600, loss = 0.13595
I0820 09:10:29.561847 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 09:10:29.561863 22726 solver.cpp:244]     Train net output #1: loss = 0.135949 (* 1 = 0.135949 loss)
I0820 09:10:29.644137 22726 sgd_solver.cpp:166] Iteration 69600, lr = 1.74
I0820 09:12:47.341233 22726 solver.cpp:337] Iteration 69700, Testing net (#0)
I0820 09:14:11.779757 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87972
I0820 09:14:11.780099 22726 solver.cpp:404]     Test net output #1: loss = 0.403328 (* 1 = 0.403328 loss)
I0820 09:14:13.107522 22726 solver.cpp:228] Iteration 69700, loss = 0.254295
I0820 09:14:13.107558 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 09:14:13.107573 22726 solver.cpp:244]     Train net output #1: loss = 0.254295 (* 1 = 0.254295 loss)
I0820 09:14:13.190707 22726 sgd_solver.cpp:166] Iteration 69700, lr = 1.7425
I0820 09:16:30.715970 22726 solver.cpp:337] Iteration 69800, Testing net (#0)
I0820 09:17:55.156390 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88124
I0820 09:17:55.156759 22726 solver.cpp:404]     Test net output #1: loss = 0.387623 (* 1 = 0.387623 loss)
I0820 09:17:56.483971 22726 solver.cpp:228] Iteration 69800, loss = 0.151105
I0820 09:17:56.484014 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 09:17:56.484036 22726 solver.cpp:244]     Train net output #1: loss = 0.151105 (* 1 = 0.151105 loss)
I0820 09:17:56.570612 22726 sgd_solver.cpp:166] Iteration 69800, lr = 1.745
I0820 09:20:14.156886 22726 solver.cpp:337] Iteration 69900, Testing net (#0)
I0820 09:21:38.589495 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88056
I0820 09:21:38.589848 22726 solver.cpp:404]     Test net output #1: loss = 0.389729 (* 1 = 0.389729 loss)
I0820 09:21:39.917541 22726 solver.cpp:228] Iteration 69900, loss = 0.268492
I0820 09:21:39.917582 22726 solver.cpp:244]     Train net output #0: accuracy = 0.904
I0820 09:21:39.917603 22726 solver.cpp:244]     Train net output #1: loss = 0.268492 (* 1 = 0.268492 loss)
I0820 09:21:40.003394 22726 sgd_solver.cpp:166] Iteration 69900, lr = 1.7475
I0820 09:23:57.665026 22726 solver.cpp:337] Iteration 70000, Testing net (#0)
I0820 09:25:22.750417 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88508
I0820 09:25:22.750690 22726 solver.cpp:404]     Test net output #1: loss = 0.387121 (* 1 = 0.387121 loss)
I0820 09:25:24.081751 22726 solver.cpp:228] Iteration 70000, loss = 0.143119
I0820 09:25:24.081796 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 09:25:24.081812 22726 solver.cpp:244]     Train net output #1: loss = 0.143118 (* 1 = 0.143118 loss)
I0820 09:25:24.161767 22726 sgd_solver.cpp:166] Iteration 70000, lr = 1.75
I0820 09:27:41.929497 22726 solver.cpp:337] Iteration 70100, Testing net (#0)
I0820 09:29:06.847404 22726 solver.cpp:404]     Test net output #0: accuracy = 0.882321
I0820 09:29:06.847672 22726 solver.cpp:404]     Test net output #1: loss = 0.391737 (* 1 = 0.391737 loss)
I0820 09:29:08.177248 22726 solver.cpp:228] Iteration 70100, loss = 0.186881
I0820 09:29:08.177289 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 09:29:08.177304 22726 solver.cpp:244]     Train net output #1: loss = 0.186881 (* 1 = 0.186881 loss)
I0820 09:29:08.258493 22726 sgd_solver.cpp:166] Iteration 70100, lr = 1.7525
I0820 09:31:26.044796 22726 solver.cpp:337] Iteration 70200, Testing net (#0)
I0820 09:32:50.978389 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8802
I0820 09:32:50.978737 22726 solver.cpp:404]     Test net output #1: loss = 0.383868 (* 1 = 0.383868 loss)
I0820 09:32:52.309770 22726 solver.cpp:228] Iteration 70200, loss = 0.173911
I0820 09:32:52.309815 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 09:32:52.309830 22726 solver.cpp:244]     Train net output #1: loss = 0.173911 (* 1 = 0.173911 loss)
I0820 09:32:52.388073 22726 sgd_solver.cpp:166] Iteration 70200, lr = 1.755
I0820 09:35:10.203351 22726 solver.cpp:337] Iteration 70300, Testing net (#0)
I0820 09:36:35.307996 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87132
I0820 09:36:35.308280 22726 solver.cpp:404]     Test net output #1: loss = 0.434022 (* 1 = 0.434022 loss)
I0820 09:36:36.638295 22726 solver.cpp:228] Iteration 70300, loss = 0.213355
I0820 09:36:36.638339 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 09:36:36.638355 22726 solver.cpp:244]     Train net output #1: loss = 0.213355 (* 1 = 0.213355 loss)
I0820 09:36:36.720278 22726 sgd_solver.cpp:166] Iteration 70300, lr = 1.7575
I0820 09:38:54.455955 22726 solver.cpp:337] Iteration 70400, Testing net (#0)
I0820 09:40:19.576666 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87608
I0820 09:40:19.576994 22726 solver.cpp:404]     Test net output #1: loss = 0.416732 (* 1 = 0.416732 loss)
I0820 09:40:20.907842 22726 solver.cpp:228] Iteration 70400, loss = 0.173722
I0820 09:40:20.907886 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 09:40:20.907902 22726 solver.cpp:244]     Train net output #1: loss = 0.173721 (* 1 = 0.173721 loss)
I0820 09:40:20.997927 22726 sgd_solver.cpp:166] Iteration 70400, lr = 1.76
I0820 09:42:38.758816 22726 solver.cpp:337] Iteration 70500, Testing net (#0)
I0820 09:44:03.891670 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88632
I0820 09:44:03.892005 22726 solver.cpp:404]     Test net output #1: loss = 0.379709 (* 1 = 0.379709 loss)
I0820 09:44:05.221276 22726 solver.cpp:228] Iteration 70500, loss = 0.0582815
I0820 09:44:05.221328 22726 solver.cpp:244]     Train net output #0: accuracy = 0.992
I0820 09:44:05.221345 22726 solver.cpp:244]     Train net output #1: loss = 0.0582808 (* 1 = 0.0582808 loss)
I0820 09:44:05.305063 22726 sgd_solver.cpp:166] Iteration 70500, lr = 1.7625
I0820 09:46:23.230856 22726 solver.cpp:337] Iteration 70600, Testing net (#0)
I0820 09:47:48.358654 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87976
I0820 09:47:48.358989 22726 solver.cpp:404]     Test net output #1: loss = 0.404501 (* 1 = 0.404501 loss)
I0820 09:47:49.689469 22726 solver.cpp:228] Iteration 70600, loss = 0.149544
I0820 09:47:49.689522 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 09:47:49.689538 22726 solver.cpp:244]     Train net output #1: loss = 0.149543 (* 1 = 0.149543 loss)
I0820 09:47:49.770917 22726 sgd_solver.cpp:166] Iteration 70600, lr = 1.765
I0820 09:50:07.449978 22726 solver.cpp:337] Iteration 70700, Testing net (#0)
I0820 09:51:32.557509 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87328
I0820 09:51:32.557801 22726 solver.cpp:404]     Test net output #1: loss = 0.416162 (* 1 = 0.416162 loss)
I0820 09:51:33.888243 22726 solver.cpp:228] Iteration 70700, loss = 0.17159
I0820 09:51:33.888284 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 09:51:33.888299 22726 solver.cpp:244]     Train net output #1: loss = 0.17159 (* 1 = 0.17159 loss)
I0820 09:51:33.965296 22726 sgd_solver.cpp:166] Iteration 70700, lr = 1.7675
I0820 09:53:51.687633 22726 solver.cpp:337] Iteration 70800, Testing net (#0)
I0820 09:55:16.763420 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88752
I0820 09:55:16.763734 22726 solver.cpp:404]     Test net output #1: loss = 0.373654 (* 1 = 0.373654 loss)
I0820 09:55:18.093866 22726 solver.cpp:228] Iteration 70800, loss = 0.149509
I0820 09:55:18.093917 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 09:55:18.093932 22726 solver.cpp:244]     Train net output #1: loss = 0.149508 (* 1 = 0.149508 loss)
I0820 09:55:18.173280 22726 sgd_solver.cpp:166] Iteration 70800, lr = 1.77
I0820 09:57:35.883316 22726 solver.cpp:337] Iteration 70900, Testing net (#0)
I0820 09:59:01.028794 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88096
I0820 09:59:01.029103 22726 solver.cpp:404]     Test net output #1: loss = 0.413113 (* 1 = 0.413113 loss)
I0820 09:59:02.359165 22726 solver.cpp:228] Iteration 70900, loss = 0.154544
I0820 09:59:02.359215 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 09:59:02.359230 22726 solver.cpp:244]     Train net output #1: loss = 0.154543 (* 1 = 0.154543 loss)
I0820 09:59:02.438309 22726 sgd_solver.cpp:166] Iteration 70900, lr = 1.7725
I0820 10:01:20.100575 22726 solver.cpp:337] Iteration 71000, Testing net (#0)
I0820 10:02:45.237671 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87992
I0820 10:02:45.238044 22726 solver.cpp:404]     Test net output #1: loss = 0.403228 (* 1 = 0.403228 loss)
I0820 10:02:46.568158 22726 solver.cpp:228] Iteration 71000, loss = 0.147844
I0820 10:02:46.568202 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 10:02:46.568217 22726 solver.cpp:244]     Train net output #1: loss = 0.147844 (* 1 = 0.147844 loss)
I0820 10:02:46.652429 22726 sgd_solver.cpp:166] Iteration 71000, lr = 1.775
I0820 10:05:04.616595 22726 solver.cpp:337] Iteration 71100, Testing net (#0)
I0820 10:06:29.769075 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88164
I0820 10:06:29.769362 22726 solver.cpp:404]     Test net output #1: loss = 0.393243 (* 1 = 0.393243 loss)
I0820 10:06:31.099179 22726 solver.cpp:228] Iteration 71100, loss = 0.204066
I0820 10:06:31.099231 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 10:06:31.099246 22726 solver.cpp:244]     Train net output #1: loss = 0.204065 (* 1 = 0.204065 loss)
I0820 10:06:31.176877 22726 sgd_solver.cpp:166] Iteration 71100, lr = 1.7775
I0820 10:08:49.029050 22726 solver.cpp:337] Iteration 71200, Testing net (#0)
I0820 10:10:13.926174 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8808
I0820 10:10:13.926498 22726 solver.cpp:404]     Test net output #1: loss = 0.410208 (* 1 = 0.410208 loss)
I0820 10:10:15.256198 22726 solver.cpp:228] Iteration 71200, loss = 0.161669
I0820 10:10:15.256242 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 10:10:15.256258 22726 solver.cpp:244]     Train net output #1: loss = 0.161668 (* 1 = 0.161668 loss)
I0820 10:10:15.338841 22726 sgd_solver.cpp:166] Iteration 71200, lr = 1.78
I0820 10:12:33.037461 22726 solver.cpp:337] Iteration 71300, Testing net (#0)
I0820 10:13:57.955684 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87704
I0820 10:13:57.955950 22726 solver.cpp:404]     Test net output #1: loss = 0.402606 (* 1 = 0.402606 loss)
I0820 10:13:59.285024 22726 solver.cpp:228] Iteration 71300, loss = 0.128342
I0820 10:13:59.285075 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 10:13:59.285091 22726 solver.cpp:244]     Train net output #1: loss = 0.128341 (* 1 = 0.128341 loss)
I0820 10:13:59.362522 22726 sgd_solver.cpp:166] Iteration 71300, lr = 1.7825
I0820 10:16:17.134945 22726 solver.cpp:337] Iteration 71400, Testing net (#0)
I0820 10:17:41.937682 22726 solver.cpp:404]     Test net output #0: accuracy = 0.875
I0820 10:17:41.937952 22726 solver.cpp:404]     Test net output #1: loss = 0.434478 (* 1 = 0.434478 loss)
I0820 10:17:43.267983 22726 solver.cpp:228] Iteration 71400, loss = 0.126453
I0820 10:17:43.268036 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 10:17:43.268054 22726 solver.cpp:244]     Train net output #1: loss = 0.126453 (* 1 = 0.126453 loss)
I0820 10:17:43.353888 22726 sgd_solver.cpp:166] Iteration 71400, lr = 1.785
I0820 10:20:01.095376 22726 solver.cpp:337] Iteration 71500, Testing net (#0)
I0820 10:21:26.012888 22726 solver.cpp:404]     Test net output #0: accuracy = 0.872441
I0820 10:21:26.013283 22726 solver.cpp:404]     Test net output #1: loss = 0.427102 (* 1 = 0.427102 loss)
I0820 10:21:27.343010 22726 solver.cpp:228] Iteration 71500, loss = 0.19057
I0820 10:21:27.343060 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 10:21:27.343078 22726 solver.cpp:244]     Train net output #1: loss = 0.190569 (* 1 = 0.190569 loss)
I0820 10:21:27.421674 22726 sgd_solver.cpp:166] Iteration 71500, lr = 1.7875
I0820 10:23:45.195658 22726 solver.cpp:337] Iteration 71600, Testing net (#0)
I0820 10:25:10.020031 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88608
I0820 10:25:10.020381 22726 solver.cpp:404]     Test net output #1: loss = 0.380053 (* 1 = 0.380053 loss)
I0820 10:25:11.350046 22726 solver.cpp:228] Iteration 71600, loss = 0.209798
I0820 10:25:11.350098 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 10:25:11.350116 22726 solver.cpp:244]     Train net output #1: loss = 0.209798 (* 1 = 0.209798 loss)
I0820 10:25:11.431200 22726 sgd_solver.cpp:166] Iteration 71600, lr = 1.79
I0820 10:27:29.208915 22726 solver.cpp:337] Iteration 71700, Testing net (#0)
I0820 10:28:54.190004 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87596
I0820 10:28:54.190390 22726 solver.cpp:404]     Test net output #1: loss = 0.418918 (* 1 = 0.418918 loss)
I0820 10:28:55.520330 22726 solver.cpp:228] Iteration 71700, loss = 0.202189
I0820 10:28:55.520375 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 10:28:55.520390 22726 solver.cpp:244]     Train net output #1: loss = 0.202188 (* 1 = 0.202188 loss)
I0820 10:28:55.599264 22726 sgd_solver.cpp:166] Iteration 71700, lr = 1.7925
I0820 10:31:13.352670 22726 solver.cpp:337] Iteration 71800, Testing net (#0)
I0820 10:32:38.510337 22726 solver.cpp:404]     Test net output #0: accuracy = 0.881
I0820 10:32:38.510689 22726 solver.cpp:404]     Test net output #1: loss = 0.383638 (* 1 = 0.383638 loss)
I0820 10:32:39.841614 22726 solver.cpp:228] Iteration 71800, loss = 0.138713
I0820 10:32:39.841656 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 10:32:39.841672 22726 solver.cpp:244]     Train net output #1: loss = 0.138712 (* 1 = 0.138712 loss)
I0820 10:32:39.921936 22726 sgd_solver.cpp:166] Iteration 71800, lr = 1.795
I0820 10:34:57.710019 22726 solver.cpp:337] Iteration 71900, Testing net (#0)
I0820 10:36:22.686369 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87408
I0820 10:36:22.686750 22726 solver.cpp:404]     Test net output #1: loss = 0.420842 (* 1 = 0.420842 loss)
I0820 10:36:24.017225 22726 solver.cpp:228] Iteration 71900, loss = 0.210559
I0820 10:36:24.017280 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 10:36:24.017297 22726 solver.cpp:244]     Train net output #1: loss = 0.210558 (* 1 = 0.210558 loss)
I0820 10:36:24.095890 22726 sgd_solver.cpp:166] Iteration 71900, lr = 1.7975
I0820 10:38:41.849505 22726 solver.cpp:337] Iteration 72000, Testing net (#0)
I0820 10:40:06.768293 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88764
I0820 10:40:06.768622 22726 solver.cpp:404]     Test net output #1: loss = 0.379095 (* 1 = 0.379095 loss)
I0820 10:40:08.098397 22726 solver.cpp:228] Iteration 72000, loss = 0.156229
I0820 10:40:08.098450 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 10:40:08.098466 22726 solver.cpp:244]     Train net output #1: loss = 0.156229 (* 1 = 0.156229 loss)
I0820 10:40:08.181696 22726 sgd_solver.cpp:166] Iteration 72000, lr = 1.8
I0820 10:42:25.952255 22726 solver.cpp:337] Iteration 72100, Testing net (#0)
I0820 10:43:51.121927 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87636
I0820 10:43:51.122284 22726 solver.cpp:404]     Test net output #1: loss = 0.408834 (* 1 = 0.408834 loss)
I0820 10:43:52.452154 22726 solver.cpp:228] Iteration 72100, loss = 0.137471
I0820 10:43:52.452198 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 10:43:52.452214 22726 solver.cpp:244]     Train net output #1: loss = 0.13747 (* 1 = 0.13747 loss)
I0820 10:43:52.531143 22726 sgd_solver.cpp:166] Iteration 72100, lr = 1.8025
I0820 10:46:10.335834 22726 solver.cpp:337] Iteration 72200, Testing net (#0)
I0820 10:47:35.496749 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8782
I0820 10:47:35.497135 22726 solver.cpp:404]     Test net output #1: loss = 0.399339 (* 1 = 0.399339 loss)
I0820 10:47:36.826761 22726 solver.cpp:228] Iteration 72200, loss = 0.189145
I0820 10:47:36.826812 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 10:47:36.826828 22726 solver.cpp:244]     Train net output #1: loss = 0.189144 (* 1 = 0.189144 loss)
I0820 10:47:36.909224 22726 sgd_solver.cpp:166] Iteration 72200, lr = 1.805
I0820 10:49:54.782097 22726 solver.cpp:337] Iteration 72300, Testing net (#0)
I0820 10:51:19.940902 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86844
I0820 10:51:19.941309 22726 solver.cpp:404]     Test net output #1: loss = 0.436186 (* 1 = 0.436186 loss)
I0820 10:51:21.271284 22726 solver.cpp:228] Iteration 72300, loss = 0.254975
I0820 10:51:21.271333 22726 solver.cpp:244]     Train net output #0: accuracy = 0.896
I0820 10:51:21.271350 22726 solver.cpp:244]     Train net output #1: loss = 0.254974 (* 1 = 0.254974 loss)
I0820 10:51:21.352625 22726 sgd_solver.cpp:166] Iteration 72300, lr = 1.8075
I0820 10:53:39.165994 22726 solver.cpp:337] Iteration 72400, Testing net (#0)
I0820 10:55:04.343282 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87828
I0820 10:55:04.343684 22726 solver.cpp:404]     Test net output #1: loss = 0.407108 (* 1 = 0.407108 loss)
I0820 10:55:05.673940 22726 solver.cpp:228] Iteration 72400, loss = 0.164941
I0820 10:55:05.673985 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 10:55:05.674001 22726 solver.cpp:244]     Train net output #1: loss = 0.16494 (* 1 = 0.16494 loss)
I0820 10:55:05.756621 22726 sgd_solver.cpp:166] Iteration 72400, lr = 1.81
I0820 10:57:23.541935 22726 solver.cpp:337] Iteration 72500, Testing net (#0)
I0820 10:58:48.709252 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87904
I0820 10:58:48.709656 22726 solver.cpp:404]     Test net output #1: loss = 0.402522 (* 1 = 0.402522 loss)
I0820 10:58:50.039541 22726 solver.cpp:228] Iteration 72500, loss = 0.139575
I0820 10:58:50.039589 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 10:58:50.039605 22726 solver.cpp:244]     Train net output #1: loss = 0.139574 (* 1 = 0.139574 loss)
I0820 10:58:50.119729 22726 sgd_solver.cpp:166] Iteration 72500, lr = 1.8125
I0820 11:01:07.933034 22726 solver.cpp:337] Iteration 72600, Testing net (#0)
I0820 11:02:33.101984 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88252
I0820 11:02:33.102380 22726 solver.cpp:404]     Test net output #1: loss = 0.384468 (* 1 = 0.384468 loss)
I0820 11:02:34.432270 22726 solver.cpp:228] Iteration 72600, loss = 0.122739
I0820 11:02:34.432320 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 11:02:34.432337 22726 solver.cpp:244]     Train net output #1: loss = 0.122739 (* 1 = 0.122739 loss)
I0820 11:02:34.513339 22726 sgd_solver.cpp:166] Iteration 72600, lr = 1.815
I0820 11:04:52.314965 22726 solver.cpp:337] Iteration 72700, Testing net (#0)
I0820 11:06:17.485890 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87788
I0820 11:06:17.486274 22726 solver.cpp:404]     Test net output #1: loss = 0.392187 (* 1 = 0.392187 loss)
I0820 11:06:18.815748 22726 solver.cpp:228] Iteration 72700, loss = 0.0959956
I0820 11:06:18.815796 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 11:06:18.815811 22726 solver.cpp:244]     Train net output #1: loss = 0.0959951 (* 1 = 0.0959951 loss)
I0820 11:06:18.899089 22726 sgd_solver.cpp:166] Iteration 72700, lr = 1.8175
I0820 11:08:36.613688 22726 solver.cpp:337] Iteration 72800, Testing net (#0)
I0820 11:10:01.781847 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88144
I0820 11:10:01.782251 22726 solver.cpp:404]     Test net output #1: loss = 0.392143 (* 1 = 0.392143 loss)
I0820 11:10:03.112709 22726 solver.cpp:228] Iteration 72800, loss = 0.12834
I0820 11:10:03.112753 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 11:10:03.112769 22726 solver.cpp:244]     Train net output #1: loss = 0.128339 (* 1 = 0.128339 loss)
I0820 11:10:03.192623 22726 sgd_solver.cpp:166] Iteration 72800, lr = 1.82
I0820 11:12:20.920439 22726 solver.cpp:337] Iteration 72900, Testing net (#0)
I0820 11:13:46.085108 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86936
I0820 11:13:46.085484 22726 solver.cpp:404]     Test net output #1: loss = 0.447936 (* 1 = 0.447936 loss)
I0820 11:13:47.415562 22726 solver.cpp:228] Iteration 72900, loss = 0.140577
I0820 11:13:47.415609 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 11:13:47.415626 22726 solver.cpp:244]     Train net output #1: loss = 0.140577 (* 1 = 0.140577 loss)
I0820 11:13:47.493862 22726 sgd_solver.cpp:166] Iteration 72900, lr = 1.8225
I0820 11:16:05.255584 22726 solver.cpp:337] Iteration 73000, Testing net (#0)
I0820 11:17:30.425602 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87432
I0820 11:17:30.426018 22726 solver.cpp:404]     Test net output #1: loss = 0.435592 (* 1 = 0.435592 loss)
I0820 11:17:31.756062 22726 solver.cpp:228] Iteration 73000, loss = 0.283941
I0820 11:17:31.756106 22726 solver.cpp:244]     Train net output #0: accuracy = 0.872
I0820 11:17:31.756124 22726 solver.cpp:244]     Train net output #1: loss = 0.283941 (* 1 = 0.283941 loss)
I0820 11:17:31.839960 22726 sgd_solver.cpp:166] Iteration 73000, lr = 1.825
I0820 11:19:49.579555 22726 solver.cpp:337] Iteration 73100, Testing net (#0)
I0820 11:21:14.733685 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87448
I0820 11:21:14.734084 22726 solver.cpp:404]     Test net output #1: loss = 0.410845 (* 1 = 0.410845 loss)
I0820 11:21:16.064571 22726 solver.cpp:228] Iteration 73100, loss = 0.147223
I0820 11:21:16.064618 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 11:21:16.064635 22726 solver.cpp:244]     Train net output #1: loss = 0.147222 (* 1 = 0.147222 loss)
I0820 11:21:16.145506 22726 sgd_solver.cpp:166] Iteration 73100, lr = 1.8275
I0820 11:23:33.839465 22726 solver.cpp:337] Iteration 73200, Testing net (#0)
I0820 11:24:58.982480 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88336
I0820 11:24:58.982879 22726 solver.cpp:404]     Test net output #1: loss = 0.378834 (* 1 = 0.378834 loss)
I0820 11:25:00.312954 22726 solver.cpp:228] Iteration 73200, loss = 0.118786
I0820 11:25:00.313005 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 11:25:00.313020 22726 solver.cpp:244]     Train net output #1: loss = 0.118785 (* 1 = 0.118785 loss)
I0820 11:25:00.397295 22726 sgd_solver.cpp:166] Iteration 73200, lr = 1.83
I0820 11:27:18.198314 22726 solver.cpp:337] Iteration 73300, Testing net (#0)
I0820 11:28:43.360569 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8804
I0820 11:28:43.360975 22726 solver.cpp:404]     Test net output #1: loss = 0.397878 (* 1 = 0.397878 loss)
I0820 11:28:44.690668 22726 solver.cpp:228] Iteration 73300, loss = 0.145092
I0820 11:28:44.690718 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 11:28:44.690733 22726 solver.cpp:244]     Train net output #1: loss = 0.145092 (* 1 = 0.145092 loss)
I0820 11:28:44.768121 22726 sgd_solver.cpp:166] Iteration 73300, lr = 1.8325
I0820 11:31:02.479619 22726 solver.cpp:337] Iteration 73400, Testing net (#0)
I0820 11:32:27.633184 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88424
I0820 11:32:27.633553 22726 solver.cpp:404]     Test net output #1: loss = 0.3898 (* 1 = 0.3898 loss)
I0820 11:32:28.962769 22726 solver.cpp:228] Iteration 73400, loss = 0.113096
I0820 11:32:28.962816 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 11:32:28.962831 22726 solver.cpp:244]     Train net output #1: loss = 0.113095 (* 1 = 0.113095 loss)
I0820 11:32:29.039880 22726 sgd_solver.cpp:166] Iteration 73400, lr = 1.835
I0820 11:34:46.713765 22726 solver.cpp:337] Iteration 73500, Testing net (#0)
I0820 11:36:11.857766 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88852
I0820 11:36:11.858157 22726 solver.cpp:404]     Test net output #1: loss = 0.366737 (* 1 = 0.366737 loss)
I0820 11:36:13.187871 22726 solver.cpp:228] Iteration 73500, loss = 0.108575
I0820 11:36:13.187925 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 11:36:13.187942 22726 solver.cpp:244]     Train net output #1: loss = 0.108574 (* 1 = 0.108574 loss)
I0820 11:36:13.268416 22726 sgd_solver.cpp:166] Iteration 73500, lr = 1.8375
I0820 11:38:31.111351 22726 solver.cpp:337] Iteration 73600, Testing net (#0)
I0820 11:39:56.269541 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8778
I0820 11:39:56.269919 22726 solver.cpp:404]     Test net output #1: loss = 0.411401 (* 1 = 0.411401 loss)
I0820 11:39:57.599716 22726 solver.cpp:228] Iteration 73600, loss = 0.148045
I0820 11:39:57.599767 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 11:39:57.599783 22726 solver.cpp:244]     Train net output #1: loss = 0.148044 (* 1 = 0.148044 loss)
I0820 11:39:57.678833 22726 sgd_solver.cpp:166] Iteration 73600, lr = 1.84
I0820 11:42:15.361892 22726 solver.cpp:337] Iteration 73700, Testing net (#0)
I0820 11:43:40.515883 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87576
I0820 11:43:40.516268 22726 solver.cpp:404]     Test net output #1: loss = 0.393616 (* 1 = 0.393616 loss)
I0820 11:43:41.846554 22726 solver.cpp:228] Iteration 73700, loss = 0.138618
I0820 11:43:41.846599 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 11:43:41.846616 22726 solver.cpp:244]     Train net output #1: loss = 0.138618 (* 1 = 0.138618 loss)
I0820 11:43:41.928092 22726 sgd_solver.cpp:166] Iteration 73700, lr = 1.8425
I0820 11:45:59.599375 22726 solver.cpp:337] Iteration 73800, Testing net (#0)
I0820 11:47:24.756860 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87088
I0820 11:47:24.757272 22726 solver.cpp:404]     Test net output #1: loss = 0.436342 (* 1 = 0.436342 loss)
I0820 11:47:26.086541 22726 solver.cpp:228] Iteration 73800, loss = 0.197622
I0820 11:47:26.086594 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 11:47:26.086611 22726 solver.cpp:244]     Train net output #1: loss = 0.197622 (* 1 = 0.197622 loss)
I0820 11:47:26.169463 22726 sgd_solver.cpp:166] Iteration 73800, lr = 1.845
I0820 11:49:43.774395 22726 solver.cpp:337] Iteration 73900, Testing net (#0)
I0820 11:51:08.922466 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86876
I0820 11:51:08.922859 22726 solver.cpp:404]     Test net output #1: loss = 0.427255 (* 1 = 0.427255 loss)
I0820 11:51:10.252629 22726 solver.cpp:228] Iteration 73900, loss = 0.276647
I0820 11:51:10.252681 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 11:51:10.252697 22726 solver.cpp:244]     Train net output #1: loss = 0.276647 (* 1 = 0.276647 loss)
I0820 11:51:10.334928 22726 sgd_solver.cpp:166] Iteration 73900, lr = 1.8475
I0820 11:53:28.124955 22726 solver.cpp:337] Iteration 74000, Testing net (#0)
I0820 11:54:53.280405 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8704
I0820 11:54:53.280804 22726 solver.cpp:404]     Test net output #1: loss = 0.429218 (* 1 = 0.429218 loss)
I0820 11:54:54.613836 22726 solver.cpp:228] Iteration 74000, loss = 0.127418
I0820 11:54:54.613891 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 11:54:54.613909 22726 solver.cpp:244]     Train net output #1: loss = 0.127417 (* 1 = 0.127417 loss)
I0820 11:54:54.694069 22726 sgd_solver.cpp:166] Iteration 74000, lr = 1.85
I0820 11:57:12.384099 22726 solver.cpp:337] Iteration 74100, Testing net (#0)
I0820 11:58:37.550624 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87
I0820 11:58:37.551050 22726 solver.cpp:404]     Test net output #1: loss = 0.43936 (* 1 = 0.43936 loss)
I0820 11:58:38.881559 22726 solver.cpp:228] Iteration 74100, loss = 0.273559
I0820 11:58:38.881613 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 11:58:38.881629 22726 solver.cpp:244]     Train net output #1: loss = 0.273559 (* 1 = 0.273559 loss)
I0820 11:58:38.960186 22726 sgd_solver.cpp:166] Iteration 74100, lr = 1.8525
I0820 12:00:56.631110 22726 solver.cpp:337] Iteration 74200, Testing net (#0)
I0820 12:02:21.791791 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88456
I0820 12:02:21.792189 22726 solver.cpp:404]     Test net output #1: loss = 0.381362 (* 1 = 0.381362 loss)
I0820 12:02:23.122297 22726 solver.cpp:228] Iteration 74200, loss = 0.161437
I0820 12:02:23.122351 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 12:02:23.122366 22726 solver.cpp:244]     Train net output #1: loss = 0.161436 (* 1 = 0.161436 loss)
I0820 12:02:23.201836 22726 sgd_solver.cpp:166] Iteration 74200, lr = 1.855
I0820 12:04:41.015264 22726 solver.cpp:337] Iteration 74300, Testing net (#0)
I0820 12:06:06.073945 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87808
I0820 12:06:06.074301 22726 solver.cpp:404]     Test net output #1: loss = 0.414032 (* 1 = 0.414032 loss)
I0820 12:06:07.403988 22726 solver.cpp:228] Iteration 74300, loss = 0.175402
I0820 12:06:07.404042 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 12:06:07.404058 22726 solver.cpp:244]     Train net output #1: loss = 0.175402 (* 1 = 0.175402 loss)
I0820 12:06:07.485280 22726 sgd_solver.cpp:166] Iteration 74300, lr = 1.8575
I0820 12:08:25.190868 22726 solver.cpp:337] Iteration 74400, Testing net (#0)
I0820 12:09:50.216363 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87916
I0820 12:09:50.216634 22726 solver.cpp:404]     Test net output #1: loss = 0.417671 (* 1 = 0.417671 loss)
I0820 12:09:51.545940 22726 solver.cpp:228] Iteration 74400, loss = 0.220767
I0820 12:09:51.546000 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 12:09:51.546016 22726 solver.cpp:244]     Train net output #1: loss = 0.220767 (* 1 = 0.220767 loss)
I0820 12:09:51.628697 22726 sgd_solver.cpp:166] Iteration 74400, lr = 1.86
I0820 12:12:09.326095 22726 solver.cpp:337] Iteration 74500, Testing net (#0)
I0820 12:13:34.194365 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86932
I0820 12:13:34.194635 22726 solver.cpp:404]     Test net output #1: loss = 0.456222 (* 1 = 0.456222 loss)
I0820 12:13:35.525853 22726 solver.cpp:228] Iteration 74500, loss = 0.234297
I0820 12:13:35.525908 22726 solver.cpp:244]     Train net output #0: accuracy = 0.888
I0820 12:13:35.525925 22726 solver.cpp:244]     Train net output #1: loss = 0.234296 (* 1 = 0.234296 loss)
I0820 12:13:35.600615 22726 sgd_solver.cpp:166] Iteration 74500, lr = 1.8625
I0820 12:15:53.253850 22726 solver.cpp:337] Iteration 74600, Testing net (#0)
I0820 12:17:18.103492 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88248
I0820 12:17:18.103766 22726 solver.cpp:404]     Test net output #1: loss = 0.401099 (* 1 = 0.401099 loss)
I0820 12:17:19.434414 22726 solver.cpp:228] Iteration 74600, loss = 0.263947
I0820 12:17:19.434468 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 12:17:19.434486 22726 solver.cpp:244]     Train net output #1: loss = 0.263947 (* 1 = 0.263947 loss)
I0820 12:17:19.515516 22726 sgd_solver.cpp:166] Iteration 74600, lr = 1.865
I0820 12:19:37.202075 22726 solver.cpp:337] Iteration 74700, Testing net (#0)
I0820 12:21:02.000208 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87496
I0820 12:21:02.000535 22726 solver.cpp:404]     Test net output #1: loss = 0.407754 (* 1 = 0.407754 loss)
I0820 12:21:03.331686 22726 solver.cpp:228] Iteration 74700, loss = 0.145471
I0820 12:21:03.331730 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 12:21:03.331745 22726 solver.cpp:244]     Train net output #1: loss = 0.14547 (* 1 = 0.14547 loss)
I0820 12:21:03.414275 22726 sgd_solver.cpp:166] Iteration 74700, lr = 1.8675
I0820 12:23:21.107062 22726 solver.cpp:337] Iteration 74800, Testing net (#0)
I0820 12:24:46.004844 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87628
I0820 12:24:46.005136 22726 solver.cpp:404]     Test net output #1: loss = 0.423634 (* 1 = 0.423634 loss)
I0820 12:24:47.335346 22726 solver.cpp:228] Iteration 74800, loss = 0.130791
I0820 12:24:47.335398 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 12:24:47.335414 22726 solver.cpp:244]     Train net output #1: loss = 0.13079 (* 1 = 0.13079 loss)
I0820 12:24:47.414327 22726 sgd_solver.cpp:166] Iteration 74800, lr = 1.87
I0820 12:27:05.093946 22726 solver.cpp:337] Iteration 74900, Testing net (#0)
I0820 12:28:29.937723 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8782
I0820 12:28:29.937991 22726 solver.cpp:404]     Test net output #1: loss = 0.402774 (* 1 = 0.402774 loss)
I0820 12:28:31.269340 22726 solver.cpp:228] Iteration 74900, loss = 0.168822
I0820 12:28:31.269393 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 12:28:31.269410 22726 solver.cpp:244]     Train net output #1: loss = 0.168821 (* 1 = 0.168821 loss)
I0820 12:28:31.349129 22726 sgd_solver.cpp:166] Iteration 74900, lr = 1.8725
I0820 12:30:49.075723 22726 solver.cpp:337] Iteration 75000, Testing net (#0)
I0820 12:32:14.190596 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86916
I0820 12:32:14.190982 22726 solver.cpp:404]     Test net output #1: loss = 0.410561 (* 1 = 0.410561 loss)
I0820 12:32:15.521625 22726 solver.cpp:228] Iteration 75000, loss = 0.0878397
I0820 12:32:15.521670 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 12:32:15.521687 22726 solver.cpp:244]     Train net output #1: loss = 0.0878391 (* 1 = 0.0878391 loss)
I0820 12:32:15.606149 22726 sgd_solver.cpp:166] Iteration 75000, lr = 1.875
I0820 12:34:33.466787 22726 solver.cpp:337] Iteration 75100, Testing net (#0)
I0820 12:35:58.626025 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87808
I0820 12:35:58.626448 22726 solver.cpp:404]     Test net output #1: loss = 0.405628 (* 1 = 0.405628 loss)
I0820 12:35:59.957455 22726 solver.cpp:228] Iteration 75100, loss = 0.200765
I0820 12:35:59.957501 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 12:35:59.957525 22726 solver.cpp:244]     Train net output #1: loss = 0.200764 (* 1 = 0.200764 loss)
I0820 12:36:00.036020 22726 sgd_solver.cpp:166] Iteration 75100, lr = 1.8775
I0820 12:38:17.758461 22726 solver.cpp:337] Iteration 75200, Testing net (#0)
I0820 12:39:42.949434 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8856
I0820 12:39:42.949826 22726 solver.cpp:404]     Test net output #1: loss = 0.392046 (* 1 = 0.392046 loss)
I0820 12:39:44.281790 22726 solver.cpp:228] Iteration 75200, loss = 0.114813
I0820 12:39:44.281838 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 12:39:44.281854 22726 solver.cpp:244]     Train net output #1: loss = 0.114812 (* 1 = 0.114812 loss)
I0820 12:39:44.358238 22726 sgd_solver.cpp:166] Iteration 75200, lr = 1.88
I0820 12:42:02.054738 22726 solver.cpp:337] Iteration 75300, Testing net (#0)
I0820 12:43:27.244580 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87908
I0820 12:43:27.244972 22726 solver.cpp:404]     Test net output #1: loss = 0.38889 (* 1 = 0.38889 loss)
I0820 12:43:28.574936 22726 solver.cpp:228] Iteration 75300, loss = 0.251905
I0820 12:43:28.574978 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 12:43:28.574995 22726 solver.cpp:244]     Train net output #1: loss = 0.251904 (* 1 = 0.251904 loss)
I0820 12:43:28.653579 22726 sgd_solver.cpp:166] Iteration 75300, lr = 1.8825
I0820 12:45:46.331573 22726 solver.cpp:337] Iteration 75400, Testing net (#0)
I0820 12:47:11.514461 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88092
I0820 12:47:11.514855 22726 solver.cpp:404]     Test net output #1: loss = 0.397534 (* 1 = 0.397534 loss)
I0820 12:47:12.844463 22726 solver.cpp:228] Iteration 75400, loss = 0.164249
I0820 12:47:12.844506 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 12:47:12.844521 22726 solver.cpp:244]     Train net output #1: loss = 0.164248 (* 1 = 0.164248 loss)
I0820 12:47:12.922722 22726 sgd_solver.cpp:166] Iteration 75400, lr = 1.885
I0820 12:49:30.600100 22726 solver.cpp:337] Iteration 75500, Testing net (#0)
I0820 12:50:55.769506 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87892
I0820 12:50:55.769870 22726 solver.cpp:404]     Test net output #1: loss = 0.398464 (* 1 = 0.398464 loss)
I0820 12:50:57.099788 22726 solver.cpp:228] Iteration 75500, loss = 0.13427
I0820 12:50:57.099827 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 12:50:57.099841 22726 solver.cpp:244]     Train net output #1: loss = 0.13427 (* 1 = 0.13427 loss)
I0820 12:50:57.182193 22726 sgd_solver.cpp:166] Iteration 75500, lr = 1.8875
I0820 12:53:15.098526 22726 solver.cpp:337] Iteration 75600, Testing net (#0)
I0820 12:54:40.269979 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88032
I0820 12:54:40.270364 22726 solver.cpp:404]     Test net output #1: loss = 0.408873 (* 1 = 0.408873 loss)
I0820 12:54:41.602969 22726 solver.cpp:228] Iteration 75600, loss = 0.149693
I0820 12:54:41.603013 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 12:54:41.603035 22726 solver.cpp:244]     Train net output #1: loss = 0.149692 (* 1 = 0.149692 loss)
I0820 12:54:41.680789 22726 sgd_solver.cpp:166] Iteration 75600, lr = 1.89
I0820 12:56:59.682093 22726 solver.cpp:337] Iteration 75700, Testing net (#0)
I0820 12:58:24.850605 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87584
I0820 12:58:24.851011 22726 solver.cpp:404]     Test net output #1: loss = 0.416317 (* 1 = 0.416317 loss)
I0820 12:58:26.180848 22726 solver.cpp:228] Iteration 75700, loss = 0.176042
I0820 12:58:26.180887 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 12:58:26.180902 22726 solver.cpp:244]     Train net output #1: loss = 0.176041 (* 1 = 0.176041 loss)
I0820 12:58:26.262768 22726 sgd_solver.cpp:166] Iteration 75700, lr = 1.8925
I0820 13:00:44.236052 22726 solver.cpp:337] Iteration 75800, Testing net (#0)
I0820 13:02:09.399945 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88
I0820 13:02:09.400351 22726 solver.cpp:404]     Test net output #1: loss = 0.389832 (* 1 = 0.389832 loss)
I0820 13:02:10.729926 22726 solver.cpp:228] Iteration 75800, loss = 0.215055
I0820 13:02:10.729964 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 13:02:10.729979 22726 solver.cpp:244]     Train net output #1: loss = 0.215055 (* 1 = 0.215055 loss)
I0820 13:02:10.814836 22726 sgd_solver.cpp:166] Iteration 75800, lr = 1.895
I0820 13:04:28.762104 22726 solver.cpp:337] Iteration 75900, Testing net (#0)
I0820 13:05:53.905349 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87716
I0820 13:05:53.905728 22726 solver.cpp:404]     Test net output #1: loss = 0.404673 (* 1 = 0.404673 loss)
I0820 13:05:55.235736 22726 solver.cpp:228] Iteration 75900, loss = 0.19645
I0820 13:05:55.235775 22726 solver.cpp:244]     Train net output #0: accuracy = 0.904
I0820 13:05:55.235791 22726 solver.cpp:244]     Train net output #1: loss = 0.19645 (* 1 = 0.19645 loss)
I0820 13:05:55.312050 22726 sgd_solver.cpp:166] Iteration 75900, lr = 1.8975
I0820 13:08:13.238243 22726 solver.cpp:337] Iteration 76000, Testing net (#0)
I0820 13:09:38.400279 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88036
I0820 13:09:38.400687 22726 solver.cpp:404]     Test net output #1: loss = 0.38327 (* 1 = 0.38327 loss)
I0820 13:09:39.730602 22726 solver.cpp:228] Iteration 76000, loss = 0.227653
I0820 13:09:39.730641 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 13:09:39.730656 22726 solver.cpp:244]     Train net output #1: loss = 0.227652 (* 1 = 0.227652 loss)
I0820 13:09:39.816097 22726 sgd_solver.cpp:166] Iteration 76000, lr = 1.9
I0820 13:11:57.702373 22726 solver.cpp:337] Iteration 76100, Testing net (#0)
I0820 13:13:22.837357 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87888
I0820 13:13:22.837759 22726 solver.cpp:404]     Test net output #1: loss = 0.396481 (* 1 = 0.396481 loss)
I0820 13:13:24.167028 22726 solver.cpp:228] Iteration 76100, loss = 0.144588
I0820 13:13:24.167068 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 13:13:24.167083 22726 solver.cpp:244]     Train net output #1: loss = 0.144588 (* 1 = 0.144588 loss)
I0820 13:13:24.254005 22726 sgd_solver.cpp:166] Iteration 76100, lr = 1.9025
I0820 13:15:42.205215 22726 solver.cpp:337] Iteration 76200, Testing net (#0)
I0820 13:17:07.350438 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88448
I0820 13:17:07.350810 22726 solver.cpp:404]     Test net output #1: loss = 0.385264 (* 1 = 0.385264 loss)
I0820 13:17:08.680835 22726 solver.cpp:228] Iteration 76200, loss = 0.0905902
I0820 13:17:08.680877 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 13:17:08.680893 22726 solver.cpp:244]     Train net output #1: loss = 0.0905896 (* 1 = 0.0905896 loss)
I0820 13:17:08.761554 22726 sgd_solver.cpp:166] Iteration 76200, lr = 1.905
I0820 13:19:26.691099 22726 solver.cpp:337] Iteration 76300, Testing net (#0)
I0820 13:20:51.837505 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88608
I0820 13:20:51.837882 22726 solver.cpp:404]     Test net output #1: loss = 0.37673 (* 1 = 0.37673 loss)
I0820 13:20:53.167799 22726 solver.cpp:228] Iteration 76300, loss = 0.173885
I0820 13:20:53.167840 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 13:20:53.167855 22726 solver.cpp:244]     Train net output #1: loss = 0.173885 (* 1 = 0.173885 loss)
I0820 13:20:53.256880 22726 sgd_solver.cpp:166] Iteration 76300, lr = 1.9075
I0820 13:23:11.362239 22726 solver.cpp:337] Iteration 76400, Testing net (#0)
I0820 13:24:36.511334 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87292
I0820 13:24:36.511749 22726 solver.cpp:404]     Test net output #1: loss = 0.426561 (* 1 = 0.426561 loss)
I0820 13:24:37.842514 22726 solver.cpp:228] Iteration 76400, loss = 0.203817
I0820 13:24:37.842555 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 13:24:37.842569 22726 solver.cpp:244]     Train net output #1: loss = 0.203816 (* 1 = 0.203816 loss)
I0820 13:24:37.924984 22726 sgd_solver.cpp:166] Iteration 76400, lr = 1.91
I0820 13:26:55.935068 22726 solver.cpp:337] Iteration 76500, Testing net (#0)
I0820 13:28:20.846060 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87272
I0820 13:28:20.846391 22726 solver.cpp:404]     Test net output #1: loss = 0.408585 (* 1 = 0.408585 loss)
I0820 13:28:22.176949 22726 solver.cpp:228] Iteration 76500, loss = 0.144184
I0820 13:28:22.176990 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 13:28:22.177011 22726 solver.cpp:244]     Train net output #1: loss = 0.144184 (* 1 = 0.144184 loss)
I0820 13:28:22.257505 22726 sgd_solver.cpp:166] Iteration 76500, lr = 1.9125
I0820 13:30:40.172514 22726 solver.cpp:337] Iteration 76600, Testing net (#0)
I0820 13:32:05.253355 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87536
I0820 13:32:05.253713 22726 solver.cpp:404]     Test net output #1: loss = 0.409231 (* 1 = 0.409231 loss)
I0820 13:32:06.583416 22726 solver.cpp:228] Iteration 76600, loss = 0.230276
I0820 13:32:06.583458 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 13:32:06.583473 22726 solver.cpp:244]     Train net output #1: loss = 0.230276 (* 1 = 0.230276 loss)
I0820 13:32:06.665987 22726 sgd_solver.cpp:166] Iteration 76600, lr = 1.915
I0820 13:34:24.560045 22726 solver.cpp:337] Iteration 76700, Testing net (#0)
I0820 13:35:49.630429 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87988
I0820 13:35:49.630720 22726 solver.cpp:404]     Test net output #1: loss = 0.396744 (* 1 = 0.396744 loss)
I0820 13:35:50.960469 22726 solver.cpp:228] Iteration 76700, loss = 0.189339
I0820 13:35:50.960510 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 13:35:50.960526 22726 solver.cpp:244]     Train net output #1: loss = 0.189339 (* 1 = 0.189339 loss)
I0820 13:35:51.045434 22726 sgd_solver.cpp:166] Iteration 76700, lr = 1.9175
I0820 13:38:09.004689 22726 solver.cpp:337] Iteration 76800, Testing net (#0)
I0820 13:39:34.119557 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87276
I0820 13:39:34.119894 22726 solver.cpp:404]     Test net output #1: loss = 0.431531 (* 1 = 0.431531 loss)
I0820 13:39:35.449302 22726 solver.cpp:228] Iteration 76800, loss = 0.136495
I0820 13:39:35.449345 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 13:39:35.449362 22726 solver.cpp:244]     Train net output #1: loss = 0.136494 (* 1 = 0.136494 loss)
I0820 13:39:35.532024 22726 sgd_solver.cpp:166] Iteration 76800, lr = 1.92
I0820 13:41:53.430372 22726 solver.cpp:337] Iteration 76900, Testing net (#0)
I0820 13:43:18.222316 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88464
I0820 13:43:18.222642 22726 solver.cpp:404]     Test net output #1: loss = 0.380116 (* 1 = 0.380116 loss)
I0820 13:43:19.552345 22726 solver.cpp:228] Iteration 76900, loss = 0.133879
I0820 13:43:19.552388 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 13:43:19.552403 22726 solver.cpp:244]     Train net output #1: loss = 0.133878 (* 1 = 0.133878 loss)
I0820 13:43:19.636019 22726 sgd_solver.cpp:166] Iteration 76900, lr = 1.9225
I0820 13:45:37.563534 22726 solver.cpp:337] Iteration 77000, Testing net (#0)
I0820 13:47:02.413808 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87668
I0820 13:47:02.414091 22726 solver.cpp:404]     Test net output #1: loss = 0.39802 (* 1 = 0.39802 loss)
I0820 13:47:03.743608 22726 solver.cpp:228] Iteration 77000, loss = 0.245751
I0820 13:47:03.743649 22726 solver.cpp:244]     Train net output #0: accuracy = 0.928
I0820 13:47:03.743662 22726 solver.cpp:244]     Train net output #1: loss = 0.24575 (* 1 = 0.24575 loss)
I0820 13:47:03.831125 22726 sgd_solver.cpp:166] Iteration 77000, lr = 1.925
I0820 13:49:21.787550 22726 solver.cpp:337] Iteration 77100, Testing net (#0)
I0820 13:50:46.807502 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87932
I0820 13:50:46.807883 22726 solver.cpp:404]     Test net output #1: loss = 0.410063 (* 1 = 0.410063 loss)
I0820 13:50:48.138108 22726 solver.cpp:228] Iteration 77100, loss = 0.153369
I0820 13:50:48.138149 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 13:50:48.138164 22726 solver.cpp:244]     Train net output #1: loss = 0.153368 (* 1 = 0.153368 loss)
I0820 13:50:48.219696 22726 sgd_solver.cpp:166] Iteration 77100, lr = 1.9275
I0820 13:53:06.418627 22726 solver.cpp:337] Iteration 77200, Testing net (#0)
I0820 13:54:31.532109 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88556
I0820 13:54:31.532407 22726 solver.cpp:404]     Test net output #1: loss = 0.394801 (* 1 = 0.394801 loss)
I0820 13:54:32.862540 22726 solver.cpp:228] Iteration 77200, loss = 0.0961737
I0820 13:54:32.862581 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 13:54:32.862596 22726 solver.cpp:244]     Train net output #1: loss = 0.096173 (* 1 = 0.096173 loss)
I0820 13:54:32.944257 22726 sgd_solver.cpp:166] Iteration 77200, lr = 1.93
I0820 13:56:50.903728 22726 solver.cpp:337] Iteration 77300, Testing net (#0)
I0820 13:58:15.670276 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87784
I0820 13:58:15.670588 22726 solver.cpp:404]     Test net output #1: loss = 0.412729 (* 1 = 0.412729 loss)
I0820 13:58:17.000195 22726 solver.cpp:228] Iteration 77300, loss = 0.135441
I0820 13:58:17.000237 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 13:58:17.000253 22726 solver.cpp:244]     Train net output #1: loss = 0.135441 (* 1 = 0.135441 loss)
I0820 13:58:17.079990 22726 sgd_solver.cpp:166] Iteration 77300, lr = 1.9325
I0820 14:00:35.096531 22726 solver.cpp:337] Iteration 77400, Testing net (#0)
I0820 14:02:00.120770 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87828
I0820 14:02:00.121101 22726 solver.cpp:404]     Test net output #1: loss = 0.397102 (* 1 = 0.397102 loss)
I0820 14:02:01.450671 22726 solver.cpp:228] Iteration 77400, loss = 0.192876
I0820 14:02:01.450716 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 14:02:01.450731 22726 solver.cpp:244]     Train net output #1: loss = 0.192876 (* 1 = 0.192876 loss)
I0820 14:02:01.539140 22726 sgd_solver.cpp:166] Iteration 77400, lr = 1.935
I0820 14:04:19.499665 22726 solver.cpp:337] Iteration 77500, Testing net (#0)
I0820 14:05:44.366962 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88508
I0820 14:05:44.367285 22726 solver.cpp:404]     Test net output #1: loss = 0.375663 (* 1 = 0.375663 loss)
I0820 14:05:45.697445 22726 solver.cpp:228] Iteration 77500, loss = 0.0958344
I0820 14:05:45.697486 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 14:05:45.697502 22726 solver.cpp:244]     Train net output #1: loss = 0.0958337 (* 1 = 0.0958337 loss)
I0820 14:05:45.778276 22726 sgd_solver.cpp:166] Iteration 77500, lr = 1.9375
I0820 14:08:03.847447 22726 solver.cpp:337] Iteration 77600, Testing net (#0)
I0820 14:09:28.955492 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88416
I0820 14:09:28.955831 22726 solver.cpp:404]     Test net output #1: loss = 0.374539 (* 1 = 0.374539 loss)
I0820 14:09:30.285182 22726 solver.cpp:228] Iteration 77600, loss = 0.104719
I0820 14:09:30.285223 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 14:09:30.285238 22726 solver.cpp:244]     Train net output #1: loss = 0.104718 (* 1 = 0.104718 loss)
I0820 14:09:30.365470 22726 sgd_solver.cpp:166] Iteration 77600, lr = 1.94
I0820 14:11:48.365609 22726 solver.cpp:337] Iteration 77700, Testing net (#0)
I0820 14:13:13.407794 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8746
I0820 14:13:13.408176 22726 solver.cpp:404]     Test net output #1: loss = 0.415667 (* 1 = 0.415667 loss)
I0820 14:13:14.738032 22726 solver.cpp:228] Iteration 77700, loss = 0.146508
I0820 14:13:14.738075 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 14:13:14.738090 22726 solver.cpp:244]     Train net output #1: loss = 0.146507 (* 1 = 0.146507 loss)
I0820 14:13:14.818399 22726 sgd_solver.cpp:166] Iteration 77700, lr = 1.9425
I0820 14:15:32.785533 22726 solver.cpp:337] Iteration 77800, Testing net (#0)
I0820 14:16:57.630792 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8794
I0820 14:16:57.631098 22726 solver.cpp:404]     Test net output #1: loss = 0.40116 (* 1 = 0.40116 loss)
I0820 14:16:58.960631 22726 solver.cpp:228] Iteration 77800, loss = 0.105144
I0820 14:16:58.960674 22726 solver.cpp:244]     Train net output #0: accuracy = 0.968
I0820 14:16:58.960688 22726 solver.cpp:244]     Train net output #1: loss = 0.105143 (* 1 = 0.105143 loss)
I0820 14:16:59.041939 22726 sgd_solver.cpp:166] Iteration 77800, lr = 1.945
I0820 14:19:16.984874 22726 solver.cpp:337] Iteration 77900, Testing net (#0)
I0820 14:20:41.822753 22726 solver.cpp:404]     Test net output #0: accuracy = 0.86888
I0820 14:20:41.823083 22726 solver.cpp:404]     Test net output #1: loss = 0.438538 (* 1 = 0.438538 loss)
I0820 14:20:43.152793 22726 solver.cpp:228] Iteration 77900, loss = 0.163665
I0820 14:20:43.152835 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 14:20:43.152850 22726 solver.cpp:244]     Train net output #1: loss = 0.163664 (* 1 = 0.163664 loss)
I0820 14:20:43.238137 22726 sgd_solver.cpp:166] Iteration 77900, lr = 1.9475
I0820 14:23:01.229079 22726 solver.cpp:337] Iteration 78000, Testing net (#0)
I0820 14:24:26.024283 22726 solver.cpp:404]     Test net output #0: accuracy = 0.8802
I0820 14:24:26.024552 22726 solver.cpp:404]     Test net output #1: loss = 0.410094 (* 1 = 0.410094 loss)
I0820 14:24:27.353356 22726 solver.cpp:228] Iteration 78000, loss = 0.221017
I0820 14:24:27.353399 22726 solver.cpp:244]     Train net output #0: accuracy = 0.912
I0820 14:24:27.353415 22726 solver.cpp:244]     Train net output #1: loss = 0.221016 (* 1 = 0.221016 loss)
I0820 14:24:27.432350 22726 sgd_solver.cpp:166] Iteration 78000, lr = 1.95
I0820 14:26:45.271493 22726 solver.cpp:337] Iteration 78100, Testing net (#0)
I0820 14:28:10.316627 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88492
I0820 14:28:10.317055 22726 solver.cpp:404]     Test net output #1: loss = 0.369684 (* 1 = 0.369684 loss)
I0820 14:28:11.648133 22726 solver.cpp:228] Iteration 78100, loss = 0.183313
I0820 14:28:11.648175 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 14:28:11.648190 22726 solver.cpp:244]     Train net output #1: loss = 0.183313 (* 1 = 0.183313 loss)
I0820 14:28:11.733726 22726 sgd_solver.cpp:166] Iteration 78100, lr = 1.9525
I0820 14:30:29.611793 22726 solver.cpp:337] Iteration 78200, Testing net (#0)
I0820 14:31:54.591418 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88228
I0820 14:31:54.591733 22726 solver.cpp:404]     Test net output #1: loss = 0.392198 (* 1 = 0.392198 loss)
I0820 14:31:55.922189 22726 solver.cpp:228] Iteration 78200, loss = 0.144744
I0820 14:31:55.922232 22726 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0820 14:31:55.922247 22726 solver.cpp:244]     Train net output #1: loss = 0.144743 (* 1 = 0.144743 loss)
I0820 14:31:56.006717 22726 sgd_solver.cpp:166] Iteration 78200, lr = 1.955
I0820 14:34:13.982762 22726 solver.cpp:337] Iteration 78300, Testing net (#0)
I0820 14:35:39.074765 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87696
I0820 14:35:39.075067 22726 solver.cpp:404]     Test net output #1: loss = 0.413357 (* 1 = 0.413357 loss)
I0820 14:35:40.404901 22726 solver.cpp:228] Iteration 78300, loss = 0.206835
I0820 14:35:40.404948 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 14:35:40.404965 22726 solver.cpp:244]     Train net output #1: loss = 0.206835 (* 1 = 0.206835 loss)
I0820 14:35:40.487354 22726 sgd_solver.cpp:166] Iteration 78300, lr = 1.9575
I0820 14:37:58.528717 22726 solver.cpp:337] Iteration 78400, Testing net (#0)
I0820 14:39:23.593358 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88504
I0820 14:39:23.593660 22726 solver.cpp:404]     Test net output #1: loss = 0.388896 (* 1 = 0.388896 loss)
I0820 14:39:24.923424 22726 solver.cpp:228] Iteration 78400, loss = 0.114951
I0820 14:39:24.923467 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 14:39:24.923483 22726 solver.cpp:244]     Train net output #1: loss = 0.11495 (* 1 = 0.11495 loss)
I0820 14:39:25.010965 22726 sgd_solver.cpp:166] Iteration 78400, lr = 1.96
I0820 14:41:42.990394 22726 solver.cpp:337] Iteration 78500, Testing net (#0)
I0820 14:43:08.141666 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87592
I0820 14:43:08.142048 22726 solver.cpp:404]     Test net output #1: loss = 0.407938 (* 1 = 0.407938 loss)
I0820 14:43:09.472627 22726 solver.cpp:228] Iteration 78500, loss = 0.205523
I0820 14:43:09.472674 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 14:43:09.472697 22726 solver.cpp:244]     Train net output #1: loss = 0.205523 (* 1 = 0.205523 loss)
I0820 14:43:09.557405 22726 sgd_solver.cpp:166] Iteration 78500, lr = 1.9625
I0820 14:45:27.553800 22726 solver.cpp:337] Iteration 78600, Testing net (#0)
I0820 14:46:52.682548 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87688
I0820 14:46:52.682888 22726 solver.cpp:404]     Test net output #1: loss = 0.391885 (* 1 = 0.391885 loss)
I0820 14:46:54.015544 22726 solver.cpp:228] Iteration 78600, loss = 0.236874
I0820 14:46:54.015592 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 14:46:54.015615 22726 solver.cpp:244]     Train net output #1: loss = 0.236873 (* 1 = 0.236873 loss)
I0820 14:46:54.096665 22726 sgd_solver.cpp:166] Iteration 78600, lr = 1.965
I0820 14:49:12.108933 22726 solver.cpp:337] Iteration 78700, Testing net (#0)
I0820 14:50:37.069764 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87992
I0820 14:50:37.070111 22726 solver.cpp:404]     Test net output #1: loss = 0.394966 (* 1 = 0.394966 loss)
I0820 14:50:38.404484 22726 solver.cpp:228] Iteration 78700, loss = 0.164385
I0820 14:50:38.404531 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 14:50:38.404552 22726 solver.cpp:244]     Train net output #1: loss = 0.164384 (* 1 = 0.164384 loss)
I0820 14:50:38.488199 22726 sgd_solver.cpp:166] Iteration 78700, lr = 1.9675
I0820 14:52:56.671677 22726 solver.cpp:337] Iteration 78800, Testing net (#0)
I0820 14:54:21.709843 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87624
I0820 14:54:21.710211 22726 solver.cpp:404]     Test net output #1: loss = 0.411141 (* 1 = 0.411141 loss)
I0820 14:54:23.043853 22726 solver.cpp:228] Iteration 78800, loss = 0.242659
I0820 14:54:23.043895 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 14:54:23.043910 22726 solver.cpp:244]     Train net output #1: loss = 0.242659 (* 1 = 0.242659 loss)
I0820 14:54:23.123684 22726 sgd_solver.cpp:166] Iteration 78800, lr = 1.97
I0820 14:56:41.109457 22726 solver.cpp:337] Iteration 78900, Testing net (#0)
I0820 14:58:05.920125 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88712
I0820 14:58:05.920460 22726 solver.cpp:404]     Test net output #1: loss = 0.373551 (* 1 = 0.373551 loss)
I0820 14:58:07.254307 22726 solver.cpp:228] Iteration 78900, loss = 0.102107
I0820 14:58:07.254349 22726 solver.cpp:244]     Train net output #0: accuracy = 0.976
I0820 14:58:07.254365 22726 solver.cpp:244]     Train net output #1: loss = 0.102107 (* 1 = 0.102107 loss)
I0820 14:58:07.336570 22726 sgd_solver.cpp:166] Iteration 78900, lr = 1.9725
I0820 15:00:25.357919 22726 solver.cpp:337] Iteration 79000, Testing net (#0)
I0820 15:01:50.287083 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88412
I0820 15:01:50.287427 22726 solver.cpp:404]     Test net output #1: loss = 0.379112 (* 1 = 0.379112 loss)
I0820 15:01:51.620398 22726 solver.cpp:228] Iteration 79000, loss = 0.172804
I0820 15:01:51.620441 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 15:01:51.620457 22726 solver.cpp:244]     Train net output #1: loss = 0.172804 (* 1 = 0.172804 loss)
I0820 15:01:51.699148 22726 sgd_solver.cpp:166] Iteration 79000, lr = 1.975
I0820 15:04:09.659492 22726 solver.cpp:337] Iteration 79100, Testing net (#0)
I0820 15:05:34.476621 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87652
I0820 15:05:34.476960 22726 solver.cpp:404]     Test net output #1: loss = 0.402809 (* 1 = 0.402809 loss)
I0820 15:05:35.810365 22726 solver.cpp:228] Iteration 79100, loss = 0.203202
I0820 15:05:35.810408 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 15:05:35.810425 22726 solver.cpp:244]     Train net output #1: loss = 0.203202 (* 1 = 0.203202 loss)
I0820 15:05:35.893276 22726 sgd_solver.cpp:166] Iteration 79100, lr = 1.9775
I0820 15:07:53.833035 22726 solver.cpp:337] Iteration 79200, Testing net (#0)
I0820 15:09:18.758970 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87944
I0820 15:09:18.759366 22726 solver.cpp:404]     Test net output #1: loss = 0.385764 (* 1 = 0.385764 loss)
I0820 15:09:20.093422 22726 solver.cpp:228] Iteration 79200, loss = 0.202657
I0820 15:09:20.093463 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 15:09:20.093479 22726 solver.cpp:244]     Train net output #1: loss = 0.202657 (* 1 = 0.202657 loss)
I0820 15:09:20.174994 22726 sgd_solver.cpp:166] Iteration 79200, lr = 1.98
I0820 15:11:38.123219 22726 solver.cpp:337] Iteration 79300, Testing net (#0)
I0820 15:13:03.287431 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87972
I0820 15:13:03.287798 22726 solver.cpp:404]     Test net output #1: loss = 0.396796 (* 1 = 0.396796 loss)
I0820 15:13:04.620286 22726 solver.cpp:228] Iteration 79300, loss = 0.151116
I0820 15:13:04.620326 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 15:13:04.620342 22726 solver.cpp:244]     Train net output #1: loss = 0.151116 (* 1 = 0.151116 loss)
I0820 15:13:04.698114 22726 sgd_solver.cpp:166] Iteration 79300, lr = 1.9825
I0820 15:15:22.628248 22726 solver.cpp:337] Iteration 79400, Testing net (#0)
I0820 15:16:47.792357 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87148
I0820 15:16:47.792734 22726 solver.cpp:404]     Test net output #1: loss = 0.444745 (* 1 = 0.444745 loss)
I0820 15:16:49.126015 22726 solver.cpp:228] Iteration 79400, loss = 0.175507
I0820 15:16:49.126052 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 15:16:49.126068 22726 solver.cpp:244]     Train net output #1: loss = 0.175507 (* 1 = 0.175507 loss)
I0820 15:16:49.207145 22726 sgd_solver.cpp:166] Iteration 79400, lr = 1.985
I0820 15:19:07.168638 22726 solver.cpp:337] Iteration 79500, Testing net (#0)
I0820 15:20:32.325142 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87116
I0820 15:20:32.325515 22726 solver.cpp:404]     Test net output #1: loss = 0.417953 (* 1 = 0.417953 loss)
I0820 15:20:33.659170 22726 solver.cpp:228] Iteration 79500, loss = 0.270332
I0820 15:20:33.659212 22726 solver.cpp:244]     Train net output #0: accuracy = 0.904
I0820 15:20:33.659229 22726 solver.cpp:244]     Train net output #1: loss = 0.270332 (* 1 = 0.270332 loss)
I0820 15:20:33.733561 22726 sgd_solver.cpp:166] Iteration 79500, lr = 1.9875
I0820 15:22:51.736801 22726 solver.cpp:337] Iteration 79600, Testing net (#0)
I0820 15:24:16.900254 22726 solver.cpp:404]     Test net output #0: accuracy = 0.881201
I0820 15:24:16.900660 22726 solver.cpp:404]     Test net output #1: loss = 0.397514 (* 1 = 0.397514 loss)
I0820 15:24:18.234474 22726 solver.cpp:228] Iteration 79600, loss = 0.142845
I0820 15:24:18.234518 22726 solver.cpp:244]     Train net output #0: accuracy = 0.952
I0820 15:24:18.234534 22726 solver.cpp:244]     Train net output #1: loss = 0.142845 (* 1 = 0.142845 loss)
I0820 15:24:18.310619 22726 sgd_solver.cpp:166] Iteration 79600, lr = 1.99
I0820 15:26:36.373544 22726 solver.cpp:337] Iteration 79700, Testing net (#0)
I0820 15:28:01.548301 22726 solver.cpp:404]     Test net output #0: accuracy = 0.87988
I0820 15:28:01.548703 22726 solver.cpp:404]     Test net output #1: loss = 0.394269 (* 1 = 0.394269 loss)
I0820 15:28:02.881055 22726 solver.cpp:228] Iteration 79700, loss = 0.164867
I0820 15:28:02.881094 22726 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0820 15:28:02.881110 22726 solver.cpp:244]     Train net output #1: loss = 0.164867 (* 1 = 0.164867 loss)
I0820 15:28:02.964377 22726 sgd_solver.cpp:166] Iteration 79700, lr = 1.9925
I0820 15:30:20.995602 22726 solver.cpp:337] Iteration 79800, Testing net (#0)
I0820 15:31:46.186054 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88016
I0820 15:31:46.186437 22726 solver.cpp:404]     Test net output #1: loss = 0.397034 (* 1 = 0.397034 loss)
I0820 15:31:47.520376 22726 solver.cpp:228] Iteration 79800, loss = 0.218511
I0820 15:31:47.520417 22726 solver.cpp:244]     Train net output #0: accuracy = 0.944
I0820 15:31:47.520432 22726 solver.cpp:244]     Train net output #1: loss = 0.218511 (* 1 = 0.218511 loss)
I0820 15:31:47.605747 22726 sgd_solver.cpp:166] Iteration 79800, lr = 1.995
I0820 15:34:05.613067 22726 solver.cpp:337] Iteration 79900, Testing net (#0)
I0820 15:35:30.785610 22726 solver.cpp:404]     Test net output #0: accuracy = 0.88268
I0820 15:35:30.786031 22726 solver.cpp:404]     Test net output #1: loss = 0.373418 (* 1 = 0.373418 loss)
I0820 15:35:32.120077 22726 solver.cpp:228] Iteration 79900, loss = 0.182946
I0820 15:35:32.120120 22726 solver.cpp:244]     Train net output #0: accuracy = 0.936
I0820 15:35:32.120136 22726 solver.cpp:244]     Train net output #1: loss = 0.182946 (* 1 = 0.182946 loss)
I0820 15:35:32.199110 22726 sgd_solver.cpp:166] Iteration 79900, lr = 1.9975
I0820 15:37:50.248652 22726 solver.cpp:454] Snapshotting to binary proto file examples/sc/snapshots/range2SS80kRes56LR_iter_80000.caffemodel
I0820 15:37:50.698093 22726 sgd_solver.cpp:333] Snapshotting solver state to binary proto file examples/sc/snapshots/range2SS80kRes56LR_iter_80000.solverstate
I0820 15:37:51.153499 22726 solver.cpp:317] Iteration 80000, loss = 0.150606
I0820 15:37:51.153550 22726 solver.cpp:337] Iteration 80000, Testing net (#0)
I0820 15:39:16.310055 22726 solver.cpp:404]     Test net output #0: accuracy = 0.877321
I0820 15:39:16.310467 22726 solver.cpp:404]     Test net output #1: loss = 0.406934 (* 1 = 0.406934 loss)
I0820 15:39:16.310478 22726 solver.cpp:322] Optimization Done.
I0820 15:39:21.727124 22726 caffe.cpp:254] Optimization Done.
